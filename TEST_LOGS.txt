========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 2028.06s (0:33:48) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_Boxes[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
        transpiled_boxes = transpiled_kornia.geometry.boxes.Boxes.from_tensor(*transpiled_args, mode="xyxy")
        _check_boxes_same(torch_boxes, transpiled_boxes)
    
        # test .compute_area
        torch_area = torch_boxes.compute_area()
        transpiled_area = transpiled_boxes.compute_area()
        _to_numpy_and_allclose(torch_area, transpiled_area)
    
        # test .get_boxes_shape
        torch_heights, torch_widths = torch_boxes.get_boxes_shape()
        transpiled_heights, transpiled_widths = transpiled_boxes.get_boxes_shape()
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .merge
        torch_x = torch.as_tensor([[6, 6, 10, 10], [6, 6, 10, 10]])
        transpiled_x = _nest_torch_tensor_to_new_framework(torch_x, target_framework)
        merge_boxes = kornia.geometry.boxes.Boxes.from_tensor(torch_x, mode="xyxy")
        transpiled_merge_boxes = transpiled_kornia.geometry.boxes.Boxes.from_tensor(transpiled_x, mode="xyxy")
        torch_merged_boxes = torch_boxes.merge(merge_boxes)
        transpiled_merged_boxes = transpiled_boxes.merge(transpiled_merge_boxes)
        _check_boxes_same(torch_merged_boxes, transpiled_merged_boxes)
    
        # test .to_mask
        height, width = 10, 10
        torch_mask = torch_boxes.to_mask(height, width)
        transpiled_mask = transpiled_boxes.to_mask(height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0....., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(2, 10, 10), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0....,
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
__________________________________________________________________________________ test_Boxes3D[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
        transpiled_boxes3d = transpiled_kornia.geometry.boxes.Boxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
        _check_boxes_same(torch_boxes3d, transpiled_boxes3d)
    
        # test .get_boxes_shape
        torch_depths, torch_heights, torch_widths = torch_boxes3d.get_boxes_shape()
        transpiled_depths, transpiled_heights, transpiled_widths = transpiled_boxes3d.get_boxes_shape()
        _to_numpy_and_allclose(torch_depths, transpiled_depths)
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .to_mask
        depth, height, width = 10, 10, 10
        torch_mask = torch_boxes3d.to_mask(depth, height, width)
        transpiled_mask = transpiled_boxes3d.to_mask(depth, height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0... [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
transpiled_x = <tf.Tensor: shape=(2, 10, 10, 10), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0.,...., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
y = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
==================================================================================== 2 failed in 246.85s (0:04:06) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py F                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_Quaternion[jax-s2s-False] ____________________________________________________________________________________

args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f941c79ac20>
array_like = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), pattern = '_bknd_|_bknd|_frnt_|_frnt', fn_name = 'data', new_fn = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
            return fn(*args, **kwargs)
        else:
            pattern = "_bknd_|_bknd|_frnt_|_frnt"
            fn_name = extract_function_name(re.sub(pattern, "", fn.__name__))
            try:
                new_fn = getattr(array_like, fn_name)
                if not callable(new_fn):
                    return new_fn
>               return new_fn(*args[1:], **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), args = (), kwargs = {}

    def __call__(self, *args, **kwargs) -> tp.Any:
>     return self.value(*args, **kwargs)  # type: ignore
E     TypeError: 'jaxlib.xla_extension.ArrayImpl' object is not callable

/opt/fw/jax/flax/nnx/variablelib.py:435: TypeError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py", line 208, in wrapper
    return new_fn(*args[1:], **kwargs)
  File "/opt/fw/jax/flax/nnx/variablelib.py", line 435, in __call__
    return self.value(*args, **kwargs)  # type: ignore
TypeError: 'jaxlib.xla_extension.ArrayImpl' object is not callable

During handling of the above exception, another exception occurred:

TypeError: float() argument must be a string or a real number, not 'jax_Quaternion'

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Quaternion(target_framework, mode, backend_compile):
        print("kornia.geometry.quaternion.Quaternion")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledQuaternion = ivy.transpile(Quaternion, source="torch", target=target_framework)
    
        # test Quaternion.identity
    
        torch_q = Quaternion.identity(batch_size=4)
        transpiled_q = TranspiledQuaternion.identity(batch_size=4)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__add__
    
        torch_q1 = Quaternion.identity()
        torch_q2 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q3 = torch_q1 + torch_q2
        transpiled_q1 = TranspiledQuaternion.identity()
        transpiled_q2 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
>       transpiled_q3 = transpiled_q1 + transpiled_q2

kornia/geometry/test_quaternion.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([1., 0., 0., 0.], dtype=float32)
), right = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    def __add__(self, right):
        from ..core.check import jax_KORNIA_CHECK_TYPE
        from ...ivy.functional.frontends.torch.tensor import jax_data_frnt_
    
        jax_KORNIA_CHECK_TYPE(right, jax_Quaternion)
>       return jax_Quaternion(self.data + jax_data_frnt_(right))

ivy_transpiled_outputs/jax_outputs/kornia/geometry/quaternion.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f941c79ac20>
array_like = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), pattern = '_bknd_|_bknd|_frnt_|_frnt', fn_name = 'data', new_fn = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
            return fn(*args, **kwargs)
        else:
            pattern = "_bknd_|_bknd|_frnt_|_frnt"
            fn_name = extract_function_name(re.sub(pattern, "", fn.__name__))
            try:
                new_fn = getattr(array_like, fn_name)
                if not callable(new_fn):
                    return new_fn
                return new_fn(*args[1:], **kwargs)
            except Exception:
>               return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @jax_handle_methods
    def jax_data_frnt_(tensor):
        from .creation_ops import jax_tensor_frnt
        from ...backends.jax.gradients import jax_stop_gradient
    
>       return jax_tensor_frnt(jax_stop_gradient(tensor, preserve_type=False))

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)], kwargs = {'preserve_type': False}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f941c79ac20>
jax_set_item = <function jax_set_item at 0x7f941c5b9e10>, jax_asarray = <function jax_asarray at 0x7f941c79b520>, jax_get_item = <function jax_get_item at 0x7f941c5b9c60>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('preserve_type', <Parameter "preserve_type: bool = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'preserve_type', 'out'], annotations = [<class 'jax.Array'>, <class 'bool'>, typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
>                       args = jax_set_item(args, i, jax_asarray(arg, device=device))

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)], kwargs = {'device': CpuDevice(id=0)}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f941c79ac20>
jax_set_item = <function jax_set_item at 0x7f941c5b9e10>, jax_asarray = <function jax_asarray at 0x7f941c79b520>, jax_get_item = <function jax_get_item at 0x7f941c5b9c60>, num_args = 1
type_hints = mappingproxy(OrderedDict([('obj', <Parameter "obj: Union[jax.Array, bool, int, float, tuple, ivy_transpiled_outputs.ja...', <Parameter "device: jaxlib.xla_extension.Device = None">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['obj', 'copy', 'dtype', 'device', 'out']
annotations = [typing.Union[jax.Array, bool, int, float, tuple, ivy_transpiled_outputs.jax_outputs.ivy.functional.ivy.creation.jax_N...typing.Optional[bool], typing.Optional[numpy.dtype], <class 'jaxlib.xla_extension.Device'>, typing.Optional[jax.Array]]
device = None, i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = None, args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {'device': CpuDevice(id=0)}, jax_default_dtype_bknd = <function jax_default_dtype_bknd at 0x7f941c79a170>
jax_to_ivy_bknd_ = <function jax_to_ivy_bknd_ at 0x7f941c756560>, new_arg = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)
new_args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),)

    @functools.wraps(fn)
    def _asarray_to_native_arrays_and_back_wrapper(*args, dtype=None, **kwargs):
        from .data_type import jax_default_dtype_bknd
        from ...data_classes.array.conversions import jax_to_ivy_bknd_
    
        new_arg = args[0]
        new_args = (new_arg,) + args[1:]
        if dtype is not None:
            dtype = jax_default_dtype_bknd(dtype=dtype, as_native=True)
>       return jax_to_ivy_bknd_(fn(*new_args, dtype=dtype, **kwargs))

ivy_transpiled_outputs/jax_outputs/ivy/functional/ivy/creation.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = <class 'jax.numpy.float32'>, args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {'device': CpuDevice(id=0)}
jax_default_float_dtype_bknd = <function jax_default_float_dtype_bknd at 0x7f941c79a050>, jax_as_native_dtype = <function jax_as_native_dtype at 0x7f941c5b8310>
jax_exists_bknd = <function jax_exists_bknd at 0x7f941c79ad40>, jax_nested_map_bknd = <function jax_nested_map_bknd at 0x7f941c79b130>
jax_promote_types_bknd = <function jax_promote_types_bknd at 0x7f941c79a680>, arr = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype_list = [<class 'jax.numpy.float32'>]

    @functools.wraps(fn)
    def _asarray_infer_dtype_wrapper(*args, dtype=None, **kwargs):
        from .data_type import jax_default_float_dtype_bknd
        from ..backends.jax.data_type import jax_as_native_dtype
        from .general import jax_exists_bknd
        from .nest import jax_nested_map_bknd
        from .data_type import jax_promote_types_bknd
    
        def _infer_dtype(obj):
            from .data_type import jax_default_dtype_bknd
    
            if isinstance(obj, tuple):
                obj = list(obj)
            if hasattr(obj, "dtype"):
                return obj.dtype.name if isinstance(obj, np.ndarray) else obj.dtype
            else:
                return jax_default_dtype_bknd(item=obj)
    
        if not jax_exists_bknd(dtype):
            arr = args[0]
            dtype_list = [
                jax_nested_map_bknd(lambda x: _infer_dtype(x), arr, shallow=False)
            ]
            dtype_list = jax__flatten_nest_bknd(dtype_list)
            dtype_list = list(set(dtype_list))
            if len(dtype_list) != 0:
                dtype = dtype_list[0]
                for dt in dtype_list[1:]:
                    dtype = jax_promote_types_bknd(dtype, dt)
            else:
                dtype = jax_default_float_dtype_bknd()
            dtype = jax_as_native_dtype(dtype)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/functional/ivy/creation.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @jax_handle_array_like_without_promotion
    @jax__asarray_to_native_arrays_and_back_bknd
    @jax__asarray_infer_dtype_bknd
    def jax_asarray(
        obj: Union[
            jax.Array,
            bool,
            int,
            float,
            tuple,
            jax_NestedSequence_bknd,
            SupportsBufferProtocol,
            np.ndarray,
        ],
        /,
        *,
        copy: Optional[bool] = None,
        dtype: Optional[jax.numpy.dtype] = None,
        device: jaxlib.xla_extension.Device = None,
        out: Optional[jax.Array] = None,
    ):
        from ...ivy.device import jax_dev_bknd
    
>       ret = jax.numpy.asarray(obj, dtype=dtype)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/creation.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype = dtype('float32'), order = None

    def asarray(a: Any, dtype: DTypeLike | None = None, order: str | None = None,
                *, copy: bool | None = None,
                device: xc.Device | Sharding | None = None) -> Array:
      """Convert an object to a JAX array.
    
      JAX implementation of :func:`numpy.asarray`.
    
      Args:
        a: an object that is convertible to an array. This includes JAX
          arrays, NumPy arrays, Python scalars, Python collections like lists
          and tuples, objects with an ``__array__`` method, and objects
          supporting the Python buffer protocol.
        dtype: optionally specify the dtype of the output array. If not
          specified it will be inferred from the input.
        order: not implemented in JAX
        copy: optional boolean specifying the copy mode. If True, then always
          return a copy. If False, then error if a copy is necessary. Default is
          None, which will only copy when necessary.
        device: optional :class:`~jax.Device` or :class:`~jax.sharding.Sharding`
          to which the created array will be committed.
    
      Returns:
        A JAX array constructed from the input.
    
      See also:
        - :func:`jax.numpy.array`: like `asarray`, but defaults to `copy=True`.
        - :func:`jax.numpy.from_dlpack`: construct a JAX array from an object
          that implements the dlpack interface.
        - :func:`jax.numpy.frombuffer`: construct a JAX array from an object
          that implements the buffer interface.
    
      Examples:
        Constructing JAX arrays from Python scalars:
    
        >>> jnp.asarray(True)
        Array(True, dtype=bool)
        >>> jnp.asarray(42)
        Array(42, dtype=int32, weak_type=True)
        >>> jnp.asarray(3.5)
        Array(3.5, dtype=float32, weak_type=True)
        >>> jnp.asarray(1 + 1j)
        Array(1.+1.j, dtype=complex64, weak_type=True)
    
        Constructing JAX arrays from Python collections:
    
        >>> jnp.asarray([1, 2, 3])  # list of ints -> 1D array
        Array([1, 2, 3], dtype=int32)
        >>> jnp.asarray([(1, 2, 3), (4, 5, 6)])  # list of tuples of ints -> 2D array
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.asarray(range(5))
        Array([0, 1, 2, 3, 4], dtype=int32)
    
        Constructing JAX arrays from NumPy arrays:
    
        >>> jnp.asarray(np.linspace(0, 2, 5))
        Array([0. , 0.5, 1. , 1.5, 2. ], dtype=float32)
    
        Constructing a JAX array via the Python buffer interface, using Python's
        built-in :mod:`array` module.
    
        >>> from array import array
        >>> pybuffer = array('i', [2, 3, 5, 7])
        >>> jnp.asarray(pybuffer)
        Array([2, 3, 5, 7], dtype=int32)
      """
      # For copy=False, the array API specifies that we raise a ValueError if the input supports
      # the buffer protocol but a copy is required. Since array() supports the buffer protocol
      # via numpy, this is only the case when the default device is not 'cpu'
      if (copy is False and not isinstance(a, Array)
          and jax.default_backend() != 'cpu'
          and _supports_buffer_protocol(a)):
        raise ValueError(f"jnp.asarray: cannot convert object of type {type(a)} to JAX Array "
                         f"on backend={jax.default_backend()!r} with copy=False. "
                          "Consider using copy=None or copy=True instead.")
      dtypes.check_user_dtype_supported(dtype, "asarray")
      if dtype is not None:
        dtype = dtypes.canonicalize_dtype(dtype, allow_extended_dtype=True)  # type: ignore[assignment]
>     return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5592: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype = dtype('float32'), copy = False, order = None, ndmin = 0

    def array(object: Any, dtype: DTypeLike | None = None, copy: bool = True,
              order: str | None = "K", ndmin: int = 0,
              *, device: xc.Device | Sharding | None = None) -> Array:
      """Convert an object to a JAX array.
    
      JAX implementation of :func:`numpy.array`.
    
      Args:
        object: an object that is convertible to an array. This includes JAX
          arrays, NumPy arrays, Python scalars, Python collections like lists
          and tuples, objects with an ``__array__`` method, and objects
          supporting the Python buffer protocol.
        dtype: optionally specify the dtype of the output array. If not
          specified it will be inferred from the input.
        copy: specify whether to force a copy of the input. Default: True.
        order: not implemented in JAX
        ndmin: integer specifying the minimum number of dimensions in the
          output array.
        device: optional :class:`~jax.Device` or :class:`~jax.sharding.Sharding`
          to which the created array will be committed.
    
      Returns:
        A JAX array constructed from the input.
    
      See also:
        - :func:`jax.numpy.asarray`: like `array`, but by default only copies
          when necessary.
        - :func:`jax.numpy.from_dlpack`: construct a JAX array from an object
          that implements the dlpack interface.
        - :func:`jax.numpy.frombuffer`: construct a JAX array from an object
          that implements the buffer interface.
    
      Examples:
        Constructing JAX arrays from Python scalars:
    
        >>> jnp.array(True)
        Array(True, dtype=bool)
        >>> jnp.array(42)
        Array(42, dtype=int32, weak_type=True)
        >>> jnp.array(3.5)
        Array(3.5, dtype=float32, weak_type=True)
        >>> jnp.array(1 + 1j)
        Array(1.+1.j, dtype=complex64, weak_type=True)
    
        Constructing JAX arrays from Python collections:
    
        >>> jnp.array([1, 2, 3])  # list of ints -> 1D array
        Array([1, 2, 3], dtype=int32)
        >>> jnp.array([(1, 2, 3), (4, 5, 6)])  # list of tuples of ints -> 2D array
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.array(range(5))
        Array([0, 1, 2, 3, 4], dtype=int32)
    
        Constructing JAX arrays from NumPy arrays:
    
        >>> jnp.array(np.linspace(0, 2, 5))
        Array([0. , 0.5, 1. , 1.5, 2. ], dtype=float32)
    
        Constructing a JAX array via the Python buffer interface, using Python's
        built-in :mod:`array` module.
    
        >>> from array import array
        >>> pybuffer = array('i', [2, 3, 5, 7])
        >>> jnp.array(pybuffer)
        Array([2, 3, 5, 7], dtype=int32)
      """
      if order is not None and order != "K":
        raise NotImplementedError("Only implemented for order='K'")
    
      # check if the given dtype is compatible with JAX
      dtypes.check_user_dtype_supported(dtype, "array")
    
      # Here we make a judgment call: we only return a weakly-typed array when the
      # input object itself is weakly typed. That ensures asarray(x) is a no-op
      # whenever x is weak, but avoids introducing weak types with something like
      # array([1, 2, 3])
      weak_type = dtype is None and dtypes.is_weakly_typed(object)
      if (config.sharding_in_types.value and device is None and
          isinstance(object, Array)):
        sharding = object.sharding
      else:
        sharding = canonicalize_device_to_sharding(device)  # type: ignore
    
      # Use device_put to avoid a copy for ndarray inputs.
      if (not copy and isinstance(object, np.ndarray) and
          (dtype is None or dtype == object.dtype) and (ndmin <= object.ndim) and
          device is None):
        # Keep the output uncommitted.
        return jax.device_put(object)
    
      # For Python scalar literals, call coerce_to_array to catch any overflow
      # errors. We don't use dtypes.is_python_scalar because we don't want this
      # triggering for traced values. We do this here because it matters whether or
      # not dtype is None. We don't assign the result because we want the raw object
      # to be used for type inference below.
      if isinstance(object, (bool, int, float, complex)):
        _ = dtypes.coerce_to_array(object, dtype)
      elif not isinstance(object, Array):
        # Check if object supports any of the data exchange protocols
        # (except dlpack, see data-apis/array-api#301). If it does,
        # consume the object as jax array and continue (but not return) so
        # that other array() arguments get processed against the input
        # object.
        #
        # Notice that data exchange protocols define dtype in the
        # corresponding data structures and it may not be available as
        # object.dtype. So, we'll resolve the protocols here before
        # evaluating object.dtype.
        if hasattr(object, '__jax_array__'):
          object = object.__jax_array__()
        elif hasattr(object, '__cuda_array_interface__'):
          cai = object.__cuda_array_interface__
          backend = xla_bridge.get_backend("cuda")
          if cuda_plugin_extension is None:
            device_id = None
          else:
            device_id = cuda_plugin_extension.get_device_ordinal(cai["data"][0])
          object = xc._xla.cuda_array_interface_to_buffer(
              cai=cai, gpu_backend=backend, device_id=device_id)
    
      object = tree_map(lambda leaf: leaf.__jax_array__()
                        if hasattr(leaf, "__jax_array__") else leaf, object)
      leaves = tree_leaves(object, is_leaf=lambda x: x is None)
      if any(leaf is None for leaf in leaves):
        # Added Nov 16 2023
        if deprecations.is_accelerated("jax-numpy-array-none"):
          raise TypeError("None is not a valid value for jnp.array")
        warnings.warn(
          "None encountered in jnp.array(); this is currently treated as NaN. "
          "In the future this will result in an error.",
          FutureWarning, stacklevel=2)
        leaves = tree_leaves(object)
      if dtype is None:
        # Use lattice_result_type rather than result_type to avoid canonicalization.
        # Otherwise, weakly-typed inputs would have their dtypes canonicalized.
        try:
          dtype = dtypes._lattice_result_type(*leaves)[0] if leaves else dtypes.float_
        except TypeError:
          # This happens if, e.g. one of the entries is a memoryview object.
          # This is rare, so we only handle it if the normal path fails.
          leaves = [_convert_to_array_if_dtype_fails(leaf) for leaf in leaves]
          dtype = dtypes._lattice_result_type(*leaves)[0]
    
      if not weak_type:
        dtype = dtypes.canonicalize_dtype(dtype, allow_extended_dtype=True)  # type: ignore[assignment]
    
      out: ArrayLike
    
      if all(not isinstance(leaf, Array) for leaf in leaves):
        # TODO(jakevdp): falling back to numpy here fails to overflow for lists
        # containing large integers; see discussion in
        # https://github.com/jax-ml/jax/pull/6047. More correct would be to call
        # coerce_to_array on each leaf, but this may have performance implications.
>       out = np.asarray(object, dtype=dtype)
E       ValueError: setting an array element with a sequence.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5411: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.quaternion.Quaternion
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_quaternion.py::test_Quaternion[jax-s2s-False] - ValueError: setting an array element with a sequence.
===================================================================================== 1 failed in 91.82s (0:01:31) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_solve_pnp_dlt[jax-s2s-False] ___________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fdd0d938d30>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fdd0d938d30>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = Array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]], dtype=float64)
img_points = Array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]], dtype=float64)
intrinsics = Array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]], dtype=float64), weights = None, svd_eps = 0.001

    def jax_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...utils.helpers import jax__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import jax_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_inverse_frnt
        from ..conversions import jax_convert_points_to_homogeneous
        from ..linalg import jax_transform_points
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            jax_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...utils.misc import jax_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import jax_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import jax_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import jax_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = jnp.float32, jnp.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if len(jax_shape_frnt_(world_points)) != 3 or jax_shape_frnt_(world_points)[2] != 3:
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {jax_shape_frnt_(world_points)}."
            )
        if len(jax_shape_frnt_(img_points)) != 3 or jax_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {jax_shape_frnt_(img_points)}."
            )
        if len(jax_shape_frnt_(intrinsics)) != 3 or jax_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {jax_shape_frnt_(intrinsics)}."
            )
        if jax_shape_frnt_(world_points)[1] != jax_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(img_points)[0]
            or jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if jax_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {jax_shape_frnt_(world_points)[1]} points."
            )
        B, N = jax_shape_frnt_(world_points)[:2][0], jax_shape_frnt_(world_points)[:2][1]
        world_points_norm, world_transform_norm = jax__mean_isotropic_scale_normalize(
            world_points
        )
        s = jax__torch_linalg_svdvals(world_points_norm)
        if jax_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = jax_inverse_frnt(intrinsics)
        world_points_norm_h = jax_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = jax_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = jax__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = jax_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = jax_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = jax_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = jax_eye_like(4, solution)
        solution_4x4 = jax_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = jax_bmm_frnt(solution_4x4, world_transform_norm)
        solution = jax_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = jax_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = jax_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/calibration/pnp.py:217: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': Array([[0.0754885 , 0.02388222, 0.0574928 ]], dtype=float64), 'p': 2}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fdc80b9d240>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[jax-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 427.74s (0:07:07) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py s                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.06s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 5 skipped in 5.07s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py ...................                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1606.14s (0:26:46) ====================================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ........                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 481.92s (0:08:01) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py .........F...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_ScaleSpaceDetector[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.ScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature3.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[9.314592  , 6.6535854 , 3.5757189 , ..., 3.7426834 ...
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x555d069d4640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[9.314592  , 6.6535854 , 3.5757189 , ..., 3.7426834 ...
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[9.314592  , 6.6535854 , 3.5757189 , ..., 3.7426834 ...
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[9.314592  , 6.6535854 , 3.5757189 , ..., 3.7426834 ,...],
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img, mask=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...es=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF()),)
kwargs = {'img': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[9.314592  , 6.6535854 , 3.5757189 , ..., 3.7...,
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[9.314592  , 6.6535854 , 3.5757189 , ..., 3.7426834 ,...],
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>
mask = None

    def call(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[9.314592  , 6.6535854 , 3.5757189 , ..., 3.7426834 ,...],
         [6.267304  , 2.8833537 , 0.51825404, ..., 9.923604  ,
          0.7687634 , 2.6221638 ]]]], dtype=float32)>
num_feats = 500, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import (
            tensorflow_topk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from .laf import tensorflow_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
        sp, sigmas, _ = self.scale_pyr(img)
        all_responses: typing.Any = []
        all_lafs: typing.Any = []
        px_size = 0.5 if self.scale_pyr.double_image else 1.0
        for oct_idx, octave in enumerate(sp):
            sigmas_oct = tensorflow_get_item(sigmas, oct_idx)
            B, CH, L, H, W = tensorflow_size_frnt_(octave)
            if self.scale_space_response:
                oct_resp = self.resp(octave, tensorflow_view_frnt_(sigmas_oct, -1))
            else:
                oct_resp = tensorflow_view_frnt_(
                    self.resp(
                        tensorflow_reshape_frnt_(
                            tensorflow_permute_frnt_(octave, 0, 2, 1, 3, 4),
                            B * L,
                            CH,
                            H,
                            W,
                        ),
                        tensorflow_view_frnt_(sigmas_oct, -1),
                    ),
                    B,
                    L,
                    CH,
                    H,
                    W,
                )
                oct_resp = tensorflow_permute_frnt_(oct_resp, 0, 2, 1, 3, 4)
                if (
                    isinstance(
                        self.scale_pyr.extra_levels,
                        (tensorflow.Tensor, tensorflow.keras.Variable),
                    )
                    and self.scale_pyr.extra_levels % 2 != 0
                ):
                    oct_resp = oct_resp[:, :, :-1]
            if mask is not None:
                oct_mask: typing.Any = tensorflow__create_octave_mask(
                    mask, tensorflow_shape_frnt_(oct_resp)
                )
                oct_resp = oct_mask * oct_resp
            coord_max: typing.Any
            response_max: typing.Any
            coord_max, response_max = self.nms(oct_resp)
            if self.minima_are_also_good:
                coord_min, response_min = self.nms(-oct_resp)
                take_min_mask = tensorflow_to_frnt_(
                    response_min > response_max, response_max.dtype
                )
                response_max = (
                    response_min * take_min_mask + (1 - take_min_mask) * response_max
                )
                coord_max = (
                    coord_min * tensorflow_unsqueeze_frnt_(take_min_mask, 2)
                    + (1 - tensorflow_unsqueeze_frnt_(take_min_mask, 2)) * coord_max
                )
            responses_flatten = tensorflow_view_frnt_(
                response_max, tensorflow_size_frnt_(response_max, 0), -1
            )
            max_coords_flatten = tensorflow_permute_frnt_(
                tensorflow_view_frnt_(
                    coord_max, tensorflow_size_frnt_(response_max, 0), 3, -1
                ),
                0,
                2,
                1,
            )
            if tensorflow_size_frnt_(responses_flatten, 1) > num_feats:
                resp_flat_best, idxs = tensorflow_topk_frnt(
                    responses_flatten, k=num_feats, dim=1
                )
                max_coords_best = tensorflow_gather_frnt(
                    max_coords_flatten,
                    1,
                    tensorflow_repeat_frnt_(
                        tensorflow_unsqueeze_frnt_(idxs, -1), 1, 1, 3
                    ),
                )
            else:
                resp_flat_best = responses_flatten
                max_coords_best = max_coords_flatten
            B, N = tensorflow_size_frnt_(resp_flat_best)
            if isinstance(
                self.scale_pyr.n_levels, (tensorflow.Tensor, tensorflow.keras.Variable)
            ):
                num_levels = int(tensorflow_item_frnt_(self.scale_pyr.n_levels))
            elif isinstance(self.scale_pyr.n_levels, (int,)):
                num_levels = self.scale_pyr.n_levels
            else:
                raise TypeError(
                    f"Expected the scale pyramid module to have `n_levels` as a Tensor or int.Gotcha {type(self.scale_pyr.n_levels)}"
                )
            max_coords_best = tensorflow__scale_index_to_scale(
                max_coords_best, sigmas_oct, num_levels
            )
            rotmat = tensorflow_view_frnt_(eye(2, dtype=dtype, device=dev), 1, 1, 2, 2)
            current_lafs = concatenate(
                [
                    self.mr_size
                    * tensorflow_view_frnt_(max_coords_best[:, :, 0], B, N, 1, 1)
                    * rotmat,
                    tensorflow_view_frnt_(max_coords_best[:, :, 1:3], B, N, 2, 1),
                ],
                3,
            )
>           good_mask = tensorflow_laf_is_inside_image(current_lafs, octave[:, 0])

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:252: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 500, 2, 3), dtype=float32, numpy=
array([[[[10.708658  ,  0.        , 30.521435  ],
         [ 0...
        [[19.1499    ,  0.        , 21.960266  ],
         [ 0.        , 19.1499    ,  1.9501797 ]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 6, 32, 32), dtype=float32, numpy=
array([[[[4.6555705, 4.3921638, 3.8135338, ..., 5.308701 , 5.2...43547 ],
         [5.257714 , 5.254384 , 5.244533 , ..., 5.3245964, 5.341669 ,
          5.3472905]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False, False,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True, False, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False, False,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True, False, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False, False,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True, False, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False, False,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True, False, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpaceDetector.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ScaleSpaceDetector.call():
E         • img=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)
E         • mask=None

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:239: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
kornia.feature.ScaleSpaceDetector
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpac...
============================================================================== 1 failed, 12 passed in 2082.13s (0:34:42) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py ...........FF                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_map_location_to_cpu[tensorflow-s2s-False] ____________________________________________________________________________

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs'

VM.pyx:244: ModuleNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_map_location_to_cpu(target_framework, mode, backend_compile):
        print("kornia.utils.map_location_to_cpu")
    
        if backend_compile:
            pytest.skip()
    
        tensor = torch.rand(3, 3)
        transpiled_tensor = _nest_torch_tensor_to_new_framework(tensor, target_framework)
    
>       transpiled_func = ivy.transpile(kornia.utils.map_location_to_cpu, source="torch", target=target_framework)

kornia/test_utils.py:332: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <function map_location_to_cpu at 0x7f3255630b80>, source = 'torch', target = 'tensorflow', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ImportError: Error loading module ivy_transpiled_outputs.torch_frontend_outputs.__init__: No module named 'ivy_transpiled_outputs'

VM.pyx:247: ImportError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.utils.map_location_to_cpu
____________________________________________________________________________ test_is_autocast_enabled[tensorflow-s2s-False] ____________________________________________________________________________

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs'

VM.pyx:244: ModuleNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_is_autocast_enabled(target_framework, mode, backend_compile):
        print("kornia.utils.is_autocast_enabled")
    
        if backend_compile:
            pytest.skip()
    
>       transpiled_func = ivy.transpile(kornia.utils.is_autocast_enabled, source="torch", target=target_framework)

kornia/test_utils.py:346: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <function is_autocast_enabled at 0x7f3255631120>, source = 'torch', target = 'tensorflow', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ImportError: Error loading module ivy_transpiled_outputs.torch_frontend_outputs.__init__: No module named 'ivy_transpiled_outputs'

VM.pyx:247: ImportError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.utils.is_autocast_enabled
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_utils.py::test_map_location_to_cpu[tensorflow-s2s-False] - ImportError: Error loading module ivy_transpiled_outputs.torch_frontend_outputs.__init__: No module named 'ivy_transpil...
FAILED kornia/test_utils.py::test_is_autocast_enabled[tensorflow-s2s-False] - ImportError: Error loading module ivy_transpiled_outputs.torch_frontend_outputs.__init__: No module named 'ivy_transpil...
=============================================================================== 2 failed, 11 passed in 680.03s (0:11:20) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .F...F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_NerfModelRenderer[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
_________________________________________________________________________________ test_RandomRaySampler[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7f385127d630>
cameras = <ivy_transpiled_outputs.jax_outputs.kornia.geometry.camera.pinhole.jax_PinholeCamera object at 0x7f3851155030>, num_img_rays = Array([1], dtype=int64)

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != jax_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {jax_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:359: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7f385127d630>, heights = Array([256], dtype=int64), widths = Array([256], dtype=int64)
num_img_rays = Array([1], dtype=int32)

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_trunc_frnt
        from ...ivy.functional.frontends.torch.random_sampling import jax_rand_frnt
    
        num_img_rays = jax_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                jax_tolist_frnt_(heights),
                jax_tolist_frnt_(widths),
                jax_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = jax_trunc_frnt(
>               jax_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
jax_random_uniform = <function jax_random_uniform at 0x7f38283da950>, seed = None

    def jax_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.jax.random import jax_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return jax_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/random_sampling.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, jax_exists_bknd = <function jax_exists_bknd at 0x7f382849eb90>
jax_default_dtype_bknd = <function jax_default_dtype_bknd at 0x7f382849dfc0>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import jax_exists_bknd
        from .functional.ivy.data_type import jax_default_dtype_bknd
    
        arr = None if jax_exists_bknd(dtype) else jax__get_first_array(*args, **kwargs)
        dtype = jax_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @jax_infer_dtype
    def jax_random_uniform(
        *,
        low: Union[float, jax.Array] = 0.0,
        high: Union[float, jax.Array, None] = 1.0,
        shape: Optional[Union[tuple, Sequence[int]]] = None,
        device: jaxlib.xla_extension.Device = None,
        dtype: jax.numpy.dtype,
        seed: Optional[int] = None,
        out: Optional[jax.Array] = None,
    ):
        from ...ivy.random import jax__check_bounds_and_get_shape_bknd
    
        if high is None:
            high = float(
                jax.numpy.finfo(dtype).max
                if dtype is not None
                else jax.numpy.finfo(jax.numpy.float32).max
            )
        shape = jax__check_bounds_and_get_shape_bknd(low, high, shape)
        if seed:
            rng_input = jax.random.PRNGKey(seed)
        else:
            RNG_, rng_input = jax.random.split(jax__getRNG())
            jax__setRNG(RNG_)
>       return jax.numpy.astype(
            jax.random.uniform(
                rng_input, shape, minval=low, maxval=high, dtype=jax.numpy.float32
            ),
            dtype,
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/random.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([0.10536897], dtype=float32), dtype = torch.float32

    def astype(x: ArrayLike, dtype: DTypeLike | None,
               /, *, copy: bool = False,
               device: xc.Device | Sharding | None = None) -> Array:
      """Convert an array to a specified dtype.
    
      JAX imlementation of :func:`numpy.astype`.
    
      This is implemented via :func:`jax.lax.convert_element_type`, which may
      have slightly different behavior than :func:`numpy.astype` in some cases.
      In particular, the details of float-to-int and int-to-float casts are
      implementation dependent.
    
      Args:
        x: input array to convert
        dtype: output dtype
        copy: if True, then always return a copy. If False (default) then only
          return a copy if necessary.
        device: optionally specify the device to which the output will be committed.
    
      Returns:
        An array with the same shape as ``x``, containing values of the specified
        dtype.
    
      See Also:
        - :func:`jax.lax.convert_element_type`: lower-level function for XLA-style
          dtype conversions.
    
      Examples:
        >>> x = jnp.array([0, 1, 2, 3])
        >>> x
        Array([0, 1, 2, 3], dtype=int32)
        >>> x.astype('float32')
        Array([0.0, 1.0, 2.0, 3.0], dtype=float32)
    
        >>> y = jnp.array([0.0, 0.5, 1.0])
        >>> y.astype(int)  # truncates fractional values
        Array([0, 0, 1], dtype=int32)
      """
      util.check_arraylike("astype", x)
      x_arr = asarray(x)
    
      if dtype is None:
        dtype = dtypes.canonicalize_dtype(float_)
>     dtypes.check_user_dtype_supported(dtype, "astype")

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5492: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, fun_name = 'astype'

    def check_user_dtype_supported(dtype, fun_name=None):
      if isinstance(dtype, Array):
        # Deprecation warning added 2024 June 13.
        warnings.warn("Passing an array as a dtype argument is deprecated; "
                      "instead of dtype=arr use dtype=arr.dtype.",
                      category=DeprecationWarning, stacklevel=3)
        return  # no further check needed, as array dtypes have already been validated.
>     if issubdtype(dtype, extended):

/opt/fw/jax/jax/_src/dtypes.py:776: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = torch.float32, b = <class 'jax.dtypes.extended'>

    def issubdtype(a: DTypeLike | ExtendedDType | None,
                   b: DTypeLike | ExtendedDType | None) -> bool:
      """Returns True if first argument is a typecode lower/equal in type hierarchy.
    
      This is like :func:`numpy.issubdtype`, but can handle dtype extensions such as
      :obj:`jax.dtypes.bfloat16` and `jax.dtypes.prng_key`.
      """
      # Main departures from np.issubdtype are:
      # - "extended" dtypes (like prng key types) are not normal numpy dtypes, so we
      #   need to handle them specifically. However, their scalar types do conform to
      #   the numpy scalar type hierarchy.
      # - custom dtypes (like bfloat16, int4, etc.) are normal numpy dtypes, but they
      #   don't conform to the standard numpy type hierarchy (e.g. the bfloat16 scalar
      #   type is not a subclass of np.floating) so we must also handle these specially.
    
      # We cannot use the cached version directly for all inputs, because some may be
      # unhashable (e.g. custom objects with a dtype attribute). The following check is
      # fast and covers the majority of calls to this function within JAX library code.
      return _issubdtype_cached(
>       a if isinstance(a, (type, np.dtype, ExtendedDType)) else np.dtype(a),  # type: ignore[arg-type]
        b if isinstance(b, (type, np.dtype, ExtendedDType)) else np.dtype(b),  # type: ignore[arg-type]
      )
E     TypeError: Cannot interpret 'torch.float32' as a data type

/opt/fw/jax/jax/_src/dtypes.py:363: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[jax-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_RandomRaySampler[jax-s2s-False] - TypeError: Cannot interpret 'torch.float32' as a data type
=============================================================================== 2 failed, 4 passed in 558.65s (0:09:18) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 180.77s (0:03:00) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_conv_quad_interp3d[tensorflow-s2s-False] _____________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fea9ac2f1c0>
trace_args = (tensor([[[[[0.6506, 0.5702, 0.5840, 0.9896, 0.4827],
           [0.2636, 0.3090, 0.9759, 0.9209, 0.0251],
           ....0644],
           [0.8248, 0.2948, 0.8867, 0.2008, 0.9757],
           [0.5138, 0.2893, 0.8251, 0.7345, 0.7865]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.9386, 0.3624, 0.1717, 0.2143, 0.6712],
           [0.1339, 0.7718, 0.8130, 0.2590, 0.5638],
           ....4928],
           [0.4374, 0.0374, 0.7117, 0.9110, 0.3731],
           [0.9143, 0.2091, 0.5146, 0.7734, 0.4659]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7fea9ac2f1c0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.6506, 0.5702, 0.5840, 0.9896, 0.4827],
           [0.2636, 0.3090, 0.9759, 0.9209, 0.0251],
           ....0644],
           [0.8248, 0.2948, 0.8867, 0.2008, 0.9757],
           [0.5138, 0.2893, 0.8251, 0.7345, 0.7865]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.9386, 0.3624, 0.1717, 0.2143, 0.6712],
           [0.1339, 0.7718, 0.8130, 0.2590, 0.5638],
           ....4928],
           [0.4374, 0.0374, 0.7117, 0.9110, 0.3731],
           [0.9143, 0.2091, 0.5146, 0.7734, 0.4659]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=float32, numpy=
array([[[[[0.65063506, 0.57020974, 0.58401114, 0.98961926, 0....0075643, 0.97566706],
          [0.51378685, 0.28931767, 0.82512856, 0.73451376, 0.78646564]]]]],
      dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=bool, numpy=
array([[[[[False, False, False, False, False],
          [False,...alse, False, False],
          [False, False, False, False, False],
          [False, False, False, False, False]]]]])>
name = 'view'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________ test_ConvQuadInterp3d[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = transpiled_kornia.geometry.subpix.ConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-6.7052877e-01,  1.0529226e+00,  1.3494502e+00,
 ...     [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x557790d9dd30, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...      [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-6.7052877e-01,  1.0529226e+00,  1.3494502e+00,
 ...     [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...      [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-6.7052877e-01,  1.0529226e+00,  1.3494502e+00,
 ...     [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-6.7052877e-01,  1.0529226e+00,  1.3494502e+00,
  ...       [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-6.7052877e-01,  1.0529226e+00,  1.3494502e+...      [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-6.7052877e-01,  1.0529226e+00,  1.3494502e+00,
  ...       [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>

    def call(self, x):
>       return tensorflow_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-6.7052877e-01,  1.0529226e+00,  1.3494502e+00,
  ...       [ 3.3786692e-02,  7.2385378e-02,  1.9383274e-01,
           -1.6479486e-01, -2.7951446e-01]]]]], dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )
E       AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'[0m
E       
E       Arguments received by tensorflow_ConvQuadInterp3d.call():
E         • x=tf.Tensor(shape=(1, 1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:114: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
============================================================================== 2 failed, 13 passed in 1334.14s (0:22:14) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py .F.....F                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________ test_find_homography_dlt_iterated[jax-s2s-False] ___________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "IXC.pyx", line 328, in IXC._wrap_callable.wrapper
TypeError: 'NoneType' object is not iterable

During handling of the above exception, another exception occurred:

jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f90cc4eb490>
trace_args = (tensor([[[0.1918, 0.2560],
         [0.4023, 0.4751],
         [0.0702, 0.1389],
         [0.8557, 0.2520]]]), tensor... [0.9143, 0.0940],
         [0.7313, 0.1592],
         [0.1857, 0.4246]]]), tensor([[0.7518, 0.2419, 0.3957, 0.7344]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.9742, 0.9647],
         [0.5246, 0.8010],
         [0.4189, 0.3076],
         [0.2757, 0.3166]],

       ...[0.3726, 0.7547, 0.2040, 0.9016],
        [0.3593, 0.4506, 0.2419, 0.0800],
        [0.5526, 0.5476, 0.6317, 0.0241]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f90cc4eb490>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.1918, 0.2560],
         [0.4023, 0.4751],
         [0.0702, 0.1389],
         [0.8557, 0.2520]]]), tensor... [0.9143, 0.0940],
         [0.7313, 0.1592],
         [0.1857, 0.4246]]]), tensor([[0.7518, 0.2419, 0.3957, 0.7344]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.9742, 0.9647],
         [0.5246, 0.8010],
         [0.4189, 0.3076],
         [0.2757, 0.3166]],

       ...[0.3726, 0.7547, 0.2040, 0.9016],
        [0.3593, 0.4506, 0.2419, 0.0800],
        [0.5526, 0.5476, 0.6317, 0.0241]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.19182211, 0.25598264],
        [0.40230018, 0.47508943],
        [0.07023323, 0.1389386 ],
        [0.8557345 , 0.25196695]]], dtype=float32)
points2 = Array([[[0.7945376 , 0.03204197],
        [0.91431385, 0.09400415],
        [0.7313202 , 0.1591894 ],
        [0.18567938, 0.42459375]]], dtype=float32)
weights = Array([[0.75183785, 0.24188954, 0.39570868, 0.734359  ]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def jax_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_exp_frnt
    
>       H: typing.Any = jax_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.19182211, 0.25598264],
        [0.40230018, 0.47508943],
        [0.07023323, 0.1389386 ],
        [0.8557345 , 0.25196695]]], dtype=float32)
points2 = Array([[[0.7945376 , 0.03204197],
        [0.91431385, 0.09400415],
        [0.7313202 , 0.1591894 ],
        [0.18567938, 0.42459375]]], dtype=float32)
weights = Array([[0.75183785, 0.24188954, 0.39570868, 0.734359  ]], dtype=float32), solver = 'lu'

    def jax_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ..utils.helpers import jax__extract_device_dtype
        from .epipolar.fundamental import jax_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import jax_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import jax_diag_embed_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ..utils.helpers import jax__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import jax_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ..utils.helpers import jax_safe_solve_with_mask
        from ..utils.helpers import jax_safe_inverse_with_mask
    
        if jax_shape_frnt_(points1) != jax_shape_frnt_(points2):
            raise AssertionError(jax_shape_frnt_(points1))
        if jax_shape_frnt_(points1)[1] < 4:
            raise AssertionError(jax_shape_frnt_(points1))
        jax_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        jax_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = jax__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = jax_normalize_points(points1)
        points2_norm, transform2 = jax_normalize_points(points2)
        x1, y1 = jax_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = jax_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = jax_ones_like_v_0p4p0_and_above_frnt(x1), jax_zeros_like_frnt(x1)
        ax = jax_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = jax_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = jax_reshape_frnt_(
            jax_cat_frnt((ax, ay), dim=-1),
            jax_shape_frnt_(ax)[0],
            -1,
            jax_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = jax_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(jax_shape_frnt_(weights)) == 2
                and jax_shape_frnt_(weights) == jax_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(jax_shape_frnt_(weights))
            w_diag = jax_diag_embed_frnt(
                jax_reshape_frnt_(
                    jax_repeat_frnt_(jax_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    jax_shape_frnt_(weights)[0],
                    -1,
                )
            )
            A = jax_transpose_frnt_(A, -2, -1) @ w_diag @ A
        if solver == "svd":
            try:
                _, _, V = jax__torch_svd_cast(A)
            except RuntimeError:
                warnings.warn("SVD did not converge", RuntimeWarning)
                return jax_empty_frnt(
                    (jax_size_frnt_(points1_norm, 0), 3, 3), device=device, dtype=dtype
                )
            H = jax_view_frnt_(V[..., -1], -1, 3, 3)
        elif solver == "lu":
            B = jax_ones_frnt(
                jax_shape_frnt_(A)[0], jax_shape_frnt_(A)[1], device=device, dtype=dtype
            )
>           sol, _, _ = jax_safe_solve_with_mask(B, A)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)
A = Array([[[ 5.1073446 ,  0.2632909 ,  0.42632413,  0.        ,
          0.        ,  0.        ,  8.302684  , -0.780615...374 , -2.6769168 ,
          0.13304251, -0.23428899, 11.959368  , -0.45634705,
          7.0731115 ]]], dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([[[ 5.1073446 ,  0.2632909 ,  0.42632413,  0.        ,
          0.        ,  0.        ,  8.302684  , -0.780615...374 , -2.6769168 ,
          0.13304251, -0.23428899, 11.959368  , -0.45634705,
          7.0731115 ]]], dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([[[ 5.1073446 ,  0.2632909 ,  0.42632413,  0.        ,
          0.        ,  0.        ,  8.302684  , -0.78061...74 , -2.6769168 ,
          0.13304251, -0.23428899, 11.959368  , -0.45634705,
          7.0731115 ]]], dtype=float32)]
kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f9042642b00>, jax_set_item = <function jax_set_item at 0x7f90426b20e0>
jax_asarray = <function jax_asarray at 0x7f9042643520>, jax_get_item = <function jax_get_item at 0x7f90426b1f30>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[ 5.1073446 ,  0.2632909 ,  0.42632413,  0.        ,
          0.        ,  0.        ,  8.302684  , -0.780615...374 , -2.6769168 ,
          0.13304251, -0.23428899, 11.959368  , -0.45634705,
          7.0731115 ]]], dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
_____________________________________________________________________________ test_symmetric_transfer_error[jax-s2s-False] _____________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_symmetric_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.symmetric_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7f90cc4eb250>
trace_args = (tensor([[[0.3722, 0.0495],
         [0.1955, 0.1881],
         [0.1926, 0.4633],
         [0.9930, 0.6962]]]), tensor...0.3182]]]), tensor([[[0.7480, 0.8896, 0.4424],
         [0.6763, 0.4941, 0.2242],
         [0.9671, 0.1421, 0.1061]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.4592, 0.1941],
         [0.2219, 0.9396],
         [0.0032, 0.3595],
         [0.1715, 0.3960]],

       ... 0.7587]],

        [[0.0378, 0.3916, 0.6269],
         [0.8332, 0.4374, 0.4349],
         [0.2276, 0.6213, 0.6688]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7f90cc4eb250>, fn_name = 'kornia.geometry.homography.symmetric_transfer_error'
trace_args = (tensor([[[0.3722, 0.0495],
         [0.1955, 0.1881],
         [0.1926, 0.4633],
         [0.9930, 0.6962]]]), tensor...0.3182]]]), tensor([[[0.7480, 0.8896, 0.4424],
         [0.6763, 0.4941, 0.2242],
         [0.9671, 0.1421, 0.1061]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.4592, 0.1941],
         [0.2219, 0.9396],
         [0.0032, 0.3595],
         [0.1715, 0.3960]],

       ... 0.7587]],

        [[0.0378, 0.3916, 0.6269],
         [0.8332, 0.4374, 0.4349],
         [0.2276, 0.6213, 0.6688]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
            _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)
        else:
            _to_numpy_and_shape_allclose(orig_out, graph_out, tolerance=tolerance)
    
        # test it works with the test_args as input
        orig_out = fn(*test_args, **test_kwargs)
        graph_out = translated_fn(*transpiled_test_args, **transpiled_test_kwargs)
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[7.5470e+01, 7.4608e+01, 4.1467e+01, 3.8265e+01],
        [3.7926e+01, 2.6458e+02, 1.1272e+01, 3.5097e+01],
  ...],
        [2.1567e+02, 1.5183e+02, 8.4897e+02, 5.1581e+01],
        [1.0678e+00, 1.1063e+02, 3.8032e+03, 1.2957e+01]])
transpiled_x = Array([[7.5470360e+01, 7.4607651e+01, 4.1466557e+01, 3.8264664e+01],
       [3.7926212e+01, 2.6457986e+02, 1.1271851e+....4897150e+02, 5.1581169e+01],
       [1.0678108e+00, 1.1062929e+02, 3.8032454e+03, 1.2957414e+01]],      dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[7.5470352e+01, 7.4607651e+01, 4.1466560e+01, 3.8264652e+01],
       [3.7926220e+01, 2.6457986e+02, 1.1271851e+...4897028e+02, 5.1581100e+01],
       [1.0678108e+00, 1.1062946e+02, 3.8031865e+03, 1.2957414e+01]],
      dtype=float32)
y = array([[7.5470360e+01, 7.4607651e+01, 4.1466557e+01, 3.8264664e+01],
       [3.7926212e+01, 2.6457986e+02, 1.1271851e+...4897150e+02, 5.1581169e+01],
       [1.0678108e+00, 1.1062929e+02, 3.8032454e+03, 1.2957414e+01]],
      dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.symmetric_transfer_error
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
FAILED kornia/geometry/test_homography.py::test_symmetric_transfer_error[jax-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 2 failed, 6 passed in 664.52s (0:11:04) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ssssssss                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 8 skipped in 5.30s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF......F..                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_diamond_square[jax-s2s-False] __________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7fcd68a1d510>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fcd80da08c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fcd80da08c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7fcd68a1d510>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fcd80da08c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fcd80da08c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = Array([[[[0.5]]]], dtype=float64), random_scale = Array([[[[1.]]]], dtype=float64), random_fn = <built-in method ones of type object at 0x7fcd80da08c0>
normalize_range = (0.0, 1.0), device = None, dtype = None

    def jax_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=jax_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_expand_frnt_
        from ..core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..enhance.normalize import jax_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
    
        jax_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (jax.Array, nnx.Param)):
            random_scale = jax_to_frnt_(jnp.asarray([[[[random_scale]]]]), device, dtype)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            jax_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = jax_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = jax_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (jax.Array, nnx.Param)):
            roughness = jax_to_frnt_(jnp.asarray([[[[roughness]]]]), device, dtype)
            roughness = jax_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = jax_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = jax_expand_frnt_(roughness, [output_size[0], output_size[1], 1, 1])
            roughness = jax_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * jax__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )
E       TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'

ivy_transpiled_outputs/jax_outputs/kornia/contrib/diamond_square.py:225: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
___________________________________________________________________________________ test_EdgeDetector[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
        transpiled_detector = transpiled_kornia.contrib.EdgeDetector()
    
        torch_args = (
            torch.rand(1, 3, 320, 320),
        )
        torch_out = torch_detector(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_detector(*transpiled_args)

kornia/test_contrib.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_EdgeDetector(
  (model): jax_DexiNed(
    (block_1): jax_DoubleConvBlock(
      (conv1): FlaxConv(in_features=3, o..., 1), padding=0, padding_mode=zeros)
      (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
    )
  )
)
image = Array([[[[0.23238981, 0.96543306, 0.2986127 , ..., 0.6577227 ,
          0.78201103, 0.1307779 ],
         [0.7556255 ...6],
         [0.76045156, 0.975647  , 0.01394212, ..., 0.27215594,
          0.4626932 , 0.9213028 ]]]], dtype=float32)

    def __call__(self, image):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
    
        jax_KORNIA_CHECK_SHAPE(image, ["B", "3", "H", "W"])
        img = self.preprocess(image)
>       out = self.model(img)

ivy_transpiled_outputs/jax_outputs/kornia/contrib/edge_detection.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DexiNed(
  (block_1): jax_DoubleConvBlock(
    (conv1): FlaxConv(in_features=3, out_features=32, kernel_size=(3, 3...rides=(1, 1), padding=0, padding_mode=zeros)
    (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
  )
)
x = Array([[[[0.23238981, 0.96543306, 0.2986127 , ..., 0.6577227 ,
          0.78201103, 0.1307779 ],
         [0.7556255 ...6],
         [0.76045156, 0.975647  , 0.01394212, ..., 0.27215594,
          0.4626932 , 0.9213028 ]]]], dtype=float32)

    def __call__(self, x):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core._backend import concatenate
    
        block_1 = self.block_1(x)
>       block_1_side = self.side_1(block_1)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SingleConvBlock(
  (conv): FlaxConv(in_features=64, out_features=128, kernel_size=(1, 1), strides=(2, 2), padding=0, padding_mode=zeros)
  (bn): FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
)
x = Array([[[[-0.11764122, -0.01184717,  0.00377934, ...,  0.1561434 ,
           0.06977478,  0.0246481 ],
         [-0.0...       [-0.01139376, -0.05908975,  0.1273445 , ...,  0.15697272,
           0.06245421,  0.02797588]]]], dtype=float32)

    def __call__(self, x):
        x = self.conv(x)
        if self.use_bn:
>           x = self.bn(x)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-0.11764122, -0.01184717,  0.00377934, ...,  0.1561434 ,
           0.06977478,  0.0246481 ],
         [-0....     [-0.01139376, -0.05908975,  0.1273445 , ...,  0.15697272,
           0.06245421,  0.02797588]]]], dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x559cd3d656d0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...y', lineno=159, function='pytest_pyfunc_call', code_context=['    result = testfunction(**testargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-0.11764122, -0.01184717,  0.00377934, ...,  0.1561434 ,
           0.06977478,  0.0246481 ],
         [-0....     [-0.01139376, -0.05908975,  0.1273445 , ...,  0.15697272,
           0.06245421,  0.02797588]]]], dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7fccb785f640>, jax_set_item = <function jax_set_item at 0x7fccb785f7f0>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[-0.11764122,  0.07497829, -0.05095669, ...,  0.18057922,
          -0.25001377,  0.01647878],
   ...      [ 0.03158261,  0.05949585, -0.30132926, ...,  0.0692257 ,
          -0.31085968,  0.02797588]]]], dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7fccdd42be20>, next_call_in_seq = None, conv_block_continued = None
arg_name = 'inputs'
input = Array([[[[-0.11764122, -0.01184717,  0.00377934, ...,  0.1561434 ,
           0.06977478,  0.0246481 ],
         [-0.0...       [-0.01139376, -0.05908975,  0.1273445 , ...,  0.15697272,
           0.06245421,  0.02797588]]]], dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
inputs = Array([[[[-0.11764122,  0.07497829, -0.05095669, ...,  0.18057922,
          -0.25001377,  0.01647878],
         [-0.0...       [ 0.03158261,  0.05949585, -0.30132926, ...,  0.0692257 ,
          -0.31085968,  0.02797588]]]], dtype=float32)
use_running_average = None

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs, use_running_average=None, *, mask=None):
        self._built = True
>       logits = super().__call__(
            inputs, use_running_average=use_running_average, mask=mask
        )

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
x = Array([[[[-0.11764122,  0.07497829, -0.05095669, ...,  0.18057922,
          -0.25001377,  0.01647878],
         [-0.0...       [ 0.03158261,  0.05949585, -0.30132926, ...,  0.0692257 ,
          -0.31085968,  0.02797588]]]], dtype=float32)
use_running_average = True

    def __call__(
      self,
      x,
      use_running_average: tp.Optional[bool] = None,
      *,
      mask: tp.Optional[jax.Array] = None,
    ):
      """Normalizes the input using batch statistics.
    
      Args:
        x: the input to be normalized.
        use_running_average: if true, the stored batch statistics will be
          used instead of computing the batch statistics on the input. The
          ``use_running_average`` flag passed into the call method will take
          precedence over the ``use_running_average`` flag passed into the
          constructor.
    
      Returns:
        Normalized inputs (the same shape as inputs).
      """
    
      use_running_average = first_from(
        use_running_average,
        self.use_running_average,
        error_msg="""No `use_running_average` argument was provided to BatchNorm
          as either a __call__ argument, class attribute, or nnx.flag.""",
      )
      feature_axes = _canonicalize_axes(x.ndim, self.axis)
      reduction_axes = tuple(i for i in range(x.ndim) if i not in feature_axes)
    
      if use_running_average:
        mean, var = self.mean.value, self.var.value
      else:
        mean, var = _compute_stats(
          x,
          reduction_axes,
          dtype=self.dtype,
          axis_name=self.axis_name,
          axis_index_groups=self.axis_index_groups,
          use_fast_variance=self.use_fast_variance,
          mask=mask,
        )
    
        self.mean.value = (
          self.momentum * self.mean.value + (1 - self.momentum) * mean
        )
        self.var.value = (
          self.momentum * self.var.value + (1 - self.momentum) * var
        )
    
>     return _normalize(
        x,
        mean,
        var,
        self.scale.value,
        self.bias.value,
        reduction_axes,
        feature_axes,
        self.dtype,
        self.epsilon,
      )

/opt/fw/jax/flax/nnx/nn/normalization.py:367: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[-0.11764122,  0.07497829, -0.05095669, ...,  0.18057922,
          -0.25001377,  0.01647878],
         [-0.0...       [ 0.03158261,  0.05949585, -0.30132926, ...,  0.0692257 ,
          -0.31085968,  0.02797588]]]], dtype=float32)
mean = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
var = Param(
  value=Array([0.2625539 , 0.27113461, 0.21946596, 0.15521275, 0.25643   ,
         0.21336786, 0.39907008, 0.2...8342604, 0.5336697 , 0.19832538, 0.22804523, 0.6139669 ,
         0.32740036, 0.37694854, 0.2545803 ], dtype=float32)
)
scale = Array([0.9180028 , 0.85888755, 0.83077097, 0.8763835 , 0.96300054,
       0.8625907 , 0.8677793 , 0.9038065 , 0.968281... 0.9293163 , 0.97165966, 0.9689161 , 0.9450734 , 0.8873313 ,
       0.88254374, 0.99936277, 0.848198  ], dtype=float32)
bias = Array([-0.07675791, -0.03457952, -0.06084337,  0.0461219 , -0.04142413,
        0.07173445, -0.01962172,  0.00044565, ...8167, -0.02156175, -0.02820837,  0.02331718, -0.01897949,
        0.0239033 ,  0.00923689, -0.05559541], dtype=float32)
reduction_axes = (0, 1, 2), feature_axes = (3,), dtype = None, epsilon = 1e-05

    def _normalize(
      x: Array,
      mean: Array,
      var: Array,
      scale: tp.Optional[Array],
      bias: tp.Optional[Array],
      reduction_axes: Axes,
      feature_axes: Axes,
      dtype: tp.Optional[Dtype],
      epsilon: float,
    ):
      """ "Normalizes the input of a normalization layer and optionally applies a learned scale and bias.
    
      Arguments:
        x: The input.
        mean: Mean to use for normalization.
        var: Variance to use for normalization.
        reduction_axes: The axes in ``x`` to reduce.
        feature_axes: Axes containing features. A separate bias and scale is learned
          for each specified feature.
        dtype: The dtype of the result (default: infer from input and params).
        epsilon: Normalization epsilon.
    
      Returns:
        The normalized input.
      """
      reduction_axes = _canonicalize_axes(x.ndim, reduction_axes)
      feature_axes = _canonicalize_axes(x.ndim, feature_axes)
      stats_shape = list(x.shape)
      for axis in reduction_axes:
        stats_shape[axis] = 1
>     mean = mean.reshape(stats_shape)

/opt/fw/jax/flax/nnx/nn/normalization.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
name = 'reshape'

    def custom_getattr(self, name):
        if name in ("shape", "device", "dtype", "ndim", "size", "itemsize", "T"):
            value = getattr(self, "value")
            if value is not None:
                # Attempt to retrieve the attribute from the wrapped object (`value`)
                return getattr(value, name)
>       return object.__getattribute__(self, name)
E       AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?

ivy_transpiled_outputs/jax_outputs/__init__.py:91: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<08:57, 262kB/s]
  0%|          | 256k/135M [00:00<05:27, 430kB/s]
  0%|          | 512k/135M [00:00<02:58, 788kB/s]
  1%|          | 896k/135M [00:01<01:49, 1.28MB/s]
  1%|▏         | 1.75M/135M [00:01<00:54, 2.56MB/s]
  3%|▎         | 3.50M/135M [00:01<00:26, 5.12MB/s]
  5%|▍         | 6.50M/135M [00:01<00:14, 9.25MB/s]
  7%|▋         | 9.50M/135M [00:01<00:10, 12.1MB/s]
  9%|▉         | 12.5M/135M [00:01<00:09, 14.1MB/s]
 12%|█▏        | 15.5M/135M [00:02<00:08, 15.4MB/s]
 14%|█▎        | 18.4M/135M [00:02<00:07, 16.3MB/s]
 16%|█▌        | 21.1M/135M [00:02<00:07, 16.5MB/s]
 18%|█▊        | 24.1M/135M [00:02<00:06, 17.1MB/s]
 20%|██        | 27.1M/135M [00:02<00:06, 17.6MB/s]
 22%|██▏       | 30.1M/135M [00:02<00:06, 18.0MB/s]
 24%|██▍       | 32.8M/135M [00:03<00:06, 17.5MB/s]
 26%|██▋       | 35.6M/135M [00:03<00:05, 17.7MB/s]
 29%|██▊       | 38.6M/135M [00:03<00:05, 18.0MB/s]
 31%|███       | 41.6M/135M [00:03<00:05, 18.2MB/s]
 33%|███▎      | 44.6M/135M [00:03<00:05, 18.4MB/s]
 35%|███▌      | 47.6M/135M [00:03<00:04, 18.5MB/s]
 38%|███▊      | 50.6M/135M [00:04<00:04, 18.6MB/s]
 40%|███▉      | 53.6M/135M [00:04<00:04, 18.6MB/s]
 42%|████▏     | 56.5M/135M [00:04<00:04, 18.5MB/s]
 44%|████▍     | 59.5M/135M [00:04<00:04, 18.1MB/s]
 46%|████▋     | 62.5M/135M [00:04<00:04, 18.3MB/s]
 49%|████▊     | 65.5M/135M [00:04<00:03, 18.5MB/s]
 51%|█████     | 68.4M/135M [00:05<00:03, 18.3MB/s]
 53%|█████▎    | 71.2M/135M [00:05<00:03, 18.2MB/s]
 55%|█████▌    | 74.2M/135M [00:05<00:03, 18.4MB/s]
 57%|█████▋    | 77.2M/135M [00:05<00:03, 18.5MB/s]
 60%|█████▉    | 80.2M/135M [00:05<00:03, 18.6MB/s]
 62%|██████▏   | 83.2M/135M [00:05<00:02, 18.6MB/s]
 64%|██████▍   | 86.2M/135M [00:06<00:02, 18.7MB/s]
 66%|██████▌   | 89.1M/135M [00:06<00:02, 18.5MB/s]
 68%|██████▊   | 91.9M/135M [00:06<00:02, 18.1MB/s]
 71%|███████   | 94.9M/135M [00:06<00:02, 17.3MB/s]
 73%|███████▎  | 97.9M/135M [00:06<00:02, 17.7MB/s]
 75%|███████▍  | 101M/135M [00:06<00:01, 18.0MB/s] 
 77%|███████▋  | 104M/135M [00:07<00:01, 19.1MB/s]
 79%|███████▉  | 107M/135M [00:07<00:01, 17.6MB/s]
 81%|████████▏ | 110M/135M [00:07<00:01, 17.9MB/s]
 84%|████████▎ | 113M/135M [00:07<00:01, 18.1MB/s]
 86%|████████▌ | 116M/135M [00:07<00:01, 18.0MB/s]
 88%|████████▊ | 118M/135M [00:07<00:00, 18.0MB/s]
 90%|█████████ | 121M/135M [00:08<00:00, 18.0MB/s]
 92%|█████████▏| 124M/135M [00:08<00:00, 18.2MB/s]
 94%|█████████▍| 127M/135M [00:08<00:00, 18.2MB/s]
 97%|█████████▋| 130M/135M [00:08<00:00, 18.3MB/s]
 99%|█████████▉| 133M/135M [00:08<00:00, 18.5MB/s]
100%|██████████| 135M/135M [00:08<00:00, 16.1MB/s]
__________________________________________________________________________________ test_ImageStitcher[jax-s2s-False] ___________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = transpiled_kornia.feature.LoFTR(pretrained='outdoor')

kornia/test_contrib.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = (), kwargs = {'pretrained': 'outdoor'}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = transpiled_kornia.feature.LoFTR(pretrained='outdoor')

kornia/test_contrib.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = (), kwargs = {'pretrained': 'outdoor'}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:57, 261kB/s]
  1%|          | 256k/44.2M [00:00<01:47, 429kB/s]
  1%|          | 512k/44.2M [00:00<00:58, 787kB/s]
  2%|▏         | 896k/44.2M [00:01<00:35, 1.27MB/s]
  4%|▍         | 1.75M/44.2M [00:01<00:17, 2.57MB/s]
  8%|▊         | 3.50M/44.2M [00:01<00:08, 5.13MB/s]
 15%|█▍        | 6.50M/44.2M [00:01<00:04, 9.28MB/s]
 21%|██▏       | 9.50M/44.2M [00:01<00:02, 12.2MB/s]
 28%|██▊       | 12.5M/44.2M [00:01<00:02, 14.2MB/s]
 34%|███▍      | 15.1M/44.2M [00:02<00:02, 14.9MB/s]
 41%|████      | 18.0M/44.2M [00:02<00:01, 15.8MB/s]
 47%|████▋     | 20.9M/44.2M [00:02<00:01, 16.4MB/s]
 54%|█████▎    | 23.8M/44.2M [00:02<00:01, 16.8MB/s]
 61%|██████    | 26.8M/44.2M [00:02<00:01, 17.4MB/s]
 67%|██████▋   | 29.6M/44.2M [00:02<00:00, 17.6MB/s]
 74%|███████▍  | 32.6M/44.2M [00:03<00:00, 17.8MB/s]
 80%|████████  | 35.5M/44.2M [00:03<00:00, 17.9MB/s]
 87%|████████▋ | 38.5M/44.2M [00:03<00:00, 18.1MB/s]
 94%|█████████▍| 41.5M/44.2M [00:03<00:00, 18.3MB/s]
100%|██████████| 44.2M/44.2M [00:03<00:00, 13.0MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[jax-s2s-False] - TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'
FAILED kornia/test_contrib.py::test_EdgeDetector[jax-s2s-False] - AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?
FAILED kornia/test_contrib.py::test_ImageStitcher[jax-s2s-False] - NameError: name 'kornia' is not defined
============================================================================== 3 failed, 12 passed in 1547.82s (0:25:47) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py FF.........F..FFF                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_RandomMosaic[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'tensorflow', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[ 7.5706e-01,  1.5016e+00, -6.4767e-01,  ...,  1.9443e-01,
            1.2421e+00,  1.1039e+00],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.57062137e-01,  1.50159252e+00, -6.47669792e-01... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fbcb856ee40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.57062137e-01,  1.50159252e+00, -6.47669792e-01... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.57062137e-01,  1.50159252e+00, -6.47669792e-01... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.57062137e-01,  1.50159252e+00, -6.47669792e-01,...55958e+00, -1.48560226e+00, ...,
           6.54491782e-01, -4.41141754e-01,  1.76929712e+00]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,...ize=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.57062137e-01,  1.50159252e+00, -6.476... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.57062137e-01,  1.50159252e+00, -6.476...5958e+00, -1.48560226e+00, ...,
           6.54491782e-01, -4.41141754e-01,  1.76929712e+00]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 7.57062137e-01,  1.50159252e+00, -6.476...5958e+00, -1.48560226e+00, ...,
           6.54491782e-01, -4.41141754e-01,  1.76929712e+00]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
___________________________________________________________________________ test_RandomTransplantation[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.transplantation.RandomTransplantation'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[ 0.8036,  0.4161, -0.8366, -1.0420,  2.1651],
          [-0.5149,  1.7870,  0.8268,  0.6971,  0.4071],
   ...1, 2, 2, 0],
         [1, 2, 1, 1, 2],
         [1, 1, 0, 1, 1],
         [0, 2, 1, 1, 0],
         [2, 1, 0, 1, 2]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.8036374 ,  0.4160784 , -0.83659655, -1.0420253 ,
 ...2, 1, 2, 2, 0],
        [1, 2, 1, 1, 2],
        [1, 1, 0, 1, 1],
        [0, 2, 1, 1, 0],
        [2, 1, 0, 1, 2]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fbcb8320240, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...2, 1, 2, 2, 0],
        [1, 2, 1, 1, 2],
        [1, 1, 0, 1, 1],
        [0, 2, 1, 1, 0],
        [2, 1, 0, 1, 2]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.8036374 ,  0.4160784 , -0.83659655, -1.0420253 ,
 ...2, 1, 2, 2, 0],
        [1, 2, 1, 1, 2],
        [1, 1, 0, 1, 1],
        [0, 2, 1, 1, 0],
        [2, 1, 0, 1, 2]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...2, 1, 2, 2, 0],
        [1, 2, 1, 1, 2],
        [1, 1, 0, 1, 1],
        [0, 2, 1, 1, 0],
        [2, 1, 0, 1, 2]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.8036374 ,  0.4160784 , -0.83659655, -1.0420253 ,
 ...2, 1, 2, 2, 0],
        [1, 2, 1, 1, 2],
        [1, 1, 0, 1, 1],
        [0, 2, 1, 1, 0],
        [2, 1, 0, 1, 2]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.8036374 ,  0.4160784 , -0.83659655, -1.0420253 ,
  ...  0.01485286],
         [-0.46652332,  0.27565235, -0.95982265, -0.96966434,
          -0.2931022 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.8036374 ,  0.4160784 , -0.83659655, -1.04...2, 1, 2, 2, 0],
        [1, 2, 1, 1, 2],
        [1, 1, 0, 1, 1],
        [0, 2, 1, 1, 0],
        [2, 1, 0, 1, 2]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[2, 0, 1, 2, 1],
        [0, 0, 0, 1, 1],
        [1, 1, 2, 2...[2, 1, 2, 2, 0],
        [1, 2, 1, 1, 2],
        [1, 1, 0, 1, 1],
        [0, 2, 1, 1, 0],
        [2, 1, 0, 1, 2]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 0.8036374 ,  0.4160784 , -0.83659655, -1.04... 0.01485286],
         [-0.46652332,  0.27565235, -0.95982265, -0.96966434,
          -0.2931022 ]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7fbcb75ba710>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fbcb814cc10>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7fbcb814c8b0>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7fbcb70dd7e0>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fbcb815b2e0>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7fbcb5bb2f50>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 0, 1, 2, 1],
       [0, 0, 0, 1, 1],
       [1, 1, 2, 2, 1],
       [2, 2, 2, 1, 1],
       [2, 0, 0, 0, 0]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 0, 1, 2, 1],
       [0, 0, 0, 1, 1],
       [1, 1, 2, 2, 1],
       [2, 2, 2, 1, 1],
       [2, 0, 0, 0, 0]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 0, 1, 2, 1],
       [0, 0, 0, 1, 1],
       [1, 1, 2, 2, 1],
       [2, 2, 2, 1, 1],
       [2, 0, 0, 0, 0]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 0, 1, 2, 1],
       [0, 0, 0, 1, 1],
       [1, 1, 2, 2, 1],
       [2, 2, 2, 1, 1],
       [2, 0, 0, 0, 0]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation.call():
E                 • input=<class 'inspect._empty'>
E                 • params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                 • data_keys=None
E                 • kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation
__________________________________________________________________________ test_RandomTransplantation3D[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation3D")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.mix.transplantation.RandomTransplantation3D'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[ 1.1229, -1.4907, -0.7304, -0.8673,  0.4562],
          [-0.4952, -0.0409, -0.4699,  1.4760,  0.6329],
   ...1, 1, 2, 1],
         [2, 0, 2, 0, 2],
         [0, 0, 0, 0, 0],
         [2, 0, 2, 2, 1],
         [0, 1, 2, 0, 2]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.1229314 , -1.4906673 , -0.7303856 , -0.8673456 ,
 ...0, 1, 1, 2, 1],
        [2, 0, 2, 0, 2],
        [0, 0, 0, 0, 0],
        [2, 0, 2, 2, 1],
        [0, 1, 2, 0, 2]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fbcb8bbee40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...0, 1, 1, 2, 1],
        [2, 0, 2, 0, 2],
        [0, 0, 0, 0, 0],
        [2, 0, 2, 2, 1],
        [0, 1, 2, 0, 2]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.1229314 , -1.4906673 , -0.7303856 , -0.8673456 ,
 ...0, 1, 1, 2, 1],
        [2, 0, 2, 0, 2],
        [0, 0, 0, 0, 0],
        [2, 0, 2, 2, 1],
        [0, 1, 2, 0, 2]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...0, 1, 1, 2, 1],
        [2, 0, 2, 0, 2],
        [0, 0, 0, 0, 0],
        [2, 0, 2, 2, 1],
        [0, 1, 2, 0, 2]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.1229314 , -1.4906673 , -0.7303856 , -0.8673456 ,
 ...0, 1, 1, 2, 1],
        [2, 0, 2, 0, 2],
        [0, 0, 0, 0, 0],
        [2, 0, 2, 2, 1],
        [0, 1, 2, 0, 2]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.1229314 , -1.4906673 , -0.7303856 , -0.8673456 ,
  ... -0.52391475],
         [ 0.82790864, -1.5169053 , -0.12622495,  0.80455655,
          -0.6265712 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.1229314 , -1.4906673 , -0.7303856 , -0.86...0, 1, 1, 2, 1],
        [2, 0, 2, 0, 2],
        [0, 0, 0, 0, 0],
        [2, 0, 2, 2, 1],
        [0, 1, 2, 0, 2]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[1, 0, 2, 2, 0],
        [0, 1, 0, 0, 0],
        [0, 0, 2, 1...[0, 1, 1, 2, 1],
        [2, 0, 2, 0, 2],
        [0, 0, 0, 0, 0],
        [2, 0, 2, 2, 1],
        [0, 1, 2, 0, 2]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.1229314 , -1.4906673 , -0.7303856 , -0.86...-0.52391475],
         [ 0.82790864, -1.5169053 , -0.12622495,  0.80455655,
          -0.6265712 ]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7fbcb635f400>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fbcb0366320>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7fbcb0307d90>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7fbcb51d7f40>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fbcb03064d0>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7fbcb58b5930>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:249: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[1, 0, 2, 2, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 2, 1, 2],
       [2, 0, 2, 1, 0],
       [2, 1, 1, 1, 0]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[1, 0, 2, 2, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 2, 1, 2],
       [2, 0, 2, 1, 0],
       [2, 1, 1, 1, 0]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[1, 0, 2, 2, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 2, 1, 2],
       [2, 0, 2, 1, 0],
       [2, 1, 1, 1, 0]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[1, 0, 2, 2, 0],
       [0, 1, 0, 0, 0],
       [0, 0, 2, 1, 2],
       [2, 0, 2, 1, 0],
       [2, 1, 1, 1, 0]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation3D.call():
E                 • input=<class 'inspect._empty'>
E                 • params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                 • data_keys=None
E                 • kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation3D
______________________________________________________________________________ test_LongestMaxSize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LongestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.LongestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 200, 200),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.LongestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:360: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.LongestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[7.5867e-01, 8.3190e-01, 8.9919e-01,  ..., 9.7185e-01,
           2.4039e-01, 3.2093e-01],
          [2.173... 6.0739e-02],
          [3.0906e-01, 3.0139e-01, 3.6073e-01,  ..., 2.1241e-01,
           5.1477e-01, 1.4963e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.7586728 , 0.8951156 , 0.54717255, ..., 0.15416867,
          0.9658222 , 0.32092553],
         [0.79404795...1],
         [0.30905795, 0.36496124, 0.44640467, ..., 0.78470916,
          0.21854383, 0.1496318 ]]]], dtype=float32)
y = array([[[[0.5279212 , 0.540571  , 0.4369989 , ..., 0.21920699,
          0.4454239 , 0.40427893],
         [0.58938783...6],
         [0.26674202, 0.51251906, 0.7436581 , ..., 0.59872144,
          0.4647022 , 0.23517859]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.LongestMaxSize
__________________________________________________________________________________ test_Resize[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Resize(target_framework, mode, backend_compile):
        print("kornia.augmentation.Resize")
    
        init_args = ((100, 100),)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.Resize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.Resize'>, target = 'tensorflow', init_args = ((100, 100),), init_kwargs = {}
call_args = (tensor([[[[9.0023e-01, 6.4049e-01, 1.0760e-01,  ..., 6.7033e-02,
           7.1793e-01, 1.3170e-01],
          [3.024... 2.6472e-01],
          [6.2160e-01, 4.8787e-01, 1.9610e-01,  ..., 2.3517e-01,
           9.0763e-01, 5.4621e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.9002255 , 0.771672  , 0.64311844, ..., 0.71200716,
          0.4218554 , 0.13170362],
         [0.46962836... ],
         [0.6216033 , 0.55540967, 0.48921597, ..., 0.9039841 ,
          0.72509694, 0.5462098 ]]]], dtype=float32)
y = array([[[[0.9002255 , 0.8352929 , 0.7054275 , ..., 0.5713725 ,
          0.27825993, 0.13170362],
         [0.68273   ... ],
         [0.6216033 , 0.58816874, 0.52129966, ..., 0.8172787 ,
          0.6365661 , 0.5462098 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.Resize
______________________________________________________________________________ test_SmallestMaxSize[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SmallestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.SmallestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.SmallestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.SmallestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[1.8574e-01, 6.2112e-01, 2.3075e-01,  ..., 3.4012e-01,
           5.1481e-01, 9.3116e-01],
          [9.283... 9.6047e-01],
          [9.8615e-01, 5.9076e-01, 5.7959e-01,  ..., 9.4018e-01,
           3.5380e-01, 3.7909e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.18574035, 0.4012308 , 0.6167213 , ..., 0.5190131 ,
          0.72508705, 0.931161  ],
         [0.55328584... ],
         [0.98614526, 0.7904496 , 0.59475386, ..., 0.35405564,
          0.3665724 , 0.37908918]]]], dtype=float32)
y = array([[[[0.18574035, 0.29458502, 0.5122744 , ..., 0.61889577,
          0.8270726 , 0.931161  ],
         [0.37138832... ],
         [0.98614526, 0.88729894, 0.68960637, ..., 0.36012244,
          0.3727669 , 0.37908918]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.SmallestMaxSize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation3D[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_LongestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_Resize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_SmallestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 6 failed, 11 passed in 4016.50s (1:06:56) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 498.59s (0:08:18) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py .F.F...FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_SIFTFeatureScaleSpace[jax-s2s-False] _______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
>       transpiled_out = transpiled_model(transpiled_x)

kornia/test_feature4.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SIFTFeatureScaleSpace(
  (detector): jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyram...ng_bins=8, num_spatial_bins=4, patch_size=41, rootsift=True, clipval=0.2), patch_size=41, grayscale_descriptor='True)
)
img = Array([[[[0.17593169, 0.52578634, 0.38800204, ..., 0.63419473,
          0.07197791, 0.7700087 ],
         [0.74858016...4],
         [0.8389864 , 0.3456943 , 0.5597322 , ..., 0.9458563 ,
          0.77232623, 0.24983305]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
        from .laf import jax_scale_laf
    
>       lafs, responses = self.detector(img, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.17593169, 0.52578634, 0.38800204, ..., 0.63419473,
          0.07197791, 0.7700087 ],
         [0.74858016...4],
         [0.8389864 , 0.3456943 , 0.5597322 , ..., 0.9458563 ,
          0.77232623, 0.24983305]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.17593169, 0.52578634, 0.38800204, ..., 0.63419473,
          0.07197791, 0.7700087 ],
         [0.74858016...4],
         [0.8389864 , 0.3456943 , 0.5597322 , ..., 0.9458563 ,
          0.77232623, 0.24983305]]]], dtype=float32)
num_feats = 10, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import jax_topk_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from .laf import jax_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
>       sp, sigmas, _ = self.scale_pyr(img)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
x = Array([[[[0.17593169, 0.52578634, 0.38800204, ..., 0.63419473,
          0.07197791, 0.7700087 ],
         [0.74858016...4],
         [0.8389864 , 0.3456943 , 0.5597322 , ..., 0.9458563 ,
          0.77232623, 0.24983305]]]], dtype=float32)

    def __call__(self, x):
        from ...filters.gaussian import jax_gaussian_blur2d
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...core._backend import ones
        from ...core._backend import stack
    
        bs, _, _, _ = jax_size_frnt_(x)
>       cur_level, cur_sigma, pixel_distance = self.get_first_level(x)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
input = Array([[[[0.17593169, 0.52578634, 0.38800204, ..., 0.63419473,
          0.07197791, 0.7700087 ],
         [0.74858016...4],
         [0.8389864 , 0.3456943 , 0.5597322 , ..., 0.9458563 ,
          0.77232623, 0.24983305]]]], dtype=float32)

    def get_first_level(self, input):
        from ...filters.gaussian import jax_gaussian_blur2d
    
        pixel_distance = 1.0
        cur_sigma = 0.5
        if self.double_image:
>           x = jax_upscale_double(input)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.17593169, 0.52578634, 0.38800204, ..., 0.63419473,
          0.07197791, 0.7700087 ],
         [0.74858016...4],
         [0.8389864 , 0.3456943 , 0.5597322 , ..., 0.9458563 ,
          0.77232623, 0.24983305]]]], dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.17593169, 0.        , 0.52578634, ..., 0.        ,
          0.7700087 , 0.        ],
         [0.        ... ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.35085902, 0.4568942 , 0.6225393 , ..., 0.35308632,
          0.4209933 , 0.        ],
         [0.4453482 ... ],
         [0.59234035, 0.45271325, 0.6701713 , ..., 0.8590913 ,
          0.51107967, 0.        ]]]], dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("JAX arrays are immutable and do not support in-place item assignment."
             " Instead of x[idx] = y, use x = x.at[idx].set(y) or another .at[] method:"
             " https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: JAX arrays are immutable and do not support in-place item assignment. Instead of x[idx] = y, use x = x.at[idx].set(y) or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:586: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
kornia.feature.SIFTFeatureScaleSpace
All parameters and buffers are now synced!
All parameters and buffers are now synced!
_______________________________________________________________________________ test_KeyNetAffNetHardNet[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_KeyNetAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.KeyNetAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.KeyNetAffNetHardNet(num_features=10)
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.KeyNetAffNetHardNet(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature4.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[ 6.2592e-02,  1.3717e+01,  3.1823e+01],
          [-1.7641e+01,  1.1542e+00,  1.4568e+02]],

         [[ 1...69, -0.0260],
         [ 0.0834,  0.0024, -0.1609,  ...,  0.1137,  0.0594, -0.0329]]],
       grad_fn=<ViewBackward0>))
transpiled_x = (Array([[[[ 6.4089634e-02,  1.3716995e+01,  3.1823206e+01],
         [-1.7640717e+01,  1.1560800e+00,  1.4567957e+02]]...        [ 0.08340117,  0.00244207, -0.1609543 , ...,  0.11364289,
          0.05936401, -0.03293817]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[ 6.2591814e-02,  1.3717006e+01,  3.1823206e+01],
         [-1.7640835e+01,  1.1541582e+00,  1.4567957e+02]]...        [ 0.08341356,  0.00244962, -0.16094594, ...,  0.11372086,
          0.05936115, -0.03294361]]], dtype=float32))
y = (array([[[[ 6.4089634e-02,  1.3716995e+01,  3.1823206e+01],
         [-1.7640717e+01,  1.1560800e+00,  1.4567957e+02]]...        [ 0.08340117,  0.00244207, -0.1609543 , ...,  0.11364289,
          0.05936401, -0.03293817]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f531c6b7700>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 6.2591814e-02,  1.3717006e+01,  3.1823206e+01],
         [-1.7640835e+01,  1.1541582e+00,  1.4567957e+02]],...01, -3.2147546e+00,  3.1000000e+01],
         [ 2.2380881e+00, -2.5411480e+01,  1.4600000e+02]]]],
      dtype=float32)
y = array([[[[ 6.4089634e-02,  1.3716995e+01,  3.1823206e+01],
         [-1.7640717e+01,  1.1560800e+00,  1.4567957e+02]],...01, -3.2152162e+00,  3.1000000e+01],
         [ 2.2387087e+00, -2.5411419e+01,  1.4600000e+02]]]],
      dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.KeyNetAffNetHardNet
kornia.feature.KeyNetAffNetHardNet
All parameters and buffers are now synced!
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/OriNet.pth" to /root/.cache/torch/hub/checkpoints/OriNet.pth

  0%|          | 0.00/316k [00:00<?, ?B/s]
100%|██████████| 316k/316k [00:00<00:00, 26.3MB/s]
Downloading: "https://github.com/axelBarroso/Key.Net-Pytorch/raw/main/model/weights/keynet_pytorch.pth" to /root/.cache/torch/hub/checkpoints/keynet_pytorch.pth

  0%|          | 0.00/78.0k [00:00<?, ?B/s]
100%|██████████| 78.0k/78.0k [00:00<00:00, 21.4MB/s]
_______________________________________________________________________________ test_LocalFeatureMatcher[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
        ...
         [0.77184945, 0.5160922 , 0.5484062 , ..., 0.6054329 ,
          0.05973196, 0.09889925]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
        ...
         [0.77184945, 0.5160922 , 0.5484062 , ..., 0.6054329 ,
          0.05973196, 0.09889925]]]], dtype=float32)},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         ...],
         [0.77184945, 0.5160922 , 0.5484062 , ..., 0.6054329 ,
          0.05973196, 0.09889925]]]], dtype=float32)}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577 ...4],
         [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32)
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577...      [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577...      [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32), None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577 ...4],
         [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577...      [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577...      [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32), None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577 ...4],
         [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577 ...4],
         [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32)
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.45794165, 0.7733723 , 0.9103405 , ..., 0.96297354,
          0.8806145 , 0.76520234],
         [0.5334577 ...4],
         [0.4788912 , 0.19309294, 0.45259172, ..., 0.6904483 ,
          0.49857938, 0.04485571]]]], dtype=float32)
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_________________________________________________________________________________ test_LightGlueMatcher[jax-s2s-False] _________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = transpiled_kornia.feature.LightGlueMatcher('disk')

kornia/test_feature4.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}, node = jax_LightGlueMatcher()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, self = jax_LightGlueMatcher(), args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import jax_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = jax_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}
node = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>
self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
features = 'disk', conf_ = {}, jax_KORNIA_CHECK = <function jax_KORNIA_CHECK at 0x7f5315fb5cf0>, jax_get_item = <function jax_get_item at 0x7f5315f1c5e0>
jax_Identity = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.linear.jax_Identity'>, jax_load_state_dict_from_url_frnt = <function jax_load_state_dict_from_url_frnt at 0x7f5313aa92d0>
jax_load_frnt = <function jax_load_frnt at 0x7f5313aa9510>, ModuleList = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.container.jax_ModuleList'>
FlaxLinear = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxLinear'>

    @jax_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...torch.nn.modules.linear import jax_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            jax_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            jax_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in jax_get_item(self.features, features).items():
                setattr(conf, k, v)
        jax_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = FlaxLinear(
                in_features=conf.input_dim,
                out_features=conf.descriptor_dim,
                use_bias=True,
            )
        else:
            self.input_proj = jax_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = jax_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = jax_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:1389: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}, node = jax_TransformerLayer()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @jax_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = jax_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:944: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}
node = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)
args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @jax_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import jax_KORNIA_CHECK
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.normalization import jax_LayerNorm
        from ...torch.nn.modules.activation import jax_GELU
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        jax_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = FlaxLinear(
            in_features=embed_dim, out_features=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = jax_Attention(flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}, node = jax_Attention()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, self = jax_Attention(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), allow_flash = True

    @jax_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:398: NameError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = transpiled_kornia.feature.LightGlueMatcher('disk')

kornia/test_feature4.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}, node = jax_LightGlueMatcher()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, self = jax_LightGlueMatcher(), args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import jax_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = jax_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}
node = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>
self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
features = 'disk', conf_ = {}, jax_KORNIA_CHECK = <function jax_KORNIA_CHECK at 0x7f5315fb5cf0>, jax_get_item = <function jax_get_item at 0x7f5315f1c5e0>
jax_Identity = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.linear.jax_Identity'>, jax_load_state_dict_from_url_frnt = <function jax_load_state_dict_from_url_frnt at 0x7f5313aa92d0>
jax_load_frnt = <function jax_load_frnt at 0x7f5313aa9510>, ModuleList = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.container.jax_ModuleList'>
FlaxLinear = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxLinear'>

    @jax_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...torch.nn.modules.linear import jax_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            jax_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            jax_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in jax_get_item(self.features, features).items():
                setattr(conf, k, v)
        jax_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = FlaxLinear(
                in_features=conf.input_dim,
                out_features=conf.descriptor_dim,
                use_bias=True,
            )
        else:
            self.input_proj = jax_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = jax_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = jax_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:1389: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}, node = jax_TransformerLayer()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @jax_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = jax_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:944: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}
node = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)
args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @jax_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import jax_KORNIA_CHECK
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.normalization import jax_LayerNorm
        from ...torch.nn.modules.activation import jax_GELU
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        jax_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = FlaxLinear(
            in_features=embed_dim, out_features=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = jax_Attention(flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}, node = jax_Attention()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, self = jax_Attention(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), allow_flash = True

    @jax_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:398: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 65%|██████▍   | 29.5M/45.4M [00:00<00:00, 308MB/s]
100%|██████████| 45.4M/45.4M [00:00<00:00, 319MB/s]
____________________________________________________________________________________ test_LightGlue[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.7820489 , 0.67171055, 0.6219945 , ..., 0.9540918 ,
         0.10798889, 0.53186...1, 9.7825056e-01],
        [6.2434042e-01, 3.6324376e-01],
        [6.2350816e-01, 6.1033309e-01]]], dtype=float32)}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.7820489 , 0.67171055, 0.6219945 , ..., 0.9540918 ,
         0.10798889, 0.53186...1, 9.7825056e-01],
        [6.2434042e-01, 3.6324376e-01],
        [6.2350816e-01, 6.1033309e-01]]], dtype=float32)}},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.7820489 , 0.67171055, 0.6219945 , ..., 0.9540918 ,
         0.10798889, 0.531866...-01, 9.7825056e-01],
        [6.2434042e-01, 3.6324376e-01],
        [6.2350816e-01, 6.1033309e-01]]], dtype=float32)}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.7820489 , 0.67171055, 0.6219945 , ..., 0.9540918 ,
         0.10798889, 0.531866...-01, 9.7825056e-01],
        [6.2434042e-01, 3.6324376e-01],
        [6.2350816e-01, 6.1033309e-01]]], dtype=float32)}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[0.20055753, 0.04697371],
        [0.2504521 , 0.66409695],
        [0.9214108 , 0.158086  ],
        [0.1630...        [0.13618547, 0.6289929 ],
        [0.6863731 , 0.06053108]]], dtype=float32), Array([[640, 480]], dtype=int64))
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = Array([[[0.20055753, 0.04697371],
        [0.2504521 , 0.66409695],
        [0.9214108 , 0.158086  ],
        [0.16304...
        [0.9502694 , 0.04134321],
        [0.13618547, 0.6289929 ],
        [0.6863731 , 0.06053108]]], dtype=float32)
size = Array([[640, 480]], dtype=int64)

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 68%|██████▊   | 30.9M/45.3M [00:00<00:00, 324MB/s]
100%|██████████| 45.3M/45.3M [00:00<00:00, 328MB/s]
______________________________________________________________________________________ test_LoFTR[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:320: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[0.6384981 , 0.4706369 , 0.21727997, ..., 0.72724867,
          0.17352939, 0.23181123],
        ...
         [0.35742927, 0.7458289 , 0.49265993, ..., 0.821325  ,
          0.2935797 , 0.85510635]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[0.6384981 , 0.4706369 , 0.21727997, ..., 0.72724867,
          0.17352939, 0.23181123],
        ...
         [0.35742927, 0.7458289 , 0.49265993, ..., 0.821325  ,
          0.2935797 , 0.85510635]]]], dtype=float32)},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': Array([[[[0.6384981 , 0.4706369 , 0.21727997, ..., 0.72724867,
          0.17352939, 0.23181123],
         ...],
         [0.35742927, 0.7458289 , 0.49265993, ..., 0.821325  ,
          0.2935797 , 0.85510635]]]], dtype=float32)}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[jax-s2s-False] - TypeError: JAX arrays are immutable and do not support in-place item assignment. Instead of x[idx] = y, use x = x.at[idx]...
FAILED kornia/test_feature4.py::test_KeyNetAffNetHardNet[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[jax-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[jax-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?
FAILED kornia/test_feature4.py::test_LoFTR[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 6 failed, 8 passed in 2573.48s (0:42:53) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py FFF....FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_SIFTFeature[tensorflow-s2s-False] ________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeature(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeature")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeature(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.SIFTFeature(num_features=10)

kornia/test_feature4.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeature object at 0x7fc141b0a770>, num_features = 10, upright = False, rootsift = True
device = 'cpu', config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_BlobDoGSingle
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_BlobDoGSingle(1.0, 1.6),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_PassLAF(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc141b095a0>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc141b095a0>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeature(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeature")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeature(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.SIFTFeature(num_features=10)

kornia/test_feature4.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeature object at 0x7fc141b0b070>, num_features = 10, upright = False, rootsift = True
device = 'cpu', config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_BlobDoGSingle
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_BlobDoGSingle(1.0, 1.6),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_PassLAF(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc141b0b880>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc141b0b880>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeature
kornia.feature.SIFTFeature
___________________________________________________________________________ test_SIFTFeatureScaleSpace[tensorflow-s2s-False] ___________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.SIFTFeatureScaleSpace(num_features=10)

kornia/test_feature4.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeatureScaleSpace object at 0x7fc1601e66e0>, num_features = 10, upright = False, rootsift = True
device = 'cpu'

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_ScaleSpaceDetector
        from .responses import tensorflow_BlobDoG
        from ..geometry.subpix.spatial_soft_argmax import tensorflow_ConvQuadInterp3d
        from ..geometry.transform.pyramid import tensorflow_ScalePyramid
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_ScaleSpaceDetector(
                num_features,
                resp_module=tensorflow_BlobDoG(),
                nms_module=tensorflow_ConvQuadInterp3d(10),
                scale_pyr_module=tensorflow_ScalePyramid(3, 1.6, 32, double_image=True),
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                scale_space_response=True,
                minima_are_also_good=True,
                mr_size=6.0,
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc160535ed0>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc160535ed0>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_3>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.SIFTFeatureScaleSpace(num_features=10)

kornia/test_feature4.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeatureScaleSpace object at 0x7fc160536020>, num_features = 10, upright = False, rootsift = True
device = 'cpu'

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_ScaleSpaceDetector
        from .responses import tensorflow_BlobDoG
        from ..geometry.subpix.spatial_soft_argmax import tensorflow_ConvQuadInterp3d
        from ..geometry.transform.pyramid import tensorflow_ScalePyramid
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_ScaleSpaceDetector(
                num_features,
                resp_module=tensorflow_BlobDoG(),
                nms_module=tensorflow_ConvQuadInterp3d(10),
                scale_pyr_module=tensorflow_ScalePyramid(3, 1.6, 32, double_image=True),
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                scale_space_response=True,
                minima_are_also_good=True,
                mr_size=6.0,
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc160535c90>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc160535c90>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_3>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_3>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
kornia.feature.SIFTFeatureScaleSpace
_____________________________________________________________________________ test_GFTTAffNetHardNet[tensorflow-s2s-False] _____________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_4>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_GFTTAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.GFTTAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.GFTTAffNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.GFTTAffNetHardNet(num_features=10)

kornia/test_feature4.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7fc13a5595d0>, num_features = 10, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:351: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc1405f29b0>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc1405f29b0>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_4>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_4>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_5>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_GFTTAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.GFTTAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.GFTTAffNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.GFTTAffNetHardNet(num_features=10)

kornia/test_feature4.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7fc1405f0c70>, num_features = 10, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:351: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc1405f1960>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fc1405f1960>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_5>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_5>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.GFTTAffNetHardNet
kornia.feature.GFTTAffNetHardNet
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 18.4MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 121MB/s]
____________________________________________________________________________ test_LocalFeatureMatcher[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, .....         [0.73323715, 0.34756082, 0.39979887, ..., 0.7459464 ,
          0.35332012, 0.8364874 ]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, .....         [0.73323715, 0.34756082, 0.39979887, ..., 0.7459464 ,
          0.35332012, 0.8364874 ]]]], dtype=float32)>},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ......,
         [0.73323715, 0.34756082, 0.39979887, ..., 0.7459464 ,
          0.35332012, 0.8364874 ]]]], dtype=float32)>}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.1054477...],
         [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.105447...     [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.105447...     [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>, None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.1054477...],
         [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.105447...     [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.105447...     [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>, None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.1054477...],
         [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.1054477...],
         [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.11229771, 0.6628215 , 0.15853804, ..., 0.1054477...],
         [0.14563215, 0.6605637 , 0.44753164, ..., 0.6879745 ,
          0.21952063, 0.49860722]]]], dtype=float32)>
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_____________________________________________________________________________ test_LightGlueMatcher[tensorflow-s2s-False] ______________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = transpiled_kornia.feature.LightGlueMatcher('disk')

kornia/test_feature4.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import tensorflow_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = tensorflow_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), features = 'disk', conf_ = {}
tensorflow_KORNIA_CHECK = <function tensorflow_KORNIA_CHECK at 0x7fc1402a2b90>, tensorflow_get_item = <function tensorflow_get_item at 0x7fc1402484c0>
tensorflow_Identity = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.linear.tensorflow_Identity'>
tensorflow_load_state_dict_from_url_frnt = <function tensorflow_load_state_dict_from_url_frnt at 0x7fc1402b57e0>, tensorflow_load_frnt = <function tensorflow_load_frnt at 0x7fc1402b5cf0>
ModuleList = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.container.tensorflow_ModuleList'>
KerasDense = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful_layers.KerasDense'>

    @tensorflow_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...torch.nn.modules.linear import tensorflow_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            tensorflow_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            tensorflow_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in tensorflow_get_item(self.features, features).items():
                setattr(conf, k, v)
        tensorflow_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = KerasDense(
                in_features=conf.input_dim, units=conf.descriptor_dim, use_bias=True
            )
        else:
            self.input_proj = tensorflow_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = tensorflow_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = tensorflow_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:1433: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @tensorflow_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = tensorflow_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:976: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @tensorflow_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...torch.nn.modules.normalization import tensorflow_LayerNorm
        from ...torch.nn.modules.activation import tensorflow_GELU
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        tensorflow_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = KerasDense(
            in_features=embed_dim, units=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = tensorflow_Attention(flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), allow_flash = True

    @tensorflow_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:411: NameError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = transpiled_kornia.feature.LightGlueMatcher('disk')

kornia/test_feature4.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import tensorflow_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = tensorflow_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), features = 'disk', conf_ = {}
tensorflow_KORNIA_CHECK = <function tensorflow_KORNIA_CHECK at 0x7fc1402a2b90>, tensorflow_get_item = <function tensorflow_get_item at 0x7fc1402484c0>
tensorflow_Identity = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.linear.tensorflow_Identity'>
tensorflow_load_state_dict_from_url_frnt = <function tensorflow_load_state_dict_from_url_frnt at 0x7fc1402b57e0>, tensorflow_load_frnt = <function tensorflow_load_frnt at 0x7fc1402b5cf0>
ModuleList = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.container.tensorflow_ModuleList'>
KerasDense = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful_layers.KerasDense'>

    @tensorflow_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...torch.nn.modules.linear import tensorflow_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            tensorflow_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            tensorflow_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in tensorflow_get_item(self.features, features).items():
                setattr(conf, k, v)
        tensorflow_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = KerasDense(
                in_features=conf.input_dim, units=conf.descriptor_dim, use_bias=True
            )
        else:
            self.input_proj = tensorflow_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = tensorflow_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = tensorflow_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:1433: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @tensorflow_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = tensorflow_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:976: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @tensorflow_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...torch.nn.modules.normalization import tensorflow_LayerNorm
        from ...torch.nn.modules.activation import tensorflow_GELU
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        tensorflow_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = KerasDense(
            in_features=embed_dim, units=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = tensorflow_Attention(flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), allow_flash = True

    @tensorflow_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:411: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 46%|████▌     | 20.8M/45.4M [00:00<00:00, 217MB/s]
100%|██████████| 45.4M/45.4M [00:00<00:00, 280MB/s]
_________________________________________________________________________________ test_LightGlue[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.7796122 , 0.26016092, 0....    [0.06769645, 0.32952893],
        [0.5022459 , 0.21428418],
        [0.62406915, 0.55308676]]], dtype=float32)>}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.7796122 , 0.26016092, 0....    [0.06769645, 0.32952893],
        [0.5022459 , 0.21428418],
        [0.62406915, 0.55308676]]], dtype=float32)>}},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.7796122 , 0.26016092, 0.3...      [0.06769645, 0.32952893],
        [0.5022459 , 0.21428418],
        [0.62406915, 0.55308676]]], dtype=float32)>}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.7796122 , 0.26016092, 0.3...      [0.06769645, 0.32952893],
        [0.5022459 , 0.21428418],
        [0.62406915, 0.55308676]]], dtype=float32)>}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[6.56503737e-01, 8.38126183e-01],
        [5.89796543e-0...[1.01240277e-01, 3.25255930e-01]]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>)
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = <tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[6.56503737e-01, 8.38126183e-01],
        [5.89796543e-01... 8.55688274e-01],
        [5.46643317e-01, 2.70942926e-01],
        [1.01240277e-01, 3.25255930e-01]]], dtype=float32)>
size = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>, name = 'float'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 54%|█████▍    | 24.6M/45.3M [00:00<00:00, 257MB/s]
100%|██████████| 45.3M/45.3M [00:00<00:00, 279MB/s]
___________________________________________________________________________________ test_LoFTR[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:320: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.91653144, 0.97776836, 0.67296207, .....         [0.00860775, 0.42814016, 0.11810589, ..., 0.8891956 ,
          0.29978383, 0.38493627]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.91653144, 0.97776836, 0.67296207, .....         [0.00860775, 0.42814016, 0.11810589, ..., 0.8891956 ,
          0.29978383, 0.38493627]]]], dtype=float32)>},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.91653144, 0.97776836, 0.67296207, ......,
         [0.00860775, 0.42814016, 0.11810589, ..., 0.8891956 ,
          0.29978383, 0.38493627]]]], dtype=float32)>}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeature[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_GFTTAffNetHardNet[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[tensorflow-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[tensorflow-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'
FAILED kornia/test_feature4.py::test_LoFTR[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 7 failed, 7 passed in 2433.33s (0:40:33) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F...                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_RandomMotionBlur[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'jax', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32), params = None
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3510fa1cf0>, jax_set_item = <function jax_set_item at 0x7f353f3dfd00>, tensor = <function jax_tensor_frnt at 0x7f353f9d5630>
in_tensor = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple((int(jax_item_frnt_(jax_sum_frnt_(to_apply))), *batch_shape[1:]))
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.jax.general import jax_set_item
        from .....ivy.functional.frontends.torch.random_sampling import jax_randint_frnt
    
        params = super().generate_parameters(batch_shape)
        params = jax_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else jax_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:66: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_____________________________________________________________________________ test_RandomSaltAndPepperNoise[jax-s2s-False] _____________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'jax', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.9131, 0.3253, 0.5677],
          [0.3966, 0.3944, 0.5156],
          [0.7384, 0.7613, 0.2660]],

       ...51]],

         [[0.6716, 0.6378, 0.2856],
          [0.8980, 0.2662, 0.0274],
          [0.6041, 0.1337, 0.3325]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9130561 , 0.32525074, 0.567716  ],
         [0.39660037, 0.39436978, 0.51564276],
         [0.7383712 , 0....62534],
         [0.89800906, 0.26619953, 0.02743906],
         [0.604106  , 0.13373762, 0.33254534]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3510391bd0>, jax_set_item = <function jax_set_item at 0x7f3502b876d0>, tensor = <function jax_tensor_frnt at 0x7f3510219ab0>
in_tensor = Array([[[[0.9130561 , 0.32525074, 0.567716  ],
         [0.39660037, 0.39436978, 0.51564276],
         [0.7383712 , 0....62534],
         [0.89800906, 0.26619953, 0.02743906],
         [0.604106  , 0.13373762, 0.33254534]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.9130561 , 0.32525074, 0.567716  ],
         [0.39660037, 0.39436978, 0.51564276],
         [0.7383712 , 0....62534],
         [0.89800906, 0.26619953, 0.02743906],
         [0.604106  , 0.13373762, 0.33254534]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9130561 , 0.32525074, 0.567716  ],
         [0.39660037, 0.39436978, 0.51564276],
         [0.7383712 , 0....62534],
         [0.89800906, 0.26619953, 0.02743906],
         [0.604106  , 0.13373762, 0.33254534]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3510391bd0>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7f353f9f64d0>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7f3502900b80>, jax_get_item = <function jax_get_item at 0x7f3502b87520>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7f3510544c10>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7f3502902b90>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7f3502903a30>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.9130561 , 0.32525074, 0.567716  ],
         [0.39660037, 0.39436978, 0.51564276],
         [0.7383712 , 0....62534],
         [0.89800906, 0.26619953, 0.02743906],
         [0.604106  , 0.13373762, 0.33254534]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import jax_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import jax_clone_frnt_
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK(
            len(jax_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(jax_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        jax_KORNIA_CHECK(
            jax_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = jax_clone_frnt_(input)
        noisy_image = jax_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:92: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
_________________________________________________________________________________ test_RandomSharpness[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:334: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'jax', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.0983, 0.1652, 0.0689, 0.5821, 0.1409],
          [0.8719, 0.1146, 0.1002, 0.7381, 0.6619],
          [0...., 0.4881],
          [0.6250, 0.7111, 0.6612, 0.5682, 0.2983],
          [0.8189, 0.7285, 0.4678, 0.4528, 0.1010]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.09831923, 0.16522878, 0.06891125, 0.5821429 , 0.14091748],
         [0.8718862 , 0.11464655, 0.10020322, 0... 0.56819963, 0.29828185],
         [0.8189352 , 0.72851515, 0.467804  , 0.4527611 , 0.10103297]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f350229eb00>, jax_set_item = <function jax_set_item at 0x7f3510dd8700>, tensor = <function jax_tensor_frnt at 0x7f353f640670>
in_tensor = Array([[[[0.09831923, 0.16522878, 0.06891125, 0.5821429 , 0.14091748],
         [0.8718862 , 0.11464655, 0.10020322, 0... 0.56819963, 0.29828185],
         [0.8189352 , 0.72851515, 0.467804  , 0.4527611 , 0.10103297]]]],      dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.09831923, 0.16522878, 0.06891125, 0.5821429 , 0.14091748],
         [0.8718862 , 0.11464655, 0.10020322, 0... 0.56819963, 0.29828185],
         [0.8189352 , 0.72851515, 0.467804  , 0.4527611 , 0.10103297]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.09831923, 0.16522878, 0.06891125, 0.5821429 , 0.14091748],
         [0.8718862 , 0.11464655, 0.10020322, 0... 0.56819963, 0.29828185],
         [0.8189352 , 0.72851515, 0.467804  , 0.4527611 , 0.10103297]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f350229eb00>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7f350229d6c0>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7f350229c670>, jax_get_item = <function jax_get_item at 0x7f3510dd8550>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7f3510d957e0>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7f350229f7f0>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7f350229c8b0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.09831923, 0.16522878, 0.06891125, 0.5821429 , 0.14091748],
         [0.8718862 , 0.11464655, 0.10020322, 0... 0.56819963, 0.29828185],
         [0.8189352 , 0.72851515, 0.467804  , 0.4527611 , 0.10103297]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: name 'sharpness' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/sharpness.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[jax-s2s-False] - TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[jax-s2s-False] - NameError: name 'sharpness' is not defined
============================================================================== 3 failed, 14 passed in 3253.20s (0:54:13) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py Fs                                                                                                                                                                  [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_fit_line[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_fit_line(target_framework, mode, backend_compile):
        print("kornia.geometry.line.fit_line")
    
        if backend_compile:
            pytest.skip()
    
>       transpiled_fit_line = ivy.transpile(kornia.geometry.line.fit_line, source="torch", target=target_framework)

kornia/geometry/test_line.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <function fit_line at 0x7fc922b5b490>, source = 'torch', target = 'numpy', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fc8cbaf7b80>, node = <gast.gast.Module object at 0x7fc8cb1ed6f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fc8cbaf7b80>, node = <gast.gast.Module object at 0x7fc8cb1ed6f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fc8cbaf7b80>, node = <gast.gast.FunctionDef object at 0x7fc8cb1ef5b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fc8cbaf7b80>, node = <gast.gast.Return object at 0x7fc8cb1eceb0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fc8cbaf7b80>, node = <gast.gast.Return object at 0x7fc8cb1eceb0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fc8cbaf7b80>, node = <gast.gast.Call object at 0x7fc8cb1ec670>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fc8cbaf7b80>, node = <gast.gast.Call object at 0x7fc8cb1ec670>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fc8cbaf7b80>, node = <gast.gast.Name object at 0x7fc8cb1ed480>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_ParametrizedLine'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.line.fit_line
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_line.py::test_fit_line[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_Para...
=============================================================================== 1 failed, 1 skipped in 66.33s (0:01:06) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 296.11s (0:04:56) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF...F............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_HausdorffERLoss[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = transpiled_kornia.losses.HausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 4.56978470e-01,  1.50141895e+00,  1.64374530e+00, ...,
          -1.07543445e+00,  1.90617949e-01,  1.70821...3582066e-01,  4.55531001e-01, ...,
          -1.82154909e-01,  4.01813060e-01, -7.23979294e-01]]]],      dtype=float32)
target = Array([[[[1, 0, 0, ..., 0, 1, 1],
         [1, 1, 0, ..., 1, 0, 0],
         [0, 1, 1, ..., 1, 0, 0],
         ...,
  ...,
         [0, 0, 1, ..., 0, 0, 1],
         [0, 1, 0, ..., 0, 1, 1],
         [1, 0, 1, ..., 1, 0, 0]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_min_frnt_
    
        if jax_dim_frnt_(pred) != 4:
            raise ValueError(f"Only 2D images supported. Got {jax_dim_frnt_(pred)}.")
        if not (
            jax_max_frnt_(target) < jax_size_frnt_(pred, 1)
            and jax_min_frnt_(target) >= 0
            and target.dtype == jnp.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {jax_size_frnt_(pred, 1)}). ({jax_min_frnt_(target)}, {jax_max_frnt_(target)})"
            )
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 4.56978470e-01,  1.50141895e+00,  1.64374530e+00, ...,
          -1.07543445e+00,  1.90617949e-01,  1.70821...3582066e-01,  4.55531001e-01, ...,
          -1.82154909e-01,  4.01813060e-01, -7.23979294e-01]]]],      dtype=float32)
target = Array([[[[1, 0, 0, ..., 0, 1, 1],
         [1, 1, 0, ..., 1, 0, 0],
         [0, 1, 1, ..., 1, 0, 0],
         ...,
  ...,
         [0, 0, 1, ..., 0, 0, 1],
         [0, 1, 0, ..., 0, 1, 1],
         [1, 0, 1, ..., 1, 0, 0]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f1a0eb2edf0>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 4.56978470e-01,  1.50141895e+00,  1.64374530e+00, ...,
          -1.07543445e+00,  1.90617949e-01,  1.70821...2269284e-01, -6.11230671e-01, ...,
          -1.46713078e+00,  6.88860774e-01, -5.84577858e-01]]]],      dtype=float32)
target = Array([[[[0, 1, 1, ..., 1, 0, 0],
         [0, 0, 1, ..., 0, 1, 1],
         [1, 0, 0, ..., 0, 1, 1],
         ...,
  ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 0, 1, ..., 1, 0, 0],
         [0, 1, 0, ..., 0, 1, 1]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
kornia.losses.HausdorffERLoss
________________________________________________________________________________ test_HausdorffERLoss3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = transpiled_kornia.losses.HausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[-5.87180674e-01, -7.45326459e-01,  1.26484823e+00, ...,
           -1.40005028e+00, -1.23271608e+00, -1.961...16554e-01,  5.84897459e-01, ...,
           -1.99284747e-01, -1.47898567e+00,  1.01438963e+00]]]]],      dtype=float32)
target = Array([[[[[0, 0, 1, ..., 0, 0, 0],
          [1, 1, 0, ..., 1, 1, 0],
          [1, 1, 0, ..., 1, 1, 0],
          ......        [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 0, 1, 1],
          [1, 0, 0, ..., 0, 1, 0]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
    
        if jax_dim_frnt_(pred) != 5:
            raise ValueError(f"Only 3D images supported. Got {jax_dim_frnt_(pred)}.")
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[-5.87180674e-01, -7.45326459e-01,  1.26484823e+00, ...,
           -1.40005028e+00, -1.23271608e+00, -1.961...16554e-01,  5.84897459e-01, ...,
           -1.99284747e-01, -1.47898567e+00,  1.01438963e+00]]]]],      dtype=float32)
target = Array([[[[[0, 0, 1, ..., 0, 0, 0],
          [1, 1, 0, ..., 1, 1, 0],
          [1, 1, 0, ..., 1, 1, 0],
          ......        [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 0, 1, 1],
          [1, 0, 0, ..., 0, 1, 0]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f1a0d15fdb0>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[-5.87180674e-01, -7.45326459e-01,  1.26484823e+00, ...,
           -1.40005028e+00, -1.23271608e+00, -1.961...23835e-02,  1.91436601e+00, ...,
           -5.12895763e-01,  1.22282609e-01, -1.61507773e+00]]]]],      dtype=float32)
target = Array([[[[[1, 1, 0, ..., 1, 1, 1],
          [0, 0, 1, ..., 0, 0, 1],
          [0, 0, 1, ..., 0, 0, 1],
          ......        [1, 1, 1, ..., 1, 1, 1],
          [0, 1, 0, ..., 1, 0, 0],
          [0, 1, 1, ..., 1, 0, 1]]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
kornia.losses.HausdorffERLoss3D
__________________________________________________________________________________ test_TotalVariation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TotalVariation(target_framework, mode, backend_compile):
        print("kornia.losses.TotalVariation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_loss_fn = kornia.losses.TotalVariation()
        transpiled_loss_fn = transpiled_kornia.losses.TotalVariation()
    
        torch_args = (
            torch.ones((2, 3, 4, 4)),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args).data
>       transpiled_res = transpiled_loss_fn(*transpiled_args).data
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'

kornia/test_losses.py:570: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.TotalVariation
kornia.losses.TotalVariation
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[jax-s2s-False] - TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[jax-s2s-False] - TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_TotalVariation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'
============================================================================== 3 failed, 32 passed in 2418.18s (0:40:18) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .F...F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_NerfModelRenderer[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
_____________________________________________________________________________ test_RandomRaySampler[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7f555cd65e40>
cameras = <ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.camera.pinhole.tensorflow_PinholeCamera object at 0x7f555e7371f0>
num_img_rays = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != tensorflow_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {tensorflow_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7f555cd65e40>, heights = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>
widths = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>, num_img_rays = <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_trunc_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_rand_frnt,
        )
    
        num_img_rays = tensorflow_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                tensorflow_tolist_frnt_(heights),
                tensorflow_tolist_frnt_(widths),
                tensorflow_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = tensorflow_trunc_frnt(
>               tensorflow_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:364: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
tensorflow_random_uniform = <function tensorflow_random_uniform at 0x7f555df1d090>, seed = None

    def tensorflow_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.tensorflow.random import tensorflow_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return tensorflow_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/random_sampling.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, tensorflow_exists_bknd = <function tensorflow_exists_bknd at 0x7f555e02b5b0>
tensorflow_default_dtype_bknd = <function tensorflow_default_dtype_bknd at 0x7f555e02ac20>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import tensorflow_exists_bknd
        from .functional.ivy.data_type import tensorflow_default_dtype_bknd
    
        arr = (
            None
            if tensorflow_exists_bknd(dtype)
            else tensorflow__get_first_array(*args, **kwargs)
        )
        dtype = tensorflow_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @tensorflow_infer_dtype
    def tensorflow_random_uniform(
        *,
        low: Union[float, tensorflow.Tensor, tensorflow.Variable] = 0.0,
        high: Union[float, tensorflow.Tensor, tensorflow.Variable, None] = 1.0,
        shape: Optional[Union[tf.TensorShape, Sequence[int], tensorflow.Tensor]] = None,
        dtype: tf.DType,
        device: Optional[str] = None,
        seed: Optional[int] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.random import tensorflow__check_bounds_and_get_shape_bknd
    
        shape = tensorflow__check_bounds_and_get_shape_bknd(
            low,
            float(
                tensorflow.experimental.numpy.finfo(tensorflow.float32).max
                if dtype is None
                else tensorflow.experimental.numpy.finfo(dtype).max
            )
            if high is None
            else high,
            shape,
        )
>       low = tensorflow.cast(low, dtype)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/random.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (0.0, torch.float32), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type_value = torch.float32

    @tf_export("dtypes.as_dtype", "as_dtype")
    def as_dtype(type_value):
      """Converts the given `type_value` to a `tf.DType`.
    
      Inputs can be existing `tf.DType` objects, a [`DataType`
      enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),
      a string type name, or a
      [`numpy.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html).
    
      Examples:
      >>> tf.as_dtype(2)  # Enum value for float64.
      tf.float64
    
      >>> tf.as_dtype('float')
      tf.float32
    
      >>> tf.as_dtype(np.int32)
      tf.int32
    
      Note: `DType` values are interned (i.e. a single instance of each dtype is
      stored in a map). When passed a new `DType` object, `as_dtype` always returns
      the interned value.
    
      Args:
        type_value: A value that can be converted to a `tf.DType` object.
    
      Returns:
        A `DType` corresponding to `type_value`.
    
      Raises:
        TypeError: If `type_value` cannot be converted to a `DType`.
      """
      if isinstance(type_value, DType):
        if type_value._handle_data is None:  # pylint:disable=protected-access
          return _INTERN_TABLE[type_value.as_datatype_enum]
        else:
          return type_value
    
      if isinstance(type_value, np.dtype):
        try:
          return _NP_TO_TF[type_value.type]
        except KeyError:
          pass
    
      try:
        return _ANY_TO_TF[type_value]
      except (KeyError, TypeError):
        # TypeError indicates that type_value is not hashable.
        pass
    
      if hasattr(type_value, "dtype"):
        try:
          return _NP_TO_TF[np.dtype(type_value.dtype).type]
        except (KeyError, TypeError):
          pass
    
      if isinstance(type_value, _dtypes.DType):
        return _INTERN_TABLE[type_value.as_datatype_enum]
    
>     raise TypeError(f"Cannot convert the argument `type_value`: {type_value!r} "
                      "to a TensorFlow DType.")
E     TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.

/opt/fw/tensorflow/tensorflow/python/framework/dtypes.py:852: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[tensorflow-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_RandomRaySampler[tensorflow-s2s-False] - TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.
=============================================================================== 2 failed, 4 passed in 536.51s (0:08:56) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py .......F.....F..F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_laf_is_inside_image[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_laf_is_inside_image(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 5, 2, 3),
            torch.rand(1, 1, 32, 32),
        )
        trace_kwargs = {'border': 0}
        test_args = (
            torch.rand(2, 10, 2, 3),
            torch.rand(2, 1, 64, 64),
        )
        test_kwargs = {'border': 1}
>       _test_function(
            kornia.feature.laf_is_inside_image,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_feature2.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7f7ea2414d30>
trace_args = (tensor([[[[0.5137, 0.6230, 0.4506],
          [0.0385, 0.2627, 0.3001]],

         [[0.6616, 0.6244, 0.5443],
       ...8, 0.2083, 0.2848,  ..., 0.6821, 0.1026, 0.6585],
          [0.1670, 0.0539, 0.1587,  ..., 0.6898, 0.7753, 0.2965]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.8602, 0.9125, 0.3796],
          [0.9276, 0.4335, 0.8688]],

         [[0.9956, 0.1898, 0.4155],
       ...8, 0.7421, 0.3641,  ..., 0.7427, 0.0198, 0.8012],
          [0.7397, 0.6288, 0.1410,  ..., 0.4690, 0.0860, 0.0132]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7f7ea2414d30>, fn_name = 'kornia.feature.laf_is_inside_image'
trace_args = (tensor([[[[0.5137, 0.6230, 0.4506],
          [0.0385, 0.2627, 0.3001]],

         [[0.6616, 0.6244, 0.5443],
       ...8, 0.2083, 0.2848,  ..., 0.6821, 0.1026, 0.6585],
          [0.1670, 0.0539, 0.1587,  ..., 0.6898, 0.7753, 0.2965]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.8602, 0.9125, 0.3796],
          [0.9276, 0.4335, 0.8688]],

         [[0.9956, 0.1898, 0.4155],
       ...8, 0.7421, 0.3641,  ..., 0.7427, 0.0198, 0.8012],
          [0.7397, 0.6288, 0.1410,  ..., 0.4690, 0.0860, 0.0132]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 5, 2, 3), dtype=float32, numpy=
array([[[[0.5137345 , 0.62296945, 0.45060378],
         [0.03847...95]],

        [[0.96783775, 0.14926898, 0.57016885],
         [0.37822402, 0.5469555 , 0.35852122]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[0.5554796 , 0.26892382, 0.4325205 , ..., 0.13679159,...],
         [0.16701043, 0.05392438, 0.15869915, ..., 0.68981427,
          0.77526915, 0.29648054]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True,  True, False, False,
         False,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True,  True, False, False,
         False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True,  True, False, False,
         False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True,  True, False, False,
         False,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:151: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fal...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      if not ops.is_auto_dtype_conversion_enabled():
>       return op(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/ops/weak_tensor_ops.py:142: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fal...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

e = _NotOkStatusException(), name = None

    def raise_from_not_ok_status(e, name) -> NoReturn:
      e.message += (" name: " + str(name if name is not None else ""))
>     raise core._status_to_exception(e) from None  # pylint: disable=protected-access
E     tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E     	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name:

/opt/fw/tensorflow/tensorflow/python/framework/ops.py:5983: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.laf.laf_is_inside_image
_______________________________________________________________________________ test_MKDDescriptor[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MKDDescriptor(target_framework, mode, backend_compile):
        print("kornia.feature.MKDDescriptor")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(23, 1, 32, 32)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.MKDDescriptor()
        torch_out = model(x)
    
>       transpiled_model = transpiled_kornia.feature.MKDDescriptor()

kornia/test_feature2.py:339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_MKDDescriptor' object has no attribute 'output_dims'") raised in repr()] tensorflow_MKDDescriptor object at 0x7f7e40cf3c70>, patch_size = 32
kernel_type = 'concat', whitening = 'pcawt', training_set = 'liberty', output_dims = 128

    def __init__(
        self,
        patch_size=32,
        kernel_type="concat",
        whitening="pcawt",
        training_set="liberty",
        output_dims=128,
    ):
        from ..filters.gaussian import tensorflow_GaussianBlur2d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            patch_size=patch_size,
            kernel_type=kernel_type,
            whitening=whitening,
            training_set=training_set,
            output_dims=output_dims,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size: typing.Any = patch_size
        self.kernel_type: typing.Any = kernel_type
        self.whitening: typing.Any = whitening
        self.training_set: typing.Any = training_set
        self.sigma = 1.4 * (patch_size / 64)
        self.smoothing = tensorflow_GaussianBlur2d(
            (5, 5), (self.sigma, self.sigma), "replicate"
        )
        self.gradients = tensorflow_MKDGradients()
        polar_s: typing.Any = "polar"
        cart_s: typing.Any = "cart"
        self.parametrizations = (
            [polar_s, cart_s] if self.kernel_type == "concat" else [self.kernel_type]
        )
        self.odims: typing.Any = 0
        relative_orientations = {polar_s: True, cart_s: False}
        self.feats = {}
        for parametrization in self.parametrizations:
            gradient_embedding = tensorflow_EmbedGradients(
                patch_size=patch_size,
                relative=tensorflow_get_item(relative_orientations, parametrization),
            )
>           spatial_encoding = tensorflow_ExplicitSpacialEncoding(
                kernel_type=parametrization,
                fmap_size=patch_size,
                in_dims=gradient_embedding.kernel.d,
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:989: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7f7e2c3d9e40>, args = ()
kwargs = {'fmap_size': 32, 'in_dims': 7, 'kernel_type': 'polar'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7f7e2c3d9e40>, kernel_type = 'polar'
fmap_size = 32, in_dims = 7, do_gmask = True, do_l2 = True

    @tensorflow_store_config_info
    def __init__(
        self, kernel_type="polar", fmap_size=32, in_dims=7, do_gmask=True, do_l2=True
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        self.super___init__(
            kernel_type=kernel_type,
            fmap_size=fmap_size,
            in_dims=in_dims,
            do_gmask=do_gmask,
            do_l2=do_l2,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if kernel_type not in ["polar", "cart"]:
            raise NotImplementedError(
                f"{kernel_type} is not valid, use polar or cart)."
            )
        self.kernel_type = kernel_type
        self.fmap_size = fmap_size
        self.in_dims = in_dims
        self.do_gmask = do_gmask
        self.do_l2 = do_l2
        self.grid = tensorflow_get_grid_dict(fmap_size)
        self.gmask = None
>       emb = tensorflow_spatial_kernel_embedding(self.kernel_type, self.grid)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:575: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kernel_type = 'polar'
grids = {'x': <tf.Tensor: shape=(32, 32), dtype=float32, numpy=
array([[-1.        , -0.9354839 , -0.87096775, ...,  0.8709677...,
       [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
         0.81871915,  0.7853981 ]], dtype=float32)>}

    def tensorflow_spatial_kernel_embedding(kernel_type, grids):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_select_frnt_
        from ..constants import pi
    
        factors = {"phi": 1.0, "rho": pi / sqrt2, "x": pi / 2, "y": pi / 2}
        if kernel_type == "cart":
            coeffs_ = "xy"
            params_ = ["x", "y"]
        elif kernel_type == "polar":
            coeffs_ = "rhophi"
            params_ = ["phi", "rho"]
        keys = list(grids.keys())
        patch_size = tensorflow_shape_frnt_(tensorflow_get_item(grids, keys[0]))[-1]
        grids_normed = {k: (v * tensorflow_get_item(factors, k)) for k, v in grids.items()}
        grids_normed = {
            k: tensorflow_float_frnt_(
                tensorflow_unsqueeze_frnt_(tensorflow_unsqueeze_frnt_(v, 0), 0)
            )
            for k, v in grids_normed.items()
        }
        vm_a = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        vm_b = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        emb_a = tensorflow_squeeze_frnt_(
>           vm_a(tensorflow_get_item(grids_normed, params_[0]))
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:534: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55e701b15d70, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...est_MKDDescriptor', code_context=['    transpiled_model = transpiled_kornia.feature.MKDDescriptor()\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
x = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ..core._backend import cos
        from ..core._backend import sin
    
        if not isinstance(x, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(x)}")
        if not len(tensorflow_shape_frnt_(x)) == 4 or tensorflow_shape_frnt_(x)[1] != 1:
            raise ValueError(
                f"Invalid input shape, we expect Bx1xHxW. Got: {tensorflow_shape_frnt_(x)}"
            )
        if not isinstance(self.emb0, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Emb0 type is not a Tensor. Got {type(x)}")
        emb0 = tensorflow_repeat_frnt_(
            tensorflow_to_frnt_(self.emb0, x), tensorflow_size_frnt_(x, 0), 1, 1, 1
        )
        frange = tensorflow_to_frnt_(self.frange, x) * x
        emb1 = cos(frange)
        emb2 = sin(frange)
        embedding = tensorflow_cat_frnt([emb0, emb1, emb2], dim=1)
>       embedding = self.pt_weights * embedding

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), name = 'pt_weights'

    @tf.autograph.experimental.do_not_convert
    def __getattr__(self, name):
        if name == "v":
            if not super().__getattribute__("_v") and not getattr(  # noqa: E501
                self, "_built", False
            ):
                return self._build_and_return_v(
                    *self._args, dynamic_backend=self._dynamic_backend, **self._kwargs
                )
    
        _dict = super().__getattribute__("__dict__")
        if name in _dict:
            return _dict[name]
    
        elif "_v" in _dict and name in _dict["_v"]:
            return _dict["_v"][name]
    
>       return super().__getattribute__(name)
E       AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
E       
E       [1m'tensorflow_VonMisesKernel' object has no attribute 'pt_weights'[0m
E       
E       Arguments received by tensorflow_VonMisesKernel.call():
E         • x=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1343: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.MKDDescriptor
kornia.feature.MKDDescriptor
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/manyids2/mkd_pytorch/raw/master/mkd_pytorch/mkd-concat-64.pth" to /root/.cache/torch/hub/checkpoints/mkd-concat-64.pth

  0%|          | 0.00/1.31M [00:00<?, ?B/s]
100%|██████████| 1.31M/1.31M [00:00<00:00, 43.8MB/s]
___________________________________________________________________________________ test_HyNet[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HyNet(target_framework, mode, backend_compile):
        print("kornia.feature.HyNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HyNet()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = transpiled_kornia.feature.HyNet()(transpiled_x)

kornia/test_feature2.py:397: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.44000894, 0.13488883, 0.6475373 , ..., 0.9267518...
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7e1e1bf300, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...,
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.44000894, 0.13488883, 0.6475373 , ..., 0.9267518...
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...,
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.44000894, 0.13488883, 0.6475373 , ..., 0.9267518...
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...flow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
),)
kwargs = {'x': <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.44000894, 0.13488883, 0.6475373 , ..., 0.92...,
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.44000894, 0.13488883, 0.6475373 , ..., 0.92675185...],
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
    
>       x = self.layer1(x)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:543: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
)
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.44000894, 0.13488883, 0.6475373 , ..., 0.9267518...
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55e703d18810, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
), v = None
buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.44000894, 0.13488883, 0.6475373 , ..., 0.9267518...
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
), v = None
buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.44000894, 0.13488883, 0.6475373 , ..., 0.9267518...
         [0.35064322, 0.44643968, 0.867165  , ..., 0.95516604,
          0.43272215, 0.1804133 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
)
input = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.7614204 , 0.2334205 , 1.1205411 , ..., 1.6037123 ...],
         [0.59112436, 0.75262076, 1.4618915 , ..., 1.6102462 ,
          0.72949535, 0.3041459 ]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.7614204 , 0.2334205 , 1.1205411 , ..., 1.6037123...
         [0.59112436, 0.75262076, 1.4618915 , ..., 1.6102462 ,
          0.72949535, 0.3041459 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f7e2c665090, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.7614204 , 0.2334205 , 1.1205411 , ..., 1.6037123...
         [0.59112436, 0.75262076, 1.4618915 , ..., 1.6102462 ,
          0.72949535, 0.3041459 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.7614204 , 0.2334205 , 1.1205411 , ..., 1.6037123...
         [0.59112436, 0.75262076, 1.4618915 , ..., 1.6102462 ,
          0.72949535, 0.3041459 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.7614204 , 0.2334205 , 1.1205411 , ..., 1.6037123 ...],
         [0.59112436, 0.75262076, 1.4618915 , ..., 1.6102462 ,
          0.72949535, 0.3041459 ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_max_frnt
    
>       return tensorflow_max_frnt(x, self.tau)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dim = <KerasVariable shape=(1, 1, 1, 1), dtype=float32, path=variable_45>, keepdim = False, out = None
input = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.7614204 , 0.2334205 , 1.1205411 , ..., 1.6037123 ...],
         [0.59112436, 0.75262076, 1.4618915 , ..., 1.6102462 ,
          0.72949535, 0.3041459 ]]]], dtype=float32)>

    def tensorflow_max_frnt(*input, dim=None, keepdim=False, out=None):
        from ...ivy.general import tensorflow_is_array_bknd
        from .comparison_ops import tensorflow_maximum_frnt
        from ...backends.tensorflow.statistical import tensorflow_max
        from ...backends.tensorflow.searching import tensorflow_argmax
    
        if len(input) == 1:
            input = input[0]
        elif len(input) == 2:
            input_0 = input[0]
            input_1 = input[1]
            if tensorflow_is_array_bknd(input_1):
                return tensorflow_maximum_frnt(*input)
            else:
                input = input_0
                dim = input_1
        else:
            input = input[0]
            dim = input[1]
            keepdim = input[2]
        if dim is None:
            return tensorflow_max(input, axis=dim, keepdims=keepdim, out=out)
        elif out is not None:
            tensorflow_max(input, axis=dim, keepdims=keepdim, out=out[0])
            tensorflow_argmax(input, axis=dim, keepdims=keepdim, out=out[1])
            return out
        else:
            max_tuple = namedtuple("max", ["values", "indices"])
            return max_tuple(
>               tensorflow_max(input, axis=dim, keepdims=keepdim),
                tensorflow_argmax(input, axis=dim, keepdims=keepdim),
            )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/reduction_ops.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.7614204 , 0.2334205 , 1.1205411 , ..., 1.6037123...,
         [0.59112436, 0.75262076, 1.4618915 , ..., 1.6102462 ,
          0.72949535, 0.3041459 ]]]], dtype=float32)>]
kwargs = {'axis': <KerasVariable shape=(1, 1, 1, 1), dtype=float32, path=variable_45>, 'keepdims': False}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f7e1c4e3010>
tensorflow_set_item = <function tensorflow_set_item at 0x7f7e1c274430>, tensorflow_asarray = <function tensorflow_asarray at 0x7f7e1c30d480>
tensorflow_get_item = <function tensorflow_get_item at 0x7f7e1c274280>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'axis', 'keepdims', 'out']
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[int, ...s 'bool'>, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType]]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.7614204 , 0.2334205 , 1.1205411 , ..., 1.6037123 ...],
         [0.59112436, 0.75262076, 1.4618915 , ..., 1.6102462 ,
          0.72949535, 0.3041459 ]]]], dtype=float32)>

    @tensorflow_handle_array_like_without_promotion
    def tensorflow_max(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        axis: Optional[Union[int, Sequence[int]]] = None,
        keepdims: bool = False,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        if "complex" in str(x.dtype):
            real = tensorflow.math.real(x)
            img = tensorflow.math.imag(x)
            const = tensorflow.constant(1.0j, dtype=x.dtype)
            real_max = tensorflow.reduce_max(real, axis=axis, keepdims=keepdims)
            imag = tensorflow.where(
                real == real_max, img, tensorflow.experimental.numpy.finfo(img.dtype).min
            )
            img_max = tensorflow.reduce_max(imag, axis=axis, keepdims=keepdims)
            img_max = tensorflow.cast(img_max, x.dtype)
            return tensorflow.add(
                tensorflow.cast(real_max, x.dtype), tensorflow.multiply(img_max, const)
            )
        axis = tuple(axis) if isinstance(axis, list) else axis
>       return tensorflow.math.reduce_max(x, axis=axis, keepdims=keepdims)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
E       
E       [1mValue for attr 'Tidx' of float is not in the list of allowed values: int32, int64
E       	; NodeDef: {{node Max}}; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Max][0m
E       
E       Arguments received by tensorflow_TLU.call():
E         • x=tf.Tensor(shape=(16, 1, 32, 32), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/statistical.py:95: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HyNet
kornia.feature.HyNet
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_laf_is_inside_image[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allow...
FAILED kornia/test_feature2.py::test_MKDDescriptor[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
FAILED kornia/test_feature2.py::test_HyNet[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
============================================================================== 3 failed, 14 passed in 1429.75s (0:23:49) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ......                                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 3132.00s (0:52:11) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...............F.                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________________ test_HardNet8[jax-s2s-False] _____________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HardNet8(target_framework, mode, backend_compile):
        print("kornia.feature.HardNet8")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HardNet8()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = transpiled_kornia.feature.HardNet8()(transpiled_x)

kornia/test_feature2.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet8(
  (features): jax_Sequential(
    (0): FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), stri...es=(1, 1), padding=0, padding_mode=zeros)
    (23): FlaxBatchNorm2D(512, eps=1e-05, momentum=0.99, affine=False, 
  )
)
input = Array([[[[0.54812473, 0.28339565, 0.6467209 , ..., 0.02731544,
          0.8345826 , 0.4301535 ],
         [0.9713111 ... ],
         [0.9405024 , 0.21048385, 0.7725998 , ..., 0.9079682 ,
          0.990794  , 0.67980254]]]], dtype=float32)

    def __call__(self, input):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.jit._jit_internal import (
            jax_annotate_frnt,
        )
        from ...ivy.functional.frontends.torch.nn.functional.non_linear_activation_functions import (
            jax_normalize_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.blas_and_lapack_ops import jax_mm_frnt
    
        jax_KORNIA_CHECK_SHAPE(input, ["B", "1", "32", "32"])
        x_norm: typing.Any = self._normalize_input(input)
>       x_features: typing.Any = self.features(x_norm)

ivy_transpiled_outputs/jax_outputs/kornia/feature/hardnet.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Sequential(
  (0): FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding... strides=(1, 1), padding=0, padding_mode=zeros)
  (23): FlaxBatchNorm2D(512, eps=1e-05, momentum=0.99, affine=False, 
)
input = Array([[[[ 0.20395662, -0.70256877,  0.5415845 , ..., -1.5794774 ,
           1.1848891 , -0.20001838],
         [ 1.6...       [ 1.4748493 , -1.0418304 ,  0.8960188 , ...,  1.3626904 ,
           1.6482255 ,  0.57610774]]]], dtype=float32)

    def __call__(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/jax_outputs/torch/nn/modules/container.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
args = (Array([[[[ 0.20395662, -0.70256877,  0.5415845 , ..., -1.5794774 ,
           1.1848891 , -0.20001838],
         [ 1....     [ 1.4748493 , -1.0418304 ,  0.8960188 , ...,  1.3626904 ,
           1.6482255 ,  0.57610774]]]], dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5625844c3f90, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...neno=103, function='_multicall', code_context=['                    res = hook_impl.function(*args)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
args = (Array([[[[ 0.20395662, -0.70256877,  0.5415845 , ..., -1.5794774 ,
           1.1848891 , -0.20001838],
         [ 1....     [ 1.4748493 , -1.0418304 ,  0.8960188 , ...,  1.3626904 ,
           1.6482255 ,  0.57610774]]]], dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7fdaf046b910>, jax_set_item = <function jax_set_item at 0x7fdaf046bac0>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[ 0.20395662],
         [-0.70256877],
         [ 0.5415845 ],
         ...,
         [-1.5794774 ...[ 0.8960188 ],
         ...,
         [ 1.3626904 ],
         [ 1.6482255 ],
         [ 0.57610774]]]], dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7fdaf087fd90>
next_call_in_seq = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , conv_block_continued = True, arg_name = 'inputs'
input = Array([[[[ 0.20395662, -0.70256877,  0.5415845 , ..., -1.5794774 ,
           1.1848891 , -0.20001838],
         [ 1.6...       [ 1.4748493 , -1.0418304 ,  0.8960188 , ...,  1.3626904 ,
           1.6482255 ,  0.57610774]]]], dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
inputs = Array([[[[ 0.20395662],
         [-0.70256877],
         [ 0.5415845 ],
         ...,
         [-1.5794774 ],
        ... [ 0.8960188 ],
         ...,
         [ 1.3626904 ],
         [ 1.6482255 ],
         [ 0.57610774]]]], dtype=float32)

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs):
        self._built = True
        if self.padding_mode != "zeros":
            padding_mode = (
                "constant" if self.padding_mode == "zeros" else self.padding_mode
            )
            # handle Pytorch-style padding
            inputs = torch_pad(
                inputs, self._reversed_padding_repeated_twice, mode=padding_mode
            )
            old_pad = self.padding
            self.padding = 0
            logits = super().__call__(inputs)
            self.padding = old_pad
            self._built = False
            return logits
>       logits = super().__call__(inputs)

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
inputs = Array([[[[ 0.20395662],
         [-0.70256877],
         [ 0.5415845 ],
         ...,
         [-1.5794774 ],
        ... [ 0.8960188 ],
         ...,
         [ 1.3626904 ],
         [ 1.6482255 ],
         [ 0.57610774]]]], dtype=float32)

    def __call__(self, inputs: Array) -> Array:
      """Applies a (potentially unshared) convolution to the inputs.
    
      Args:
        inputs: input data with dimensions ``(*batch_dims, spatial_dims..., features)``.
          This is the channels-last convention, i.e. NHWC for a 2d convolution and
          NDHWC for a 3D convolution. Note: this is different from the input convention
          used by ``lax.conv_general_dilated``, which puts the spatial dimensions last.
          Note: If the input has more than 1 batch dimension, all batch dimensions
          are flattened into a single dimension for the convolution and restored
          before returning.  In some cases directly vmap'ing the layer may yield
          better performance than this default flattening approach.  If the input
          lacks a batch dimension it will be added for the convolution and removed
          n return, an allowance made to enable writing single-example code.
    
      Returns:
        The convolved data.
      """
    
      assert isinstance(self.kernel_size, tuple)
      kernel_size = self.kernel_size
    
      def maybe_broadcast(
        x: tp.Optional[tp.Union[int, tp.Sequence[int]]],
      ) -> tuple[int, ...]:
        if x is None:
          # backward compatibility with using None as sentinel for
          # broadcast 1
          x = 1
        if isinstance(x, int):
          return (x,) * len(kernel_size)
        return tuple(x)
    
      # Combine all input batch dimensions into a single leading batch axis.
      num_batch_dimensions = inputs.ndim - (len(kernel_size) + 1)
      if num_batch_dimensions != 1:
        input_batch_shape = inputs.shape[:num_batch_dimensions]
        total_batch_size = int(np.prod(input_batch_shape))
        flat_input_shape = (total_batch_size,) + inputs.shape[
          num_batch_dimensions:
        ]
        inputs = jnp.reshape(inputs, flat_input_shape)
    
      # self.strides or (1,) * (inputs.ndim - 2)
      strides = maybe_broadcast(self.strides)
      input_dilation = maybe_broadcast(self.input_dilation)
      kernel_dilation = maybe_broadcast(self.kernel_dilation)
    
      padding_lax = canonicalize_padding(self.padding, len(kernel_size))
      if padding_lax == 'CIRCULAR':
        kernel_size_dilated = [
          (k - 1) * d + 1 for k, d in zip(kernel_size, kernel_dilation)
        ]
        zero_pad: tp.List[tuple[int, int]] = [(0, 0)]
        pads = (
          zero_pad
          + [((k - 1) // 2, k // 2) for k in kernel_size_dilated]
          + [(0, 0)]
        )
        inputs = jnp.pad(inputs, pads, mode='wrap')
        padding_lax = 'VALID'
      elif padding_lax == 'CAUSAL':
        if len(kernel_size) != 1:
          raise ValueError(
            'Causal padding is only implemented for 1D convolutions.'
          )
        left_pad = kernel_dilation[0] * (kernel_size[0] - 1)
        pads = [(0, 0), (left_pad, 0), (0, 0)]
        inputs = jnp.pad(inputs, pads)
        padding_lax = 'VALID'
    
      dimension_numbers = _conv_dimension_numbers(inputs.shape)
    
      # One shared convolutional kernel for all pixels in the output.
      assert self.in_features % self.feature_group_count == 0
    
      if self.mask is not None and self.mask.shape != self.kernel_shape:
        raise ValueError(
          'Mask needs to have the same shape as weights. '
          f'Shapes are: {self.mask.shape}, {self.kernel_shape}'
        )
    
      kernel = self.kernel.value
    
      if self.mask is not None:
        kernel *= self.mask
    
      bias = self.bias.value
    
      inputs, kernel, bias = dtypes.promote_dtype(
        (inputs, kernel, bias), dtype=self.dtype
      )
    
>     y = self.conv_general_dilated(
        inputs,
        kernel,
        strides,
        padding_lax,
        lhs_dilation=input_dilation,
        rhs_dilation=kernel_dilation,
        dimension_numbers=dimension_numbers,
        feature_group_count=self.feature_group_count,
        precision=self.precision,
      )

/opt/fw/jax/flax/nnx/nn/linear.py:764: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

lhs = Array([[[[ 0.20395662],
         [-0.70256877],
         [ 0.5415845 ],
         ...,
         [-1.5794774 ],
        ... [ 0.8960188 ],
         ...,
         [ 1.3626904 ],
         [ 1.6482255 ],
         [ 0.57610774]]]], dtype=float32)
rhs = Array([[ 0.11860507,  0.20916186,  0.07361355,  0.16715094,  0.03591876,
        -0.0396798 ,  0.02146457, -0.04032072...0.08397055,  0.05345429,  0.17081223,
        -0.07752619, -0.17410053,  0.06174944,  0.03548089]],      dtype=float32)
window_strides = (1, 1), padding = ((1, 1), (1, 1)), lhs_dilation = (1, 1), rhs_dilation = (1, 1)
dimension_numbers = ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), feature_group_count = 1, batch_group_count = 1, precision = None
preferred_element_type = None

    def conv_general_dilated(
      lhs: Array, rhs: Array, window_strides: Sequence[int],
      padding: str | Sequence[tuple[int, int]],
      lhs_dilation: Sequence[int] | None = None,
      rhs_dilation: Sequence[int] | None = None,
      dimension_numbers: ConvGeneralDilatedDimensionNumbers  = None,
      feature_group_count: int = 1, batch_group_count: int = 1,
      precision: lax.PrecisionLike = None,
      preferred_element_type: DTypeLike | None = None) -> Array:
      """General n-dimensional convolution operator, with optional dilation.
    
      Wraps XLA's `Conv
      <https://www.tensorflow.org/xla/operation_semantics#conv_convolution>`_
      operator.
    
      Args:
        lhs: a rank `n+2` dimensional input array.
        rhs: a rank `n+2` dimensional array of kernel weights.
        window_strides: a sequence of `n` integers, representing the inter-window
          strides.
        padding: either the strings `'SAME'`, `'SAME_LOWER'`, or `'VALID'`, or a
          sequence of `n` `(low, high)` integer pairs that give the padding to apply
          before and after each spatial dimension. `'SAME'` and `'SAME_LOWER'` add
          padding to produce same output size as the input. The padding is split
          between the two sides equally or almost equally. In case the padding is an
          odd number, the extra padding is added at the end for `'SAME'` and at the
          beginning for `'SAME_LOWER'`.
        lhs_dilation: `None`, or a sequence of `n` integers, giving the dilation
          factor to apply in each spatial dimension of `lhs`. LHS dilation is also
          known as transposed convolution.
        rhs_dilation: `None`, or a sequence of `n` integers, giving the dilation
          factor to apply in each spatial dimension of `rhs`. RHS dilation is also
          known as atrous convolution.
        dimension_numbers: either `None`, a ``ConvDimensionNumbers`` object, or a
          3-tuple ``(lhs_spec, rhs_spec, out_spec)``, where each element is a string
          of length `n+2`.
        feature_group_count: integer, default 1. See XLA HLO docs.
        batch_group_count: integer, default 1. See XLA HLO docs.
        precision: Optional. Either ``None``, which means the default precision for
          the backend, a :class:`~jax.lax.Precision` enum value
          (``Precision.DEFAULT``, ``Precision.HIGH`` or ``Precision.HIGHEST``), a
          string (e.g. 'highest' or 'fastest', see the
          ``jax.default_matmul_precision`` context manager), or a tuple of two
          :class:`~jax.lax.Precision` enums or strings indicating precision of
          ``lhs`` and ``rhs``.
        preferred_element_type: Optional. Either ``None``, which means the default
          accumulation type for the input types, or a datatype, indicating to
          accumulate results to and return a result with that datatype.
    
      Returns:
        An array containing the convolution result.
    
      In the string case of ``dimension_numbers``, each character identifies by
      position:
    
      - the batch dimensions in ``lhs``, ``rhs``, and the output with the character
        'N',
      - the feature dimensions in `lhs` and the output with the character 'C',
      - the input and output feature dimensions in rhs with the characters 'I'
        and 'O' respectively, and
      - spatial dimension correspondences between lhs, rhs, and the output using
        any distinct characters. The examples below use 'W' and 'H'.
    
      For example, to indicate dimension numbers consistent with the ``conv``
      function with two spatial dimensions, one could use ``('NCHW', 'OIHW',
      'NCHW')``. As another example, to indicate dimension numbers consistent with
      the TensorFlow Conv2D operation, one could use ``('NHWC', 'HWIO', 'NHWC')``.
      When using the latter form of convolution dimension specification, window
      strides are associated with spatial dimension character labels according to
      the order in which the labels appear in the ``rhs_spec`` string, so that
      ``window_strides[0]`` is matched with the dimension corresponding to the first
      character appearing in rhs_spec that is not ``'I'`` or ``'O'``.
    
      If ``dimension_numbers`` is ``None``, the default is ``('NCHW', 'OIHW',
      'NCHW')`` (for a 2D convolution).
      """
      dnums = conv_dimension_numbers(lhs.shape, rhs.shape, dimension_numbers)
      if lhs_dilation is None:
        lhs_dilation = (1,) * (lhs.ndim - 2)
      elif isinstance(padding, str) and not len(lhs_dilation) == lhs_dilation.count(1):
        raise ValueError(
            "String padding is not implemented for transposed convolution "
            "using this op. Please either exactly specify the required padding or "
            "use conv_transpose.")
      if rhs_dilation is None:
        rhs_dilation = (1,) * (rhs.ndim - 2)
      if isinstance(padding, str):
        lhs_perm, rhs_perm, _ = dnums
        rhs_shape = np.take(rhs.shape, rhs_perm)[2:]
        effective_rhs_shape = [core.dilate_dim(k, r) for k, r in zip(rhs_shape, rhs_dilation)]
        padding = lax.padtype_to_pads(
            np.take(lhs.shape, lhs_perm)[2:], effective_rhs_shape,
            window_strides, padding)
      else:
        try:
          padding = tuple((operator.index(lo), operator.index(hi))
                          for lo, hi in padding)
        except (ValueError, TypeError) as e:
          raise ValueError(
            "padding argument to conv_general_dilated should be a string or a "
            f"sequence of (low, high) pairs, got {padding}") from e
    
      preferred_element_type = (
          None if preferred_element_type is None else
          dtypes.canonicalize_dtype(np.dtype(preferred_element_type)))
>     return conv_general_dilated_p.bind(
          lhs, rhs, window_strides=tuple(window_strides), padding=tuple(padding),
          lhs_dilation=tuple(lhs_dilation), rhs_dilation=tuple(rhs_dilation),
          dimension_numbers=dnums,
          feature_group_count=feature_group_count,
          batch_group_count=batch_group_count,
          precision=lax.canonicalize_precision(precision),
          preferred_element_type=preferred_element_type)

/opt/fw/jax/jax/_src/lax/convolution.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = conv_general_dilated
args = (Array([[[[ 0.20395662],
         [-0.70256877],
         [ 0.5415845 ],
         ...,
         [-1.5794774 ],
       ....08397055,  0.05345429,  0.17081223,
        -0.07752619, -0.17410053,  0.06174944,  0.03548089]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def bind(self, *args, **params):
      assert (not config.enable_checks.value or
              all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args
>     return self.bind_with_trace(find_top_trace(args), args, params)

/opt/fw/jax/jax/_src/core.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = conv_general_dilated, trace = EvalTrace(level=0/0)
args = (Array([[[[ 0.20395662],
         [-0.70256877],
         [ 0.5415845 ],
         ...,
         [-1.5794774 ],
       ....08397055,  0.05345429,  0.17081223,
        -0.07752619, -0.17410053,  0.06174944,  0.03548089]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def bind_with_trace(self, trace, args, params):
      with pop_level(trace.level):
>       out = trace.process_primitive(self, map(trace.full_raise, args), params)

/opt/fw/jax/jax/_src/core.py:442: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = EvalTrace(level=0/0), primitive = conv_general_dilated
tracers = [Array([[[[ 0.20395662],
         [-0.70256877],
         [ 0.5415845 ],
         ...,
         [-1.5794774 ],
       ....08397055,  0.05345429,  0.17081223,
        -0.07752619, -0.17410053,  0.06174944,  0.03548089]],      dtype=float32)]
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def process_primitive(self, primitive, tracers, params):
      if config.debug_key_reuse.value:
        # Import here to avoid circular imports
        from jax.experimental.key_reuse._core import call_impl_with_key_reuse_checks  # pytype: disable=import-error
        return call_impl_with_key_reuse_checks(primitive, primitive.impl, *tracers, **params)
      else:
>       return primitive.impl(*tracers, **params)

/opt/fw/jax/jax/_src/core.py:955: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

prim = conv_general_dilated
args = (Array([[[[ 0.20395662],
         [-0.70256877],
         [ 0.5415845 ],
         ...,
         [-1.5794774 ],
       ....08397055,  0.05345429,  0.17081223,
        -0.07752619, -0.17410053,  0.06174944,  0.03548089]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}
fun = <PjitFunction of <function conv_general_dilated at 0x7fdb04b19c60>>, prev = None

    def apply_primitive(prim, *args, **params):
      """Impl rule that compiles and runs a single primitive 'prim' using XLA."""
      fun = xla_primitive_callable(prim, **params)
      # TODO(yashkatariya): Investigate adding is_primitive to jit and never
      # triggering the disable jit path instead of messing around with it here.
      prev = lib.jax_jit.swap_thread_local_state_disable_jit(False)
      try:
>       outs = fun(*args)
E       ValueError: conv_general_dilated lhs and rhs must have the same number of dimensions, but got (16, 32, 32, 1) and (32, 9).

/opt/fw/jax/jax/_src/dispatch.py:91: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HardNet8
kornia.feature.HardNet8
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_HardNet8[jax-s2s-False] - ValueError: conv_general_dilated lhs and rhs must have the same number of dimensions, but got (16, 32, 32, 1) and (32, 9).
============================================================================== 1 failed, 16 passed in 1328.34s (0:22:08) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 421.35s (0:07:01) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ........                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 706.98s (0:11:46) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py ss                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 5.20s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_bbox_to_mask[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f244f490310>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f244f490310>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(1, 5, 5), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 510.13s (0:08:30) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py sssssssssssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 13 skipped in 5.10s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 4 passed in 314.84s (0:05:14) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ss                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 5.17s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ..FF                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_So2[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_So2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        real_part = torch.tensor([1.0], requires_grad=True)
        imaginary_part = torch.tensor([2.0], requires_grad=True)
        complex_number = torch.complex(real_part, imaginary_part)
        torch_so2 = kornia.geometry.liegroup.So2(complex_number)
    
        transpiled_complex_number = _nest_torch_tensor_to_new_framework(complex_number, target_framework)
>       transpiled_so2 = transpiled_kornia.geometry.liegroup.So2(transpiled_complex_number)

kornia/geometry/test_liegroup.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_So2' object has no attribute '_z'") raised in repr()] tensorflow_So2 object at 0x7f2454cf5bd0>
z = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

    def __init__(self, z):
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ._utils import tensorflow_check_so2_z_shape
    
        self.super___init__(
            z,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        tensorflow_KORNIA_CHECK_IS_TENSOR(z)
        tensorflow_check_so2_z_shape(z)
>       self._z = tensorflow.keras.Variable(z)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_79>, initializer = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>, shape = None, dtype = 'float32'
trainable = True, autocast = True, aggregation = 'mean', name = 'variable_79'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_79>, value = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>)
kwargs = {'dtype': 'float32', 'name': 'variable_79', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So2
kornia.geometry.liegroup.So2
____________________________________________________________________________________ test_Se2[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Se2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.Se2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        so2_rotation = kornia.geometry.liegroup.So2.identity(1)
        translation_vector = torch.ones((1, 2), requires_grad=True)
        torch_se2 = kornia.geometry.liegroup.Se2(so2_rotation, translation_vector)
    
>       transpiled_so2_rotation = transpiled_kornia.geometry.liegroup.So2.identity(1)

kornia/geometry/test_liegroup.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.liegroup.so2.tensorflow_So2'>, batch_size = 1, device = None, dtype = None

    @classmethod
    def identity(cls, batch_size=None, device=None, dtype=None):
        from ...core._backend import complex
        from ...core._backend import tensor
        from ...core.check import tensorflow_KORNIA_CHECK
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        real_data = tensor(1.0, device=device, dtype=dtype)
        imag_data = tensor(0.0, device=device, dtype=dtype)
        if batch_size is not None:
            tensorflow_KORNIA_CHECK(batch_size >= 1, msg="batch_size must be positive")
            real_data = tensorflow_repeat_frnt_(real_data, batch_size)
            imag_data = tensorflow_repeat_frnt_(imag_data, batch_size)
>       return cls(complex(real_data, imag_data))

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_So2' object has no attribute '_z'") raised in repr()] tensorflow_So2 object at 0x7f24ecd5df00>
z = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>

    def __init__(self, z):
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ._utils import tensorflow_check_so2_z_shape
    
        self.super___init__(
            z,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        tensorflow_KORNIA_CHECK_IS_TENSOR(z)
        tensorflow_check_so2_z_shape(z)
>       self._z = tensorflow.keras.Variable(z)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_80>, initializer = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>, shape = None, dtype = 'float32'
trainable = True, autocast = True, aggregation = 'mean', name = 'variable_80'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_80>, value = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>)
kwargs = {'dtype': 'float32', 'name': 'variable_80', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.Se2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_liegroup.py::test_So2[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,...
FAILED kornia/geometry/test_liegroup.py::test_Se2[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,...
=============================================================================== 2 failed, 2 passed in 433.86s (0:07:13) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1214.75s (0:20:14) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F.F.                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomMotionBlur[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'tensorflow', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd68100e640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
params = None, kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fd6748bf370>, tensorflow_set_item = <function tensorflow_set_item at 0x7fd674a26dd0>
tensor = <function tensorflow_tensor_frnt at 0x7fd6856b1510>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .....ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
    
        params = super().generate_parameters(batch_shape)
        params = tensorflow_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else tensorflow_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
E       
E       [1mtensorflow_randint_frnt() missing 1 required positional argument: 'size'[0m
E       
E       Arguments received by tensorflow_RandomMotionBlur.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:73: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_________________________________________________________________________ test_RandomSaltAndPepperNoise[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'tensorflow', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.8833, 0.2673, 0.3770],
          [0.4063, 0.2471, 0.1012],
          [0.7391, 0.5766, 0.2562]],

       ...08]],

         [[0.8965, 0.2304, 0.3338],
          [0.3310, 0.4918, 0.1284],
          [0.3722, 0.7707, 0.9218]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.4063...18],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd680e7ee40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.4063...18],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.4063...18],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.40633...0318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
       ...318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.40633...0318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[False, False, False],
         [ True, False, False],
         [ True, False, False]]]])>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fd6518085e0>, tensorflow_set_item = <function tensorflow_set_item at 0x7fd65184f490>
tensor = <function tensorflow_tensor_frnt at 0x7fd651802c20>
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.40633...0318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.40633...0318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[False, False, False],
         [ True, False, False],
         [ True, False, False]]]])>, ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.40633...0318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[False, False, False],
         [ True, False, False],
         [ True, False, False]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fd6518085e0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7fd65180a0e0>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7fd65188d6c0>, tensorflow_get_item = <function tensorflow_get_item at 0x7fd65184f2e0>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7fd685358dc0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7fd65188e830>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fd65188e680>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.8832757 , 0.2672556 , 0.37696326],
         [0.40633...0318],
         [0.33098662, 0.4917614 , 0.12840158],
         [0.3721767 , 0.77070194, 0.9218009 ]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[False, False, False],
         [ True, False, False],
         [ True, False, False]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import tensorflow_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK(
            len(tensorflow_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(tensorflow_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        tensorflow_KORNIA_CHECK(
            tensorflow_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = tensorflow_clone_frnt_(input)
        noisy_image = tensorflow_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'to'[0m
E       
E       Arguments received by tensorflow_RandomSaltAndPepperNoise.call():
E         • input=tf.Tensor(shape=(1, 3, 3, 3), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:99: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
______________________________________________________________________________ test_RandomSharpness[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:334: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'tensorflow', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.0735, 0.5703, 0.1576, 0.0249, 0.9642],
          [0.2574, 0.0512, 0.3214, 0.0011, 0.3997],
          [0...., 0.8290],
          [0.5915, 0.7546, 0.2169, 0.2326, 0.7498],
          [0.7981, 0.4284, 0.1451, 0.1930, 0.8710]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.964...3259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd67eddc640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.964...3259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.964...3259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.9641....23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.024947...23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.9641....23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.60799277], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fd651601e10>, tensorflow_set_item = <function tensorflow_set_item at 0x7fd6850260e0>
tensor = <function tensorflow_tensor_frnt at 0x7fd6513c39a0>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.9641....23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.9641....23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.60799277], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.9641....23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.60799277], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fd651601e10>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7fd651602440>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7fd65170ea70>, tensorflow_get_item = <function tensorflow_get_item at 0x7fd685025f30>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7fd684f5b6d0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7fd67e783d90>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fd684feb2e0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07350028, 0.5703339 , 0.15760887, 0.0249474 , 0.9641....23259705, 0.7497546 ],
         [0.798099  , 0.4284404 , 0.14505976, 0.19296801, 0.8710232 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.60799277], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
E       
E       [1mname 'sharpness' is not defined[0m
E       
E       Arguments received by tensorflow_RandomSharpness.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/sharpness.py:46: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
______________________________________________________________________________ test_RandomSolarize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSolarize(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSolarize")
    
        init_args = (0.1, 0.1)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSolarize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.solarize.RandomSolarize'>, target = 'tensorflow', init_args = (0.1, 0.1), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.9313, 0.1972, 0.2568, 0.3944, 0.9824],
          [0.9035, 0.1209, 0.6926, 0.9042, 0.0781],
          [0...., 0.9180],
          [0.8844, 0.0217, 0.9316, 0.7823, 0.9352],
          [0.5089, 0.5759, 0.8911, 0.8562, 0.0078]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.982...8228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd6805bca40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.982...8228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.982...8228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.9824....78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.394440...78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.9824....78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.00012513], dtype=float32)>, 'batch_prob': <tf.Ten...py=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4366461], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fd651414f70>, tensorflow_set_item = <function tensorflow_set_item at 0x7fd68587dfc0>
tensor = <function tensorflow_tensor_frnt at 0x7fd652d15120>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.9824....78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.9824....78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.00012513], dtype=float32)>, 'batch_prob': <tf.Ten...py=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4366461], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.9824....78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.00012513], dtype=float32)>, 'batch_prob': <tf.Ten...py=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4366461], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fd651414f70>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7fd651279510>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7fd65127ad40>, tensorflow_get_item = <function tensorflow_get_item at 0x7fd68587de10>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7fd6851cb910>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7fd65127ab90>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fd65127a9e0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.9824....78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.00012513], dtype=float32)>, 'batch_prob': <tf.Ten...py=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4366461], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.adjust import tensorflow_solarize
    
        thresholds = params["thresholds"]
        additions: typing.Any
        if "additions" in params:
            additions = params["additions"]
        else:
            additions = None
>       return tensorflow_solarize(input, thresholds, additions)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/solarize.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.9312858 , 0.19715893, 0.2567836 , 0.3944404 , 0.9824....78228664, 0.9352459 ],
         [0.5089277 , 0.57593745, 0.8911302 , 0.8561801 , 0.00780171]]]],
      dtype=float32)>
thresholds = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4366461], dtype=float32)>, additions = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.00012513], dtype=float32)>

    def tensorflow_solarize(input, thresholds=0.5, additions=None):
        from ...ivy.functional.frontends.torch.creation_ops import tensorflow_as_tensor_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_all_frnt
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clamp_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(
            thresholds, (float, tensorflow.Tensor, tensorflow.keras.Variable)
        ):
            raise TypeError(
                f"The factor should be either a float or Tensor. Got {type(thresholds)}"
            )
        if isinstance(thresholds, (float,)):
            thresholds = tensorflow_as_tensor_frnt(thresholds)
        if additions is not None:
            if not isinstance(
                additions, (float, tensorflow.Tensor, tensorflow.keras.Variable)
            ):
                raise TypeError(
                    f"The factor should be either a float or Tensor. Got {type(additions)}"
                )
            if isinstance(additions, (float,)):
                additions = tensorflow_as_tensor_frnt(additions)
>           if not tensorflow_all_frnt((additions < 0.5) * (additions > -0.5)):

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/adjust.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, rhs = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, x2 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_RandomSolarize.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_RandomSolarize.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:299: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSolarize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSolarize[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensor...
============================================================================== 4 failed, 13 passed in 3715.63s (1:01:55) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 119.64s (0:01:59) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py ........                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 789.53s (0:13:09) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py FF...F.FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_LAFOrienter[tensorflow-s2s-False] ________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LAFOrienter(target_framework, mode, backend_compile):
        print("kornia.feature.LAFOrienter")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        laf = torch.rand(1, 2, 2, 3)
        img = torch.rand(1, 1, 32, 32)
        transpiled_laf = _nest_torch_tensor_to_new_framework(laf, target_framework)
        transpiled_img = _nest_torch_tensor_to_new_framework(img, target_framework)
    
        model = kornia.feature.LAFOrienter()
        torch_out = model(laf, img)
    
>       transpiled_model = transpiled_kornia.feature.LAFOrienter()

kornia/test_feature5.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f82d0348880>, patch_size = 32, num_angular_bins = 36
angle_detector = None

    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (32, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LAFOrienter(target_framework, mode, backend_compile):
        print("kornia.feature.LAFOrienter")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        laf = torch.rand(1, 2, 2, 3)
        img = torch.rand(1, 1, 32, 32)
        transpiled_laf = _nest_torch_tensor_to_new_framework(laf, target_framework)
        transpiled_img = _nest_torch_tensor_to_new_framework(img, target_framework)
    
        model = kornia.feature.LAFOrienter()
        torch_out = model(laf, img)
    
>       transpiled_model = transpiled_kornia.feature.LAFOrienter()

kornia/test_feature5.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f82d020d780>, patch_size = 32, num_angular_bins = 36
angle_detector = None

    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (32, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LAFOrienter
kornia.feature.LAFOrienter
_____________________________________________________________________ test_PatchDominantGradientOrientation[tensorflow-s2s-False] ______________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PatchDominantGradientOrientation(target_framework, mode, backend_compile):
        print("kornia.feature.PatchDominantGradientOrientation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        patch = torch.rand(10, 1, 32, 32)
        transpiled_patch = _nest_torch_tensor_to_new_framework(patch, target_framework)
    
        model = kornia.feature.PatchDominantGradientOrientation()
        torch_out = model(patch)
    
>       transpiled_model = transpiled_kornia.feature.PatchDominantGradientOrientation()

kornia/test_feature5.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:106: ValueError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_3>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PatchDominantGradientOrientation(target_framework, mode, backend_compile):
        print("kornia.feature.PatchDominantGradientOrientation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        patch = torch.rand(10, 1, 32, 32)
        transpiled_patch = _nest_torch_tensor_to_new_framework(patch, target_framework)
    
        model = kornia.feature.PatchDominantGradientOrientation()
        torch_out = model(patch)
    
>       transpiled_model = transpiled_kornia.feature.PatchDominantGradientOrientation()

kornia/test_feature5.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_3>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_3>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:106: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.PatchDominantGradientOrientation
kornia.feature.PatchDominantGradientOrientation
____________________________________________________________________________________ test_TLU[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TLU(target_framework, mode, backend_compile):
        print("kornia.feature.TLU")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 8, 8)
        torch_out = kornia.feature.TLU(3)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = transpiled_kornia.feature.TLU(3)(transpiled_x)

kornia/test_feature5.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , 0.287...58, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5577a81e82b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(), <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943,...258, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , 0.287...58, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(), <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943,...258, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , 0.287...58, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , 0.2871...8258, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(),)
kwargs = {'x': <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , ...258, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
x = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , 0.2871...8258, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_max_frnt
    
>       return tensorflow_max_frnt(x, self.tau)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dim = <KerasVariable shape=(1, 3, 1, 1), dtype=float32, path=variable_33>, keepdim = False, out = None
input = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , 0.2871...8258, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>

    def tensorflow_max_frnt(*input, dim=None, keepdim=False, out=None):
        from ...ivy.general import tensorflow_is_array_bknd
        from .comparison_ops import tensorflow_maximum_frnt
        from ...backends.tensorflow.statistical import tensorflow_max
        from ...backends.tensorflow.searching import tensorflow_argmax
    
        if len(input) == 1:
            input = input[0]
        elif len(input) == 2:
            input_0 = input[0]
            input_1 = input[1]
            if tensorflow_is_array_bknd(input_1):
                return tensorflow_maximum_frnt(*input)
            else:
                input = input_0
                dim = input_1
        else:
            input = input[0]
            dim = input[1]
            keepdim = input[2]
        if dim is None:
            return tensorflow_max(input, axis=dim, keepdims=keepdim, out=out)
        elif out is not None:
            tensorflow_max(input, axis=dim, keepdims=keepdim, out=out[0])
            tensorflow_argmax(input, axis=dim, keepdims=keepdim, out=out[1])
            return out
        else:
            max_tuple = namedtuple("max", ["values", "indices"])
            return max_tuple(
>               tensorflow_max(input, axis=dim, keepdims=keepdim),
                tensorflow_argmax(input, axis=dim, keepdims=keepdim),
            )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/reduction_ops.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , 0.287...258, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>]
kwargs = {'axis': <KerasVariable shape=(1, 3, 1, 1), dtype=float32, path=variable_33>, 'keepdims': False}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f82b0e8a320>
tensorflow_set_item = <function tensorflow_set_item at 0x7f82b0e7c430>, tensorflow_asarray = <function tensorflow_asarray at 0x7f82b0e8ac20>
tensorflow_get_item = <function tensorflow_get_item at 0x7f82b0e7c280>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'axis', 'keepdims', 'out']
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[int, ...s 'bool'>, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType]]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[0.623459  , 0.9086494 , 0.43536943, 0.6165004 , 0.2871...8258, 0.20144486, 0.7638614 , 0.69655526, 0.43586725,
          0.7693466 , 0.42746866, 0.38943934]]]], dtype=float32)>

    @tensorflow_handle_array_like_without_promotion
    def tensorflow_max(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        axis: Optional[Union[int, Sequence[int]]] = None,
        keepdims: bool = False,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        if "complex" in str(x.dtype):
            real = tensorflow.math.real(x)
            img = tensorflow.math.imag(x)
            const = tensorflow.constant(1.0j, dtype=x.dtype)
            real_max = tensorflow.reduce_max(real, axis=axis, keepdims=keepdims)
            imag = tensorflow.where(
                real == real_max, img, tensorflow.experimental.numpy.finfo(img.dtype).min
            )
            img_max = tensorflow.reduce_max(imag, axis=axis, keepdims=keepdims)
            img_max = tensorflow.cast(img_max, x.dtype)
            return tensorflow.add(
                tensorflow.cast(real_max, x.dtype), tensorflow.multiply(img_max, const)
            )
        axis = tuple(axis) if isinstance(axis, list) else axis
>       return tensorflow.math.reduce_max(x, axis=axis, keepdims=keepdims)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
E       
E       [1mValue for attr 'Tidx' of float is not in the list of allowed values: int32, int64
E       	; NodeDef: {{node Max}}; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Max][0m
E       
E       Arguments received by tensorflow_TLU.call():
E         • x=tf.Tensor(shape=(1, 3, 8, 8), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/statistical.py:60: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.TLU
kornia.feature.TLU
__________________________________________________________________________________ test_DeDoDe[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
        transpiled_model = transpiled_kornia.feature.DeDoDe(amp_dtype=ivy.as_native_dtype("float32"))
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30501413, 0.9229034 , 0.02831697, ..., 0.061898...
         [0.5816299 , 0.5099491 , 0.58926684, ..., 0.0381701 ,
          0.53625345, 0.24536288]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x557869375540, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.5816299 , 0.5099491 , 0.58926684, ..., 0.0381701 ,
          0.53625345, 0.24536288]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30501413, 0.9229034 , 0.02831697, ..., 0.061898...
         [0.5816299 , 0.5099491 , 0.58926684, ..., 0.0381701 ,
          0.53625345, 0.24536288]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.5816299 , 0.5099491 , 0.58926684, ..., 0.0381701 ,
          0.53625345, 0.24536288]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30501413, 0.9229034 , 0.02831697, ..., 0.061898...
         [0.5816299 , 0.5099491 , 0.58926684, ..., 0.0381701 ,
          0.53625345, 0.24536288]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30501413, 0.9229034 , 0.02831697, ..., 0.0618988...],
         [0.5816299 , 0.5099491 , 0.58926684, ..., 0.0381701 ,
          0.53625345, 0.24536288]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=10000, apply_imagenet_normalization=True, pad_if_not_divisible=True)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30501413, 0.9229034 , 0.02831697, ......,
         [0.5816299 , 0.5099491 , 0.58926684, ..., 0.0381701 ,
          0.53625345, 0.24536288]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-0.78596455,  1.9122419 , -1.9942491 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = True, pad_if_not_divisible = True

    def call(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...geometry.conversions import tensorflow_denormalize_pixel_coordinates
    
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       keypoints, scores = self.detect(
            images, n=n, apply_imagenet_normalization=False, crop_h=h, crop_w=w
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-0.78596455,  1.9122419 , -1.9942491 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = False, pad_if_not_divisible = True, crop_h = 256, crop_w = 256

    def detect(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
        crop_h=None,
        crop_w=None,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_softmax_frnt_
        from .utils import tensorflow_sample_keypoints
    
        tensorflow_KORNIA_CHECK_SHAPE(images, ["B", "3", "H", "W"])
        self.train(False)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
>       logits = self.detector.call(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDeDetector(
  (encoder): tensorflow_VGG19(
    (pt_layers): tensorflow_ModuleList(
      (0): KerasConv...rflow_ReLU()
            (3): KerasConv2D()
          )
        )
        (out_conv): KerasConv2D()
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-0.78596455,  1.9122419 , -1.9942491 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>

    def call(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_interpolate_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
    
        dtype = images.dtype
        features, sizes = self.encoder(images)
        context = None
        logits = None
        scales = ["8", "4", "2", "1"]
        for idx, (feature_map, scale) in enumerate(zip(reversed(features), scales)):
>           delta_logits, context = self.decoder(
                feature_map, context=context, scale=scale
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/detector.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}
stack = [FrameInfo(frame=<frame at 0x5577b2e84d10, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}, replace_v = False, replace_buffers = False, call_signature = <Signature (features, context=None, scale=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
features = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
...2900e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>
context = None, scale = '8'

    def call(self, features, context=None, scale=None):
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        if context is not None:
            features = tensorflow_cat_frnt((features, context), dim=1)
>       stuff = tensorflow_get_item(self.pt_layers, scale)(features)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x557903868ce0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (feats)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
feats = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
...2900e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>

    def call(self, feats):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        b, c, hs, ws = tensorflow_shape_frnt_(feats)
>       x0 = self.block1(feats)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:298: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5577a89ac5b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,...00e-03, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-2.17238651e-03, -6.77200174e-03, -1.36913394e-03,...62265e-03, -4.57846676e-04, ...,
           5.94174303e-03, -4.14707046e-03,  2.91690556e-03]]]],
      dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-2.17238651e-03, -6.77200174e-03, -1.36913394e-03...265e-03, -4.57846676e-04, ...,
           5.94174303e-03, -4.14707046e-03,  2.91690556e-03]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5578866e9cd0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-2.17238651e-03, -6.77200174e-03, -1.36913394e-03...265e-03, -4.57846676e-04, ...,
           5.94174303e-03, -4.14707046e-03,  2.91690556e-03]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    def __call__(self, *args, **kwargs):
        if not self.built:
>           res = super().__call__(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1010: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D(), input_shape = (1, 33, 33, 512)

    def build(self, input_shape):
        _, ch, _, _ = input_shape
        if (
            not self.built
            and self.axis == -1
            and os.environ.get("DATA_FORMAT", "channels_first") == "channels_first"
        ):
            order = (0, 2, 3, 1)
            new_shape = tuple(input_shape[i] for i in order)
            input_shape = tf.TensorShape(new_shape)
    
>       super().build(input_shape)
E       IndexError: Exception encountered when calling tensorflow_Sequential.call().
E       
E       [1mtuple index out of range[0m
E       
E       Arguments received by tensorflow_Sequential.call():
E         • input=tf.Tensor(shape=(1, 512, 33, 33), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1030: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  0%|          | 3.00M/1.13G [00:00<00:38, 31.2MB/s]
  1%|          | 6.12M/1.13G [00:00<00:37, 32.1MB/s]
  1%|          | 10.2M/1.13G [00:00<00:33, 36.5MB/s]
  1%|▏         | 15.1M/1.13G [00:00<00:28, 42.1MB/s]
  2%|▏         | 21.1M/1.13G [00:00<00:24, 49.5MB/s]
  2%|▏         | 28.4M/1.13G [00:00<00:20, 58.4MB/s]
  3%|▎         | 37.5M/1.13G [00:00<00:16, 70.2MB/s]
  4%|▍         | 47.9M/1.13G [00:00<00:14, 82.3MB/s]
  5%|▌         | 60.6M/1.13G [00:00<00:11, 97.6MB/s]
  6%|▋         | 75.2M/1.13G [00:01<00:09, 114MB/s] 
  8%|▊         | 94.1M/1.13G [00:01<00:08, 139MB/s]
 10%|▉         | 111M/1.13G [00:01<00:07, 149MB/s] 
 11%|█         | 128M/1.13G [00:01<00:06, 158MB/s]
 13%|█▎        | 148M/1.13G [00:01<00:06, 175MB/s]
 15%|█▍        | 169M/1.13G [00:01<00:05, 187MB/s]
 16%|█▋        | 189M/1.13G [00:01<00:05, 193MB/s]
 18%|█▊        | 209M/1.13G [00:01<00:05, 199MB/s]
 20%|█▉        | 230M/1.13G [00:01<00:04, 203MB/s]
 21%|██▏       | 249M/1.13G [00:01<00:04, 204MB/s]
 23%|██▎       | 269M/1.13G [00:02<00:04, 198MB/s]
 25%|██▍       | 289M/1.13G [00:02<00:04, 203MB/s]
 27%|██▋       | 310M/1.13G [00:02<00:04, 206MB/s]
 28%|██▊       | 330M/1.13G [00:02<00:04, 208MB/s]
 30%|███       | 350M/1.13G [00:02<00:04, 209MB/s]
 32%|███▏      | 371M/1.13G [00:02<00:03, 210MB/s]
 34%|███▎      | 391M/1.13G [00:02<00:03, 208MB/s]
 35%|███▌      | 411M/1.13G [00:02<00:03, 202MB/s]
 37%|███▋      | 432M/1.13G [00:02<00:03, 206MB/s]
 39%|███▉      | 452M/1.13G [00:02<00:03, 207MB/s]
 41%|████      | 472M/1.13G [00:03<00:03, 209MB/s]
 42%|████▏     | 492M/1.13G [00:03<00:03, 210MB/s]
 44%|████▍     | 512M/1.13G [00:03<00:03, 200MB/s]
 46%|████▌     | 532M/1.13G [00:03<00:03, 193MB/s]
 48%|████▊     | 552M/1.13G [00:03<00:03, 200MB/s]
 49%|████▉     | 573M/1.13G [00:03<00:03, 203MB/s]
 51%|█████     | 594M/1.13G [00:03<00:02, 207MB/s]
 53%|█████▎    | 614M/1.13G [00:03<00:02, 208MB/s]
 55%|█████▍    | 634M/1.13G [00:03<00:02, 210MB/s]
 56%|█████▋    | 655M/1.13G [00:03<00:02, 211MB/s]
 58%|█████▊    | 675M/1.13G [00:04<00:02, 203MB/s]
 60%|█████▉    | 695M/1.13G [00:04<00:02, 205MB/s]
 62%|██████▏   | 715M/1.13G [00:04<00:02, 205MB/s]
 63%|██████▎   | 735M/1.13G [00:04<00:02, 208MB/s]
 65%|██████▌   | 755M/1.13G [00:04<00:02, 198MB/s]
 67%|██████▋   | 774M/1.13G [00:04<00:02, 194MB/s]
 68%|██████▊   | 794M/1.13G [00:04<00:01, 193MB/s]
 70%|███████   | 814M/1.13G [00:04<00:01, 199MB/s]
 72%|███████▏  | 834M/1.13G [00:04<00:01, 202MB/s]
 74%|███████▎  | 855M/1.13G [00:05<00:01, 206MB/s]
 75%|███████▌  | 875M/1.13G [00:05<00:01, 209MB/s]
 77%|███████▋  | 896M/1.13G [00:05<00:01, 210MB/s]
 79%|███████▉  | 916M/1.13G [00:05<00:01, 212MB/s]
 81%|████████  | 937M/1.13G [00:05<00:01, 213MB/s]
 82%|████████▏ | 957M/1.13G [00:05<00:01, 213MB/s]
 84%|████████▍ | 978M/1.13G [00:05<00:00, 213MB/s]
 86%|████████▌ | 998M/1.13G [00:05<00:00, 210MB/s]
 88%|████████▊ | 0.99G/1.13G [00:05<00:00, 211MB/s]
 89%|████████▉ | 1.01G/1.13G [00:05<00:00, 210MB/s]
 91%|█████████ | 1.03G/1.13G [00:06<00:00, 199MB/s]
 93%|█████████▎| 1.05G/1.13G [00:06<00:00, 203MB/s]
 95%|█████████▍| 1.07G/1.13G [00:06<00:00, 200MB/s]
 96%|█████████▋| 1.09G/1.13G [00:06<00:00, 203MB/s]
 98%|█████████▊| 1.11G/1.13G [00:06<00:00, 206MB/s]
100%|█████████▉| 1.13G/1.13G [00:06<00:00, 209MB/s]
100%|██████████| 1.13G/1.13G [00:06<00:00, 185MB/s]
2024-10-23 15:47:31.637694: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-23 15:47:31.964245: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-23 15:47:32.531622: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-23 15:47:32.561959: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-23 15:47:32.609351: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
___________________________________________________________________________________ test_DISK[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 32, 32)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        class TorchModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.fc = torch.nn.Linear(32, 32)
    
            def forward(self, x):
                return self.fc(x)
    
        torch_unet = TorchModel()
        transpiled_unet = ivy.transpile(TorchModel, target=target_framework)()
    
        model = kornia.feature.DISK(desc_dim=2, unet=torch_unet)
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.DISK(desc_dim=2, unet=transpiled_unet)
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_TorchModel(
    (fc): KerasDense()
  )
)
args = (<tf.Tensor: shape=(1, 3, 32, 32), dtype=float32, numpy=
array([[[[0.8312422 , 0.12797856, 0.20142186, ..., 0.7306006 ...
         [0.00769848, 0.7696386 , 0.5052127 , ..., 0.39298838,
          0.87391955, 0.5959642 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f82c857a650, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_TorchModel(
    (fc): KerasDense()
  )
), <tf.Tensor: shape=(1, 3, 32, 32), dty...,
         [0.00769848, 0.7696386 , 0.5052127 , ..., 0.39298838,
          0.87391955, 0.5959642 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_TorchModel(
    (fc): KerasDense()
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 32, 32), dtype=float32, numpy=
array([[[[0.8312422 , 0.12797856, 0.20142186, ..., 0.7306006 ...
         [0.00769848, 0.7696386 , 0.5052127 , ..., 0.39298838,
          0.87391955, 0.5959642 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_TorchModel(
    (fc): KerasDense()
  )
), <tf.Tensor: shape=(1, 3, 32, 32), dty...,
         [0.00769848, 0.7696386 , 0.5052127 , ..., 0.39298838,
          0.87391955, 0.5959642 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_TorchModel(
    (fc): KerasDense()
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 32, 32), dtype=float32, numpy=
array([[[[0.8312422 , 0.12797856, 0.20142186, ..., 0.7306006 ...
         [0.00769848, 0.7696386 , 0.5052127 , ..., 0.39298838,
          0.87391955, 0.5959642 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 32, 32), dtype=float32, numpy=
array([[[[0.8312422 , 0.12797856, 0.20142186, ..., 0.7306006 ,...],
         [0.00769848, 0.7696386 , 0.5052127 , ..., 0.39298838,
          0.87391955, 0.5959642 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=None, window_size=5, score_threshold=0.0, pad_if_not_divisible=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_TorchModel(
    (fc): KerasDense()
  )
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 32, 32), dtype=float32, numpy=
array([[[[0.8312422 , 0.12797856, 0.20142186, ..., ...,
         [0.00769848, 0.7696386 , 0.5052127 , ..., 0.39298838,
          0.87391955, 0.5959642 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_TorchModel(
    (fc): KerasDense()
  )
)
images = <tf.Tensor: shape=(1, 3, 32, 32), dtype=float32, numpy=
array([[[[0.8312422 , 0.12797856, 0.20142186, ..., 0.7306006 ,...],
         [0.00769848, 0.7696386 , 0.5052127 , ..., 0.39298838,
          0.87391955, 0.5959642 ]]]], dtype=float32)>
n = None, window_size = 5, score_threshold = 0.0, pad_if_not_divisible = False

    def call(
        self,
        images,
        n=None,
        window_size=5,
        score_threshold=0.0,
        pad_if_not_divisible=False,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from .detector import tensorflow_heatmap_to_keypoints
    
        B = tensorflow_shape_frnt_(images)[0]
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 16 - h % 16 if h % 16 > 0 else 0
            pd_w = 16 - w % 16 if w % 16 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
        heatmaps, descriptors = self.heatmap_and_dense_descriptors(images)
        if pad_if_not_divisible:
            heatmaps = tensorflow_get_item(
                heatmaps, (..., slice(None, h, None), slice(None, w, None))
            )
            descriptors = tensorflow_get_item(
                descriptors, (..., slice(None, h, None), slice(None, w, None))
            )
>       keypoints = tensorflow_heatmap_to_keypoints(
            heatmaps, n=n, window_size=window_size, score_threshold=score_threshold
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

heatmap = <tf.Tensor: shape=(1, 32, 32), dtype=float32, numpy=
array([[[ 0.2842651 ,  0.8910857 ,  0.47695956, ..., -0.56642026,...        [ 0.8304509 ,  0.59994394,  0.8096775 , ..., -0.8481787 ,
         -1.3718326 , -0.384457  ]]], dtype=float32)>
n = None, window_size = 5, score_threshold = 0.0

    def tensorflow_heatmap_to_keypoints(
        heatmap, n=None, window_size=5, score_threshold=0.0
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_nonzero_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ....ivy.functional.frontends.torch.comparison_ops import (
            tensorflow_kthvalue_frnt,
        )
        from .structs import tensorflow_Keypoints
    
        heatmap = tensorflow_squeeze_frnt_(heatmap, 1)
>       nmsed = tensorflow_nms(heatmap, window_size=window_size, cutoff=score_threshold)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/detector.py:75: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

signal = <tf.Tensor: shape=(1, 32, 32), dtype=float32, numpy=
array([[[ 0.2842651 ,  0.8910857 ,  0.47695956, ..., -0.56642026,...        [ 0.8304509 ,  0.59994394,  0.8096775 , ..., -0.8481787 ,
         -1.3718326 , -0.384457  ]]], dtype=float32)>
window_size = 5, cutoff = 0.0

    def tensorflow_nms(signal, window_size=5, cutoff=0.0):
        from ....ivy.functional.frontends.torch.nn.functional.pooling_functions import (
            tensorflow_max_pool2d_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.creation_ops import tensorflow_arange_frnt
    
        if window_size % 2 != 1:
            raise ValueError(f"window_size has to be odd, got {window_size}")
>       _, ixs = tensorflow_max_pool2d_frnt(
            signal,
            kernel_size=window_size,
            stride=1,
            padding=window_size // 2,
            return_indices=True,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/detector.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 5, 36, 32), dtype=float32, numpy=
array([[[[       -inf,        -inf,        -inf, ...,        -...      [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf]]]], dtype=float32)>
kernel_size = (5, 5), stride = (1, 1), padding = ((2, 2), (2, 2)), dilation = (1, 1), ceil_mode = False, return_indices = True

    def tensorflow_max_pool2d_frnt(
        input,
        kernel_size,
        stride=None,
        padding=0,
        dilation=1,
        ceil_mode=False,
        return_indices=False,
    ):
        from ...tensor import tensorflow_ndim_frnt_
        from .....backends.tensorflow.manipulation import tensorflow_expand_dims
        from .....backends.tensorflow.experimental.layers import tensorflow_max_pool2d
        from ...tensor import tensorflow_shape_frnt_
        from .....backends.tensorflow.general import tensorflow_get_item
        from .....backends.tensorflow.general import tensorflow_set_item
        from .....ivy.experimental.layers import tensorflow__padding_ceil_mode_bknd
        from .....backends.tensorflow.manipulation import tensorflow_flatten
        from ...creation_ops import tensorflow_arange_frnt
        from ...tensor import tensorflow_reshape_frnt_
        from .vision_functions import tensorflow_pad_frnt
        from ...tensor import tensorflow_permute_frnt_
        from .convolution_functions import tensorflow_unfold_frnt
        from ...tensor import tensorflow_repeat_frnt_
        from ...reduction_ops import tensorflow_argmax_frnt
        from ...indexing_slicing_joining_mutating_ops import tensorflow_gather_frnt
        from ...indexing_slicing_joining_mutating_ops import tensorflow_unsqueeze_frnt
    
        if not stride:
            stride = kernel_size
        if tensorflow_ndim_frnt_(input) == 3:
            without_batch_dim = True
            input = tensorflow_expand_dims(input, axis=0)
        else:
            without_batch_dim = False
        output = tensorflow_max_pool2d(
            input,
            kernel_size,
            stride,
            [(pad, pad) for pad in padding] if not isinstance(padding, (int,)) else padding,
            data_format="NHWC",
            dilation=dilation,
            ceil_mode=ceil_mode,
        )
        if return_indices:
            if isinstance(stride, (list, tuple)) and len(stride) == 1:
                stride = stride[0]
            DIMS = 2
            x_shape = list(tensorflow_shape_frnt_(input)[2:])
            if isinstance(kernel_size, (int,)):
                kernel_size = kernel_size, kernel_size
            if isinstance(dilation, (int,)):
                dilation = dilation, dilation
            new_kernel = [
                (
                    tensorflow_get_item(kernel_size, i)
                    + (tensorflow_get_item(kernel_size, i) - 1)
                    * (tensorflow_get_item(dilation, i) - 1)
                )
                for i in range(DIMS)
            ]
            if isinstance(padding, (int,)):
                padding = [(padding,) * 2] * DIMS
            elif isinstance(padding, (list, tuple)) and len(padding) == DIMS:
                padding = [((tensorflow_get_item(padding, i),) * 2) for i in range(DIMS)]
            if isinstance(stride, (int,)):
                stride = (stride,) * DIMS
            if ceil_mode:
                for i in range(DIMS):
                    padding = tensorflow_set_item(
                        padding,
                        i,
                        tensorflow__padding_ceil_mode_bknd(
                            tensorflow_get_item(x_shape, i),
                            tensorflow_get_item(new_kernel, i),
                            tensorflow_get_item(padding, i),
                            tensorflow_get_item(stride, i),
                        ),
                    )
            padding = padding[1], padding[0]
            pad_list = list(tensorflow_flatten(padding))
            in_shape = tensorflow_shape_frnt_(input)
            H = in_shape[-2]
            W = in_shape[-1]
            n_indices = H * W
            input_indices = tensorflow_arange_frnt(0, n_indices, dtype=tf.int64)
            input_indices = tensorflow_reshape_frnt_(input_indices, (1, 1, H, W))
            input = tensorflow_pad_frnt(input, pad_list, value=float("-inf"))
            input_indices = tensorflow_pad_frnt(input_indices, pad_list, value=0)
            unfolded_indices = tensorflow_permute_frnt_(
                tensorflow_unfold_frnt(
                    input_indices,
                    kernel_size=kernel_size,
                    padding=0,
                    dilation=dilation,
                    stride=stride,
                ),
                (0, 2, 1),
            )[0]
            unfolded_values = tensorflow_unfold_frnt(
                input, kernel_size=kernel_size, padding=0, dilation=dilation, stride=stride
            )
            unfolded_values_shape = tensorflow_shape_frnt_(unfolded_values)
            unfolded_indices = tensorflow_repeat_frnt_(
                unfolded_indices, unfolded_values_shape[0], unfolded_values_shape[1], 1, 1
            )
            unfolded_values = tensorflow_reshape_frnt_(
                unfolded_values,
                tensorflow_shape_frnt_(input)[0],
                tensorflow_shape_frnt_(input)[1],
                tensorflow_shape_frnt_(unfolded_values)[1]
                // tensorflow_shape_frnt_(input)[1],
                tensorflow_shape_frnt_(unfolded_values)[2],
            )
            indices = tensorflow_argmax_frnt(unfolded_values, dim=2)
            indices = tensorflow_gather_frnt(
                unfolded_indices, -1, tensorflow_unsqueeze_frnt(indices, -1)
            )
>           indices = tensorflow_reshape_frnt_(indices, tensorflow_shape_frnt_(output))

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/pooling_functions.py:174: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 896, 1), dtype=int64, numpy=
array([[[[0],
         [0],
         [0],
         ...,
       ...],
         [0],
         ...,
         [0],
         [0],
         [0]]]])>, ivy.frontends.torch.Size([1, 1, 32, 32]))
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f82b012dea0>
array_like = <tf.Tensor: shape=(1, 5, 896, 1), dtype=int64, numpy=
array([[[[0],
         [0],
         [0],
         ...,
        ...,
         [0]],

        [[0],
         [0],
         [0],
         ...,
         [0],
         [0],
         [0]]]])>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 5, 896, 1), dtype=int64, numpy=
array([[[[0],
         [0],
         [0],
         ...,
        ...,
         [0]],

        [[0],
         [0],
         [0],
         ...,
         [0],
         [0],
         [0]]]])>
shape = ivy.frontends.torch.Size([1, 1, 32, 32]), args = (ivy.frontends.torch.Size([1, 1, 32, 32]),), tensorflow_reshape_frnt = <function tensorflow_reshape_frnt at 0x7f82b01bb2e0>

    @tensorflow_handle_methods
    def tensorflow_reshape_frnt_(tensor, *args, shape=None):
        from .indexing_slicing_joining_mutating_ops import tensorflow_reshape_frnt
    
        if args and shape:
            raise TypeError("reshape() got multiple values for argument 'shape'")
        if shape is not None:
            return tensorflow_reshape_frnt(tensor, shape)
        if args:
            if isinstance(args[0], (tuple, list, tuple, tf.TensorShape)):
                shape = args[0]
>               return tensorflow_reshape_frnt(tensor, shape)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 896, 1), dtype=int64, numpy=
array([[[[0],
         [0],
         [0],
         ...,
       ...],
         [0],
         ...,
         [0],
         [0],
         [0]]]])>, ivy.frontends.torch.Size([1, 1, 32, 32]))
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f82b012dea0>
array_like = <tf.Tensor: shape=(1, 5, 896, 1), dtype=int64, numpy=
array([[[[0],
         [0],
         [0],
         ...,
        ...,
         [0]],

        [[0],
         [0],
         [0],
         ...,
         [0],
         [0],
         [0]]]])>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 5, 896, 1), dtype=int64, numpy=
array([[[[0],
         [0],
         [0],
         ...,
        ...,
         [0]],

        [[0],
         [0],
         [0],
         ...,
         [0],
         [0],
         [0]]]])>
shape = ivy.frontends.torch.Size([1, 1, 32, 32])

    @tensorflow_handle_methods
    def tensorflow_reshape_frnt(input, shape):
        from ...backends.tensorflow.manipulation import tensorflow_reshape
    
>       return tensorflow_reshape(input, shape)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 5, 896, 1), dtype=int64, numpy=
array([[[[0],
         [0],
         [0],
         ...,
       ...],
         [0],
         ...,
         [0],
         [0],
         [0]]]])>, ivy.frontends.torch.Size([1, 1, 32, 32])]
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f82b012dea0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f82b01ac4c0>
tensorflow_asarray = <function tensorflow_asarray at 0x7f82b019d360>, tensorflow_get_item = <function tensorflow_get_item at 0x7f82b01ac310>, num_args = 2
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'shape', 'copy', 'order', 'allowzero', 'out']
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[tenso...s 'bool'>, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType]]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 1

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 896, 1), dtype=int64, numpy=
array([[[[0],
         [0],
         [0],
         ...,
        ...,
         [0]],

        [[0],
         [0],
         [0],
         ...,
         [0],
         [0],
         [0]]]])>
shape = ivy.frontends.torch.Size([1, 1, 32, 32])

    @tensorflow_handle_array_like_without_promotion
    def tensorflow_reshape(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        shape: Union[tf.TensorShape, Sequence[int]],
        *,
        copy: Optional[bool] = None,
        order: str = "C",
        allowzero: bool = True,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ....utils.assertions import tensorflow_check_elem_in_list
    
        tensorflow_check_elem_in_list(order, ["C", "F"])
        if not allowzero:
            shape = [
                (new_s if con else old_s)
                for new_s, con, old_s in zip(
                    shape, tensorflow.constant(shape) != 0, x.shape
                )
            ]
        if order == "F":
            return tensorflow__reshape_fortran_tf(x, shape)
>       return tensorflow.reshape(x, shape)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_DISK.call().
E       
E       [1m{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 4480 values, but the requested shape has 1024 [Op:Reshape][0m
E       
E       Arguments received by tensorflow_DISK.call():
E         • images=tf.Tensor(shape=(1, 3, 32, 32), dtype=float32)
E         • n=None
E         • window_size=5
E         • score_threshold=0.0
E         • pad_if_not_divisible=False

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:210: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
kornia.feature.DISK
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_LAFOrienter[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_PatchDominantGradientOrientation[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_TLU[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
FAILED kornia/test_feature5.py::test_DeDoDe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_Sequential.call().
FAILED kornia/test_feature5.py::test_DISK[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_DISK.call().
=============================================================================== 5 failed, 5 passed in 1822.08s (0:30:22) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py F................                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomMosaic[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'jax', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[-4.7404e-02,  1.0650e+00, -5.0510e-01,  ...,  2.8260e-01,
           -8.6297e-01, -1.5756e+00],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, same_on..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
params = None, data_keys = None
input = (Array([[[[-4.74043526e-02,  1.06497395e+00, -5.05098283e-01, ...,
           2.82604098e-01, -8.62966120e-01, -1.5756... 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7fe133d58160>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[jax-s2s-False] - KeyError: '2'
============================================================================== 1 failed, 16 passed in 3778.80s (1:02:58) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F.............F..........                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_equalize_clahe[jax-s2s-False] __________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4461: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f6585d8fc70>
trace_args = (tensor([[[0.6689, 0.0654, 0.1544, 0.2182, 0.2733, 0.4226, 0.1257, 0.6427,
          0.2532, 0.2851, 0.9630, 0.9791, 0...         0.0529, 0.6744, 0.6309, 0.9161, 0.3588, 0.6063, 0.6862, 0.7605,
          0.9831, 0.3259, 0.0347, 0.1716]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.4616, 0.8634, 0.8423,  ..., 0.8619, 0.7441, 0.7488],
          [0.1610, 0.5534, 0.2793,  ..., 0.2633, 0...., 0.7023, 0.6477,  ..., 0.0182, 0.3123, 0.8066],
          [0.8191, 0.3082, 0.9590,  ..., 0.0743, 0.8955, 0.4407]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f6585d8fc70>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.6689, 0.0654, 0.1544, 0.2182, 0.2733, 0.4226, 0.1257, 0.6427,
          0.2532, 0.2851, 0.9630, 0.9791, 0...         0.0529, 0.6744, 0.6309, 0.9161, 0.3588, 0.6063, 0.6862, 0.7605,
          0.9831, 0.3259, 0.0347, 0.1716]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.4616, 0.8634, 0.8423,  ..., 0.8619, 0.7441, 0.7488],
          [0.1610, 0.5534, 0.2793,  ..., 0.2633, 0...., 0.7023, 0.6477,  ..., 0.0182, 0.3123, 0.8066],
          [0.8191, 0.3082, 0.9590,  ..., 0.0743, 0.8955, 0.4407]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.668899  , 0.06541198, 0.15436482, 0.2181623 , 0.2732885 ,
          0.42258167, 0.1256864 , 0.6427325 , 0...., 0.6062808 , 0.68622965,
          0.7605329 , 0.9830594 , 0.32590503, 0.03472322, 0.17156625]]]],      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7f64f3dff2e0>
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f64f3dfe8c0>, jax_view_frnt_ = <function jax_view_frnt_ at 0x7f64f3dffa30>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.668899  , 0.06541198, 0.15436482, 0.2181623 , 0.2732885 ,
          0.42258167, 0.1256864 , 0.6427325 , 0...., 0.6062808 , 0.68622965,
          0.7605329 , 0.9830594 , 0.32590503, 0.03472322, 0.17156625]]]],      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:487: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[0.668899  , 0.06541198, 0.15436482, 0.2181623 , 0.2732885 ,
          0.42258167, 0.1256864 , 0.6427325 , 0...., 0.6062808 , 0.68622965,
          0.7605329 , 0.9830594 , 0.32590503, 0.03472322, 0.17156625]]]],      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
                jax_unfold_frnt_(
>                   jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[0.668899  , 0.8076032 , 0.23988551, 0.35736656, 0.24733675,
           0.76190346, 0.1661709 , 0.293889  ,...       0.9298593 , 0.90455645, 0.6956564 , 0.6511037 , 0.05607402,
           0.10954404]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f64defe30a0>
array_like = Array([[[[[0.668899  , 0.8076032 , 0.23988551, 0.35736656, 0.24733675,
           0.76190346, 0.1661709 , 0.293889  , ...659 ,
           0.9298593 , 0.90455645, 0.6956564 , 0.6511037 , 0.05607402,
           0.10954404]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[0.668899  , 0.8076032 , 0.23988551, 0.35736656, 0.24733675,
           0.76190346, 0.1661709 , 0.293889  , ...659 ,
           0.9298593 , 0.90455645, 0.6956564 , 0.6511037 , 0.05607402,
           0.10954404]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:127: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_ZCAWhitening[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ZCAWhitening(target_framework, mode, backend_compile):
        print("kornia.enhance.ZCAWhitening")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        x = torch.tensor([[0,1],[1,0],[-1,0],[0,-1]], dtype = torch.float32)
        zca = kornia.enhance.ZCAWhitening().fit(x)
        torch_out = zca(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_zca = transpiled_kornia.enhance.ZCAWhitening().fit(transpiled_x)
>       transpiled_out = transpiled_zca(x)

kornia/test_enhance.py:697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ZCAWhitening(), x = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), include_fit = False

    def __call__(self, x, include_fit=False):
        if include_fit:
            self.fit(x)
        if not self.fitted:
            raise RuntimeError(
                "Needs to be fitted first before running. Please call fit or set include_fit to True."
            )
>       x_whiten = jax_linear_transform(
            x, self.transform_matrix, self.mean_vector, self.dim
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), transform_matrix = Array([[1.224744, 0.      ],
       [0.      , 1.224744]], dtype=float32)
mean_vector = Array([[0., 0.]], dtype=float32), dim = 0

    def jax_linear_transform(inp, transform_matrix, mean_vector, dim=0):
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_arange_frnt
        from ...ivy.functional.frontends.torch.comparison_ops import jax_argsort_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import jax_prod_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_mm_frnt_
        from ..core._backend import concatenate
        from ..core._backend import tensor
    
        inp_size = jax_size_frnt_(inp)
        if dim >= len(inp_size) or dim < -len(inp_size):
            raise IndexError(
                f"Dimension out of range (expected to be in range of [{-len(inp_size)},{len(inp_size) - 1}], but got {dim}"
            )
        if dim < 0:
            dim = len(inp_size) + dim
        feat_dims = concatenate(
            [jax_arange_frnt(0, dim), jax_arange_frnt(dim + 1, len(inp_size))]
        )
        perm = concatenate([tensor([dim]), feat_dims])
        perm_inv = jax_argsort_frnt(perm)
        new_order: typing.Any = jax_tolist_frnt_(perm)
        inv_order: typing.Any = jax_tolist_frnt_(perm_inv)
        feature_sizes = tensor(
            jax_get_item(inp_size, slice(0, dim, None))
            + jax_get_item(inp_size, slice(dim + 1, None, None))
        )
        num_features: typing.Any = int(jax_item_frnt_(jax_prod_frnt(feature_sizes)))
        inp_permute = jax_permute_frnt_(inp, new_order)
        inp_flat = jax_reshape_frnt_(inp_permute, (-1, num_features))
>       inp_center = inp_flat - mean_vector
E       TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:318: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.ZCAWhitening
kornia.enhance.ZCAWhitening
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[jax-s2s-False] - Exception: Need at least one array to stack.
FAILED kornia/test_enhance.py::test_ZCAWhitening[jax-s2s-False] - TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'
============================================================================== 2 failed, 37 passed in 2922.24s (0:48:42) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py F......F.......FF.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_find_essential[numpy-s2s-False] _________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_essential(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 8, 2),
            torch.rand(1, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 8)}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8)}
>       _test_function(
            kornia.geometry.epipolar.find_essential,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_epipolar.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7f5d5d81a440>
trace_args = (tensor([[[0.4846, 0.4548],
         [0.7493, 0.7017],
         [0.3685, 0.6542],
         [0.9593, 0.9698],
         ...0.8265],
         [0.9010, 0.7838],
         [0.8736, 0.3715],
         [0.1230, 0.1537],
         [0.3211, 0.0182]]]))
trace_kwargs = {'weights': tensor([[0.9521, 0.1822, 0.2943, 0.6856, 0.6773, 0.3216, 0.0850, 0.4044]])}
test_args = (tensor([[[0.1275, 0.0673],
         [0.9887, 0.4536],
         [0.2323, 0.1192],
         [0.1130, 0.5985],
         ...0.7218],
         [0.4989, 0.6322],
         [0.9739, 1.0000],
         [0.6587, 0.5538],
         [0.3916, 0.8053]]]))
test_kwargs = {'weights': tensor([[0.3100, 0.1502, 0.5584, 0.5115, 0.5214, 0.6780, 0.7768, 0.2707],
        [0.6393, 0.4583, 0.2719,...8, 0.4235, 0.1418, 0.7211, 0.8887, 0.8095],
        [0.2854, 0.7028, 0.7132, 0.8311, 0.2790, 0.1389, 0.2299, 0.7514]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7f5d5d81a440>, fn_name = 'kornia.geometry.epipolar.find_essential'
trace_args = (tensor([[[0.4846, 0.4548],
         [0.7493, 0.7017],
         [0.3685, 0.6542],
         [0.9593, 0.9698],
         ...0.8265],
         [0.9010, 0.7838],
         [0.8736, 0.3715],
         [0.1230, 0.1537],
         [0.3211, 0.0182]]]))
trace_kwargs = {'weights': tensor([[0.9521, 0.1822, 0.2943, 0.6856, 0.6773, 0.3216, 0.0850, 0.4044]])}
test_args = (tensor([[[0.1275, 0.0673],
         [0.9887, 0.4536],
         [0.2323, 0.1192],
         [0.1130, 0.5985],
         ...0.7218],
         [0.4989, 0.6322],
         [0.9739, 1.0000],
         [0.6587, 0.5538],
         [0.3916, 0.8053]]]))
test_kwargs = {'weights': tensor([[0.3100, 0.1502, 0.5584, 0.5115, 0.5214, 0.6780, 0.7768, 0.2707],
        [0.6393, 0.4583, 0.2719,...8, 0.4235, 0.1418, 0.7211, 0.8887, 0.8095],
        [0.2854, 0.7028, 0.7132, 0.8311, 0.2790, 0.1389, 0.2299, 0.7514]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.48458827, 0.45478493],
        [0.7493017 , 0.70174986],
        [0.36845762, 0.65415955],
        [0.95926...
        [0.2233296 , 0.29745686],
        [0.38099194, 0.34744608],
        [0.06909585, 0.39702648]]], dtype=float32)
points2 = array([[[0.64662564, 0.4551466 ],
        [0.20096833, 0.535983  ],
        [0.81503135, 0.5354165 ],
        [0.06142...
        [0.8735676 , 0.37154526],
        [0.12299907, 0.15367556],
        [0.32114607, 0.01819748]]], dtype=float32)
weights = array([[0.9521439 , 0.1822322 , 0.2942893 , 0.68564945, 0.6772599 ,
        0.32156783, 0.0849548 , 0.40444958]], dtype=float32)

    def numpy_find_essential(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_to_frnt_
    
>       E = numpy_to_frnt_(numpy_run_5point(points1, points2, weights), points1.dtype)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.48458827, 0.45478493],
        [0.7493017 , 0.70174986],
        [0.36845762, 0.65415955],
        [0.95926...
        [0.2233296 , 0.29745686],
        [0.38099194, 0.34744608],
        [0.06909585, 0.39702648]]], dtype=float32)
points2 = array([[[0.64662564, 0.4551466 ],
        [0.20096833, 0.535983  ],
        [0.81503135, 0.5354165 ],
        [0.06142...
        [0.8735676 , 0.37154526],
        [0.12299907, 0.15367556],
        [0.32114607, 0.01819748]]], dtype=float32)
weights = array([[0.9521439 , 0.1822322 , 0.2942893 , 0.68564945, 0.6772599 ,
        0.32156783, 0.0849548 , 0.40444958]], dtype=float32)

    def numpy_run_5point(points1, points2, weights=None):
        from ...core.check import numpy_KORNIA_CHECK_SHAPE
        from ...core.check import numpy_KORNIA_CHECK_SAME_SHAPE
        from ...core.check import numpy_KORNIA_CHECK
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...core._backend import ones_like
    
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SAME_SHAPE(points1, points2)
        numpy_KORNIA_CHECK(
            numpy_shape_frnt_(points1)[1] >= 5, "Number of points should be >=5"
        )
        if weights is not None:
            numpy_KORNIA_CHECK_SAME_SHAPE(points1[:, :, 0], weights)
        batch_size, _, _ = numpy_shape_frnt_(points1)
        x1, y1 = numpy_chunk_frnt(points1, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x1 * x2, x1 * y2, x1, y1 * x2, y1 * y2, y1, x2, y2, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.9521439 , 0.1822322 , 0.2942893 , 0.68564945, 0.6772599 ,
         0.32156783, 0.0849548 , 0.40444958]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.essential.find_essential
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
________________________________________________________________________________ test_find_fundamental[numpy-s2s-False] ________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_fundamental(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 8, 2),
            torch.rand(2, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(2, 8), 'method': '8POINT'}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8), 'method': '8POINT'}
>       _test_function(
            kornia.geometry.epipolar.find_fundamental,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=3e-2,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7f5d5d81a9e0>
trace_args = (tensor([[[0.1414, 0.0542],
         [0.3874, 0.0592],
         [0.9819, 0.0161],
         [0.0352, 0.7126],
         ...0.4388],
         [0.1568, 0.9089],
         [0.8545, 0.7981],
         [0.9353, 0.1117],
         [0.6293, 0.2180]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.3630, 0.3162, 0.4496, 0.7929, 0.3673, 0.1240, 0.3044, 0.3056],
        [0.8968, 0.7141, 0.7350, 0.5560, 0.5473, 0.8443, 0.0639, 0.0118]])}
test_args = (tensor([[[0.5623, 0.1840],
         [0.3876, 0.6910],
         [0.4043, 0.7870],
         [0.0835, 0.3286],
         ...0.1993],
         [0.3990, 0.9491],
         [0.8164, 0.1304],
         [0.0498, 0.2859],
         [0.6331, 0.7208]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.6606, 0.7821, 0.1658, 0.1380, 0.2129, 0.8220, 0.9455, 0.6481],
        [0.3...6, 0.3691, 0.5352, 0.6799, 0.8753, 0.0107],
        [0.1407, 0.8570, 0.8979, 0.5904, 0.7403, 0.0529, 0.0740, 0.5356]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7f5d5d81a9e0>, fn_name = 'kornia.geometry.epipolar.find_fundamental'
trace_args = (tensor([[[0.1414, 0.0542],
         [0.3874, 0.0592],
         [0.9819, 0.0161],
         [0.0352, 0.7126],
         ...0.4388],
         [0.1568, 0.9089],
         [0.8545, 0.7981],
         [0.9353, 0.1117],
         [0.6293, 0.2180]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.3630, 0.3162, 0.4496, 0.7929, 0.3673, 0.1240, 0.3044, 0.3056],
        [0.8968, 0.7141, 0.7350, 0.5560, 0.5473, 0.8443, 0.0639, 0.0118]])}
test_args = (tensor([[[0.5623, 0.1840],
         [0.3876, 0.6910],
         [0.4043, 0.7870],
         [0.0835, 0.3286],
         ...0.1993],
         [0.3990, 0.9491],
         [0.8164, 0.1304],
         [0.0498, 0.2859],
         [0.6331, 0.7208]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.6606, 0.7821, 0.1658, 0.1380, 0.2129, 0.8220, 0.9455, 0.6481],
        [0.3...6, 0.3691, 0.5352, 0.6799, 0.8753, 0.0107],
        [0.1407, 0.8570, 0.8979, 0.5904, 0.7403, 0.0529, 0.0740, 0.5356]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.14140296, 0.05417246],
        [0.3874486 , 0.05915338],
        [0.9819307 , 0.01608711],
        [0.03523...
        [0.9074275 , 0.9356944 ],
        [0.9794198 , 0.17176723],
        [0.9645043 , 0.67643976]]], dtype=float32)
points2 = array([[[0.46346772, 0.5520648 ],
        [0.5460703 , 0.51908344],
        [0.3908894 , 0.20331043],
        [0.14543...
        [0.85452217, 0.79814965],
        [0.9353155 , 0.11173689],
        [0.62931675, 0.217951  ]]], dtype=float32)
weights = array([[0.3629676 , 0.31621653, 0.44958484, 0.79286903, 0.36734563,
        0.12404579, 0.30440253, 0.30559355],
     ....8967983 , 0.71413153, 0.73500973, 0.5559733 , 0.5473091 ,
        0.8443088 , 0.06390494, 0.01182461]], dtype=float32)
method = '8POINT'

    def numpy_find_fundamental(points1, points2, weights=None, method="8POINT"):
        if method.upper() == "7POINT":
            result = numpy_run_7point(points1, points2)
        elif method.upper() == "8POINT":
>           result = numpy_run_8point(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.14140296, 0.05417246],
        [0.3874486 , 0.05915338],
        [0.9819307 , 0.01608711],
        [0.03523...
        [0.9074275 , 0.9356944 ],
        [0.9794198 , 0.17176723],
        [0.9645043 , 0.67643976]]], dtype=float32)
points2 = array([[[0.46346772, 0.5520648 ],
        [0.5460703 , 0.51908344],
        [0.3908894 , 0.20331043],
        [0.14543...
        [0.85452217, 0.79814965],
        [0.9353155 , 0.11173689],
        [0.62931675, 0.217951  ]]], dtype=float32)
weights = array([[0.3629676 , 0.31621653, 0.44958484, 0.79286903, 0.36734563,
        0.12404579, 0.30440253, 0.30559355],
     ....8967983 , 0.71413153, 0.73500973, 0.5559733 , 0.5473091 ,
        0.8443088 , 0.06390494, 0.01182461]], dtype=float32)

    def numpy_run_8point(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...utils.helpers import numpy__torch_svd_cast
        from ....ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ....ivy.functional.frontends.torch.creation_ops import numpy_tensor_frnt
        from ...core._backend import ones_like
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1), numpy_shape_frnt_(points2))
        if numpy_shape_frnt_(points1)[1] < 8:
            raise AssertionError(numpy_shape_frnt_(points1))
        if weights is not None:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights)[1] == numpy_shape_frnt_(points1)[1]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x2 * x1, x2 * y1, x2, y2 * x1, y2 * y1, y2, x1, y1, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.3629676 , 0.31621653, 0.44958484, 0.79286903, 0.36734563,
         0.12404579, 0.30440253, 0.30559355]],

 ...967983 , 0.71413153, 0.73500973, 0.5559733 , 0.5473091 ,
         0.8443088 , 0.06390494, 0.01182461]]], dtype=float32)
offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.fundamental.find_fundamental
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  cond = numpy_reshape_frnt_(cond, cond_shape)
___________________________________________________________________________ test_sampson_epipolar_distance[numpy-s2s-False] ____________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_sampson_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.sampson_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7f5d5d818820>
trace_args = (tensor([[[0.8032, 0.8675],
         [0.2597, 0.0518],
         [0.2361, 0.7703],
         [0.3782, 0.1611]]]), tensor...0.7381]]]), tensor([[[0.8502, 0.8554, 0.0087],
         [0.7579, 0.0023, 0.9016],
         [0.0253, 0.9671, 0.3293]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.0049, 0.6756],
         [0.6399, 0.2884],
         [0.4088, 0.3796],
         [0.9105, 0.7205]],

       ...1627e-01, 6.9273e-01],
         [5.1702e-01, 7.2464e-01, 9.6178e-01],
         [7.3790e-01, 1.6003e-01, 5.7232e-01]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7f5d5d818820>, fn_name = 'kornia.geometry.epipolar.sampson_epipolar_distance'
trace_args = (tensor([[[0.8032, 0.8675],
         [0.2597, 0.0518],
         [0.2361, 0.7703],
         [0.3782, 0.1611]]]), tensor...0.7381]]]), tensor([[[0.8502, 0.8554, 0.0087],
         [0.7579, 0.0023, 0.9016],
         [0.0253, 0.9671, 0.3293]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.0049, 0.6756],
         [0.6399, 0.2884],
         [0.4088, 0.3796],
         [0.9105, 0.7205]],

       ...1627e-01, 6.9273e-01],
         [5.1702e-01, 7.2464e-01, 9.6178e-01],
         [7.3790e-01, 1.6003e-01, 5.7232e-01]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.8031625 , 0.8675197 , 1.        ],
        [0.25967073, 0.05182904, 1.        ],
        [0.23612398, 0.7703027 , 1.        ],
        [0.37818986, 0.16106153, 1.        ]]], dtype=float32)
pts2 = array([[[0.59268594, 0.96833366, 1.        ],
        [0.95947963, 0.8986255 , 1.        ],
        [0.74877805, 0.71621966, 1.        ],
        [0.5447101 , 0.73808515, 1.        ]]], dtype=float32)
Fm = array([[[0.85015345, 0.8554385 , 0.00870949],
        [0.75787526, 0.00233275, 0.9016255 ],
        [0.02534842, 0.9670789 , 0.32925016]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_sampson_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[3.5027175, 1.6358465, 2.5056343, 1.6268283]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5d04f675b0>
array_like = array([[3.5027175, 1.6358465, 2.5056343, 1.6268283]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[3.5027175, 1.6358465, 2.5056343, 1.6268283]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[3.5027175, 1.6358465, 2.5056343, 1.6268283]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5d04f675b0>
array_like = array([[3.5027175, 1.6358465, 2.5056343, 1.6268283]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[3.5027175, 1.6358465, 2.5056343, 1.6268283]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[3.5027175, 1.6358465, 2.5056343, 1.6268283]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.sampson_epipolar_distance
_________________________________________________________________________ test_symmetrical_epipolar_distance[numpy-s2s-False] __________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetrical_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.symmetrical_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:426: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7f5d5d818940>
trace_args = (tensor([[[0.1045, 0.7658],
         [0.7144, 0.5325],
         [0.1753, 0.7769],
         [0.0406, 0.5178]]]), tensor...0.7175]]]), tensor([[[0.8427, 0.7919, 0.8374],
         [0.3793, 0.8931, 0.9670],
         [0.8711, 0.8150, 0.4032]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.4878, 0.6923],
         [0.4721, 0.9422],
         [0.5604, 0.3719],
         [0.5072, 0.1365]],

       ... 0.6266]],

        [[0.2006, 0.9377, 0.3330],
         [0.2375, 0.9957, 0.9977],
         [0.6742, 0.4750, 0.2235]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7f5d5d818940>, fn_name = 'kornia.geometry.epipolar.symmetrical_epipolar_distance'
trace_args = (tensor([[[0.1045, 0.7658],
         [0.7144, 0.5325],
         [0.1753, 0.7769],
         [0.0406, 0.5178]]]), tensor...0.7175]]]), tensor([[[0.8427, 0.7919, 0.8374],
         [0.3793, 0.8931, 0.9670],
         [0.8711, 0.8150, 0.4032]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.4878, 0.6923],
         [0.4721, 0.9422],
         [0.5604, 0.3719],
         [0.5072, 0.1365]],

       ... 0.6266]],

        [[0.2006, 0.9377, 0.3330],
         [0.2375, 0.9957, 0.9977],
         [0.6742, 0.4750, 0.2235]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.10452366, 0.76584363, 1.        ],
        [0.7143726 , 0.53249794, 1.        ],
        [0.17526758, 0.7768914 , 1.        ],
        [0.04057556, 0.5177854 , 1.        ]]], dtype=float32)
pts2 = array([[[0.59597516, 0.43496948, 1.        ],
        [0.10606325, 0.08351237, 1.        ],
        [0.91352236, 0.8125704 , 1.        ],
        [0.6366144 , 0.71748716, 1.        ]]], dtype=float32)
Fm = array([[[0.8426749 , 0.79190546, 0.837385  ],
        [0.37927717, 0.893145  , 0.96703714],
        [0.87112385, 0.81495506, 0.4032495 ]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetrical_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[2.7668276, 1.8000133, 4.054599 , 2.7131472]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5d04dedf30>
array_like = array([[2.7668276, 1.8000133, 4.054599 , 2.7131472]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[2.7668276, 1.8000133, 4.054599 , 2.7131472]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[2.7668276, 1.8000133, 4.054599 , 2.7131472]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5d04dedf30>
array_like = array([[2.7668276, 1.8000133, 4.054599 , 2.7131472]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[2.7668276, 1.8000133, 4.054599 , 2.7131472]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[2.7668276, 1.8000133, 4.054599 , 2.7131472]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.symmetrical_epipolar_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_epipolar.py::test_find_essential[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_find_fundamental[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_sampson_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_epipolar.py::test_symmetrical_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
============================================================================== 4 failed, 22 passed in 1633.41s (0:27:13) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_RandomClahe[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'tensorflow', init_args = (), init_kwargs = {}
call_args = (tensor([[[[0.9564, 0.0551, 0.9215,  ..., 0.5702, 0.2990, 0.9665],
          [0.1682, 0.4390, 0.4204,  ..., 0.7171, 0...., 0.7209, 0.0120,  ..., 0.2643, 0.0686, 0.0039],
          [0.8139, 0.3969, 0.4826,  ..., 0.4332, 0.7579, 0.1281]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0.570185  ...
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f131fb53640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slo...,
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0.570185  ...
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slo...,
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0.570185  ...
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0.570185  ,...],
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0...,
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0.570185  ,...],
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f132205cca0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f131c0951b0>
tensor = <function tensorflow_tensor_frnt at 0x7f1326736b90>
in_tensor = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0.570185  ,...],
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0.570185  ,...],
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.95643896, 0.05506778, 0.92150027, ..., 0.570185  ,...],
         [0.8138507 , 0.39692664, 0.4825977 , ..., 0.43318665,
          0.75786024, 0.1280942 ]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f132205cca0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f13268797e0>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f1326887130>, tensorflow_get_item = <function tensorflow_get_item at 0x7f131c095000>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f131f9880d0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f1326884160>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f13268871c0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not tensorflow_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                tensorflow_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else tensorflow_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[0.9520532 , 0.8162805 , 0.92439735, 0.23911262, 0.21...0.26183903, 0.7949702 ,
          0.53027606, 0.28088456, 0.43318665, 0.75786024, 0.1280942 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import tensorflow_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return tensorflow_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/clahe.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[0.9520532 , 0.8162805 , 0.92439735, 0.23911262, 0.21...0.26183903, 0.7949702 ,
          0.53027606, 0.28088456, 0.43318665, 0.75786024, 0.1280942 ]]]],
      dtype=float32)>
args = (40.0, (8, 8), False), kwargs = {}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7f1326879360>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f132205cca0>
tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7f132687bb50>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[0.9520532 , 0.8162805 , 0.92439735, 0.23911262, 0.21...0.26183903, 0.7949702 ,
          0.53027606, 0.28088456, 0.43318665, 0.75786024, 0.1280942 ]]]],
      dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[0.9520532 , 0.8162805 , 0.92439735, 0.23911262, 0.21...0.26183903, 0.7949702 ,
          0.53027606, 0.28088456, 0.43318665, 0.75786024, 0.1280942 ]]]],
      dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
>               tensorflow_unfold_frnt_(
                    tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.9520532 , 0.8162805 , 0.92439735, ..., 0.....7579114 , 0.9854837 , 0.24982524, ..., 0.1059742 ,
            0.8879421 , 0.6137482 ]]]]]], dtype=float32)>, 3, 4, 4)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f13266f01f0>
array_like = <tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.9520532 , 0.8162805 , 0.92439735, ..., 0.9...        [0.7579114 , 0.9854837 , 0.24982524, ..., 0.1059742 ,
            0.8879421 , 0.6137482 ]]]]]], dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.9520532 , 0.8162805 , 0.92439735, ..., 0.9...        [0.7579114 , 0.9854837 , 0.24982524, ..., 0.1059742 ,
            0.8879421 , 0.6137482 ]]]]]], dtype=float32)>
dimension = 3, size = 4, step = 4

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:660: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)
E           IndexError: Exception encountered when calling tensorflow_RandomClahe.call().
E           
E           [1mlist index out of range[0m
E           
E           Arguments received by tensorflow_RandomClahe.call():
E             • input=tf.Tensor(shape=(2, 3, 10, 20), dtype=float32)
E             • params=None
E             • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:260: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_RandomClahe.call().
============================================================================== 1 failed, 17 passed in 3644.33s (1:00:44) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py s                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.44s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py ..                                                                                                                                                                  [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 144.31s (0:02:24) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ssssss                                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.13s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 451.04s (0:07:31) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py sss                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 3 skipped in 5.03s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_solve_pnp_dlt[numpy-s2s-False] __________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f251d3b0d30>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f251d3b0d30>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])
img_points = array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])
intrinsics = array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]]), weights = None, svd_eps = 0.001

    def numpy_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...utils.helpers import numpy__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_inverse_frnt,
        )
        from ..conversions import numpy_convert_points_to_homogeneous
        from ..linalg import numpy_transform_points
        from ....ivy.functional.backends.numpy.general import numpy_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...utils.misc import numpy_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import numpy_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import numpy_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = np.float32, np.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(numpy_shape_frnt_(world_points)) != 3
            or numpy_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {numpy_shape_frnt_(world_points)}."
            )
        if len(numpy_shape_frnt_(img_points)) != 3 or numpy_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {numpy_shape_frnt_(img_points)}."
            )
        if len(numpy_shape_frnt_(intrinsics)) != 3 or numpy_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {numpy_shape_frnt_(intrinsics)}."
            )
        if numpy_shape_frnt_(world_points)[1] != numpy_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(img_points)[0]
            or numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if numpy_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {numpy_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            numpy_shape_frnt_(world_points)[:2][0],
            numpy_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = numpy__mean_isotropic_scale_normalize(
            world_points
        )
        s = numpy__torch_linalg_svdvals(world_points_norm)
        if numpy_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = numpy_inverse_frnt(intrinsics)
        world_points_norm_h = numpy_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = numpy_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = numpy__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = numpy_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=None)
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = numpy_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = numpy_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = numpy_eye_like(4, solution)
        solution_4x4 = numpy_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = numpy_bmm_frnt(solution_4x4, world_transform_norm)
        solution = numpy_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = numpy_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = numpy_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/calibration/pnp.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': array([[0.0754885 , 0.02388223, 0.0574928 ]]), 'p': 2}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f24c47e2200>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[numpy-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 370.69s (0:06:10) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 4054.14s (1:07:34) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 2421.46s (0:40:21) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1920.28s (0:32:00) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F........................                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_equalize_clahe[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7fcc4b69bc70>
trace_args = (tensor([[[0.5652, 0.4565, 0.7350, 0.4441, 0.2500, 0.3850, 0.3139, 0.8808,
          0.7143, 0.3764, 0.7006, 0.7727, 0...         0.9541, 0.3519, 0.9101, 0.8011, 0.1541, 0.2465, 0.9616, 0.9763,
          0.5798, 0.3529, 0.0138, 0.3864]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.4812, 0.7050, 0.0195,  ..., 0.2325, 0.4841, 0.8836],
          [0.8857, 0.7176, 0.9188,  ..., 0.4984, 0...., 0.2549, 0.8949,  ..., 0.1727, 0.4436, 0.5970],
          [0.0744, 0.2614, 0.7661,  ..., 0.6739, 0.0574, 0.2990]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True
deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7fcc4b69bc70>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.5652, 0.4565, 0.7350, 0.4441, 0.2500, 0.3850, 0.3139, 0.8808,
          0.7143, 0.3764, 0.7006, 0.7727, 0...         0.9541, 0.3519, 0.9101, 0.8011, 0.1541, 0.2465, 0.9616, 0.9763,
          0.5798, 0.3529, 0.0138, 0.3864]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.4812, 0.7050, 0.0195,  ..., 0.2325, 0.4841, 0.8836],
          [0.8857, 0.7176, 0.9188,  ..., 0.4984, 0...., 0.2549, 0.8949,  ..., 0.1727, 0.4436, 0.5970],
          [0.0744, 0.2614, 0.7661,  ..., 0.6739, 0.0574, 0.2990]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.5652039 , 0.45645744, 0.7350301 , 0.44413304, 0.24...0.24645734, 0.96161467,
          0.97632056, 0.5798392 , 0.3528707 , 0.01375991, 0.38637275]]]],
      dtype=float32)>
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7fcbd176f9a0>
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fcbe8828700>, tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7fcbd176fa30>
input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.5652039 , 0.45645744, 0.7350301 , 0.44413304, 0.24...0.24645734, 0.96161467,
          0.97632056, 0.5798392 , 0.3528707 , 0.01375991, 0.38637275]]]],
      dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.5652039 , 0.45645744, 0.7350301 , 0.44413304, 0.24...0.24645734, 0.96161467,
          0.97632056, 0.5798392 , 0.3528707 , 0.01375991, 0.38637275]]]],
      dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
                tensorflow_unfold_frnt_(
>                   tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.5652039 , 0.66179395, 0.23959756, 0.01780403,...      0.5809519 , 0.9449883 , 0.03362197, 0.8947602 , 0.73065794,
           0.01349676]]]]], dtype=float32)>, 2, 2, 2)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7fcbc3e869e0>
array_like = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.5652039 , 0.66179395, 0.23959756, 0.01780403, ...927,
           0.5809519 , 0.9449883 , 0.03362197, 0.8947602 , 0.73065794,
           0.01349676]]]]], dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.5652039 , 0.66179395, 0.23959756, 0.01780403, ...927,
           0.5809519 , 0.9449883 , 0.03362197, 0.8947602 , 0.73065794,
           0.01349676]]]]], dtype=float32)>
dimension = 2, size = 2, step = 2

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2

    @tf_export.tf_export('experimental.numpy.stack', v1=[])
    @np_utils.np_doc('stack')
    def stack(arrays, axis=0):  # pylint: disable=missing-function-docstring
      if isinstance(arrays, (np_arrays.ndarray, tensor_lib.Tensor)):
        arrays = asarray(arrays)
        if axis == 0:
          return arrays
        else:
          return swapaxes(arrays, 0, axis)
      arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access
      unwrapped_arrays = [
          a if isinstance(a, np_arrays.ndarray) else a for a in arrays
      ]
>     return asarray(array_ops_stack.stack(unwrapped_arrays, axis))

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_array_ops.py:1211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ([], 2), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = [], axis = 2, name = 'stack'

    @tf_export("stack")
    @dispatch.add_dispatch_support
    def stack(values, axis=0, name="stack"):
      """Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.
    
      See also `tf.concat`, `tf.tile`, `tf.repeat`.
    
      Packs the list of tensors in `values` into a tensor with rank one higher than
      each tensor in `values`, by packing them along the `axis` dimension.
      Given a list of length `N` of tensors of shape `(A, B, C)`;
    
      if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
      if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
      Etc.
    
      For example:
    
      >>> x = tf.constant([1, 4])
      >>> y = tf.constant([2, 5])
      >>> z = tf.constant([3, 6])
      >>> tf.stack([x, y, z])
      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=
      array([[1, 4],
             [2, 5],
             [3, 6]], dtype=int32)>
      >>> tf.stack([x, y, z], axis=1)
      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=
      array([[1, 2, 3],
             [4, 5, 6]], dtype=int32)>
    
      This is the opposite of unstack.  The numpy equivalent is `np.stack`
    
      >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))
      True
    
      Args:
        values: A list of `Tensor` objects with the same shape and type.
        axis: An `int`. The axis to stack along. Defaults to the first dimension.
          Negative values wrap around, so the valid range is `[-(R+1), R+1)`.
        name: A name for this operation (optional).
    
      Returns:
        output: A stacked `Tensor` with the same type as `values`.
    
      Raises:
        ValueError: If `axis` is out of the range [-(R+1), R+1).
      """
      if axis == 0:
        try:
          # If the input is a constant list, it can be converted to a constant op
          return ops.convert_to_tensor(values, name=name)
        except (TypeError, ValueError, NotImplementedError):
          pass  # Input list contains non-constant tensors
    
>     value_shape = ops.convert_to_tensor(values[0], name=name)._shape_tuple()  # pylint: disable=protected-access
E     IndexError: list index out of range

/opt/fw/tensorflow/tensorflow/python/ops/array_ops_stack.py:78: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 1 failed, 38 passed in 2754.01s (0:45:54) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F.........sssssssssssssssssssssssssssssssss.ss                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_rgb_to_hls[numpy-s2s-False] ___________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f39d11d03a0>
trace_args = (tensor([[[[0.4469, 0.8984, 0.4195, 0.8234, 0.0183],
          [0.6764, 0.1738, 0.0095, 0.5633, 0.1987],
          [0.... [0.9139, 0.1709, 0.8271, 0.7550, 0.2156],
          [0.9236, 0.0287, 0.3906, 0.0796, 0.2328]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.3612, 0.0536, 0.5201, 0.5232, 0.9868],
          [0.7894, 0.7719, 0.9822, 0.4919, 0.0731],
          [0.... [0.1102, 0.8420, 0.8856, 0.1069, 0.1962],
          [0.0248, 0.5330, 0.9962, 0.0639, 0.3044]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f39d11d03a0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.4469, 0.8984, 0.4195, 0.8234, 0.0183],
          [0.6764, 0.1738, 0.0095, 0.5633, 0.1987],
          [0.... [0.9139, 0.1709, 0.8271, 0.7550, 0.2156],
          [0.9236, 0.0287, 0.3906, 0.0796, 0.2328]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.3612, 0.0536, 0.5201, 0.5232, 0.9868],
          [0.7894, 0.7719, 0.9822, 0.4919, 0.0731],
          [0.... [0.1102, 0.8420, 0.8856, 0.1069, 0.1962],
          [0.0248, 0.5330, 0.9962, 0.0639, 0.3044]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = array([[[[0.4469329 , 0.8983744 , 0.41954666, 0.8233731 , 0.01829112],
         [0.6763879 , 0.17378086, 0.00949037, 0...0.7550377 , 0.21559143],
         [0.9235503 , 0.02869409, 0.3905778 , 0.07964814, 0.23279083]]]],
      dtype=float32)
eps = 1e-08

    def numpy_rgb_to_hls(image, eps=1e-08):
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.pointwise_ops import sub
        from ..core._backend import where
        from ..core._backend import stack
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_requires_grad_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_like_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_add_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_mul_frnt
    
        if not isinstance(image, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(image)}")
        if len(numpy_shape_frnt_(image)) < 3 or numpy_shape_frnt_(image)[-3] != 3:
            raise ValueError(
                f"Input size must have a shape of (*, 3, H, W). Got {numpy_shape_frnt_(image)}"
            )
        _RGB2HSL_IDX = tensor([[[0.0]], [[1.0]], [[2.0]]], device=None, dtype=image.dtype)
        _img_max: typing.Any = numpy_max_frnt_(image, -3)
        maxc = _img_max[0]
        imax = _img_max[1]
        minc: typing.Any = numpy_min_frnt_(image, -3)[0]
        if numpy_requires_grad_frnt_(image):
            l_ = maxc + minc
            s = maxc - minc
            h = l_
            image_hls = l_
        else:
            image_hls = numpy_empty_like_frnt(image)
            h, l_, s = (
                image_hls[..., 0, :, :],
                image_hls[..., 1, :, :],
                image_hls[..., 2, :, :],
            )
            numpy_add_frnt(maxc, minc, out=l_)
            sub(maxc, minc, out=s)
        im = image / numpy_unsqueeze_frnt_(s + eps, -3)
        s = s / (where(l_ < 1.0, l_, 2.0 - l_) + eps)
        l_ = l_ / 2
        r, g, b = im[..., 0, :, :], im[..., 1, :, :], im[..., 2, :, :]
        cond = imax[..., None, :, :] == _RGB2HSL_IDX
        if numpy_requires_grad_frnt_(image):
            h = (g - b) % 6 * cond[..., 0, :, :]
        else:
>           numpy_mul_frnt((g - b) % 6, cond[..., 0, :, :], out=h)

ivy_transpiled_outputs/numpy_outputs/kornia/color/hls.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[5.1005363 , 5.373325  , 5.1871076 , 5.5625277 , 5.379264  ],
        [5.5627193 , 5.8029413 , 5.9363413 , 5. ..., 5.7840433 , 1.        ],
        [5.0363255 , 0.21377082, 0.9671869 , 0.99150157, 5.499846  ]]],
      dtype=float32)
other = array([[[False,  True, False,  True, False],
        [ True, False, False, False, False],
        [False, False,  True,  True, False],
        [ True,  True, False, False,  True]]])

    def numpy_mul_frnt(input, other, *, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.elementwise import numpy_multiply
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[5.1005363 , 5.373325  , 5.1871076 , 5.5625277 , 5.379264  ],
        [5.5627193 , 5.8029413 , 5.9363413 , 5. ..., 5.7840433 , 1.        ],
        [5.0363255 , 0.21377082, 0.9671869 , 0.99150157, 5.499846  ]]],
      dtype=float32)
x2 = array([[[False,  True, False,  True, False],
        [ True, False, False, False, False],
        [False, False,  True,  True, False],
        [ True,  True, False, False,  True]]])

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('bool')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_________________________________________________________________________________ test_rgb_to_yuv420[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f39d11d20e0>
trace_args = (tensor([[[[0.7398, 0.0590, 0.9868, 0.4761, 0.1338, 0.0387],
          [0.3510, 0.1930, 0.9219, 0.5205, 0.9864, 0.2490...     [0.7819, 0.9835, 0.2861, 0.2081, 0.8315, 0.7479],
          [0.4850, 0.3403, 0.3925, 0.0492, 0.7721, 0.4616]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.3633, 0.8821, 0.2617, 0.9470, 0.5979, 0.2958],
          [0.6987, 0.8103, 0.2020, 0.2954, 0.0688, 0.7395...     [0.7339, 0.4380, 0.4724, 0.0390, 0.4064, 0.4807],
          [0.0492, 0.2789, 0.5976, 0.1349, 0.2491, 0.3392]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f39d11d20e0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.7398, 0.0590, 0.9868, 0.4761, 0.1338, 0.0387],
          [0.3510, 0.1930, 0.9219, 0.5205, 0.9864, 0.2490...     [0.7819, 0.9835, 0.2861, 0.2081, 0.8315, 0.7479],
          [0.4850, 0.3403, 0.3925, 0.0492, 0.7721, 0.4616]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.3633, 0.8821, 0.2617, 0.9470, 0.5979, 0.2958],
          [0.6987, 0.8103, 0.2020, 0.2954, 0.0688, 0.7395...     [0.7339, 0.4380, 0.4724, 0.0390, 0.4064, 0.4807],
          [0.0492, 0.2789, 0.5976, 0.1349, 0.2491, 0.3392]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.8888, 0.4461, 0.5454, 0.3469, 0.1038, 0.4197],
          [0.4548, 0.4129, 0.4547, 0.4467, 0.3488, 0.7401...       [ 0.0448, -0.0791,  0.0810]],

         [[-0.1886,  0.2438, -0.0448],
          [ 0.0968,  0.1060,  0.1874]]]]))
transpiled_x = (array([[[[0.8887968 , 0.44607276, 0.5454014 , 0.34691498, 0.10382076,
          0.41966718],
         [0.45478946, 0....
        [[ 0.19901073, -0.08051003,  0.13351133],
         [ 0.06604628,  0.11398186, -0.03145571]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.8887968 , 0.44607276, 0.5454014 , 0.34691498, 0.10382076,
          0.41966718],
         [0.45478946, 0....
        [[-0.18856326,  0.24383956, -0.04484694],
         [ 0.09676212,  0.10600177,  0.1873912 ]]]], dtype=float32))
y = (array([[[[0.8887968 , 0.44607276, 0.5454014 , 0.34691498, 0.10382076,
          0.41966718],
         [0.45478946, 0....
        [[ 0.19901073, -0.08051003,  0.13351133],
         [ 0.06604628,  0.11398186, -0.03145571]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f3978a7ea00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.09437764,  0.08680752, -0.0137752 ],
         [ 0.04479105, -0.07910021,  0.08099017]],

        [[-0.18856326,  0.24383956, -0.04484694],
         [ 0.09676212,  0.10600177,  0.1873912 ]]]], dtype=float32)
y = array([[[[ 0.06124841,  0.1495328 ,  0.08521306],
         [ 0.0447805 , -0.04063305, -0.08605076]],

        [[ 0.19901073, -0.08051003,  0.13351133],
         [ 0.06604628,  0.11398186, -0.03145571]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_color.py::test_rgb_to_yuv420[numpy-s2s-False] - AssertionError: numpy array values are not all close
======================================================================== 2 failed, 32 passed, 35 skipped in 1827.57s (0:30:27) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py .                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 305.56s (0:05:05) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py ssssssssssssss                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 14 skipped in 5.37s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py ssssss                                                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.46s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 293.45s (0:04:53) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 774.27s (0:12:54) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 4 passed in 313.05s (0:05:13) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py ..                                                                                                                                                                  [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 140.20s (0:02:20) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 4 passed in 451.90s (0:07:31) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 318.02s (0:05:18) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 462.32s (0:07:42) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py F                                                                                                                                                                    [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_Swin2SR[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Swin2SR(target_framework, mode, backend_compile):
        # NOTE: this is in the form `integration.subsection.model`, the class submodule would just be transformers.Swin2SRModel
        print("transformers.vision.Swin2SRModel")
    
        ivy.set_backend(target_framework)
        dataset = load_dataset("huggingface/cats-image", trust_remote_code=True)
        image = dataset["test"]["image"][0]
        image_processor = AutoImageProcessor.from_pretrained(
            "caidas/swin2SR-classical-sr-x2-64"
        )
    
        # modify the config to avoid OOM issues
        swin2sr_config = Swin2SRConfig()
        swin2sr_config.embed_dim = 2
        swin2sr_config.depths = [2, 2]
        swin2sr_config.num_heads = [2, 2]
    
        torch_model = Swin2SRModel.from_pretrained(
            "caidas/swin2SR-classical-sr-x2-64",
            config=swin2sr_config,
            ignore_mismatched_sizes=True,
        )
        torch_inputs = image_processor(image, return_tensors="pt")
        with torch.no_grad():
            torch_outputs = torch_model(**torch_inputs)
        torch_last_hidden_states = torch_outputs.last_hidden_state
    
        TranslatedSwin2SRModel = ivy.transpile(
            Swin2SRModel, source="torch", target=target_framework
        )
        if target_framework == "tensorflow":
            # TODO: fix the issue with from_pretrained not working due to name-mismatch b/w PT model and translated TF model
>           translated_model = TranslatedSwin2SRModel.from_pretrained(
                "caidas/swin2SR-classical-sr-x2-64",
                from_pt=True,
                config=swin2sr_config,
                ignore_mismatched_sizes=True,
            )

transformers/test_vision.py:284: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.transformers.models.swin2sr.modeling_swin2sr.tensorflow_Swin2SRModel'>, pretrained_model_name_or_path = 'caidas/swin2SR-classical-sr-x2-64'
config = Swin2SRConfig {
  "attention_probs_dropout_prob": 0.0,
  "depths": [
    2,
    2
  ],
  "drop_path_rate": 0.1,
  "emb...on": "4.45.2",
  "upsampler": "pixelshuffle",
  "upscale": 2,
  "use_absolute_embeddings": false,
  "window_size": 8
}

cache_dir = None, ignore_mismatched_sizes = True, force_download = False, local_files_only = False, token = None, revision = 'main', use_safetensors = None, model_args = (), kwargs = {}
from_pt = True, resume_download = None

    @classmethod
    def from_pretrained(
        cls,
        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],
        *model_args,
        config: Optional[Union[PretrainedConfig, str, os.PathLike]] = None,
        cache_dir: Optional[Union[str, os.PathLike]] = None,
        ignore_mismatched_sizes: bool = False,
        force_download: bool = False,
        local_files_only: bool = False,
        token: Optional[Union[str, bool]] = None,
        revision: str = "main",
        use_safetensors: bool = None,
        **kwargs,
    ):
        r"""
        Instantiate a pretrained TF 2.0 model from a pre-trained model configuration.
    
        The warning *Weights from XXX not initialized from pretrained model* means that the weights of XXX do not come
        pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
        task.
    
        The warning *Weights from XXX not used in YYY* means that the layer XXX is not used by YYY, therefore those
        weights are discarded.
    
        Parameters:
            pretrained_model_name_or_path (`str`, *optional*):
                Can be either:
    
                    - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.
                    - A path to a *directory* containing model weights saved using
                      [`~TFPreTrainedModel.save_pretrained`], e.g., `./my_model_directory/`.
                    - A path or url to a *PyTorch state_dict save file* (e.g, `./pt_model/pytorch_model.bin`). In this
                      case, `from_pt` should be set to `True` and a configuration object should be provided as `config`
                      argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
                      using the provided conversion scripts and loading the TensorFlow model afterwards.
                    - `None` if you are both providing the configuration and state dictionary (resp. with keyword
                      arguments `config` and `state_dict`).
            model_args (sequence of positional arguments, *optional*):
                All remaining positional arguments will be passed to the underlying model's `__init__` method.
            config (`Union[PretrainedConfig, str]`, *optional*):
                Can be either:
    
                    - an instance of a class derived from [`PretrainedConfig`],
                    - a string valid as input to [`~PretrainedConfig.from_pretrained`].
    
                Configuration for the model to use instead of an automatically loaded configuration. Configuration can
                be automatically loaded when:
    
                    - The model is a model provided by the library (loaded with the *model id* string of a pretrained
                      model).
                    - The model was saved using [`~TFPreTrainedModel.save_pretrained`] and is reloaded by supplying the
                      save directory.
                    - The model is loaded by supplying a local directory as `pretrained_model_name_or_path` and a
                      configuration JSON file named *config.json* is found in the directory.
            from_pt (`bool`, *optional*, defaults to `False`):
                Load the model weights from a PyTorch state_dict save file (see docstring of
                `pretrained_model_name_or_path` argument).
            ignore_mismatched_sizes (`bool`, *optional*, defaults to `False`):
                Whether or not to raise an error if some of the weights from the checkpoint do not have the same size
                as the weights of the model (if for instance, you are instantiating a model with 10 labels from a
                checkpoint with 3 labels).
            cache_dir (`str`, *optional*):
                Path to a directory in which a downloaded pretrained model configuration should be cached if the
                standard cache should not be used.
            force_download (`bool`, *optional*, defaults to `False`):
                Whether or not to force the (re-)download of the model weights and configuration files, overriding the
                cached versions if they exist.
            resume_download:
                Deprecated and ignored. All downloads are now resumed by default when possible.
                Will be removed in v5 of Transformers.
            proxies:
                (`Dict[str, str], `optional`): A dictionary of proxy servers to use by protocol or endpoint, e.g.,
                `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.
                output_loading_info(`bool`, *optional*, defaults to `False`): Whether ot not to also return a
                dictionary containing missing keys, unexpected keys and error messages.
            local_files_only(`bool`, *optional*, defaults to `False`):
                Whether or not to only look at local files (e.g., not try downloading the model).
            token (`str` or `bool`, *optional*):
                The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use
                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).
            revision (`str`, *optional*, defaults to `"main"`):
                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
                git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any
                identifier allowed by git.
    
    
                <Tip>
    
                To test a pull request you made on the Hub, you can pass `revision="refs/pr/<pr_number>".
    
                </Tip>
    
            mirror (`str`, *optional*):
                Mirror source to accelerate downloads in China. If you are from China and have an accessibility
                problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
                Please refer to the mirror site for more information.
            subfolder (`str`, *optional*, defaults to `""`):
                In case the relevant files are located inside a subfolder of the model repo on huggingface.co, you can
                specify the folder name here.
            tf_to_pt_weight_rename (`Callable`, *optional*):
                A function that is called to transform the names of weights during the PyTorch to TensorFlow
                crossloading process. This is not necessary for most models, but is useful to allow composite models to
                be crossloaded correctly.
            use_safetensors (`bool`, *optional*, defaults to `None`):
                Whether or not to use `safetensors` checkpoints. Defaults to `None`. If not specified and `safetensors`
                is not installed, it will be set to `False`.
            kwargs (remaining dictionary of keyword arguments, *optional*):
                Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
                `output_attentions=True`). Behaves differently depending on whether a `config` is provided or
                automatically loaded:
    
                    - If a configuration is provided with `config`, `**kwargs` will be directly passed to the
                      underlying model's `__init__` method (we assume all relevant updates to the configuration have
                      already been done)
                    - If a configuration is not provided, `kwargs` will be first passed to the configuration class
                      initialization function ([`~PretrainedConfig.from_pretrained`]). Each key of `kwargs` that
                      corresponds to a configuration attribute will be used to override said attribute with the
                      supplied `kwargs` value. Remaining keys that do not correspond to any configuration attribute
                      will be passed to the underlying model's `__init__` function.
    
        Examples:
    
        ```python
        >>> from transformers import BertConfig, TFBertModel
    
        >>> # Download model and configuration from huggingface.co and cache.
        >>> model = TFBertModel.from_pretrained("google-bert/bert-base-uncased")
        >>> # Model was saved using *save_pretrained('./test/saved_model/')* (for example purposes, not runnable).
        >>> model = TFBertModel.from_pretrained("./test/saved_model/")
        >>> # Update configuration during loading.
        >>> model = TFBertModel.from_pretrained("google-bert/bert-base-uncased", output_attentions=True)
        >>> assert model.config.output_attentions == True
        >>> # Loading from a Pytorch model file instead of a TensorFlow checkpoint (slower, for example purposes, not runnable).
        >>> config = BertConfig.from_json_file("./pt_model/my_pt_model_config.json")
        >>> model = TFBertModel.from_pretrained("./pt_model/my_pytorch_model.bin", from_pt=True, config=config)
        ```"""
        from_pt = kwargs.pop("from_pt", False)
        resume_download = kwargs.pop("resume_download", None)
        proxies = kwargs.pop("proxies", None)
        output_loading_info = kwargs.pop("output_loading_info", False)
        use_auth_token = kwargs.pop("use_auth_token", None)
        trust_remote_code = kwargs.pop("trust_remote_code", None)
        _ = kwargs.pop("mirror", None)
        load_weight_prefix = kwargs.pop("load_weight_prefix", None)
        from_pipeline = kwargs.pop("_from_pipeline", None)
        from_auto_class = kwargs.pop("_from_auto", False)
        subfolder = kwargs.pop("subfolder", "")
        commit_hash = kwargs.pop("_commit_hash", None)
        tf_to_pt_weight_rename = kwargs.pop("tf_to_pt_weight_rename", None)
    
        # Not relevant for TF models
        _ = kwargs.pop("adapter_kwargs", None)
    
        if use_auth_token is not None:
            warnings.warn(
                "The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.",
                FutureWarning,
            )
            if token is not None:
                raise ValueError(
                    "`token` and `use_auth_token` are both specified. Please set only the argument `token`."
                )
            token = use_auth_token
    
        if trust_remote_code is True:
            logger.warning(
                "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is"
                " ignored."
            )
    
        user_agent = {"file_type": "model", "framework": "tensorflow", "from_auto_class": from_auto_class}
        if from_pipeline is not None:
            user_agent["using_pipeline"] = from_pipeline
    
        if is_offline_mode() and not local_files_only:
            logger.info("Offline mode: forcing local_files_only=True")
            local_files_only = True
    
        if use_safetensors is None and not is_safetensors_available():
            use_safetensors = False
    
        # Load config if we don't provide a configuration
        if not isinstance(config, PretrainedConfig):
            config_path = config if config is not None else pretrained_model_name_or_path
            config, model_kwargs = cls.config_class.from_pretrained(
                config_path,
                cache_dir=cache_dir,
                return_unused_kwargs=True,
                force_download=force_download,
                resume_download=resume_download,
                proxies=proxies,
                local_files_only=local_files_only,
                token=token,
                revision=revision,
                _from_auto=from_auto_class,
                _from_pipeline=from_pipeline,
                _commit_hash=commit_hash,
                **kwargs,
            )
        else:
            model_kwargs = kwargs
    
        if commit_hash is None:
            commit_hash = getattr(config, "_commit_hash", None)
    
        # This variable will flag if we're loading a sharded checkpoint. In this case the archive file is just the
        # index of the files.
        is_sharded = False
        # Load model
        if pretrained_model_name_or_path is not None:
            pretrained_model_name_or_path = str(pretrained_model_name_or_path)
            is_local = os.path.isdir(pretrained_model_name_or_path)
            if is_local:
                if from_pt and os.path.isfile(os.path.join(pretrained_model_name_or_path, WEIGHTS_NAME)):
                    # Load from a PyTorch checkpoint in priority if from_pt
                    archive_file = os.path.join(pretrained_model_name_or_path, WEIGHTS_NAME)
                elif from_pt and os.path.isfile(os.path.join(pretrained_model_name_or_path, WEIGHTS_INDEX_NAME)):
                    # Load from a sharded PyTorch checkpoint
                    archive_file = os.path.join(pretrained_model_name_or_path, WEIGHTS_INDEX_NAME)
                    is_sharded = True
                elif use_safetensors is not False and os.path.isfile(
                    os.path.join(pretrained_model_name_or_path, SAFE_WEIGHTS_NAME)
                ):
                    # Load from a safetensors checkpoint
                    archive_file = os.path.join(pretrained_model_name_or_path, SAFE_WEIGHTS_NAME)
                elif use_safetensors is not False and os.path.isfile(
                    os.path.join(pretrained_model_name_or_path, SAFE_WEIGHTS_INDEX_NAME)
                ):
                    # Load from a sharded safetensors checkpoint
                    archive_file = os.path.join(pretrained_model_name_or_path, SAFE_WEIGHTS_INDEX_NAME)
                    is_sharded = True
                elif os.path.isfile(os.path.join(pretrained_model_name_or_path, TF2_WEIGHTS_NAME)):
                    # Load from a TF 2.0 checkpoint
                    archive_file = os.path.join(pretrained_model_name_or_path, TF2_WEIGHTS_NAME)
                elif os.path.isfile(os.path.join(pretrained_model_name_or_path, TF2_WEIGHTS_INDEX_NAME)):
                    # Load from a sharded TF 2.0 checkpoint
                    archive_file = os.path.join(pretrained_model_name_or_path, TF2_WEIGHTS_INDEX_NAME)
                    is_sharded = True
    
                # At this stage we don't have a weight file so we will raise an error.
                elif use_safetensors:
                    raise EnvironmentError(
                        f"Error no file named {SAFE_WEIGHTS_NAME} or {SAFE_WEIGHTS_INDEX_NAME} found in directory {pretrained_model_name_or_path}. "
                        f"Please make sure that the model has been saved with `safe_serialization=True` or do not "
                        f"set `use_safetensors=True`."
                    )
                elif os.path.isfile(os.path.join(pretrained_model_name_or_path, WEIGHTS_NAME)) or os.path.isfile(
                    os.path.join(pretrained_model_name_or_path, WEIGHTS_INDEX_NAME)
                ):
                    raise EnvironmentError(
                        f"Error no file named {TF2_WEIGHTS_NAME} or {SAFE_WEIGHTS_NAME} found in directory {pretrained_model_name_or_path} "
                        "but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those "
                        "weights."
                    )
                else:
                    raise EnvironmentError(
                        f"Error no file named {TF2_WEIGHTS_NAME}, {SAFE_WEIGHTS_NAME} or {WEIGHTS_NAME} found in directory "
                        f"{pretrained_model_name_or_path}."
                    )
            elif os.path.isfile(pretrained_model_name_or_path):
                archive_file = pretrained_model_name_or_path
                is_local = True
            elif os.path.isfile(pretrained_model_name_or_path + ".index"):
                archive_file = pretrained_model_name_or_path + ".index"
                is_local = True
            elif is_remote_url(pretrained_model_name_or_path):
                filename = pretrained_model_name_or_path
                resolved_archive_file = download_url(pretrained_model_name_or_path)
            else:
                # set correct filename
                if from_pt:
                    filename = WEIGHTS_NAME
                elif use_safetensors is not False:
                    filename = SAFE_WEIGHTS_NAME
                else:
                    filename = TF2_WEIGHTS_NAME
    
                try:
                    # Load from URL or cache if already cached
                    cached_file_kwargs = {
                        "cache_dir": cache_dir,
                        "force_download": force_download,
                        "proxies": proxies,
                        "resume_download": resume_download,
                        "local_files_only": local_files_only,
                        "token": token,
                        "user_agent": user_agent,
                        "revision": revision,
                        "subfolder": subfolder,
                        "_raise_exceptions_for_gated_repo": False,
                        "_raise_exceptions_for_missing_entries": False,
                        "_commit_hash": commit_hash,
                    }
                    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)
    
                    # Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None
                    # result when internet is up, the repo and revision exist, but the file does not.
                    if resolved_archive_file is None and filename == SAFE_WEIGHTS_NAME:
                        # Did not find the safetensors file, let's fallback to TF.
                        # No support for sharded safetensors yet, so we'll raise an error if that's all we find.
                        filename = TF2_WEIGHTS_NAME
                        resolved_archive_file = cached_file(
                            pretrained_model_name_or_path, TF2_WEIGHTS_NAME, **cached_file_kwargs
                        )
                    if resolved_archive_file is None and filename == TF2_WEIGHTS_NAME:
                        # Maybe the checkpoint is sharded, we try to grab the index name in this case.
                        resolved_archive_file = cached_file(
                            pretrained_model_name_or_path, TF2_WEIGHTS_INDEX_NAME, **cached_file_kwargs
                        )
                        if resolved_archive_file is not None:
                            is_sharded = True
                    if resolved_archive_file is None and filename == WEIGHTS_NAME:
                        # Maybe the checkpoint is sharded, we try to grab the index name in this case.
                        resolved_archive_file = cached_file(
                            pretrained_model_name_or_path, WEIGHTS_INDEX_NAME, **cached_file_kwargs
                        )
                        if resolved_archive_file is not None:
                            is_sharded = True
                    if resolved_archive_file is None:
                        # Otherwise, maybe there is a PyTorch or Flax model file.  We try those to give a helpful error
                        # message.
                        has_file_kwargs = {
                            "revision": revision,
                            "proxies": proxies,
                            "token": token,
                            "cache_dir": cache_dir,
                            "local_files_only": local_files_only,
                        }
                        if has_file(pretrained_model_name_or_path, SAFE_WEIGHTS_INDEX_NAME, **has_file_kwargs):
                            is_sharded = True
                        elif has_file(pretrained_model_name_or_path, WEIGHTS_NAME, **has_file_kwargs):
>                           raise EnvironmentError(
                                f"{pretrained_model_name_or_path} does not appear to have a file named"
                                f" {TF2_WEIGHTS_NAME} but there is a file for PyTorch weights. Use `from_pt=True` to"
                                " load this model from those weights."
                            )
E                           OSError: caidas/swin2SR-classical-sr-x2-64 does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:2873: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
transformers.vision.Swin2SRModel
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------

Downloading data:   0%|          | 0.00/173k [00:00<?, ?B/s]
Downloading data: 100%|██████████| 173k/173k [00:00<00:00, 2.73MB/s]

Generating test split: 0 examples [00:00, ? examples/s]
Generating test split: 1 examples [00:00, 113.62 examples/s]
Some weights of Swin2SRModel were not initialized from the model checkpoint at caidas/swin2SR-classical-sr-x2-64 and are newly initialized because the shapes did not match:
- swin2sr.conv_after_body.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.conv_after_body.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.layernorm.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.layernorm.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.embeddings.patch_embeddings.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.conv.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.conv.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.0.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.layers.1.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.0.patch_embed.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.0.patch_embed.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.conv.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.conv.weight: found shape torch.Size([180, 180, 3, 3]) in the checkpoint and torch.Size([2, 2, 3, 3]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.0.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.output.dense.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.continuous_position_bias_mlp.2.weight: found shape torch.Size([6, 512]) in the checkpoint and torch.Size([2, 512]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.key.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.logit_scale: found shape torch.Size([6, 1, 1]) in the checkpoint and torch.Size([2, 1, 1]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.query.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.query.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.value.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.attention.self.value.weight: found shape torch.Size([180, 180]) in the checkpoint and torch.Size([2, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.intermediate.dense.bias: found shape torch.Size([360]) in the checkpoint and torch.Size([4]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.intermediate.dense.weight: found shape torch.Size([360, 180]) in the checkpoint and torch.Size([4, 2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_after.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_after.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_before.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.layernorm_before.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.output.dense.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.layers.1.output.dense.weight: found shape torch.Size([180, 360]) in the checkpoint and torch.Size([2, 4]) in the model instantiated
- swin2sr.encoder.stages.1.patch_embed.projection.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.encoder.stages.1.patch_embed.projection.weight: found shape torch.Size([180, 180, 1, 1]) in the checkpoint and torch.Size([2, 2, 1, 1]) in the model instantiated
- swin2sr.first_convolution.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.first_convolution.weight: found shape torch.Size([180, 3, 3, 3]) in the checkpoint and torch.Size([2, 3, 3, 3]) in the model instantiated
- swin2sr.layernorm.bias: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
- swin2sr.layernorm.weight: found shape torch.Size([180]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED transformers/test_vision.py::test_Swin2SR[tensorflow-s2s-False] - OSError: caidas/swin2SR-classical-sr-x2-64 does not appear to have a file named tf_model.h5 but there is a file for PyTorch ...
==================================================================================== 1 failed in 314.14s (0:05:14) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 312.21s (0:05:12) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py ssssssssssssssssss                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 18 skipped in 5.17s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 134.14s (0:02:14) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_conv_quad_interp3d[jax-s2s-False] ________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "IXC.pyx", line 328, in IXC._wrap_callable.wrapper
TypeError: 'NoneType' object is not iterable

During handling of the above exception, another exception occurred:

jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f85696f31c0>
trace_args = (tensor([[[[[0.7047, 0.0970, 0.2031, 0.9844, 0.4052],
           [0.5809, 0.2539, 0.8365, 0.7331, 0.0477],
           ....9544],
           [0.0727, 0.0513, 0.0790, 0.6580, 0.9226],
           [0.0728, 0.1198, 0.7936, 0.6261, 0.0064]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[9.0770e-01, 1.4408e-01, 3.6982e-01, 2.0988e-01, 3.5179e-01],
           [5.3764e-01, 3.5665e-01, 8.5970e-...01, 3.8962e-02, 3.9126e-01, 1.5623e-01],
           [6.2543e-01, 5.8436e-01, 5.4002e-01, 9.3504e-01, 2.0018e-01]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f85696f31c0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.7047, 0.0970, 0.2031, 0.9844, 0.4052],
           [0.5809, 0.2539, 0.8365, 0.7331, 0.0477],
           ....9544],
           [0.0727, 0.0513, 0.0790, 0.6580, 0.9226],
           [0.0728, 0.1198, 0.7936, 0.6261, 0.0064]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[9.0770e-01, 1.4408e-01, 3.6982e-01, 2.0988e-01, 3.5179e-01],
           [5.3764e-01, 3.5665e-01, 8.5970e-...01, 3.8962e-02, 3.9126e-01, 1.5623e-01],
           [6.2543e-01, 5.8436e-01, 5.4002e-01, 9.3504e-01, 2.0018e-01]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[0.7046697 , 0.09704351, 0.20308042, 0.98436815, 0.4052074 ],
          [0.5809027 , 0.25394702, 0.83651084,....6579859 , 0.9226133 ],
          [0.07276088, 0.11979085, 0.7936092 , 0.62605995, 0.00640059]]]]],      dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([], shape=(0, 3, 1), dtype=float32), A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([], shape=(0, 3, 3), dtype=float32)], kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f84dd4304c0>
jax_set_item = <function jax_set_item at 0x7f84dd433880>, jax_asarray = <function jax_asarray at 0x7f84dd431360>, jax_get_item = <function jax_get_item at 0x7f84dd4336d0>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([], shape=(0, 3, 3), dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_________________________________________________________________________________ test_ConvQuadInterp3d[jax-s2s-False] _________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = transpiled_kornia.geometry.subpix.ConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = Array([[[[[-0.14401743, -0.67563075,  1.790072  ,  1.0566032 ,
           -0.63808477],
          [-0.33503288, -0.189...0.8549521 ],
          [ 0.5721451 ,  0.2736273 ,  0.45840633, -0.8815674 ,
            0.95982   ]]]]], dtype=float32)

    def __call__(self, x):
>       return jax_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[-0.14401743, -0.67563075,  1.790072  ,  1.0566032 ,
           -0.63808477],
          [-0.33503288, -0.189...0.8549521 ],
          [ 0.5721451 ,  0.2736273 ,  0.45840633, -0.8815674 ,
            0.95982   ]]]]], dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([], shape=(0, 3, 1), dtype=float32), A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([], shape=(0, 3, 3), dtype=float32)], kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f84c95851b0>
jax_set_item = <function jax_set_item at 0x7f84c95705e0>, jax_asarray = <function jax_asarray at 0x7f84c9586050>, jax_get_item = <function jax_get_item at 0x7f84c9570430>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([], shape=(0, 3, 3), dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
============================================================================== 2 failed, 13 passed in 1212.28s (0:20:12) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................................ssssssssssssssss                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 40 passed, 16 skipped in 3356.20s (0:55:56) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_get_laf_descriptors[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f97cb025d80>
trace_args = (tensor([[[[0.2320, 0.9233, 0.6479,  ..., 0.5462, 0.8198, 0.6811],
          [0.7092, 0.1274, 0.9467,  ..., 0.9489, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.6985, 0.8261, 0.0795,  ..., 0.4154, 0.5993, 0.3807],
          [0.6590, 0.8305, 0.1519,  ..., 0.7310, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f97cb025d80>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.2320, 0.9233, 0.6479,  ..., 0.5462, 0.8198, 0.6811],
          [0.7092, 0.1274, 0.9467,  ..., 0.9489, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.6985, 0.8261, 0.0795,  ..., 0.4154, 0.5993, 0.3807],
          [0.6590, 0.8305, 0.1519,  ..., 0.7310, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
>       transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]

helpers.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <enumerate object at 0x7f9772c14ec0>

    transpiled_trace_args = [
>       transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
        for i, arg in enumerate(trace_args)
    ]

helpers.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arg = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
arg_class_info = {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}

    def transpile_and_instantiate(arg, arg_class_info=None):
        if arg_class_info:
            # If we have class info, transpile the class and instantiate it
>           transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)

helpers.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.feature.orientation.OriNet'>, source = 'torch', target = 'numpy', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientation.ivy_OriNet'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientat...
============================================================================== 1 failed, 18 passed in 1375.86s (0:22:55) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F......F.............F....F......F.....F......                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_rgb_to_hls[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fa6405d43a0>
trace_args = (tensor([[[[0.7122, 0.7568, 0.2833, 0.5464, 0.7320],
          [0.6709, 0.7467, 0.4159, 0.4888, 0.6936],
          [0.... [0.7640, 0.5323, 0.9996, 0.4861, 0.0781],
          [0.3110, 0.5748, 0.6026, 0.9074, 0.2874]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.8508, 0.1477, 0.1987, 0.7476, 0.5023],
          [0.9723, 0.9258, 0.3964, 0.7253, 0.6815],
          [0.... [0.4906, 0.5334, 0.6098, 0.6776, 0.2288],
          [0.0210, 0.0338, 0.1722, 0.1818, 0.8966]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fa6405d43a0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.7122, 0.7568, 0.2833, 0.5464, 0.7320],
          [0.6709, 0.7467, 0.4159, 0.4888, 0.6936],
          [0.... [0.7640, 0.5323, 0.9996, 0.4861, 0.0781],
          [0.3110, 0.5748, 0.6026, 0.9074, 0.2874]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.8508, 0.1477, 0.1987, 0.7476, 0.5023],
          [0.9723, 0.9258, 0.3964, 0.7253, 0.6815],
          [0.... [0.4906, 0.5334, 0.6098, 0.6776, 0.2288],
          [0.0210, 0.0338, 0.1722, 0.1818, 0.8966]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[3.3506, 1.0433, 3.0791, 1.8295, 5.1960],
          [1.9141, 1.1510, 1.3715, 2.5561, 5.9644],
          [5.5....5073, 0.9989, 0.1649, 0.6286],
          [0.8149, 0.4380, 0.8119, 0.7266, 0.3935]]]],
       grad_fn=<StackBackward0>)
transpiled_x = <tf.Tensor: shape=(1, 3, 4, 5), dtype=float32, numpy=
array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
  ...., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[3.350642  , 1.0432645 , 3.079067  , 1.8295493 , 5.195984  ],
         [1.9140805 , 1.1509638 , 1.3715272 , 2...0.1649304 , 0.628572  ],
         [0.8149061 , 0.43796924, 0.81187665, 0.72658205, 0.39345172]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_______________________________________________________________________________ test_rgb_to_yuv420[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fa6405d60e0>
trace_args = (tensor([[[[0.9614, 0.9345, 0.6280, 0.5513, 0.1438, 0.2567],
          [0.8506, 0.7362, 0.3715, 0.8382, 0.6002, 0.5643...     [0.7052, 0.3101, 0.9543, 0.7778, 0.2554, 0.1133],
          [0.1790, 0.6804, 0.3858, 0.6319, 0.4348, 0.3669]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.0357, 0.9445, 0.9241, 0.8955, 0.3033, 0.5035],
          [0.1053, 0.2394, 0.1285, 0.2560, 0.0969, 0.6371...     [0.7257, 0.1077, 0.5691, 0.1277, 0.9586, 0.3829],
          [0.3396, 0.8035, 0.5859, 0.3995, 0.7380, 0.4246]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fa6405d60e0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.9614, 0.9345, 0.6280, 0.5513, 0.1438, 0.2567],
          [0.8506, 0.7362, 0.3715, 0.8382, 0.6002, 0.5643...     [0.7052, 0.3101, 0.9543, 0.7778, 0.2554, 0.1133],
          [0.1790, 0.6804, 0.3858, 0.6319, 0.4348, 0.3669]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.0357, 0.9445, 0.9241, 0.8955, 0.3033, 0.5035],
          [0.1053, 0.2394, 0.1285, 0.2560, 0.0969, 0.6371...     [0.7257, 0.1077, 0.5691, 0.1277, 0.9586, 0.3829],
          [0.3396, 0.8035, 0.5859, 0.3995, 0.7380, 0.4246]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.4014, 0.6283, 0.5221, 0.4210, 0.3407, 0.6150],
          [0.6686, 0.7228, 0.5834, 0.5914, 0.6345, 0.7154...       [ 0.0233,  0.0784, -0.0574]],

         [[ 0.2328,  0.0595, -0.1625],
          [-0.0637, -0.1704, -0.0140]]]]))
transpiled_x = (<tf.Tensor: shape=(1, 1, 4, 6), dtype=float32, numpy=
array([[[[0.40137047, 0.6282728 , 0.5221082 , 0.4209875 , 0.340...        [[ 0.01674452,  0.02578075, -0.0309831 ],
         [-0.13127726,  0.03144578, -0.02993331]]]], dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.40137047, 0.6282728 , 0.5221082 , 0.4209875 , 0.34065154,
          0.61503106],
         [0.6686069 , 0....
        [[ 0.23283942,  0.05949538, -0.16245183],
         [-0.06368321, -0.17040765, -0.01401473]]]], dtype=float32))
y = (array([[[[0.40137047, 0.6282728 , 0.5221082 , 0.4209875 , 0.34065154,
          0.61503106],
         [0.6686069 , 0....
        [[ 0.01674452,  0.02578075, -0.0309831 ],
         [-0.13127726,  0.03144578, -0.02993331]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fa5dee2c080>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.04907024,  0.03396239, -0.10232833],
         [ 0.02325573,  0.07837618, -0.05737524]],

        [[ 0.23283942,  0.05949538, -0.16245183],
         [-0.06368321, -0.17040765, -0.01401473]]]], dtype=float32)
y = array([[[[ 0.06981725, -0.11963341, -0.02873478],
         [-0.09030304,  0.0462534 ,  0.04942109]],

        [[ 0.01674452,  0.02578075, -0.0309831 ],
         [-0.13127726,  0.03144578, -0.02993331]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
________________________________________________________________________________ test_raw_to_rgb[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_raw_to_rgb(target_framework, mode, backend_compile):
        print("kornia.color.raw_to_rgb")
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_x = torch.rand(5, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.raw_to_rgb(torch_x, kornia.color.CFA.RG)
        transpiled_out = transpiled_kornia.color.raw_to_rgb(transpiled_x, transpiled_kornia.color.CFA.RG)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:715: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.0635, 0.0635, 0.1183, 0.1732, 0.3015, 0.4299],
          [0.0635, 0.0635, 0.1183, 0.1732, 0.3015, 0.4299]...       [0.8663, 0.9202, 0.9741, 0.6426, 0.3112, 0.3112],
          [0.8663, 0.9202, 0.9741, 0.6426, 0.3112, 0.3112]]]])
transpiled_x = <tf.Tensor: shape=(5, 3, 4, 6), dtype=float32, numpy=
array([[[[0.06351733, 0.06351733, 0.11833495, 0.19149172, 0.3382...1772 ],
         [0.86634195, 0.9048315 , 0.96641487, 0.642645  , 0.3111772 ,
          0.3111772 ]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.06351733, 0.06351733, 0.11833495, 0.17315257, 0.30152628,
          0.4299    ],
         [0.06351733, 0.0...11772 ],
         [0.86634195, 0.92022735, 0.9741128 , 0.642645  , 0.3111772 ,
          0.3111772 ]]]], dtype=float32)
y = array([[[[0.06351733, 0.06351733, 0.11833495, 0.19149172, 0.33820453,
          0.4299    ],
         [0.06351733, 0.0...11772 ],
         [0.86634195, 0.9048315 , 0.96641487, 0.642645  , 0.3111772 ,
          0.3111772 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.raw_to_rgb
kornia.color.raw_to_rgb
_________________________________________________________________________________ test_RgbToHls[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            "kornia.color.RgbToHls",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>, cls_name = 'kornia.color.RgbToHls'
args = (tensor([[[[0.1133, 0.6678, 0.5857, 0.9242, 0.0118],
          [0.7679, 0.0488, 0.5502, 0.6906, 0.0975],
          [0...., 0.4492],
          [0.6550, 0.7900, 0.2778, 0.5268, 0.9591],
          [0.3378, 0.9032, 0.4813, 0.3267, 0.2781]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[2.80421   , 4.552545  , 1.3589872 , 5.151577  , 3.9994044 ],
         [5.668219  , 4.6707883 , 4.605944  , 1...0.72155577, 0.7571717 ],
         [0.8818691 , 0.8047554 , 0.95759755, 0.8667159 , 0.38708943]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
_________________________________________________________________________________ test_LuvToRgb[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LuvToRgb(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.LuvToRgb,
            "kornia.color.RgbToLuv",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:990: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.luv.LuvToRgb'>, cls_name = 'kornia.color.RgbToLuv'
args = (tensor([[[[0.3332, 0.0233, 0.2156, 0.5458, 0.7880],
          [0.5335, 0.5649, 0.4692, 0.4908, 0.4044],
          [0...., 0.8692],
          [0.1172, 0.5220, 0.6604, 0.2590, 0.2063],
          [0.2805, 0.2949, 0.0147, 0.3844, 0.4922]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 6.38204347e-03,  1.86905114e-03,  1.18596042e-02,
           1.53813716e-02,  1.55205792e-02],
         [ 1...     [ 8.87241040e-04,  9.35220160e-04,  3.72219388e-03,
           6.07827026e-03,  5.88769093e-03]]]], dtype=float32)
y = array([[[[  20.00343   ,   10.9475    ,   77.387634  ,   61.11798   ,
            47.49341   ],
         [  39.88974  ...4  ],
         [  87.11115   ,   84.74583   ,   60.81154   ,   -1.3840042 ,
           -15.559356  ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.luv.LuvToRgb
________________________________________________________________________________ test_RgbToYuv420[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            "kornia.color.RgbToYuv420",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1088: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>, cls_name = 'kornia.color.RgbToYuv420'
args = (tensor([[[[0.0895, 0.9581, 0.5165, 0.7571, 0.7058, 0.7452],
          [0.0369, 0.1051, 0.7613, 0.0944, 0.6985, 0.6924...     [0.6688, 0.8171, 0.8541, 0.3861, 1.0000, 0.0887],
          [0.6023, 0.1642, 0.2848, 0.7918, 0.8028, 0.6099]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.11938043, 0.7539401 , 0.5469086 , 0.66517884, 0.7511026 ,
          0.5161579 ],
         [0.47899422, 0....
        [[ 0.01242443,  0.01349048, -0.0480608 ],
         [ 0.07267256,  0.23378295,  0.23823962]]]], dtype=float32))
y = (array([[[[0.11938043, 0.7539401 , 0.5469086 , 0.66517884, 0.7511026 ,
          0.5161579 ],
         [0.47899422, 0....
        [[ 0.1768896 ,  0.08296176,  0.20019177],
         [ 0.01481445, -0.02324076,  0.0709324 ]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fa5ecea7680>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.12482867, -0.0938895 , -0.04226457],
         [ 0.06087828,  0.03152621, -0.08281353]],

        [[-0.153...

        [[ 0.01242443,  0.01349048, -0.0480608 ],
         [ 0.07267256,  0.23378295,  0.23823962]]]], dtype=float32)
y = array([[[[ 0.0953836 , -0.17301744, -0.07579157],
         [-0.05415782,  0.00339893, -0.04720752]],

        [[ 0.018...

        [[ 0.1768896 ,  0.08296176,  0.20019177],
         [ 0.01481445, -0.02324076,  0.0709324 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
_________________________________________________________________________________ test_RawToRgb[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RawToRgb(target_framework, mode, backend_compile):
        print("kornia.color.RawToRgb")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_x = torch.rand(2, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.RawToRgb(kornia.color.CFA.RG)(torch_x)
        transpiled_out = transpiled_kornia.color.RawToRgb(transpiled_kornia.color.CFA.RG)(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:1184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.1980, 0.1980, 0.1135, 0.0290, 0.4161, 0.8032],
          [0.1980, 0.1980, 0.1135, 0.0290, 0.4161, 0.8032]...       [0.5894, 0.6811, 0.7728, 0.5860, 0.3993, 0.3993],
          [0.5894, 0.6811, 0.7728, 0.5860, 0.3993, 0.3993]]]])
transpiled_x = <tf.Tensor: shape=(2, 3, 4, 6), dtype=float32, numpy=
array([[[[0.19800097, 0.19800097, 0.11351037, 0.08432141, 0.5267...2592 ],
         [0.5893531 , 0.6548556 , 0.7596595 , 0.5860096 , 0.3992592 ,
          0.3992592 ]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.19800097, 0.19800097, 0.11351037, 0.02901977, 0.4161301 ,
          0.8032404 ],
         [0.19800097, 0.1...92592 ],
         [0.5893531 , 0.68105656, 0.77276003, 0.5860096 , 0.3992592 ,
          0.3992592 ]]]], dtype=float32)
y = array([[[[0.19800097, 0.19800097, 0.11351037, 0.08432141, 0.52673316,
          0.8032404 ],
         [0.19800097, 0.1...92592 ],
         [0.5893531 , 0.6548556 , 0.7596595 , 0.5860096 , 0.3992592 ,
          0.3992592 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.RawToRgb
kornia.color.RawToRgb
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_raw_to_rgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToHls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_LuvToRgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RawToRgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 7 failed, 62 passed in 4254.36s (1:10:54) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 168.19s (0:02:48) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py s                                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.03s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 836.86s (0:13:56) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 492.97s (0:08:12) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................ssssssssssssssssss                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 17 passed, 18 skipped in 1103.56s (0:18:23) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py .FF....FFssssss                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_conv_soft_argmax3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_soft_argmax3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(20, 16, 3, 50, 32),
        )
        trace_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(1.0),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
        test_args = (
            torch.rand(10, 16, 5, 50, 32),
        )
        test_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(0.5),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
>       _test_function(
            kornia.geometry.subpix.conv_soft_argmax3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7f5785f730a0>
trace_args = (tensor([[[[[0.8975, 0.1004, 0.7158,  ..., 0.6108, 0.3603, 0.2474],
           [0.9837, 0.1061, 0.6978,  ..., 0.5899, ...0.7311, 0.0134,  ..., 0.8485, 0.8019, 0.7444],
           [0.6408, 0.0959, 0.4986,  ..., 0.3487, 0.9032, 0.4810]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[3.3105e-01, 7.0262e-01, 4.3166e-01,  ..., 8.2168e-01,
            4.5381e-01, 2.4423e-01],
           [2....8981e-01],
           [6.7412e-01, 8.7272e-01, 7.1171e-01,  ..., 7.6665e-01,
            7.9425e-01, 9.8902e-01]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7f5785f730a0>, fn_name = 'kornia.geometry.subpix.conv_soft_argmax3d'
trace_args = (tensor([[[[[0.8975, 0.1004, 0.7158,  ..., 0.6108, 0.3603, 0.2474],
           [0.9837, 0.1061, 0.6978,  ..., 0.5899, ...0.7311, 0.0134,  ..., 0.8485, 0.8019, 0.7444],
           [0.6408, 0.0959, 0.4986,  ..., 0.3487, 0.9032, 0.4810]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[3.3105e-01, 7.0262e-01, 4.3166e-01,  ..., 8.2168e-01,
            4.5381e-01, 2.4423e-01],
           [2....8981e-01],
           [6.7412e-01, 8.7272e-01, 7.1171e-01,  ..., 7.6665e-01,
            7.9425e-01, 9.8902e-01]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:312: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.Module object at 0x7f572d6772b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.Module object at 0x7f572d6772b0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.FunctionDef object at 0x7f572d675030>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.If object at 0x7f572ce67b80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.If object at 0x7f572ce67b80>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.AnnAssign object at 0x7f572c9e3a60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.Call object at 0x7f572cf1a710>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.Call object at 0x7f572cf1a710>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.Call object at 0x7f572cf199f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.Call object at 0x7f572cf199f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6cc940>, node = <gast.gast.Name object at 0x7f572cf1baf0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Module object at 0x7f5727fc76a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Module object at 0x7f5727fc76a0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.FunctionDef object at 0x7f5727fc4760>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Return object at 0x7f5727fc5bd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Return object at 0x7f5727fc5bd0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Call object at 0x7f5727fc6620>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Call object at 0x7f5727fc6620>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Call object at 0x7f5727fc70d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Call object at 0x7f5727fc70d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd89030>, node = <gast.gast.Name object at 0x7f5727fc51b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_soft_argmax3d
_______________________________________________________________________________ test_conv_quad_interp3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f5785f731c0>
trace_args = (tensor([[[[[0.3489, 0.5236, 0.7623, 0.2420, 0.8789],
           [0.8489, 0.2434, 0.6624, 0.7880, 0.4253],
           ....6313],
           [0.7268, 0.2622, 0.1072, 0.0668, 0.3805],
           [0.0543, 0.7543, 0.5004, 0.1270, 0.9063]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.1940, 0.9154, 0.0767, 0.5122, 0.5025],
           [0.6126, 0.4489, 0.6294, 0.3521, 0.8792],
           ....1229],
           [0.3120, 0.9861, 0.0464, 0.2387, 0.0496],
           [0.2229, 0.0269, 0.8392, 0.6151, 0.8931]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f5785f731c0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.3489, 0.5236, 0.7623, 0.2420, 0.8789],
           [0.8489, 0.2434, 0.6624, 0.7880, 0.4253],
           ....6313],
           [0.7268, 0.2622, 0.1072, 0.0668, 0.3805],
           [0.0543, 0.7543, 0.5004, 0.1270, 0.9063]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.1940, 0.9154, 0.0767, 0.5122, 0.5025],
           [0.6126, 0.4489, 0.6294, 0.3521, 0.8792],
           ....1229],
           [0.3120, 0.9861, 0.0464, 0.2387, 0.0496],
           [0.2229, 0.0269, 0.8392, 0.6151, 0.8931]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:312: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5727fc75b0>, node = <gast.gast.Module object at 0x7f572cef74f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5727fc75b0>, node = <gast.gast.Module object at 0x7f572cef74f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5727fc75b0>, node = <gast.gast.FunctionDef object at 0x7f572c701840>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5727fc75b0>, node = <gast.gast.AnnAssign object at 0x7f572c6f34f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5727fc75b0>, node = <gast.gast.Call object at 0x7f572c6f3af0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5727fc75b0>, node = <gast.gast.Call object at 0x7f572c6f3af0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5727fc75b0>, node = <gast.gast.Name object at 0x7f572c6f1030>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Module object at 0x7f5727c37850>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Module object at 0x7f5727c37850>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.FunctionDef object at 0x7f5727c34790>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Return object at 0x7f5727c351b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Return object at 0x7f5727c351b0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Call object at 0x7f5727c35ea0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Call object at 0x7f5727c35ea0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Call object at 0x7f5727c35d50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Call object at 0x7f5727c35d50>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cd53df0>, node = <gast.gast.Name object at 0x7f5727c37be0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________________ test_nms2d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5),
            (3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5),
            (3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7f5785f723b0>
trace_args = (tensor([[[[0.8721, 0.8437, 0.0089, 0.7103, 0.3847],
          [0.1435, 0.3227, 0.9870, 0.8811, 0.4973],
          [0....6],
          [0.2396, 0.7964, 0.1222, 0.0254, 0.5168],
          [0.1411, 0.9458, 0.1737, 0.9354, 0.6306]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.7320, 0.2975, 0.0143, 0.1387, 0.0507],
          [0.9935, 0.7616, 0.0224, 0.6501, 0.6773],
          [0....9],
          [0.8042, 0.8801, 0.8598, 0.1676, 0.2079],
          [0.3600, 0.5657, 0.8858, 0.8864, 0.5904]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7f5785f723b0>, fn_name = 'kornia.geometry.subpix.nms2d'
trace_args = (tensor([[[[0.8721, 0.8437, 0.0089, 0.7103, 0.3847],
          [0.1435, 0.3227, 0.9870, 0.8811, 0.4973],
          [0....6],
          [0.2396, 0.7964, 0.1222, 0.0254, 0.5168],
          [0.1411, 0.9458, 0.1737, 0.9354, 0.6306]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.7320, 0.2975, 0.0143, 0.1387, 0.0507],
          [0.9935, 0.7616, 0.0224, 0.6501, 0.6773],
          [0....9],
          [0.8042, 0.8801, 0.8598, 0.1676, 0.2079],
          [0.3600, 0.5657, 0.8858, 0.8864, 0.5904]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:312: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Module object at 0x7f572c1c7bb0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Module object at 0x7f572c1c7bb0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.FunctionDef object at 0x7f572c1c75b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Return object at 0x7f572c1c4d00>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Return object at 0x7f572c1c4d00>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Call object at 0x7f572c1c7ca0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Call object at 0x7f572c1c7ca0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Call object at 0x7f572c1c4bb0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Call object at 0x7f572c1c4bb0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572cdb7cd0>, node = <gast.gast.Name object at 0x7f572c1c71f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression2d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms2d
_____________________________________________________________________________________ test_nms3d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5, 5),
            (3, 3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5, 5),
            (3, 3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7f5785f727a0>
trace_args = (tensor([[[[[0.9983, 0.3502, 0.8263, 0.2715, 0.2836],
           [0.0273, 0.8954, 0.6361, 0.1630, 0.5677],
           ...         [0.9915, 0.4533, 0.0734, 0.3095, 0.6889],
           [0.9161, 0.6927, 0.6617, 0.7857, 0.8245]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[3.9122e-01, 1.7590e-01, 6.6095e-01, 3.1088e-01, 7.8360e-01],
           [1.9150e-01, 9.5445e-01, 8.0887e-...e-02, 6.2938e-01, 2.4517e-01],
           [6.0887e-01, 1.0010e-01, 6.3891e-01, 5.4439e-01, 7.5107e-01]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7f5785f727a0>, fn_name = 'kornia.geometry.subpix.nms3d'
trace_args = (tensor([[[[[0.9983, 0.3502, 0.8263, 0.2715, 0.2836],
           [0.0273, 0.8954, 0.6361, 0.1630, 0.5677],
           ...         [0.9915, 0.4533, 0.0734, 0.3095, 0.6889],
           [0.9161, 0.6927, 0.6617, 0.7857, 0.8245]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[3.9122e-01, 1.7590e-01, 6.6095e-01, 3.1088e-01, 7.8360e-01],
           [1.9150e-01, 9.5445e-01, 8.0887e-...e-02, 6.2938e-01, 2.4517e-01],
           [6.0887e-01, 1.0010e-01, 6.3891e-01, 5.4439e-01, 7.5107e-01]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:312: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Module object at 0x7f572d182920>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Module object at 0x7f572d182920>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.FunctionDef object at 0x7f572d1825c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Return object at 0x7f572d1831c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Return object at 0x7f572d1831c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Call object at 0x7f572d1809d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Call object at 0x7f572d1809d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Call object at 0x7f572d182980>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Call object at 0x7f572d182980>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f572d6e9480>, node = <gast.gast.Name object at 0x7f572d183730>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_soft_argmax3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.s...
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.s...
FAILED kornia/geometry/test_subpix.py::test_nms2d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy...
FAILED kornia/geometry/test_subpix.py::test_nms3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy...
========================================================================== 4 failed, 5 passed, 6 skipped in 661.14s (0:11:01) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1211.89s (0:20:11) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_HomographyTracker[jax-s2s-False] _________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = transpiled_kornia.tracking.HomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}
node = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>
self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import jax_LocalFeatureMatcher
        from ..feature.integrated import jax_GFTTAffNetHardNet
        from ..feature.matching import jax_DescriptorMatcher
        from ..feature.loftr.loftr import jax_LoFTR
        from ..geometry.ransac import jax_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or jax_LocalFeatureMatcher(
            jax_GFTTAffNetHardNet(3000), jax_DescriptorMatcher("smnn", 0.95)
        )
>       self.fast_matcher = fast_matcher or jax_LoFTR("outdoor")

ivy_transpiled_outputs/jax_outputs/kornia/tracking/planar_tracker.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    @jax_store_config_info
    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = transpiled_kornia.tracking.HomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}
node = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>
self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import jax_LocalFeatureMatcher
        from ..feature.integrated import jax_GFTTAffNetHardNet
        from ..feature.matching import jax_DescriptorMatcher
        from ..feature.loftr.loftr import jax_LoFTR
        from ..geometry.ransac import jax_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or jax_LocalFeatureMatcher(
            jax_GFTTAffNetHardNet(3000), jax_DescriptorMatcher("smnn", 0.95)
        )
>       self.fast_matcher = fast_matcher or jax_LoFTR("outdoor")

ivy_transpiled_outputs/jax_outputs/kornia/tracking/planar_tracker.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    @jax_store_config_info
    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 49.0MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 248MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:05, 369kB/s]
  1%|          | 256k/44.2M [00:00<01:15, 607kB/s]
  1%|          | 512k/44.2M [00:00<00:41, 1.11MB/s]
  2%|▏         | 896k/44.2M [00:00<00:25, 1.80MB/s]
  4%|▍         | 1.75M/44.2M [00:00<00:12, 3.63MB/s]
  8%|▊         | 3.50M/44.2M [00:00<00:05, 7.26MB/s]
 15%|█▍        | 6.50M/44.2M [00:01<00:03, 13.1MB/s]
 21%|██▏       | 9.50M/44.2M [00:01<00:02, 17.2MB/s]
 28%|██▊       | 12.5M/44.2M [00:01<00:01, 20.0MB/s]
 35%|███▍      | 15.4M/44.2M [00:01<00:01, 21.7MB/s]
 42%|████▏     | 18.4M/44.2M [00:01<00:01, 23.1MB/s]
 48%|████▊     | 21.1M/44.2M [00:01<00:01, 23.4MB/s]
 55%|█████▍    | 24.1M/44.2M [00:01<00:00, 24.3MB/s]
 61%|██████    | 27.0M/44.2M [00:01<00:00, 24.7MB/s]
 68%|██████▊   | 30.0M/44.2M [00:02<00:00, 25.2MB/s]
 75%|███████▍  | 33.0M/44.2M [00:02<00:00, 25.6MB/s]
 81%|████████▏ | 36.0M/44.2M [00:02<00:00, 25.9MB/s]
 88%|████████▊ | 38.9M/44.2M [00:02<00:00, 25.8MB/s]
 94%|█████████▍| 41.6M/44.2M [00:02<00:00, 25.3MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 18.5MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 1 failed in 444.61s (0:07:24) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_mean_average_precision[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f41e9786680>
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f41e9786680>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>]
pred_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], pred_scores = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.7], dtype=float32)>]
gt_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], gt_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]
n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 1 failed, 12 passed in 912.84s (0:15:12) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_solve_pnp_dlt[tensorflow-s2s-False] _______________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fe2aa924d30>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fe2aa924d30>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = <tf.Tensor: shape=(1, 6, 3), dtype=float64, numpy=
array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])>
img_points = <tf.Tensor: shape=(1, 6, 2), dtype=float64, numpy=
array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
   ...92.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])>
intrinsics = <tf.Tensor: shape=(1, 3, 3), dtype=float64, numpy=
array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]])>, weights = None, svd_eps = 0.001

    def tensorflow_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...utils.helpers import tensorflow__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_inverse_frnt,
        )
        from ..conversions import tensorflow_convert_points_to_homogeneous
        from ..linalg import tensorflow_transform_points
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...utils.misc import tensorflow_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_det_frnt,
        )
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import tensorflow_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import tensorflow_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(
            weights, (tensorflow.Tensor, tensorflow.keras.Variable)
        ):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = tf.float32, tf.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(tensorflow_shape_frnt_(world_points)) != 3
            or tensorflow_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {tensorflow_shape_frnt_(world_points)}."
            )
        if (
            len(tensorflow_shape_frnt_(img_points)) != 3
            or tensorflow_shape_frnt_(img_points)[2] != 2
        ):
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {tensorflow_shape_frnt_(img_points)}."
            )
        if len(tensorflow_shape_frnt_(intrinsics)) != 3 or tensorflow_shape_frnt_(
            intrinsics
        )[1:] != (3, 3):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {tensorflow_shape_frnt_(intrinsics)}."
            )
        if tensorflow_shape_frnt_(world_points)[1] != tensorflow_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            tensorflow_shape_frnt_(world_points)[0] != tensorflow_shape_frnt_(img_points)[0]
            or tensorflow_shape_frnt_(world_points)[0]
            != tensorflow_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if tensorflow_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {tensorflow_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            tensorflow_shape_frnt_(world_points)[:2][0],
            tensorflow_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = (
            tensorflow__mean_isotropic_scale_normalize(world_points)
        )
        s = tensorflow__torch_linalg_svdvals(world_points_norm)
        if tensorflow_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = tensorflow_inverse_frnt(intrinsics)
        world_points_norm_h = tensorflow_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = tensorflow_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = tensorflow__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = tensorflow_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = tensorflow_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = tensorflow_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = tensorflow_eye_like(4, solution)
        solution_4x4 = tensorflow_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = tensorflow_bmm_frnt(solution_4x4, world_transform_norm)
        solution = tensorflow_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = tensorflow_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = tensorflow_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/calibration/pnp.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': <tf.Tensor: shape=(1, 3), dtype=float64, numpy=array([[-0.02017229,  0.02388222,  0.0574928 ]])>, 'p': 2}
tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7fe2440b9bd0>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:195: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[tensorflow-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 507.36s (0:08:27) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 2171.60s (0:36:11) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF..F...FF.                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_diamond_square[tensorflow-s2s-False] _______________________________________________________________________________

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}, arg = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def rep_method(*args, **kwargs):
        for arg in args:
            if ivy.is_ivy_array(arg):
                return NotImplemented
>       return func(*args, **kwargs)

../ivy/ivy/functional/backends/tensorflow/__init__.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays_and_dtypes = [<class 'numpy.float32'>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])]

    def _result_type(*arrays_and_dtypes):
      """Returns the resulting type given a set of arrays."""
    
      def preprocess_float(x):
        if is_prefer_float32():
          if isinstance(x, float):
            return np.float32(x)
          elif isinstance(x, complex):
            return np.complex64(x)
        return x
    
      arrays_and_dtypes = [preprocess_float(x) for x in arrays_and_dtypes]
>     dtype = np.result_type(*arrays_and_dtypes)
E     TypeError: Cannot interpret 'tensor([[[[0.3333, 1.0000, 0.3333],
E               [1.0000, 0.3333, 1.0000],
E               [0.3333, 1.0000, 0.3333]]]])' as a data type

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_dtypes.py:190: TypeError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f44336cd510>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f444ba3e8c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f444ba3e8c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f44336cd510>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f444ba3e8c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f444ba3e8c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[0.5]]]], dtype=float32)>
random_scale = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, random_fn = <built-in method ones of type object at 0x7f444ba3e8c0>, normalize_range = (0.0, 1.0)
device = None, dtype = None

    def tensorflow_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=tensorflow_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ..core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..enhance.normalize import tensorflow_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
    
        tensorflow_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (tensorflow.Tensor, tensorflow.keras.Variable)):
            random_scale = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[random_scale]]]]), device, dtype
            )
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            tensorflow_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = tensorflow_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = tensorflow_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (tensorflow.Tensor, tensorflow.keras.Variable)):
            roughness = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[roughness]]]]), device, dtype
            )
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = tensorflow_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0], output_size[1], 1, 1]
            )
            roughness = tensorflow_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * tensorflow__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/diamond_square.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
_______________________________________________________________________________ test_EdgeDetector[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
>       transpiled_detector = transpiled_kornia.contrib.EdgeDetector()

kornia/test_contrib.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_EdgeDetector()

    def __init__(self):
        from ..filters.dexined import tensorflow_DexiNed
    
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.model = tensorflow_DexiNed(pretrained=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/edge_detection.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
args = (), kwargs = {'pretrained': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
pretrained = True

    @tensorflow_store_config_info
    def __init__(self, pretrained):
        from ...torch.nn.modules.pooling import tensorflow_MaxPool2d
    
        self.super___init__(
            pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.block_1 = tensorflow_DoubleConvBlock(3, 32, 64, stride=2)
        self.block_2 = tensorflow_DoubleConvBlock(64, 128, use_act=False)
        self.dblock_3 = tensorflow__DenseBlock(2, 128, 256)
        self.dblock_4 = tensorflow__DenseBlock(3, 256, 512)
        self.dblock_5 = tensorflow__DenseBlock(3, 512, 512)
        self.dblock_6 = tensorflow__DenseBlock(3, 512, 256)
        self.maxpool = tensorflow_MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.side_1 = tensorflow_SingleConvBlock(64, 128, 2)
        self.side_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.side_3 = tensorflow_SingleConvBlock(256, 512, 2)
        self.side_4 = tensorflow_SingleConvBlock(512, 512, 1)
        self.side_5 = tensorflow_SingleConvBlock(512, 256, 1)
        self.pre_dense_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.pre_dense_3 = tensorflow_SingleConvBlock(128, 256, 1)
        self.pre_dense_4 = tensorflow_SingleConvBlock(256, 512, 1)
        self.pre_dense_5 = tensorflow_SingleConvBlock(512, 512, 1)
        self.pre_dense_6 = tensorflow_SingleConvBlock(512, 256, 1)
        self.up_block_1 = tensorflow_UpConvBlock(64, 1)
        self.up_block_2 = tensorflow_UpConvBlock(128, 1)
        self.up_block_3 = tensorflow_UpConvBlock(256, 2)
        self.up_block_4 = tensorflow_UpConvBlock(512, 3)
        self.up_block_5 = tensorflow_UpConvBlock(512, 4)
        self.up_block_6 = tensorflow_UpConvBlock(256, 4)
        self.block_cat = tensorflow_SingleConvBlock(6, 1, stride=1, use_bs=False)
        if pretrained:
>           self.load_from_file(url)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
path_file = 'http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth'

    def load_from_file(self, path_file):
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        pretrained_dict = tensorflow_load_state_dict_from_url_frnt(
            path_file, map_location=tensorflow_map_location_to_cpu
        )
>       self.load_state_dict(pretrained_dict, strict=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:613: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
strict = True, assign = False

    def load_state_dict(
        self,
        state_dict: typing.Mapping[str, Any],
        strict: bool = True,
        assign: bool = False,
    ):
        r"""Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.
    
        If :attr:`strict` is ``True``, then
        the keys of :attr:`state_dict` must exactly match the keys returned
        by this module's :meth:`~Module.state_dict` function.
    
        Args:
            state_dict (dict): a dict containing parameters and
                persistent buffers.
            strict (bool, optional): whether to strictly enforce that the keys
                in :attr:`state_dict` match the keys returned by this module's
                :meth:`~Module.state_dict` function. Default: ``True``
    
        Returns:
            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:
                * **missing_keys** is a list of str containing any keys that are expected
                    by this module but missing from the provided ``state_dict``.
                * **unexpected_keys** is a list of str containing the keys that are not
                    expected by this module but present in the provided ``state_dict``.
        """
        if not isinstance(state_dict, typing.Mapping):
            raise TypeError(
                f"Expected state_dict to be dict-like, got {type(state_dict)}."
            )
    
        missing_keys: List[str] = []
        unexpected_keys: List[str] = []
        error_msgs: List[str] = []
    
        state_dict = tf.nest.map_structure(
            lambda x: tf.convert_to_tensor(x.numpy()),
            state_dict,
        )
        state_dict = OrderedDict(state_dict)
    
        def load(module, local_state_dict, prefix=""):
            module._load_from_state_dict(
                local_state_dict,
                prefix,
                strict,
                missing_keys,
                unexpected_keys,
                error_msgs,
            )
            # TODO: maybe we should implement this similar to PT
            # and make this recursive.
    
>       load(self, state_dict)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
local_state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = ''

    def load(module, local_state_dict, prefix=""):
>       module._load_from_state_dict(
            local_state_dict,
            prefix,
            strict,
            missing_keys,
            unexpected_keys,
            error_msgs,
        )

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:589: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = '', strict = True, missing_keys = [], unexpected_keys = [], error_msgs = []

    def _load_from_state_dict(
        self, state_dict, prefix, strict, missing_keys, unexpected_keys, error_msgs
    ):
        def _retrive_layer(model, key):
            if len(key.split(".")) == 1:
                return model, key
    
            module_path, weight_name = key.rsplit(".", 1)
    
            # Retrieve the layer using the module path
            layer = model
            for attr in module_path.split("."):
                layer = getattr(layer, attr)
    
            return layer, weight_name
    
        persistent_buffers = {k: v for k, v in self._buffers.items()}
        local_name_params = itertools.chain(
            self._parameters.items(), persistent_buffers.items()
        )
        local_state = {k: v for k, v in local_name_params if v is not None}
    
        for name, param in local_state.items():
            key = prefix + name
            if key in state_dict:
                input_param = state_dict[key]
                if not isinstance(input_param, tf.Tensor):
                    error_msgs.append(
                        f'While copying the parameter named "{key}", '
                        "expected ArrayLike object from checkpoint but "
                        f"received {type(input_param)}"
                    )
                    continue
    
                if not isinstance(input_param, KerasVariable):
>                   input_param = KerasVariable(input_param)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:522: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_175>, initializer = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, shape = None, dtype = 'float32', trainable = True
autocast = True, aggregation = 'mean', name = 'variable_175'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_175>, value = <tf.Tensor: shape=(), dtype=int64, numpy=79200>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(), dtype=int64, numpy=79200>), kwargs = {'dtype': 'float32', 'name': 'variable_175', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtype=int64, numpy=79200>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<08:59, 261kB/s]
  0%|          | 256k/135M [00:00<05:28, 429kB/s]
  0%|          | 512k/135M [00:00<02:58, 787kB/s]
  1%|          | 896k/135M [00:01<01:50, 1.27MB/s]
  1%|▏         | 1.75M/135M [00:01<00:54, 2.57MB/s]
  3%|▎         | 3.50M/135M [00:01<00:26, 5.12MB/s]
  5%|▍         | 6.38M/135M [00:01<00:14, 9.01MB/s]
  7%|▋         | 9.25M/135M [00:01<00:11, 11.7MB/s]
  9%|▉         | 12.2M/135M [00:01<00:09, 13.8MB/s]
 11%|█         | 15.1M/135M [00:02<00:08, 15.1MB/s]
 13%|█▎        | 18.0M/135M [00:02<00:07, 16.0MB/s]
 15%|█▌        | 20.8M/135M [00:02<00:07, 16.3MB/s]
 18%|█▊        | 23.8M/135M [00:02<00:06, 17.0MB/s]
 20%|█▉        | 26.6M/135M [00:02<00:06, 17.3MB/s]
 22%|██▏       | 29.5M/135M [00:02<00:06, 17.5MB/s]
 24%|██▍       | 32.4M/135M [00:03<00:06, 17.6MB/s]
 26%|██▋       | 35.4M/135M [00:03<00:05, 18.0MB/s]
 28%|██▊       | 38.0M/135M [00:03<00:05, 17.5MB/s]
 30%|███       | 41.0M/135M [00:03<00:05, 17.9MB/s]
 33%|███▎      | 43.9M/135M [00:03<00:05, 17.9MB/s]
 35%|███▍      | 46.9M/135M [00:03<00:05, 18.2MB/s]
 37%|███▋      | 49.9M/135M [00:04<00:04, 18.3MB/s]
 39%|███▉      | 52.8M/135M [00:04<00:04, 18.2MB/s]
 41%|████▏     | 55.6M/135M [00:04<00:04, 18.2MB/s]
 44%|████▎     | 58.6M/135M [00:04<00:04, 18.3MB/s]
 46%|████▌     | 61.5M/135M [00:04<00:04, 18.2MB/s]
 48%|████▊     | 64.4M/135M [00:04<00:04, 18.1MB/s]
 50%|█████     | 67.4M/135M [00:05<00:03, 18.3MB/s]
 52%|█████▏    | 70.4M/135M [00:05<00:03, 18.4MB/s]
 55%|█████▍    | 73.4M/135M [00:05<00:03, 18.5MB/s]
 57%|█████▋    | 76.4M/135M [00:05<00:03, 18.6MB/s]
 59%|█████▉    | 79.4M/135M [00:05<00:03, 18.6MB/s]
 61%|██████    | 82.1M/135M [00:05<00:03, 18.2MB/s]
 63%|██████▎   | 85.1M/135M [00:06<00:02, 18.3MB/s]
 66%|██████▌   | 88.1M/135M [00:06<00:02, 18.4MB/s]
 68%|██████▊   | 91.1M/135M [00:06<00:02, 18.5MB/s]
 70%|██████▉   | 94.0M/135M [00:06<00:02, 18.4MB/s]
 72%|███████▏  | 96.9M/135M [00:06<00:02, 18.1MB/s]
 74%|███████▍  | 99.9M/135M [00:06<00:01, 18.3MB/s]
 76%|███████▋  | 103M/135M [00:07<00:01, 18.4MB/s] 
 79%|███████▊  | 106M/135M [00:07<00:01, 18.3MB/s]
 81%|████████  | 109M/135M [00:07<00:01, 18.3MB/s]
 83%|████████▎ | 112M/135M [00:07<00:01, 18.3MB/s]
 85%|████████▌ | 115M/135M [00:07<00:01, 18.3MB/s]
 87%|████████▋ | 117M/135M [00:07<00:01, 17.9MB/s]
 89%|████████▉ | 120M/135M [00:08<00:00, 17.9MB/s]
 92%|█████████▏| 123M/135M [00:08<00:00, 18.1MB/s]
 94%|█████████▎| 126M/135M [00:08<00:00, 18.1MB/s]
 96%|█████████▌| 129M/135M [00:08<00:00, 18.3MB/s]
 98%|█████████▊| 132M/135M [00:08<00:00, 18.4MB/s]
100%|██████████| 135M/135M [00:08<00:00, 16.1MB/s]
__________________________________________________________________________________ test_KMeans[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KMeans(target_framework, mode, backend_compile):
        print("kornia.contrib.KMeans")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_kmeans = kornia.contrib.KMeans(3, None, 10e-4, 100, 0)
        transpiled_kmeans = transpiled_kornia.contrib.KMeans(3, None, 10e-4, 100, 0)
    
        torch_x1 = torch.rand((1000, 5))
        torch_x2 = torch.rand((10, 5))
        transpiled_x1 = _array_to_new_backend(torch_x1, target_framework)
        transpiled_x2 = _array_to_new_backend(torch_x2, target_framework)
    
        torch_kmeans.fit(torch_x1)
        torch_predictions = torch_kmeans.predict(torch_x2)
    
>       transpiled_kmeans.fit(transpiled_x1)

kornia/test_contrib.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.contrib.kmeans.tensorflow_KMeans object at 0x7f43df3de200>
X = <tf.Tensor: shape=(1000, 5), dtype=float32, numpy=
array([[0.64394623, 0.13828903, 0.5104355 , 0.88903964, 0.58980507]...3, 0.7058755 , 0.32629776],
       [0.09731001, 0.6854588 , 0.4615414 , 0.7533255 , 0.1392085 ]],
      dtype=float32)>

    def fit(self, X):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ..core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_argmin_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_nonzero_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_index_select_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import tensorflow_sqrt_frnt
    
        tensorflow_KORNIA_CHECK_SHAPE(X, ["N", "D"])
        if self._cluster_centers is None:
            self._cluster_centers = self._initialise_cluster_centers(
                X, self.num_clusters
            )
        else:
            tensorflow_KORNIA_CHECK(
                tensorflow_shape_frnt_(X)[1]
                == tensorflow_shape_frnt_(self._cluster_centers)[1],
                f"Dimensions at position 1 of X and cluster_centers do not match.                 {tensorflow_shape_frnt_(X)[1]} != {tensorflow_shape_frnt_(self._cluster_centers)[1]}",
            )
        current_centers = self._cluster_centers
        previous_centers: typing.Any = None
        iteration: typing.Any = 0
        while True:
            distance: typing.Any = self._pairwise_euclidean_distance(X, current_centers)
            cluster_assignment = tensorflow_argmin_frnt_(distance, -1)
            previous_centers = tensorflow_clone_frnt_(current_centers)
            for index in range(self.num_clusters):
                selected = tensorflow_squeeze_frnt_(
                    tensorflow_nonzero_frnt(cluster_assignment == index)
                )
                selected = tensorflow_index_select_frnt(X, 0, selected)
                if tensorflow_shape_frnt_(selected)[0] == 0:
                    selected = X[tensorflow_randint_frnt(len(X), (1,), device=X.device)]
>               current_centers[index] = tensorflow_mean_frnt_(selected, dim=0)
E               TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/kmeans.py:149: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.KMeans
kornia.contrib.KMeans
_______________________________________________________________________________ test_ImageStitcher[tensorflow-s2s-False] _______________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = transpiled_kornia.feature.LoFTR(pretrained='outdoor')

kornia/test_contrib.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .backbone.__init__ import tensorflow_build_backbone
        from .utils.position_encoding import tensorflow_PositionEncodingSine
        from .loftr_module.transformer import tensorflow_LocalFeatureTransformer
        from .utils.coarse_matching import tensorflow_CoarseMatching
        from .loftr_module.fine_preprocess import tensorflow_FinePreprocess
        from .utils.fine_matching import tensorflow_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = tensorflow_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = tensorflow_build_backbone(config)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/loftr.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def tensorflow_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/backbone/__init__.py:41: NameError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = transpiled_kornia.feature.LoFTR(pretrained='outdoor')

kornia/test_contrib.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .backbone.__init__ import tensorflow_build_backbone
        from .utils.position_encoding import tensorflow_PositionEncodingSine
        from .loftr_module.transformer import tensorflow_LocalFeatureTransformer
        from .utils.coarse_matching import tensorflow_CoarseMatching
        from .loftr_module.fine_preprocess import tensorflow_FinePreprocess
        from .utils.fine_matching import tensorflow_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = tensorflow_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = tensorflow_build_backbone(config)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/loftr.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def tensorflow_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/backbone/__init__.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:57, 261kB/s]
  1%|          | 256k/44.2M [00:00<01:47, 428kB/s]
  1%|          | 512k/44.2M [00:00<00:58, 785kB/s]
  2%|▏         | 896k/44.2M [00:01<00:35, 1.27MB/s]
  4%|▍         | 1.75M/44.2M [00:01<00:17, 2.56MB/s]
  8%|▊         | 3.50M/44.2M [00:01<00:08, 5.12MB/s]
 15%|█▍        | 6.50M/44.2M [00:01<00:04, 9.26MB/s]
 21%|██▏       | 9.50M/44.2M [00:01<00:03, 12.1MB/s]
 28%|██▊       | 12.4M/44.2M [00:01<00:02, 13.9MB/s]
 35%|███▍      | 15.4M/44.2M [00:02<00:01, 15.3MB/s]
 42%|████▏     | 18.4M/44.2M [00:02<00:01, 16.4MB/s]
 48%|████▊     | 21.0M/44.2M [00:02<00:01, 16.4MB/s]
 54%|█████▍    | 23.9M/44.2M [00:02<00:01, 16.9MB/s]
 61%|██████    | 26.8M/44.2M [00:02<00:01, 17.2MB/s]
 67%|██████▋   | 29.8M/44.2M [00:02<00:00, 17.7MB/s]
 74%|███████▍  | 32.8M/44.2M [00:03<00:00, 18.0MB/s]
 80%|████████  | 35.4M/44.2M [00:03<00:00, 17.5MB/s]
 87%|████████▋ | 38.2M/44.2M [00:03<00:00, 17.6MB/s]
 93%|█████████▎| 41.2M/44.2M [00:03<00:00, 18.0MB/s]
100%|█████████▉| 44.1M/44.2M [00:03<00:00, 18.0MB/s]
100%|██████████| 44.2M/44.2M [00:03<00:00, 12.6MB/s]
__________________________________________________________________________________ test_Lambda[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Lambda(target_framework, mode, backend_compile):
        print("kornia.contrib.Lambda")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        x = torch.rand(1, 3, 5, 5)
        torch_out = kornia.contrib.Lambda(lambda x: kornia.color.rgb_to_grayscale(x))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = transpiled_kornia.contrib.Lambda(lambda x: transpiled_kornia.color.rgb_to_grayscale(x))(transpiled_x)

kornia/test_contrib.py:338: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.contrib.lambda_module.tensorflow_Lambda'>, args = (<function test_Lambda.<locals>.<lambda> at 0x7f43d0cab760>,), kwargs = {}

    def __new__(cls, *args, **kwargs):
        # Signature detection for usage of `Model` as a `Functional`
        if functional_init_arguments(args, kwargs) and cls == Model:
            from keras.src.models.functional import Functional
    
            return Functional.__new__(Functional, *args, **kwargs)
>       return typing.cast(cls, super().__new__(cls))

/opt/fw/tensorflow/keras/src/models/model.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.contrib.lambda_module.tensorflow_Lambda'>, args = (), kwargs = {}

    def __new__(cls, *args, **kwargs):
>       obj = super().__new__(cls, *args, **kwargs)

/opt/fw/tensorflow/keras/src/layers/layer.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.contrib.lambda_module.tensorflow_Lambda'>, args = (), kwargs = {}
instance = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_Lambda object at 0x7f43db863fa0>, arg_names = ['self', 'func'], dtype = None
supported_types = (<class 'str'>, <class 'int'>, <class 'float'>, <class 'bool'>, <class 'NoneType'>), flat_arg_values = [], auto_config = True

    def __new__(cls, *args, **kwargs):
        """We override __new__ to saving serializable constructor arguments.
    
        These arguments are used to auto-generate an object serialization
        config, which enables user-created subclasses to be serializable
        out of the box in most cases without forcing the user
        to manually implement `get_config()`.
        """
        instance = super(Operation, cls).__new__(cls)
    
        # Generate a config to be returned by default by `get_config()`.
        arg_names = inspect.getfullargspec(cls.__init__).args
        kwargs.update(dict(zip(arg_names[1 : len(args) + 1], args)))
    
        # Explicitly serialize `dtype` to support auto_config
        dtype = kwargs.get("dtype", None)
        if dtype is not None and isinstance(dtype, dtype_policies.DTypePolicy):
            # For backward compatibility, we use a str (`name`) for
            # `DTypePolicy`
            if dtype.quantization_mode is None:
                kwargs["dtype"] = dtype.name
            # Otherwise, use `dtype_policies.serialize`
            else:
                kwargs["dtype"] = dtype_policies.serialize(dtype)
    
        # For safety, we only rely on auto-configs for a small set of
        # serializable types.
        supported_types = (str, int, float, bool, type(None))
        try:
            flat_arg_values = tree.flatten(kwargs)
            auto_config = True
            for value in flat_arg_values:
                if not isinstance(value, supported_types):
                    auto_config = False
                    break
        except TypeError:
            auto_config = False
        try:
>           instance._lock = False

/opt/fw/tensorflow/keras/src/ops/operation.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_Lambda object at 0x7f43db863fa0>, name = '_lock', value = False

    def __setattr__(self, name, value):
        def remove_from(*dicts_or_sets):
            for d in dicts_or_sets:
                if name in d:
                    if isinstance(d, (dict,)):
                        del d[name]
                    else:
                        d.discard(name)
    
        params = self.__dict__.get("_v")
        if (
            params is not None
            and name in params
            and isinstance(value, (tensorflow.keras.Variable,))
        ):
            remove_from(self.__dict__, self._buffers, self._module_dict)
            self.register_parameter(name, value)
            super().__setattr__(name, value)
        else:
>           super().__setattr__(name, value)

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/lambda_module.py:151: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_Lambda object at 0x7f43db863fa0>, '_lock', False), kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_Lambda object at 0x7f43db863fa0>, name = '_lock', value = False

    @tf.autograph.experimental.do_not_convert
    def __setattr__(self, name, value):
        if name in ["v", "buffers"]:
            name = "_" + name
        if isinstance(value, (Layer, tf.keras.layers.Layer, Model, tf.keras.Model)):
            _dict = getattr(self, "__dict__", None)
            if _dict:
                _dict[name] = value
    
            # compute the module dict
            self._compute_module_dict()
    
            obj_to_search = (
                None
                if not isinstance(value, (tf.keras.layers.Layer, Layer, Model))
                else (
                    self._modules
                    if hasattr(self, "_modules") and self._modules
                    else self
                )
            )
            found_vars = self._find_variables(
                obj=obj_to_search,
                without_initialisation=(
                    True
                    if self._v_from_constructor and not self._with_partial_v
                    else False
                ),
            )
            flattened_v, v_spec = tree_flatten(found_vars)
            flattend_kc = v_spec.get_keychains()
            for kc, v in zip(flattend_kc, flattened_v):
                new_kc = kc.replace("/", ".")
                if new_kc not in self.v:
                    self.register_parameter(new_kc, v)
    
            # once all variables built, find and assign buffers
            found_buffers = self._find_variables(
                obj=obj_to_search,
                without_initialisation=(
                    True
                    if self._v_from_constructor and not self._with_partial_v
                    else False
                ),
                trainable=False,
            )
            flattened_buf, buf_spec = tree_flatten(found_buffers)
            flattend_kc = buf_spec.get_keychains()
            for kc, buf in zip(flattend_kc, flattened_buf):
                new_kc = kc.replace("/", ".")
                self.register_buffer(new_kc, buf)
    
            super().__setattr__(name, value)
            return
        elif isinstance(value, (tf.Variable, KerasVariable)) and not name.startswith(
            "_"
        ):
            _dict = getattr(self, "__dict__", None)
            if _dict:
                _dict[name] = value
    
            # Manual solution for cases where a `tf.int32` tensor
            # is placed on the GPU. TensorFlow doesn't have dedicated
            # kernels for placing `tf.int32` variables on the GPU and so
            # we manually cast them to `tf.int64` here otherwise due to
            # `tf.config.soft_device_placement(True)` by default,
            # TensorFlow puts the `tf.int32` variables on CPU which causes
            # unintended consequences downstream during tracing or
            # `tf.function` compilation e.g.
            # Ref: https://github.com/tensorflow/tensorflow/issues/9506
            # Ref: https://stackoverflow.com/questions/44813939/could-not-satisfy-explicit-device-specification-devicegpu0-because-no-devic
            dtype = (
                tf.int64
                if value.dtype == tf.int32 and "gpu:" in value.device.lower()
                else value.dtype
            )
            cast_dtype = dtype != value.dtype
            val = (
                value
                if not cast_dtype
                else KerasVariable(
                    initial_value=tf.cast(value.value(), dtype), name=name
                )
            )
            self.register_parameter(name, val)
            super().__setattr__(name, val)
        else:
            try:
>               obj_to_search = getattr(self, name)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_Lambda object at 0x7f43db863fa0>, '_lock'), kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_Lambda object at 0x7f43db863fa0>, name = '_lock'

    @tf.autograph.experimental.do_not_convert
    def __getattr__(self, name):
        if name == "v":
            if not super().__getattribute__("_v") and not getattr(  # noqa: E501
                self, "_built", False
            ):
                return self._build_and_return_v(
                    *self._args, dynamic_backend=self._dynamic_backend, **self._kwargs
                )
    
>       _dict = super().__getattribute__("__dict__")
E       TypeError: super(type, obj): obj must be an instance or subtype of type

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2030: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.Lambda
kornia.contrib.Lambda
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[tensorflow-s2s-False] - KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
FAILED kornia/test_contrib.py::test_EdgeDetector[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtyp...
FAILED kornia/test_contrib.py::test_KMeans[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/test_contrib.py::test_ImageStitcher[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/test_contrib.py::test_Lambda[tensorflow-s2s-False] - TypeError: super(type, obj): obj must be an instance or subtype of type
============================================================================== 5 failed, 10 passed in 1612.53s (0:26:52) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3627.10s (1:00:27) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 588.65s (0:09:48) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F....................F....F......F............                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_rgb_to_hls[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f8b27de43a0>
trace_args = (tensor([[[[0.6172, 0.6164, 0.0084, 0.2042, 0.3168],
          [0.4975, 0.4453, 0.3510, 0.1173, 0.9629],
          [0.... [0.8145, 0.6500, 0.4822, 0.2401, 0.7971],
          [0.4317, 0.3507, 0.3253, 0.6617, 0.6748]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[8.5800e-01, 9.2448e-01, 7.1139e-01, 5.7258e-01, 9.8054e-01],
          [7.8740e-01, 1.0910e-01, 4.4035e-01...1, 1.7799e-01],
          [8.0413e-01, 6.0889e-01, 4.8627e-01, 3.3633e-01, 6.6863e-01]]]],
       requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f8b27de43a0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.6172, 0.6164, 0.0084, 0.2042, 0.3168],
          [0.4975, 0.4453, 0.3510, 0.1173, 0.9629],
          [0.... [0.8145, 0.6500, 0.4822, 0.2401, 0.7971],
          [0.4317, 0.3507, 0.3253, 0.6617, 0.6748]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[8.5800e-01, 9.2448e-01, 7.1139e-01, 5.7258e-01, 9.8054e-01],
          [7.8740e-01, 1.0910e-01, 4.4035e-01...1, 1.7799e-01],
          [8.0413e-01, 6.0889e-01, 4.8627e-01, 3.3633e-01, 6.6863e-01]]]],
       requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[1.4063, 4.7355, 3.9067, 3.2071, 3.2357],
          [1.9250, 1.9033, 0.8430, 3.7751, 5.3627],
          [5.2....0995, 0.2578, 0.5421, 0.2372],
          [0.5771, 0.7762, 0.3600, 0.6640, 0.4493]]]],
       grad_fn=<StackBackward0>)
transpiled_x = Array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[1.406339  , 4.7354984 , 3.9066648 , 3.2070692 , 3.2356532 ],
         [1.9249673 , 1.9032935 , 0.84304965, 3...0.5420755 , 0.23717962],
         [0.57713103, 0.77618575, 0.3600479 , 0.6639839 , 0.44929013]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
__________________________________________________________________________________ test_rgb_to_yuv420[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f8b27de60e0>
trace_args = (tensor([[[[0.7654, 0.1026, 0.0030, 0.8011, 0.1729, 0.2014],
          [0.2807, 0.6899, 0.2855, 0.4492, 0.0830, 0.8976...     [0.3955, 0.7854, 0.0791, 0.6280, 0.8445, 0.4507],
          [0.9289, 0.1101, 0.7033, 0.3837, 0.4190, 0.0436]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[6.8829e-01, 7.0785e-01, 3.0952e-01, 9.6303e-01, 2.1117e-01,
           5.3790e-01],
          [5.8269e-02,...       4.0582e-01],
          [7.8349e-01, 5.1710e-01, 9.2932e-01, 8.6597e-01, 4.9676e-01,
           2.6551e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f8b27de60e0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.7654, 0.1026, 0.0030, 0.8011, 0.1729, 0.2014],
          [0.2807, 0.6899, 0.2855, 0.4492, 0.0830, 0.8976...     [0.3955, 0.7854, 0.0791, 0.6280, 0.8445, 0.4507],
          [0.9289, 0.1101, 0.7033, 0.3837, 0.4190, 0.0436]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[6.8829e-01, 7.0785e-01, 3.0952e-01, 9.6303e-01, 2.1117e-01,
           5.3790e-01],
          [5.8269e-02,...       4.0582e-01],
          [7.8349e-01, 5.1710e-01, 9.2932e-01, 8.6597e-01, 4.9676e-01,
           2.6551e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.8545, 0.2567, 0.3391, 0.8128, 0.3680, 0.3033],
          [0.6202, 0.8320, 0.6704, 0.3723, 0.5190, 0.9434...       [ 0.0327,  0.0502, -0.0785]],

         [[-0.1590, -0.1438, -0.1708],
          [ 0.0193, -0.0311,  0.0461]]]]))
transpiled_x = (Array([[[[0.85445213, 0.2566895 , 0.3390699 , 0.8128001 , 0.36799818,
          0.30334038],
         [0.62022823, 0....
        [[-0.07291678, -0.16039577, -0.05579413],
         [-0.14235225, -0.1027943 ,  0.09496576]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.85445213, 0.2566895 , 0.3390699 , 0.8128001 , 0.36799818,
          0.30334038],
         [0.62022823, 0....
        [[-0.15895495, -0.14380866, -0.17082825],
         [ 0.01929816, -0.03113735,  0.04614361]]]], dtype=float32))
y = (array([[[[0.85445213, 0.2566895 , 0.3390699 , 0.8128001 , 0.36799818,
          0.30334038],
         [0.62022823, 0....
        [[-0.07291678, -0.16039577, -0.05579413],
         [-0.14235225, -0.1027943 ,  0.09496576]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f8a9d730f00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.05210037,  0.0167307 ,  0.00192477],
         [ 0.03269101,  0.05024721, -0.07849812]],

        [[-0.15895495, -0.14380866, -0.17082825],
         [ 0.01929816, -0.03113735,  0.04614361]]]], dtype=float32)
y = array([[[[ 0.0006753 ,  0.09153527, -0.02371892],
         [ 0.10099405, -0.0205944 , -0.07369536]],

        [[-0.07291678, -0.16039577, -0.05579413],
         [-0.14235225, -0.1027943 ,  0.09496576]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
_____________________________________________________________________________________ test_RgbToHls[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            "kornia.color.RgbToHls",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:920: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>, cls_name = 'kornia.color.RgbToHls'
args = (tensor([[[[0.9122, 0.3150, 0.8449, 0.1805, 0.4857],
          [0.7626, 0.3688, 0.3648, 0.3792, 0.9019],
          [0...., 0.8551],
          [0.9063, 0.0620, 0.7660, 0.1432, 0.0246],
          [0.3537, 0.5790, 0.0246, 0.1890, 0.6437]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[1.0968789 , 4.609732  , 1.1390936 , 3.5003045 , 3.8604114 ],
         [1.6787606 , 3.7105742 , 2.607097  , 1...0.6970155 , 0.92313826],
         [0.62122965, 0.6551373 , 0.93612397, 0.9687539 , 0.9788141 ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
_____________________________________________________________________________________ test_LuvToRgb[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LuvToRgb(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.LuvToRgb,
            "kornia.color.RgbToLuv",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:990: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.luv.LuvToRgb'>, cls_name = 'kornia.color.RgbToLuv'
args = (tensor([[[[0.7311, 0.9798, 0.5703, 0.4619, 0.2711],
          [0.7726, 0.2522, 0.3567, 0.8311, 0.8115],
          [0...., 0.6482],
          [0.4452, 0.8787, 0.8680, 0.5693, 0.7475],
          [0.6988, 0.6095, 0.5065, 0.2961, 0.7126]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 2.19699666e-02,  2.54659299e-02,  1.01669393e-02,
           1.61978304e-02,  4.98669641e-03],
         [ 1...     [-7.92562147e-04,  3.11527145e-03, -2.13637788e-04,
          -1.95437949e-03,  6.91962661e-04]]]], dtype=float32)
y = array([[[[  81.42274  ,   76.42329  ,   34.837303 ,   66.15375  ,
            34.681705 ],
         [  53.83889  ,   4....99362  ],
         [  39.777016 ,  -50.303375 ,   49.170826 ,   29.994196 ,
           -13.703017 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.luv.LuvToRgb
___________________________________________________________________________________ test_RgbToYuv420[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            "kornia.color.RgbToYuv420",
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1088: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>, cls_name = 'kornia.color.RgbToYuv420'
args = (tensor([[[[0.6186, 0.9211, 0.7863, 0.4100, 0.2209, 0.7096],
          [0.1333, 0.5531, 0.9801, 0.4942, 0.8835, 0.8190...     [0.2436, 0.1523, 0.6831, 0.8703, 0.2775, 0.0850],
          [0.3893, 0.4027, 0.0592, 0.5740, 0.0803, 0.3542]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        cls_name,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        if cls_name:
            transpiled_obj = eval("transpiled_" + f"{cls_name}")(*init_args)
        else:
            transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.49666065, 0.61069036, 0.81176305, 0.5314939 , 0.23829365,
          0.7847696 ],
         [0.25596854, 0....
        [[ 0.05130252, -0.07852639,  0.13961512],
         [ 0.08683484, -0.14840448,  0.0983279 ]]]], dtype=float32))
y = (array([[[[0.49666065, 0.61069036, 0.81176305, 0.5314939 , 0.23829365,
          0.7847696 ],
         [0.25596854, 0....
        [[-0.14874259,  0.2925958 , -0.04805427],
         [ 0.04164964,  0.03592037, -0.02421943]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f8a80cc3f40>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.0248966 , -0.23658119, -0.05590083],
         [-0.02315804, -0.09021209,  0.02936213]],

        [[ 0.067...

        [[ 0.05130252, -0.07852639,  0.13961512],
         [ 0.08683484, -0.14840448,  0.0983279 ]]]], dtype=float32)
y = array([[[[-0.06286371,  0.04614194, -0.23205939],
         [ 0.06981201, -0.11819044, -0.10422707]],

        [[-0.109...

        [[-0.14874259,  0.2925958 , -0.04805427],
         [ 0.04164964,  0.03592037, -0.02421943]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToHls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_LuvToRgb[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 5 failed, 64 passed in 4314.36s (1:11:54) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ....F....F...FFFFF........sssssssssssss                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_adjust_gamma[numpy-s2s-False] __________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_adjust_gamma(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 2, 2),
            2.2,
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 1, 2, 2),
            0.4,
        )
        test_kwargs = {}
>       _test_function(
            kornia.enhance.adjust_gamma,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f7fef275360>, trace_args = (tensor([[[[0.9598, 0.6047],
          [0.2869, 0.5773]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.8353, 0.9334],
          [0.8628, 0.1562]]],


        [[[0.1618, 0.6691],
          [0.0206, 0.4998]]],...   [[[0.9424, 0.8412],
          [0.8091, 0.5138]]],


        [[[0.0660, 0.1584],
          [0.5265, 0.2506]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f7fef275360>, fn_name = 'kornia.enhance.adjust_gamma', trace_args = (tensor([[[[0.9598, 0.6047],
          [0.2869, 0.5773]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.8353, 0.9334],
          [0.8628, 0.1562]]],


        [[[0.1618, 0.6691],
          [0.0206, 0.4998]]],...   [[[0.9424, 0.8412],
          [0.8091, 0.5138]]],


        [[[0.0660, 0.1584],
          [0.5265, 0.2506]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.95983285, 0.6046987 ],
         [0.2869473 , 0.5772581 ]]]], dtype=float32), gamma = 2.2, gain = 1.0

    def numpy_adjust_gamma(input, gamma, gain=1.0):
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_any_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_unsqueeze_frnt,
        )
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_pow_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_clamp_frnt
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(gamma, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gamma should be a positive float or Tensor. Got {type(gamma)}"
            )
        if not isinstance(gain, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gain should be a positive float or Tensor. Got {type(gain)}"
            )
        if isinstance(gamma, (float,)):
>           gamma = numpy.ndarray([gamma])
E           TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:52: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.adjust_gamma
_____________________________________________________________________________________ test_invert[numpy-s2s-False] _____________________________________________________________________________________

>   ???

VM.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Copyright (c) 2024 Transpile AI Ltd. All rights reserved.
    
    This file is automatically generated by Transpile AI Ltd.'s software.
    
    License: Non-Enterprise Use Only
    
    This software is licensed for personal, educational, or non-commercial use only.
    Non-commercial use includes personal projects, educational purposes, or other activities
    that do not generate revenue or are not used in any business, organization, or institution.
    Commercial, production, or enterprise use—including any use in a for-profit business environment, within an organization,
    or in a revenue-generating activity—is strictly prohibited without a valid enterprise contract with Transpile AI Ltd.
    Unauthorized enterprise use may result in legal action, including but not limited to injunctions, damages, and financial penalties.
    
    To obtain an enterprise license, please visit https://ivy.dev/ or contact enterprise@ivy.dev.
    
    Redistribution: You may not distribute, sublicense, or sell copies of the generated source code or
    any derivative works thereof without express written permission from Transpile AI Ltd.
    
    Termination: This license automatically terminates upon failure to comply with any of its terms and conditions.
    Upon termination, you must immediately cease all use of the software and destroy any copies in your possession.
    
    Disclaimer: This software is provided "AS IS", WITHOUT WARRANTY OF ANY KIND, either express or implied.
    Transpile AI Ltd. disclaims all liability for damages or liabilities arising from the use of this software, to the fullest extent permitted by law.
    """
    
    import numpy
    
    
>   def numpy_invert(image, max_val=numpy.ndarray([1.0])):
E   TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:30: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_invert(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 1, 2, 2),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 1, 2, 2),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.invert,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f7fef275ea0>, trace_args = (tensor([[[[0.8612, 0.0085],
          [0.0653, 0.7989]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.3923, 0.1504],
          [0.5433, 0.2118]]],


        [[[0.4168, 0.7900],
          [0.1185, 0.3372]]],...       [[[0.7523, 0.7480],
          [0.8902, 0.4320]]],


        [[[0.5252, 0.9414],
          [0.8416, 0.2867]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f7fef275ea0>, fn_name = 'kornia.enhance.invert', trace_args = (tensor([[[[0.8612, 0.0085],
          [0.0653, 0.7989]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.3923, 0.1504],
          [0.5433, 0.2118]]],


        [[[0.4168, 0.7900],
          [0.1185, 0.3372]]],...       [[[0.7523, 0.7480],
          [0.8902, 0.4320]]],


        [[[0.5252, 0.9414],
          [0.8416, 0.2867]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:312: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ImportError: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as an integer

VM.pyx:247: ImportError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.invert
____________________________________________________________________________________ test_equalize[numpy-s2s-False] ____________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f7fef275cf0>
trace_args = (tensor([[[[0.9655, 0.1249, 0.9853],
          [0.9745, 0.5232, 0.1678],
          [0.2104, 0.8716, 0.4841]],

         [[0.5270, 0.5960, 0.5057],
          [0.6368, 0.8950, 0.8645],
          [0.2697, 0.0886, 0.8930]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.2236, 0.6423, 0.1958],
          [0.3429, 0.8712, 0.9916],
          [0.5403, 0.9905, 0.9658]],

       ...87]],

         [[0.5244, 0.2050, 0.9823],
          [0.5124, 0.0536, 0.9106],
          [0.5103, 0.0474, 0.8257]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f7fef275cf0>, fn_name = 'kornia.enhance.equalize'
trace_args = (tensor([[[[0.9655, 0.1249, 0.9853],
          [0.9745, 0.5232, 0.1678],
          [0.2104, 0.8716, 0.4841]],

         [[0.5270, 0.5960, 0.5057],
          [0.6368, 0.8950, 0.8645],
          [0.2697, 0.0886, 0.8930]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.2236, 0.6423, 0.1958],
          [0.3429, 0.8712, 0.9916],
          [0.5403, 0.9905, 0.9658]],

       ...87]],

         [[0.5244, 0.2050, 0.9823],
          [0.5124, 0.0536, 0.9106],
          [0.5103, 0.0474, 0.8257]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.96553177, 0.12491643, 0.9852976 ],
         [0.97454125, 0.5231693 , 0.16784167],
         [0.21037394, 0....72747],
         [0.6367537 , 0.89502823, 0.8645355 ],
         [0.2696752 , 0.08856457, 0.89295316]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f7f969d4f70>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f7f969d4700>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f7f969d52d0>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.96553177, 0.12491643, 0.9852976 ],
         [0.97454125, 0.5231693 , 0.16784167],
         [0.21037394, 0....72747],
         [0.6367537 , 0.89502823, 0.8645355 ],
         [0.2696752 , 0.08856457, 0.89295316]]]], dtype=float32)

    @numpy_perform_keep_shape_image
    def numpy_equalize(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for image in input:
            scaled_image = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            image, (i, slice(None, None, None), slice(None, None, None))
                        )
                    )
                    for i in range(len(image))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f7f97e7f840>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    image, (i, slice(None, None, None), slice(None, None, None))
                )
            )
            for i in range(len(image))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[246.2106  ,  31.853691, 251.2509  ],
       [248.50801 , 133.40817 ,  42.799625],
       [ 53.645355, 222.25258 , 123.43505 ]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 8.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(8., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize
_________________________________________________________________________________ test_equalize_clahe[numpy-s2s-False] _________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f7fef277c70>
trace_args = (tensor([[[0.7154, 0.5536, 0.6242, 0.5655, 0.9786, 0.5914, 0.2265, 0.0655,
          0.4313, 0.7836, 0.5133, 0.1876, 0...         0.5784, 0.5976, 0.8930, 0.5456, 0.5256, 0.7635, 0.6339, 0.8002,
          0.9845, 0.0411, 0.8321, 0.0091]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.8034, 0.9595, 0.8318,  ..., 0.7844, 0.4555, 0.9246],
          [0.5549, 0.9415, 0.6443,  ..., 0.5422, 0...., 0.9693, 0.1055,  ..., 0.1741, 0.9054, 0.2457],
          [0.6189, 0.7992, 0.6006,  ..., 0.7813, 0.6722, 0.2909]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f7fef277c70>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.7154, 0.5536, 0.6242, 0.5655, 0.9786, 0.5914, 0.2265, 0.0655,
          0.4313, 0.7836, 0.5133, 0.1876, 0...         0.5784, 0.5976, 0.8930, 0.5456, 0.5256, 0.7635, 0.6339, 0.8002,
          0.9845, 0.0411, 0.8321, 0.0091]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.8034, 0.9595, 0.8318,  ..., 0.7844, 0.4555, 0.9246],
          [0.5549, 0.9415, 0.6443,  ..., 0.5422, 0...., 0.9693, 0.1055,  ..., 0.1741, 0.9054, 0.2457],
          [0.6189, 0.7992, 0.6006,  ..., 0.7813, 0.6722, 0.2909]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.71544236, 0.55355114, 0.62415695, 0.5655427 , 0.9786466 ,
          0.5913648 , 0.22653937, 0.06554002, 0.... 0.76348174, 0.63391364,
          0.8002413 , 0.9845243 , 0.04106432, 0.8320847 , 0.00908369]]]],
      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f7f969d4550>
numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f7f971001f0>, numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f7f969d4040>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.71544236, 0.55355114, 0.62415695, 0.5655427 , 0.9786466 ,
          0.5913648 , 0.22653937, 0.06554002, 0.... 0.76348174, 0.63391364,
          0.8002413 , 0.9845243 , 0.04106432, 0.8320847 , 0.00908369]]]],
      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @numpy_perform_keep_shape_image
    def numpy_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_permute_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = numpy__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:490: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = array([[[[0.71544236, 0.55355114, 0.62415695, 0.5655427 , 0.9786466 ,
          0.5913648 , 0.22653937, 0.06554002, 0.... 0.76348174, 0.63391364,
          0.8002413 , 0.9845243 , 0.04106432, 0.8320847 , 0.00908369]]]],
      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def numpy__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            numpy_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = numpy_shape_frnt_(batch)[-2:][0], numpy_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > numpy_shape_frnt_(batch)[-2]
            or pad_horz > numpy_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = numpy_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = numpy_shape_frnt_(batch)[-3]
        tiles: typing.Any = numpy_contiguous_frnt_(
            numpy_squeeze_frnt_(
                numpy_unfold_frnt_(
>                   numpy_unfold_frnt_(
                        numpy_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[[[0.71544236, 0.66167665, 0.32352424, 0.6643588 , 0.49728256,
           0.735978  , 0.9908763 , 0.4692309 ,...       0.5046344 , 0.71052295, 0.01745129, 0.6408101 , 0.7984196 ,
           0.16086054]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f7f96bc3130>
array_like = array([[[[[0.71544236, 0.66167665, 0.32352424, 0.6643588 , 0.49728256,
           0.735978  , 0.9908763 , 0.4692309 , ...263 ,
           0.5046344 , 0.71052295, 0.01745129, 0.6408101 , 0.7984196 ,
           0.16086054]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[[[0.71544236, 0.66167665, 0.32352424, 0.6643588 , 0.49728256,
           0.735978  , 0.9908763 , 0.4692309 , ...263 ,
           0.5046344 , 0.71052295, 0.01745129, 0.6408101 , 0.7984196 ,
           0.16086054]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @numpy_handle_methods
    def numpy_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.general import numpy_set_item
        from .indexing_slicing_joining_mutating_ops import numpy_stack_frnt
    
        slices = []
        self_shape = tuple(numpy_shape_frnt_(tensor))
        for i in range(0, numpy_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(numpy_shape_frnt_(tensor))
            slicing = numpy_set_item(slicing, dimension, slice(i, i + size))
            slices.append(numpy_get_item(tensor, tuple(slicing)))
>       stacked = numpy_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def numpy_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.numpy.manipulation import numpy_stack
    
>       return numpy_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def numpy_stack(
        arrays: Union[Tuple[np.ndarray], List[np.ndarray]],
        /,
        *,
        axis: int = 0,
        out: Optional[np.ndarray] = None,
    ):
>       return np.stack(arrays, axis, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/backends/numpy/manipulation.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None

    @array_function_dispatch(_stack_dispatcher)
    def stack(arrays, axis=0, out=None, *, dtype=None, casting="same_kind"):
        """
        Join a sequence of arrays along a new axis.
    
        The ``axis`` parameter specifies the index of the new axis in the
        dimensions of the result. For example, if ``axis=0`` it will be the first
        dimension and if ``axis=-1`` it will be the last dimension.
    
        .. versionadded:: 1.10.0
    
        Parameters
        ----------
        arrays : sequence of array_like
            Each array must have the same shape.
    
        axis : int, optional
            The axis in the result array along which the input arrays are stacked.
    
        out : ndarray, optional
            If provided, the destination to place the result. The shape must be
            correct, matching that of what stack would have returned if no
            out argument were specified.
    
        dtype : str or dtype
            If provided, the destination array will have this dtype. Cannot be
            provided together with `out`.
    
            .. versionadded:: 1.24
    
        casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
            Controls what kind of data casting may occur. Defaults to 'same_kind'.
    
            .. versionadded:: 1.24
    
    
        Returns
        -------
        stacked : ndarray
            The stacked array has one more dimension than the input arrays.
    
        See Also
        --------
        concatenate : Join a sequence of arrays along an existing axis.
        block : Assemble an nd-array from nested lists of blocks.
        split : Split array into a list of multiple sub-arrays of equal size.
    
        Examples
        --------
        >>> arrays = [np.random.randn(3, 4) for _ in range(10)]
        >>> np.stack(arrays, axis=0).shape
        (10, 3, 4)
    
        >>> np.stack(arrays, axis=1).shape
        (3, 10, 4)
    
        >>> np.stack(arrays, axis=2).shape
        (3, 4, 10)
    
        >>> a = np.array([1, 2, 3])
        >>> b = np.array([4, 5, 6])
        >>> np.stack((a, b))
        array([[1, 2, 3],
               [4, 5, 6]])
    
        >>> np.stack((a, b), axis=-1)
        array([[1, 4],
               [2, 5],
               [3, 6]])
    
        """
        arrays = [asanyarray(arr) for arr in arrays]
        if not arrays:
>           raise ValueError('need at least one array to stack')
E           ValueError: need at least one array to stack

/opt/fw/mxnet/numpy/core/shape_base.py:445: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_equalize3d[numpy-s2s-False] ___________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize3d(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:383: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f7fef275e10>
trace_args = (tensor([[[[[0.8098, 0.6741, 0.8155],
           [0.6298, 0.4130, 0.8391],
           [0.6515, 0.5732, 0.0591]],

    ...,

          [[0.4825, 0.5929, 0.2071],
           [0.5242, 0.8753, 0.9729],
           [0.4724, 0.3061, 0.0850]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.9963, 0.9640, 0.5431],
           [0.7103, 0.2951, 0.2004],
           [0.8384, 0.9127, 0.4813]],

    ...,

          [[0.5646, 0.5115, 0.3390],
           [0.3301, 0.6868, 0.0654],
           [0.0379, 0.6411, 0.5979]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f7fef275e10>, fn_name = 'kornia.enhance.equalize3d'
trace_args = (tensor([[[[[0.8098, 0.6741, 0.8155],
           [0.6298, 0.4130, 0.8391],
           [0.6515, 0.5732, 0.0591]],

    ...,

          [[0.4825, 0.5929, 0.2071],
           [0.5242, 0.8753, 0.9729],
           [0.4724, 0.3061, 0.0850]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.9963, 0.9640, 0.5431],
           [0.7103, 0.2951, 0.2004],
           [0.8384, 0.9127, 0.4813]],

    ...,

          [[0.5646, 0.5115, 0.3390],
           [0.3301, 0.6868, 0.0654],
           [0.0379, 0.6411, 0.5979]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.8098378 , 0.6741029 , 0.8154546 ],
          [0.62977666, 0.41298217, 0.83907247],
          [0.6515421 ,...61],
          [0.5241741 , 0.87532616, 0.9729135 ],
          [0.4724288 , 0.30612117, 0.08499688]]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f7f96c3a9e0>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f7f96c39870>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f7f97347400>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bcdhw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.8098378 , 0.6741029 , 0.8154546 ],
          [0.62977666, 0.41298217, 0.83907247],
          [0.6515421 ,...61],
          [0.5241741 , 0.87532616, 0.9729135 ],
          [0.4724288 , 0.30612117, 0.08499688]]]]], dtype=float32)

    @numpy_perform_keep_shape_video
    def numpy_equalize3d(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for volume in input:
            scaled_input = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            volume,
                            (
                                i,
                                slice(None, None, None),
                                slice(None, None, None),
                                slice(None, None, None),
                            ),
                        )
                    )
                    for i in range(len(volume))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f7f97d54ae0>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    volume,
                    (
                        i,
                        slice(None, None, None),
                        slice(None, None, None),
                        slice(None, None, None),
                    ),
                )
            )
            for i in range(len(volume))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[[206.50864 , 171.89624 , 207.94092 ],
        [160.59305 , 105.310455, 213.96349 ],
        [166.14325 , 146.1...1.4077  ],
        [185.02322 , 134.03403 ,  38.123096],
        [222.76942 , 200.83554 , 178.05643 ]]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 26.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(26., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize3d
___________________________________________________________________________________ test_histogram[numpy-s2s-False] ____________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f7fef2776d0>
trace_args = (tensor([[0.4258, 0.2490, 0.2109, 0.3733, 0.2507, 0.9238, 0.0745, 0.4698, 0.9494,
         0.6377]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.6040, 0.3455, 0.7334, 0.8267, 0.6546, 0.1456, 0.3058, 0.5864, 0.9972,
         0.7753],
        [0.0177, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f7fef2776d0>, fn_name = 'kornia.enhance.histogram'
trace_args = (tensor([[0.4258, 0.2490, 0.2109, 0.3733, 0.2507, 0.9238, 0.0745, 0.4698, 0.9494,
         0.6377]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.6040, 0.3455, 0.7334, 0.8267, 0.6546, 0.1456, 0.3058, 0.5864, 0.9972,
         0.7753],
        [0.0177, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.42583   , 0.2490043 , 0.21091765, 0.37333816, 0.2506699 ,
        0.9237782 , 0.07454079, 0.46983212, 0.9494075 , 0.6377261 ]],
      dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram(x, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       pdf, _ = numpy_marginal_pdf(numpy_unsqueeze_frnt_(x, 2), bins, bandwidth, epsilon)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.42583   ],
        [0.2490043 ],
        [0.21091765],
        [0.37333816],
        [0.2506699 ],
        [0.9237782 ],
        [0.07454079],
        [0.46983212],
        [0.9494075 ],
        [0.6377261 ]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 4.7314447e-01, -1.7578267e+00, -3.9887981e+00, ...,
         -2.7839825e+02, -2.8062924e+02, -2.8286020e+02...01, -1.5223867e+00, -3.7533579e+00, ...,
         -2.7816281e+02, -2.8039380e+02, -2.8262476e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f7f9693e320>
array_like = array([[[ 4.7314447e-01, -1.7578267e+00, -3.9887981e+00, ...,
         -2.7839825e+02, -2.8062924e+02, -2.8286020e+02]...61e-01, -1.5223867e+00, -3.7533579e+00, ...,
         -2.7816281e+02, -2.8039380e+02, -2.8262476e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 4.7314447e-01, -1.7578267e+00, -3.9887981e+00, ...,
         -2.7839825e+02, -2.8062924e+02, -2.8286020e+02]...61e-01, -1.5223867e+00, -3.7533579e+00, ...,
         -2.7816281e+02, -2.8039380e+02, -2.8262476e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 4.7314447e-01, -1.7578267e+00, -3.9887981e+00, ...,
         -2.7839825e+02, -2.8062924e+02, -2.8286020e+02...01, -1.5223867e+00, -3.7533579e+00, ...,
         -2.7816281e+02, -2.8039380e+02, -2.8262476e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f7f9693e320>
array_like = array([[[ 4.7314447e-01, -1.7578267e+00, -3.9887981e+00, ...,
         -2.7839825e+02, -2.8062924e+02, -2.8286020e+02]...61e-01, -1.5223867e+00, -3.7533579e+00, ...,
         -2.7816281e+02, -2.8039380e+02, -2.8262476e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 4.7314447e-01, -1.7578267e+00, -3.9887981e+00, ...,
         -2.7839825e+02, -2.8062924e+02, -2.8286020e+02]...61e-01, -1.5223867e+00, -3.7533579e+00, ...,
         -2.7816281e+02, -2.8039380e+02, -2.8262476e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 4.7314447e-01, -1.7578267e+00, -3.9887981e+00, ...,
         -2.7839825e+02, -2.8062924e+02, -2.8286020e+02]...61e-01, -1.5223867e+00, -3.7533579e+00, ...,
         -2.7816281e+02, -2.8039380e+02, -2.8262476e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram
__________________________________________________________________________________ test_histogram2d[numpy-s2s-False] ___________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 32),
            torch.rand(2, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 32),
            torch.rand(5, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f7fef2777f0>
trace_args = (tensor([[0.8719, 0.0963, 0.0787, 0.0058, 0.3497, 0.5627, 0.9065, 0.0380, 0.8446,
         0.0262, 0.4210, 0.9883, 0.1...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.2229, 0.4972, 0.3363, 0.7961, 0.6398, 0.3590, 0.8439, 0.5711, 0.7791,
         0.5895, 0.7548, 0.6714, 0.0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f7fef2777f0>, fn_name = 'kornia.enhance.histogram2d'
trace_args = (tensor([[0.8719, 0.0963, 0.0787, 0.0058, 0.3497, 0.5627, 0.9065, 0.0380, 0.8446,
         0.0262, 0.4210, 0.9883, 0.1...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.2229, 0.4972, 0.3363, 0.7961, 0.6398, 0.3590, 0.8439, 0.5711, 0.7791,
         0.5895, 0.7548, 0.6714, 0.0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[0.87186164, 0.09628922, 0.07865089, 0.00581026, 0.34972638,
        0.56270695, 0.906529  , 0.03802645, 0.8445...5,
        0.45322174, 0.2070536 , 0.2503144 , 0.6408628 , 0.7583874 ,
        0.99851817, 0.36381006]], dtype=float32)
x2 = array([[0.8057801 , 0.3667137 , 0.7854461 , 0.80773425, 0.3166529 ,
        0.90901506, 0.35101187, 0.44842505, 0.0347...5,
        0.37273324, 0.12700629, 0.11946017, 0.03279936, 0.9518203 ,
        0.846596  , 0.21473962]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram2d(x1, x2, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       _, kernel_values1 = numpy_marginal_pdf(
            numpy_unsqueeze_frnt_(x1, 2), bins, bandwidth, epsilon
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.87186164],
        [0.09628922],
        [0.07865089],
        [0.00581026],
        [0.34972638],
        ... [0.2503144 ],
        [0.6408628 ],
        [0.7583874 ],
        [0.99851817],
        [0.36381006]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 9.6873516e-01, -1.2622360e+00, -3.4932072e+00, ...,
         -2.7790268e+02, -2.8013364e+02, -2.8236462e+02...01, -1.8267378e+00, -4.0577087e+00, ...,
         -2.7846716e+02, -2.8069812e+02, -2.8292911e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f7f96ee13f0>
array_like = array([[[ 9.6873516e-01, -1.2622360e+00, -3.4932072e+00, ...,
         -2.7790268e+02, -2.8013364e+02, -2.8236462e+02]...43e-01, -1.8267378e+00, -4.0577087e+00, ...,
         -2.7846716e+02, -2.8069812e+02, -2.8292911e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 9.6873516e-01, -1.2622360e+00, -3.4932072e+00, ...,
         -2.7790268e+02, -2.8013364e+02, -2.8236462e+02]...43e-01, -1.8267378e+00, -4.0577087e+00, ...,
         -2.7846716e+02, -2.8069812e+02, -2.8292911e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 9.6873516e-01, -1.2622360e+00, -3.4932072e+00, ...,
         -2.7790268e+02, -2.8013364e+02, -2.8236462e+02...01, -1.8267378e+00, -4.0577087e+00, ...,
         -2.7846716e+02, -2.8069812e+02, -2.8292911e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f7f96ee13f0>
array_like = array([[[ 9.6873516e-01, -1.2622360e+00, -3.4932072e+00, ...,
         -2.7790268e+02, -2.8013364e+02, -2.8236462e+02]...43e-01, -1.8267378e+00, -4.0577087e+00, ...,
         -2.7846716e+02, -2.8069812e+02, -2.8292911e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 9.6873516e-01, -1.2622360e+00, -3.4932072e+00, ...,
         -2.7790268e+02, -2.8013364e+02, -2.8236462e+02]...43e-01, -1.8267378e+00, -4.0577087e+00, ...,
         -2.7846716e+02, -2.8069812e+02, -2.8292911e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 9.6873516e-01, -1.2622360e+00, -3.4932072e+00, ...,
         -2.7790268e+02, -2.8013364e+02, -2.8236462e+02]...43e-01, -1.8267378e+00, -4.0577087e+00, ...,
         -2.7846716e+02, -2.8069812e+02, -2.8292911e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram2d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_adjust_gamma[numpy-s2s-False] - TypeError: 'float' object cannot be interpreted as an integer
FAILED kornia/test_enhance.py::test_invert[numpy-s2s-False] - ImportError: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as a...
FAILED kornia/test_enhance.py::test_equalize[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_equalize_clahe[numpy-s2s-False] - ValueError: need at least one array to stack
FAILED kornia/test_enhance.py::test_equalize3d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram2d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
======================================================================== 7 failed, 19 passed, 13 skipped in 1698.81s (0:28:18) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.04s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....Fssssssssss                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_diamond_square[numpy-s2s-False] _________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f06f88c1510>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f0710c488c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f0710c488c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f06f88c1510>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f0710c488c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f0710c488c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = 0.5, random_scale = 1.0, random_fn = <built-in method ones of type object at 0x7f0710c488c0>, normalize_range = (0.0, 1.0), device = None, dtype = None

    def numpy_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=numpy_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import numpy_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_frnt_
        from ..core.check import numpy_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ..enhance.normalize import numpy_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
    
        numpy_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (numpy.ndarray, numpy.ndarray)):
            random_scale = numpy_to_frnt_(
>               numpy.ndarray([[[[random_scale]]]]), device, dtype
            )
E           TypeError: 'list' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/contrib/diamond_square.py:197: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[numpy-s2s-False] - TypeError: 'list' object cannot be interpreted as an integer
========================================================================= 1 failed, 4 passed, 10 skipped in 343.98s (0:05:43) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ssss                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 5.22s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ssssssssssssssss                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 16 skipped in 5.25s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_AutoAugment[tensorflow-s2s-False] ________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = transpiled_kornia.augmentation.auto.AutoAugment()

kornia/augmentation/test_auto.py:25: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bb50>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bb50>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bb50>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bb50>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f67e8c3bc10>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bb50>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        return tensorflow_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f67e8c3b910>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:138: NameError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = transpiled_kornia.augmentation.auto.AutoAugment()

kornia/augmentation/test_auto.py:25: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bdf0>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bdf0>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bdf0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bdf0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f67e8c3ab90>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f67e8c3bdf0>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        return tensorflow_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f67e8c3bee0>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:138: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
kornia.augmentation.auto.AutoAugment
________________________________________________________________________________ test_RandAugment[tensorflow-s2s-False] ________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = transpiled_kornia.augmentation.auto.RandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e6772200>, n = 2, m = 10, policy = None
transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e6772200>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e6772200>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e6772200>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f67e6771c90>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e6772200>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:83: NameError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = transpiled_kornia.augmentation.auto.RandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e67708e0>, n = 2, m = 10, policy = None
transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e67708e0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e67708e0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e67708e0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f67e6773430>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f67e67708e0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:83: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
kornia.augmentation.auto.RandAugment
______________________________________________________________________________ test_TrivialAugment[tensorflow-s2s-False] _______________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = transpiled_kornia.augmentation.auto.TrivialAugment()

kornia/augmentation/test_auto.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2440>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_tensor_frnt,
        )
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2440>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2440>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2440>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f67e74f0d00>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2440>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:71: NameError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = transpiled_kornia.augmentation.auto.TrivialAugment()

kornia/augmentation/test_auto.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2410>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_tensor_frnt,
        )
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2410>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2410>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2410>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f67e74f23e0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f67e74f2410>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:71: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1419.55s (0:23:39) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py .......F                                                                                                                                                          [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_euclidean_distance[numpy-s2s-False] _______________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_euclidean_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(3, 5),
            torch.rand(3, 5),
        )
        trace_kwargs = {'keepdim': False, 'eps': 1e-6}
        test_args = (
            torch.rand(5, 3, 5),
            torch.rand(5, 3, 5),
        )
        test_kwargs = {'keepdim': False, 'eps': 1e-6}
>       _test_function(
            kornia.geometry.linalg.euclidean_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_linalg.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f5b81fe00d0>
trace_args = (tensor([[0.2270, 0.7534, 0.7868, 0.3916, 0.4893],
        [0.2951, 0.7820, 0.7246, 0.3039, 0.1900],
        [0.8540, ....5657e-01, 7.3575e-02, 9.1791e-04, 9.9691e-01],
        [8.4755e-02, 6.9569e-01, 5.2682e-01, 4.4865e-01, 1.8683e-01]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.4866, 0.3098, 0.6572, 0.0022, 0.4210],
         [0.6367, 0.4432, 0.1891, 0.8349, 0.0276],
         [0.094...1534, 0.8236],
         [0.5214, 0.8089, 0.9253, 0.8003, 0.4688],
         [0.3436, 0.5296, 0.9300, 0.4519, 0.3056]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f5b81fe00d0>, fn_name = 'kornia.geometry.linalg.euclidean_distance'
trace_args = (tensor([[0.2270, 0.7534, 0.7868, 0.3916, 0.4893],
        [0.2951, 0.7820, 0.7246, 0.3039, 0.1900],
        [0.8540, ....5657e-01, 7.3575e-02, 9.1791e-04, 9.9691e-01],
        [8.4755e-02, 6.9569e-01, 5.2682e-01, 4.4865e-01, 1.8683e-01]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.4866, 0.3098, 0.6572, 0.0022, 0.4210],
         [0.6367, 0.4432, 0.1891, 0.8349, 0.0276],
         [0.094...1534, 0.8236],
         [0.5214, 0.8089, 0.9253, 0.8003, 0.4688],
         [0.3436, 0.5296, 0.9300, 0.4519, 0.3056]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.22696918, 0.75343543, 0.78684723, 0.3915912 , 0.4893238 ],
       [0.2950524 , 0.7819713 , 0.72459465, 0.30385202, 0.19004732],
       [0.8540104 , 0.51266164, 0.32572293, 0.05034083, 0.22759789]],
      dtype=float32)
y = array([[6.4445800e-01, 8.0497801e-02, 1.2437582e-01, 6.8481058e-01,
        1.9558305e-01],
       [6.6733110e-01, 7.5...91129e-01],
       [8.4754527e-02, 6.9569367e-01, 5.2682430e-01, 4.4865096e-01,
        1.8683445e-01]], dtype=float32)
keepdim = False, eps = 1e-06

    def numpy_euclidean_distance(x, y, keepdim=False, eps=1e-06):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(x, ["*", "N"])
        numpy_KORNIA_CHECK_SHAPE(y, ["*", "N"])
        return numpy_sqrt_frnt_(
>           numpy_sum_frnt_(numpy_pow_frnt_(x - y + eps, 2), -1, keepdim)
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/linalg.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.4174878 ,  0.67293864,  0.6624724 , -0.29321837,  0.29374176],
       [-0.37227768,  0.02540301,  0.651020...3512, -0.80686295],
       [ 0.7692569 , -0.18303104, -0.20110036, -0.3983091 ,  0.04076444]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5b29568af0>
array_like = array([[-0.4174878 ,  0.67293864,  0.6624724 , -0.29321837,  0.29374176],
       [-0.37227768,  0.02540301,  0.6510201...30293512, -0.80686295],
       [ 0.7692569 , -0.18303104, -0.20110036, -0.3983091 ,  0.04076444]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[-0.4174878 ,  0.67293864,  0.6624724 , -0.29321837,  0.29374176],
       [-0.37227768,  0.02540301,  0.6510201...30293512, -0.80686295],
       [ 0.7692569 , -0.18303104, -0.20110036, -0.3983091 ,  0.04076444]],
      dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.4174878 ,  0.67293864,  0.6624724 , -0.29321837,  0.29374176],
       [-0.37227768,  0.02540301,  0.651020...3512, -0.80686295],
       [ 0.7692569 , -0.18303104, -0.20110036, -0.3983091 ,  0.04076444]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f5b29568af0>
array_like = array([[-0.4174878 ,  0.67293864,  0.6624724 , -0.29321837,  0.29374176],
       [-0.37227768,  0.02540301,  0.6510201...30293512, -0.80686295],
       [ 0.7692569 , -0.18303104, -0.20110036, -0.3983091 ,  0.04076444]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[-0.4174878 ,  0.67293864,  0.6624724 , -0.29321837,  0.29374176],
       [-0.37227768,  0.02540301,  0.6510201...30293512, -0.80686295],
       [ 0.7692569 , -0.18303104, -0.20110036, -0.3983091 ,  0.04076444]],
      dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[-0.4174878 ,  0.67293864,  0.6624724 , -0.29321837,  0.29374176],
       [-0.37227768,  0.02540301,  0.6510201...30293512, -0.80686295],
       [ 0.7692569 , -0.18303104, -0.20110036, -0.3983091 ,  0.04076444]],
      dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.linalg.euclidean_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_linalg.py::test_euclidean_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 1 failed, 7 passed in 412.55s (0:06:52) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_get_laf_descriptors[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f69a1fa1d80>
trace_args = (tensor([[[[0.2937, 0.1821, 0.6910,  ..., 0.9145, 0.5111, 0.7060],
          [0.2118, 0.8731, 0.3905,  ..., 0.9721, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.2375, 0.5236, 0.7015,  ..., 0.7560, 0.9529, 0.6455],
          [0.3512, 0.3740, 0.0308,  ..., 0.5486, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f69a1fa1d80>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.2937, 0.1821, 0.6910,  ..., 0.9145, 0.5111, 0.7060],
          [0.2118, 0.8731, 0.3905,  ..., 0.9721, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.2375, 0.5236, 0.7015,  ..., 0.7560, 0.9529, 0.6455],
          [0.3512, 0.3740, 0.0308,  ..., 0.5486, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
>       [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f69484f1800>

>   [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

original_model = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
translated_model = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models(
        original_model: "nn.Module",
        translated_model: Union["keras.Model", "KerasModel", "nnx.Module", "FlaxModel"],
    ):
        """Synchronizes the weights and buffers between a native PyTorch model
        (`torch.nn.Module`) and it's translated version in TensorFlow or Flax.
    
        Args:
        ----
            original_model (torch.nn.Module): The PyTorch model to synchronize from.
            translated_model (tf.keras.Model or nnx.Module): The target model to synchronize to,
                                                      either a TensorFlow or Flax model.
        """
        if not _is_submodule(original_model, "torch"):
            raise ivy.utils.exceptions.IvyException(
                "sync_models expected an instance of `nn.Module` as the first argument. got {}".format(
                    original_model
                )
            )
        if _is_submodule(translated_model, "keras"):
>           sync_models_torch_and_tf(original_model, translated_model)

../ivy/ivy/stateful/utilities.py:797: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model_pt = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model_tf = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models_torch_and_tf(
        model_pt: "nn.Module", model_tf: Union["keras.Model", "KerasModel"]
    ):
        """Synchronizes the weights and buffers between a PyTorch model
        (`torch.nn.Module`) and a TensorFlow model (`keras.Model`).
    
        This function ensures that both models have identical parameters and buffers by
        iterating through their submodules and synchronizing them. The TensorFlow model
        must either be an instance of `KerasModel` or have submodules that inherit from the
        translated `KerasModel`/`KerasLayer`, and expose interfaces similar to `torch.nn.Module`,
        including `named_parameters()` and `named_buffers()`.
    
        Args:
        ----
            model_pt (torch.nn.Module): The PyTorch model to synchronize from.
            model_tf (keras.Model): The TensorFlow model to synchronize to, with submodules
                                    inheriting from the custom `KerasModel`/`KerasLayer` class.
    
        Returns:
        -------
            None
    
    
        Example:
        -------
            ```python
            import torch.nn as nn
            import keras
    
            #`CustomKerasLinear` is a subclass of `Layer` that exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class CustomKerasLinear(Layer):
                def __init__(self, in_features, out_features):
                    super(CustomKerasLinear, self).__init__()
                    self.weight = tf.Variable(tf.random.normal([out_features, in_features]))
                    self.bias = tf.Variable(tf.random.normal([out_features]))
    
                def call(self, x):
                    return tf.matmul(x, self.weight) + self.bias
    
                def named_parameters(self):
                            return [("weight", self.weight), ("bias", self.bias)]
    
                def named_buffers(self):
                            return []
    
                def eval(self):
                    return False
    
            #`NativeKerasModel` is a subclass of keras.Model and does NOT exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class NativeKerasModel(keras.Model):
                def __init__(self):
                    super(NativeKerasModel, self).__init__()
                    self.linear = CustomKerasLinear(10, 5)
    
                def call(self, x):
                    return self.linear(x)
    
            class PyTorchModel(nn.Module):
                def __init__(self):
                    super(PyTorchModel, self).__init__()
                    self.linear = nn.Linear(10, 5)
    
                def forward(self, x):
                    return self.linear(x)
    
            # Instantiate both models
            model_pt = PyTorchModel()  # PyTorch model
            model_tf = NativeKerasModel()  # Native Keras model inheriting from keras.Model
    
            # Sync all submodules between the PyTorch and Keras models
            sync_models_torch_and_tf(model_pt, model_tf)
            ```
        """
    
        def _compute_module_dict_tf(model, prefix=""):
            _module_dict = dict()
            for key, value in model.__dict__.items():
                if isinstance(value, (tf.keras.Model, tf.keras.layers.Layer)):
                    if not hasattr(value, "named_parameters"):
                        _module_dict.update(
                            _compute_module_dict_tf(value, prefix=f"{key}.")
                        )
                    else:
                        _module_dict[prefix + key] = value
            return _module_dict
    
        try:
            pass
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`torch` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        try:
            import tensorflow as tf
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`tensorflow` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        if hasattr(model_tf, "named_parameters"):
>           _sync_models_torch_and_tf(model_pt, model_tf)

../ivy/ivy/stateful/utilities.py:627: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model1 = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model2 = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def _sync_models_torch_and_tf(model1: "nn.Module", model2: "KerasModel"):
        """Synchronizes the parameters and buffers of the original and the
        translated model.
    
        Args:
        ----
            model1 (torch.nn.Module): The original PyTorch model.
            model2 (ivy.Module converted keras.Model)): The converted ivy.Module converted keras.Model.
    
        Returns:
        -------
            None
        """
        def _pt_name_to_keras_name(layer, weight_name):
            if layer.__class__.__name__ in ("KerasConv2D", "KerasDense"):
                param_and_buff_map = {
                    "weight": "_kernel",
                    "bias": "bias",
                }
            elif layer.__class__.__name__ == "KerasDepthwiseConv2D":
                if parse(keras.__version__).major > 2:
                    param_and_buff_map = {
                        "weight": "kernel",
                        "bias": "bias",
                    }
                else:
                    param_and_buff_map = {
                        "weight": "depthwise_kernel",
                        "bias": "bias",
                    }
            elif layer.__class__.__name__ == "KerasBatchNorm2D":
                param_and_buff_map = {
                    "weight": "gamma",
                    "bias": "beta",
                    "running_mean": "moving_mean",
                    "running_var": "moving_variance",
                    "num_batches_tracked": "num_batches_tracked",
                }
            else:
                raise ValueError(f"Layer '{layer}' is not supported.")
    
            return param_and_buff_map[weight_name]
    
        def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
            # Update the weight in the retrieved layer
            if hasattr(layer, weight_name):
                layer._is_built = True
                weight_var = getattr(layer, weight_name)
                if isinstance(weight_var, tf.Variable):
                    weight_var.assign(tf.Variable(new_weight, dtype=weight_var.dtype))
                elif isinstance(weight_var, KerasVariable):
                    weight_var.assign(
                        KerasVariable(
                            new_weight, dtype=weight_var.dtype, name=weight_var.name
                        )
                    )
                else:
                    setattr(
                        layer,
                        weight_name,
                        tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                    )
                # now also update the PT placeholder weights for this layer
                layer._is_built = False
                pt_weight_name = (
                    "pt_weight"
                    if weight_name == "weight"
                    else "pt_bias" if weight_name == "bias" else weight_name
                )
                setattr(
                    layer,
                    pt_weight_name,
                    None if original_weight is None else tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                )
            else:
                raise AttributeError(
                    f"Layer '{layer}' does not have a weight named '{weight_name}'"
                )
    
        import torch
        import tensorflow as tf
        import keras
    
        if parse(keras.__version__).major > 2:
            KerasVariable = keras.src.backend.Variable
        else:
            KerasVariable = tf.Variable
    
        has_keras_layers = os.environ.get("USE_NATIVE_FW_LAYERS", "true") == "true"
        transpose_weights = (
            has_keras_layers
            or os.environ.get("APPLY_TRANSPOSE_OPTIMIZATION", "true") == "true"
        )
    
        params1 = dict(model1.named_parameters())
        params2 = dict(model2.named_parameters())
        buffers1 = dict(model1.named_buffers())
        buffers2 = dict(model2.named_buffers())
        # TODO: remove this once the stateful attribute name-conflict has been resolved.
        key_mapping = {}
        for k in params2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        for k in buffers2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        params2 = {k.replace("pt_", ""): v for k, v in params2.items()}
        buffers2 = {k.replace("pt_", ""): v for k, v in buffers2.items()}
    
        # Check if both models have the same parameters and buffers
        assert params1.keys() == params2.keys()
        assert buffers1.keys() == buffers2.keys()
    
        # Set the parameters and buffers of the second model to be the same as the first model
        with torch.no_grad():
            for name in params1:
                layer, weight_name = _retrive_layer(model2, key_mapping[name])
    
                params1_np = params1[name].cpu().detach().numpy()
                # Transpose the parameters to match the TensorFlow format
                params1_np = transpose_weights_pt_to_tf_jax(layer, params1_np, transpose_weights, fw='tensorflow')
    
                # inplace update the native keras layer. This is done as the parameters in
                # self.v are a different copy than the parameters in self.weights. Hence, we
                # need to explicitly update self.weights, otherwise the changes won't reflect.
                if layer.__class__.__name__.startswith("Keras"):
                    keras_name = _pt_name_to_keras_name(layer, weight_name)
>                   _maybe_update_keras_layer_weights(
                        layer=layer, weight_name=weight_name, new_weight=params1_np, original_weight=params1[name].cpu().detach().numpy()
                    )

../ivy/ivy/stateful/utilities.py:461: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

layer = KerasConv2D(), weight_name = 'weight'
new_weight = array([[[[-0.29088145,  0.19441514,  0.29097635, -0.05668513,
           0.1230129 , -0.04771725,  0.06122124,  0.2182...29131, -0.12299263,  0.21650454,
          -0.11881717,  0.24685812, -0.0465852 ,  0.19125292]]]],
      dtype=float32)
original_weight = array([[[[-0.29088145, -0.04494798,  0.28039187],
         [ 0.27970144, -0.21509485, -0.05650954],
         [ 0.26862...,
         [ 0.26586086, -0.15258703, -0.03336998],
         [-0.28721017, -0.13187513,  0.19125292]]]], dtype=float32)

    def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
        # Update the weight in the retrieved layer
        if hasattr(layer, weight_name):
            layer._is_built = True
>           weight_var = getattr(layer, weight_name)

../ivy/ivy/stateful/utilities.py:381: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasConv2D(), name = 'weight'

    def __getattribute__(self, name):
        built = object.__getattribute__(self, "__dict__").get("_is_built", False)
        use_bias = object.__getattribute__(self, "__dict__").get("use_bias", True)
        if built:
            attr_map = {"weight": "_kernel", "bias": "bias"}
        else:
            attr_map = {"weight": "pt_weight", "bias": "pt_bias"}
        if not use_bias:
            attr_map["bias"] = "pt_bias"
        new_name = attr_map[name] if name in attr_map else name
>       return super().__getattribute__(new_name)
E       AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:626: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[tensorflow-s2s-False] - AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?
============================================================================== 1 failed, 18 passed in 1656.20s (0:27:36) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_AutoAugment[jax-s2s-False] ____________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = transpiled_kornia.augmentation.auto.AutoAugment()

kornia/augmentation/test_auto.py:25: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d81c4d1b0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d81c4d1b0>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d81c4d1b0>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d81c4d1b0>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d81c4d1b0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d81c4d1b0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1d81c4cfa0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d81c4d1b0>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        return jax_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1d81c4e5f0>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:136: NameError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = transpiled_kornia.augmentation.auto.AutoAugment()

kornia/augmentation/test_auto.py:25: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d8552c6a0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d8552c6a0>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d8552c6a0>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d8552c6a0>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d8552c6a0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d8552c6a0>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1d81c4d180>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7f1d8552c6a0>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        return jax_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1d81c4f220>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:136: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
kornia.augmentation.auto.AutoAugment
___________________________________________________________________________________ test_RandAugment[jax-s2s-False] ____________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = transpiled_kornia.augmentation.auto.RandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d828b4190>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d828b4190>, args = (), kwargs = {'m': 10, 'n': 2}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d828b4190>, n = 2, m = 10, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d828b4190>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d828b4190>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d828b4190>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1d8072c250>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d828b4190>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:81: NameError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = transpiled_kornia.augmentation.auto.RandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d8072dcf0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d8072dcf0>, args = (), kwargs = {'m': 10, 'n': 2}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d8072dcf0>, n = 2, m = 10, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d8072dcf0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d8072dcf0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d8072dcf0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1d8072e890>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7f1d8072dcf0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:81: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
kornia.augmentation.auto.RandAugment
__________________________________________________________________________________ test_TrivialAugment[jax-s2s-False] __________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = transpiled_kornia.augmentation.auto.TrivialAugment()

kornia/augmentation/test_auto.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b171f0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b171f0>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b171f0>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b171f0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b171f0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b171f0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1d81b14ee0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b171f0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:67: NameError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = transpiled_kornia.augmentation.auto.TrivialAugment()

kornia/augmentation/test_auto.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b150f0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b150f0>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b150f0>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b150f0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b150f0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b150f0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f1d81b16740>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7f1d81b150f0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:67: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1339.05s (0:22:19) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py F                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_Quaternion[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Quaternion(target_framework, mode, backend_compile):
        print("kornia.geometry.quaternion.Quaternion")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledQuaternion = ivy.transpile(Quaternion, source="torch", target=target_framework)
    
        # test Quaternion.identity
    
        torch_q = Quaternion.identity(batch_size=4)
        transpiled_q = TranspiledQuaternion.identity(batch_size=4)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__add__
    
        torch_q1 = Quaternion.identity()
        torch_q2 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q3 = torch_q1 + torch_q2
        transpiled_q1 = TranspiledQuaternion.identity()
        transpiled_q2 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
        transpiled_q3 = transpiled_q1 + transpiled_q2
    
        orig_np = _nest_array_to_numpy(torch_q3.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q3.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__init__()
    
        torch_q = Quaternion(torch.tensor([[1., 0., 0., 0.], [0., 1., 0., 0.]]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([[1., 0., 0., 0.], [0., 1., 0., 0.]]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__neg__()
    
        torch_q = -Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = -TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__pow__()
    
        torch_q = Quaternion(torch.tensor([1., .5, 0., 0.])) ** 2
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., .5, 0., 0.]), target_framework)) ** 2
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__sub__()
    
        torch_q1 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q2 = Quaternion.identity()
        torch_q3 = torch_q1 - torch_q2
        transpiled_q1 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
        transpiled_q2 = TranspiledQuaternion.identity()
        transpiled_q3 = transpiled_q1 - transpiled_q2
    
        orig_np = _nest_array_to_numpy(torch_q3.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q3.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.coeffs
    
        torch_q = Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        torch_coeffs = _nest_array_to_numpy(torch_q.coeffs)
        transpiled_coeffs = _nest_array_to_numpy(transpiled_q.coeffs)
        _check_allclose(torch_coeffs, transpiled_coeffs)
    
    
        # test Quaternion.data
    
        torch_q = Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_axis_angle()
    
        torch_q = Quaternion.from_axis_angle(torch.tensor([[1., 0., 0.]]))
        transpiled_q = TranspiledQuaternion.from_axis_angle(_array_to_new_backend(torch.tensor([[1., 0., 0.]]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_coeffs()
    
        torch_q = Quaternion.from_coeffs(1., 0., 0., 0.)
        transpiled_q = TranspiledQuaternion.from_coeffs(1., 0., 0., 0.)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_euler()
    
        roll, pitch, yaw = torch.tensor(0), torch.tensor(1), torch.tensor(0)
        torch_q = Quaternion.from_euler(roll, pitch, yaw)
>       transpiled_q = TranspiledQuaternion.from_euler(
            _array_to_new_backend(roll, target_framework), _array_to_new_backend(pitch, target_framework), _array_to_new_backend(yaw, target_framework)
        )

kornia/geometry/test_quaternion.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.quaternion.tensorflow_Quaternion'>, roll = <tf.Tensor: shape=(), dtype=int64, numpy=0>
pitch = <tf.Tensor: shape=(), dtype=int64, numpy=1>, yaw = <tf.Tensor: shape=(), dtype=int64, numpy=0>

    @classmethod
    def from_euler(cls, roll, pitch, yaw):
        from ..core._backend import stack
        from .conversions import tensorflow_quaternion_from_euler
    
        w, x, y, z = tensorflow_quaternion_from_euler(roll=roll, pitch=pitch, yaw=yaw)
        q = stack((w, x, y, z), -1)
>       return cls(q)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/quaternion.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_Quaternion' object has no attribute '_data'") raised in repr()] tensorflow_Quaternion object at 0x7f33fc767a30>
data = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

    def __init__(self, data):
        self.super___init__(
            data,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self._data = tensorflow.keras.Variable(data)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/quaternion.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_16>, initializer = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>
shape = None, dtype = 'float32', trainable = True, autocast = True, aggregation = 'mean', name = 'variable_16'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_16>, value = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>)
kwargs = {'dtype': 'float32', 'name': 'variable_16', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.quaternion.Quaternion
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_quaternion.py::test_Quaternion[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: sh...
===================================================================================== 1 failed in 92.24s (0:01:32) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 2132.55s (0:35:32) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py FFFF.F                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_AugmentationSequential[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AugmentationSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.AugmentationSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug_list = kornia.augmentation.container.AugmentationSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.augmentation.RandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
        transpiled_aug_list = transpiled_kornia.augmentation.container.AugmentationSequential(
            transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
            torch.tensor([[
                [1., 1.],
                [2., 1.],
                [2., 2.],
                [1., 2.],
            ]]).expand(2, 1, -1, -1),
            torch.tensor([[[1., 1.]]]).expand(2, -1, -1),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.43204683, -0.6943697 ,  0.40185988, -0.44550905,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7efbc70c4840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.43204683, -0.6943697 ,  0.40185988, -0.44550905,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.43204683, -0.6943697 ,  0.40185988, -0.44550905,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (*args, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...e, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
),)
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.43204683, -0.6943697 ,  0.40185988, -0.445...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.43204683, -0.6943697 ,  0.40185988, -0.445...
         [ 0.3366284 ,  1.6070178 , -1.0630909 , -0.56622577,
           0.09397996,  0.10016043]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.43204683, -0.6943697 ,  0.40185988, -0.445...
         [ 0.3366284 ,  1.6070178 , -1.0630909 , -0.56622577,
           0.09397996,  0.10016043]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'args'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.AugmentationSequential
kornia.augmentation.container.AugmentationSequential
kornia.augmentation.container.AugmentationSequential
kornia.augmentation.container.AugmentationSequential
______________________________________________________________________ test_ManyToManyAugmentationDispather[tensorflow-s2s-False] ______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToManyAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToManyAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug_list = kornia.augmentation.container.ManyToManyAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = transpiled_kornia.augmentation.container.ManyToManyAugmentationDispather(
            transpiled_kornia.augmentation.container.AugmentationSequential(
                transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            transpiled_kornia.augmentation.container.AugmentationSequential(
                transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather()
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.6053469 , -0.6737468 ,  1.6839894 , -1.9824202 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55fd50e44550, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.605...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.6053469 , -0.6737468 ,  1.6839894 , -1.9824202 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.605...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.6053469 , -0.6737468 ,  1.6839894 , -1.9824202 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.6053469 , -0.6737468 ,  1.6839894 , -1.9824202 ,
  ...,
         [ 0.8668438 ,  0.5352708 , -0.10101916, -0.99808764,
           0.7113878 , -0.08612221]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(),)
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.6053469 , -0.6737468 ,  1.6839894 , -1.9...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.6053469 , -0.6737468 ,  1.6839894 , -1.9...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.6053469 , -0.6737468 ,  1.6839894 , -1.9...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToManyAugmentationDispather
kornia.augmentation.container.ManyToManyAugmentationDispather
kornia.augmentation.container.ManyToManyAugmentationDispather
kornia.augmentation.container.ManyToManyAugmentationDispather
kornia.augmentation.container.ManyToManyAugmentationDispather
______________________________________________________________________ test_ManyToOneAugmentationDispather[tensorflow-s2s-False] _______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToOneAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToOneAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug_list = kornia.augmentation.container.ManyToOneAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = transpiled_kornia.augmentation.container.ManyToOneAugmentationDispather(
            transpiled_kornia.augmentation.container.AugmentationSequential(
                transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            transpiled_kornia.augmentation.container.AugmentationSequential(
                transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather()
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.7245513 , -0.28193554,  0.46301252,  0.9238301 ,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55fd513cd690, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.72455...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.7245513 , -0.28193554,  0.46301252,  0.9238301 ,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.72455...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.7245513 , -0.28193554,  0.46301252,  0.9238301 ,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.7245513 , -0.28193554,  0.46301252,  0.9238301 ,
  ...,
         [ 0.2775238 , -1.1979246 ,  0.33440587,  0.029765  ,
           0.18886966, -0.39259735]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.7245513 , -0.28193554,  0.46301252,  0.92...
         [ 0.2775238 , -1.1979246 ,  0.33440587,  0.029765  ,
           0.18886966, -0.39259735]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.7245513 , -0.28193554,  0.46301252,  0.92...
         [ 0.2775238 , -1.1979246 ,  0.33440587,  0.029765  ,
           0.18886966, -0.39259735]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.7245513 , -0.28193554,  0.46301252,  0.92...
         [ 0.2775238 , -1.1979246 ,  0.33440587,  0.029765  ,
           0.18886966, -0.39259735]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToOneAugmentationDispather
kornia.augmentation.container.ManyToOneAugmentationDispather
kornia.augmentation.container.ManyToOneAugmentationDispather
kornia.augmentation.container.ManyToOneAugmentationDispather
kornia.augmentation.container.ManyToOneAugmentationDispather
______________________________________________________________________________ test_ImageSequential[tensorflow-s2s-False] ______________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
>       transpiled_aug_list = transpiled_kornia.augmentation.container.ImageSequential(
            transpiled_kornia.color.BgrToRgb(),
            transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            transpiled_kornia.filters.MedianBlur((3, 3)),
            transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
            transpiled_kornia.enhance.Invert(),
            transpiled_kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406ec0>, same_on_batch = True, keepdim = None, random_apply = 10
random_apply_weights = None

    def __init__(
        self,
        *args,
        same_on_batch=None,
        keepdim=None,
        random_apply=False,
        random_apply_weights=None,
        if_unsupported_ops="raise",
    ):
        from ....ivy.functional.frontends.torch.creation_ops import tensorflow_ones_frnt
        from ...core._backend import as_tensor
    
>       super().__init__(*args, same_on_batch=same_on_batch, keepdim=keepdim)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/image.py:50: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406ec0>
args = (tensorflow_BgrToRgb(), tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1...orners=False), tensorflow_Invert(), tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False))
kwargs = {'keepdim': None, 'same_on_batch': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406ec0>, same_on_batch = True, keepdim = None
args = (tensorflow_BgrToRgb(), tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1...orners=False), tensorflow_Invert(), tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False))

    @tensorflow_store_config_info
    def __init__(self, *args, same_on_batch=None, keepdim=None):
>       super().__init__(*args)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406ec0>
args = (tensorflow_BgrToRgb(), tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1...orners=False), tensorflow_Invert(), tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False))
kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406ec0>
args = (tensorflow_BgrToRgb(), tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1...orners=False), tensorflow_Invert(), tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False))
Module = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful.Layer'>, _args = OrderedDict(), idx = 0

    @tensorflow_store_config_info
    def __init__(self, *args):
        from ...core._backend import Module
    
        _args = OrderedDict()
        for idx, mod in enumerate(args):
            if not isinstance(mod, (Module,)):
>               raise NotImplementedError(
                    f"Only Module are supported at this moment. Got {mod}."
                )
E               NotImplementedError: Only Module are supported at this moment. Got tensorflow_BgrToRgb().

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:45: NotImplementedError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
>       transpiled_aug_list = transpiled_kornia.augmentation.container.ImageSequential(
            transpiled_kornia.color.BgrToRgb(),
            transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            transpiled_kornia.filters.MedianBlur((3, 3)),
            transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
            transpiled_kornia.enhance.Invert(),
            transpiled_kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406a10>, same_on_batch = True, keepdim = None, random_apply = 10
random_apply_weights = None

    def __init__(
        self,
        *args,
        same_on_batch=None,
        keepdim=None,
        random_apply=False,
        random_apply_weights=None,
        if_unsupported_ops="raise",
    ):
        from ....ivy.functional.frontends.torch.creation_ops import tensorflow_ones_frnt
        from ...core._backend import as_tensor
    
>       super().__init__(*args, same_on_batch=same_on_batch, keepdim=keepdim)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/image.py:50: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406a10>
args = (tensorflow_BgrToRgb(), tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1...orners=False), tensorflow_Invert(), tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False))
kwargs = {'keepdim': None, 'same_on_batch': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406a10>, same_on_batch = True, keepdim = None
args = (tensorflow_BgrToRgb(), tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1...orners=False), tensorflow_Invert(), tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False))

    @tensorflow_store_config_info
    def __init__(self, *args, same_on_batch=None, keepdim=None):
>       super().__init__(*args)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406a10>
args = (tensorflow_BgrToRgb(), tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1...orners=False), tensorflow_Invert(), tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False))
kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_ImageSequential object at 0x7efbc5406a10>
args = (tensorflow_BgrToRgb(), tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1...orners=False), tensorflow_Invert(), tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False))
Module = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful.Layer'>, _args = OrderedDict(), idx = 0

    @tensorflow_store_config_info
    def __init__(self, *args):
        from ...core._backend import Module
    
        _args = OrderedDict()
        for idx, mod in enumerate(args):
            if not isinstance(mod, (Module,)):
>               raise NotImplementedError(
                    f"Only Module are supported at this moment. Got {mod}."
                )
E               NotImplementedError: Only Module are supported at this moment. Got tensorflow_BgrToRgb().

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:45: NotImplementedError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
kornia.augmentation.container.ImageSequential
kornia.augmentation.container.ImageSequential
kornia.augmentation.container.ImageSequential
kornia.augmentation.container.ImageSequential
kornia.augmentation.container.ImageSequential
kornia.augmentation.container.ImageSequential
kornia.augmentation.container.ImageSequential
______________________________________________________________________________ test_VideoSequential[tensorflow-s2s-False] ______________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
>       transpiled_aug_list =  transpiled_kornia.augmentation.container.VideoSequential(
            transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            transpiled_kornia.color.BgrToRgb(),
            transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:271: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f052a0>, data_format = 'BCTHW', same_on_frame = True
random_apply = 10, random_apply_weights = None

    def __init__(
        self,
        *args,
        data_format="BTCHW",
        same_on_frame=True,
        random_apply=False,
        random_apply_weights=None,
    ):
>       super().__init__(
            *args,
            same_on_batch=None,
            keepdim=None,
            random_apply=random_apply,
            random_apply_weights=random_apply_weights,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/video.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f052a0>
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))
kwargs = {'keepdim': None, 'random_apply': 10, 'random_apply_weights': None, 'same_on_batch': None}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f052a0>, same_on_batch = None, keepdim = None, random_apply = 10
random_apply_weights = None

    @tensorflow_store_config_info
    def __init__(
        self,
        *args,
        same_on_batch=None,
        keepdim=None,
        random_apply=False,
        random_apply_weights=None,
        if_unsupported_ops="raise",
    ):
        from ....ivy.functional.frontends.torch.creation_ops import tensorflow_ones_frnt
        from ...core._backend import as_tensor
    
>       super().__init__(*args, same_on_batch=same_on_batch, keepdim=keepdim)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/image.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f052a0>
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))
kwargs = {'keepdim': None, 'same_on_batch': None}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f052a0>, same_on_batch = None, keepdim = None
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))

    @tensorflow_store_config_info
    def __init__(self, *args, same_on_batch=None, keepdim=None):
>       super().__init__(*args)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f052a0>
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))
kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f052a0>
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))
Module = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful.Layer'>
_args = OrderedDict([('tensorflow_ColorJiggle_0', tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False))]), idx = 1

    @tensorflow_store_config_info
    def __init__(self, *args):
        from ...core._backend import Module
    
        _args = OrderedDict()
        for idx, mod in enumerate(args):
            if not isinstance(mod, (Module,)):
>               raise NotImplementedError(
                    f"Only Module are supported at this moment. Got {mod}."
                )
E               NotImplementedError: Only Module are supported at this moment. Got tensorflow_BgrToRgb().

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:45: NotImplementedError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
>       transpiled_aug_list =  transpiled_kornia.augmentation.container.VideoSequential(
            transpiled_kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            transpiled_kornia.color.BgrToRgb(),
            transpiled_kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:271: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f06860>, data_format = 'BCTHW', same_on_frame = True
random_apply = 10, random_apply_weights = None

    def __init__(
        self,
        *args,
        data_format="BTCHW",
        same_on_frame=True,
        random_apply=False,
        random_apply_weights=None,
    ):
>       super().__init__(
            *args,
            same_on_batch=None,
            keepdim=None,
            random_apply=random_apply,
            random_apply_weights=random_apply_weights,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/video.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f06860>
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))
kwargs = {'keepdim': None, 'random_apply': 10, 'random_apply_weights': None, 'same_on_batch': None}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f06860>, same_on_batch = None, keepdim = None, random_apply = 10
random_apply_weights = None

    @tensorflow_store_config_info
    def __init__(
        self,
        *args,
        same_on_batch=None,
        keepdim=None,
        random_apply=False,
        random_apply_weights=None,
        if_unsupported_ops="raise",
    ):
        from ....ivy.functional.frontends.torch.creation_ops import tensorflow_ones_frnt
        from ...core._backend import as_tensor
    
>       super().__init__(*args, same_on_batch=same_on_batch, keepdim=keepdim)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/image.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f06860>
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))
kwargs = {'keepdim': None, 'same_on_batch': None}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f06860>, same_on_batch = None, keepdim = None
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))

    @tensorflow_store_config_info
    def __init__(self, *args, same_on_batch=None, keepdim=None):
>       super().__init__(*args)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f06860>
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))
kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_VideoSequential object at 0x7efbb8f06860>
args = (tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False...None, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False))
Module = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful.Layer'>
_args = OrderedDict([('tensorflow_ColorJiggle_0', tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=1.0, p_batch=1.0, same_on_batch=False))]), idx = 1

    @tensorflow_store_config_info
    def __init__(self, *args):
        from ...core._backend import Module
    
        _args = OrderedDict()
        for idx, mod in enumerate(args):
            if not isinstance(mod, (Module,)):
>               raise NotImplementedError(
                    f"Only Module are supported at this moment. Got {mod}."
                )
E               NotImplementedError: Only Module are supported at this moment. Got tensorflow_BgrToRgb().

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:45: NotImplementedError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
kornia.augmentation.container.VideoSequential
kornia.augmentation.container.VideoSequential
kornia.augmentation.container.VideoSequential
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_AugmentationSequential[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'args'
FAILED kornia/augmentation/test_container.py::test_ManyToManyAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ManyToOneAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ImageSequential[tensorflow-s2s-False] - NotImplementedError: Only Module are supported at this moment. Got tensorflow_BgrToRgb().
FAILED kornia/augmentation/test_container.py::test_VideoSequential[tensorflow-s2s-False] - NotImplementedError: Only Module are supported at this moment. Got tensorflow_BgrToRgb().
=============================================================================== 5 failed, 1 passed in 3099.18s (0:51:39) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py ssssssssss                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 10 skipped in 5.09s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_Boxes[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
        transpiled_boxes = transpiled_kornia.geometry.boxes.Boxes.from_tensor(*transpiled_args, mode="xyxy")
        _check_boxes_same(torch_boxes, transpiled_boxes)
    
        # test .compute_area
        torch_area = torch_boxes.compute_area()
        transpiled_area = transpiled_boxes.compute_area()
        _to_numpy_and_allclose(torch_area, transpiled_area)
    
        # test .get_boxes_shape
        torch_heights, torch_widths = torch_boxes.get_boxes_shape()
        transpiled_heights, transpiled_widths = transpiled_boxes.get_boxes_shape()
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .merge
        torch_x = torch.as_tensor([[6, 6, 10, 10], [6, 6, 10, 10]])
        transpiled_x = _nest_torch_tensor_to_new_framework(torch_x, target_framework)
        merge_boxes = kornia.geometry.boxes.Boxes.from_tensor(torch_x, mode="xyxy")
        transpiled_merge_boxes = transpiled_kornia.geometry.boxes.Boxes.from_tensor(transpiled_x, mode="xyxy")
        torch_merged_boxes = torch_boxes.merge(merge_boxes)
        transpiled_merged_boxes = transpiled_boxes.merge(transpiled_merge_boxes)
        _check_boxes_same(torch_merged_boxes, transpiled_merged_boxes)
    
        # test .to_mask
        height, width = 10, 10
        torch_mask = torch_boxes.to_mask(height, width)
        transpiled_mask = transpiled_boxes.to_mask(height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0....., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
_____________________________________________________________________________________ test_Boxes3D[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
        transpiled_boxes3d = transpiled_kornia.geometry.boxes.Boxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
        _check_boxes_same(torch_boxes3d, transpiled_boxes3d)
    
        # test .get_boxes_shape
        torch_depths, torch_heights, torch_widths = torch_boxes3d.get_boxes_shape()
        transpiled_depths, transpiled_heights, transpiled_widths = transpiled_boxes3d.get_boxes_shape()
        _to_numpy_and_allclose(torch_depths, transpiled_depths)
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .to_mask
        depth, height, width = 10, 10, 10
        torch_mask = torch_boxes3d.to_mask(depth, height, width)
        transpiled_mask = transpiled_boxes3d.to_mask(depth, height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0... [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
transpiled_x = Array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
y = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[jax-s2s-False] - AssertionError: numpy array values are not all close
==================================================================================== 2 failed in 208.64s (0:03:28) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF..F.............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_HausdorffERLoss[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = transpiled_kornia.losses.HausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.06810093e+00,  2.31660771e+00, ...        ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 1, 0, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f37bc191b70, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.0...        ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 1, 0, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.06810093e+00,  2.31660771e+00, ...        ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 1, 0, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.0...        ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 1, 0, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.06810093e+00,  2.31660771e+00, ...        ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 1, 0, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 1, 1]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.06810093e+00,  2.31660771e+00, ....06904e-01, -2.97431290e-01, ...,
          -1.28202760e+00, -8.37881386e-01,  8.27971101e-01]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.06810093e+00,  2.316607...        ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 1, 0, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 1, 1]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.06810093e+00,  2.31660771e+00, ....06904e-01, -2.97431290e-01, ...,
          -1.28202760e+00, -8.37881386e-01,  8.27971101e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 1, 1, ..., 0, 0, 1],
         [1, 0, 1, ..., 1, 0, ...         ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 1, 0, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 1, 1]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        if tensorflow_dim_frnt_(pred) != 4:
            raise ValueError(
                f"Only 2D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
        if not (
            tensorflow_max_frnt_(target) < tensorflow_size_frnt_(pred, 1)
            and tensorflow_min_frnt_(target) >= 0
            and target.dtype == tf.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {tensorflow_size_frnt_(pred, 1)}). ({tensorflow_min_frnt_(target)}, {tensorflow_max_frnt_(target)})"
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:289: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.06810093e+00,  2.31660771e+00, ....06904e-01, -2.97431290e-01, ...,
          -1.28202760e+00, -8.37881386e-01,  8.27971101e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 1, 1, ..., 0, 0, 1],
         [1, 0, 1, ..., 1, 0, ...         ...,
         [1, 1, 0, ..., 1, 1, 0],
         [1, 1, 0, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 1, 1]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f37ccc918f0>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 1, 20, 20), dtype=float32, numpy=
array([[[[-1.01259792e+00,  1.06810093e+00,  2.31660771e+00, ....54072e-01, -8.67311716e-01, ...,
           6.12801552e-01,  2.54673690e-01, -2.03933507e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[0, 0, 0, ..., 1, 1, 0],
         [0, 1, 0, ..., 0, 1, ...         ...,
         [0, 0, 1, ..., 0, 0, 1],
         [0, 0, 1, ..., 1, 0, 1],
         [0, 0, 0, ..., 1, 0, 0]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
E           
E           [1mtensorflow_conv2d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss.call():
E             • pred=tf.Tensor(shape=(5, 3, 20, 20), dtype=float32)
E             • target=tf.Tensor(shape=(5, 1, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
kornia.losses.HausdorffERLoss
_____________________________________________________________________________ test_HausdorffERLoss3D[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = transpiled_kornia.losses.HausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-01,  7.00158715e-01,  4.74523455e...    ...,
          [1, 0, 1, ..., 1, 1, 0],
          [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x56038780c6d0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-0...    ...,
          [1, 0, 1, ..., 1, 1, 0],
          [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-01,  7.00158715e-01,  4.74523455e...    ...,
          [1, 0, 1, ..., 1, 1, 0],
          [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-0...    ...,
          [1, 0, 1, ..., 1, 1, 0],
          [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-01,  7.00158715e-01,  4.74523455e...    ...,
          [1, 0, 1, ..., 1, 1, 0],
          [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-01,  7.00158715e-01,  4.74523455e-...765e-01,  1.33482254e+00, ...,
            9.77963746e-01,  5.12882650e-01,  1.52520251e+00]]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-01,  7.00158715e-01,  4.7...    ...,
          [1, 0, 1, ..., 1, 1, 0],
          [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-01,  7.00158715e-01,  4.74523455e-...765e-01,  1.33482254e+00, ...,
            9.77963746e-01,  5.12882650e-01,  1.52520251e+00]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 1, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., ...     ...,
          [1, 0, 1, ..., 1, 1, 0],
          [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
    
        if tensorflow_dim_frnt_(pred) != 5:
            raise ValueError(
                f"Only 3D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:280: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-01,  7.00158715e-01,  4.74523455e-...765e-01,  1.33482254e+00, ...,
            9.77963746e-01,  5.12882650e-01,  1.52520251e+00]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 1, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., ...     ...,
          [1, 0, 1, ..., 1, 1, 0],
          [0, 0, 0, ..., 0, 0, 0],
          [1, 0, 1, ..., 1, 1, 1]]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f37cc2c5890>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=float32, numpy=
array([[[[[-4.66363907e-01,  7.00158715e-01,  4.74523455e-...277e-01,  1.49890912e+00, ...,
           -3.43435943e-01, -1.99525535e+00,  8.85976017e-01]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[1, 0, 1, ..., 1, 1, 1],
          [1, 1, 0, ..., ...     ...,
          [0, 1, 0, ..., 0, 0, 1],
          [1, 1, 1, ..., 1, 1, 1],
          [0, 1, 0, ..., 0, 0, 0]]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
E           
E           [1mtensorflow_conv3d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss3D.call():
E             • pred=tf.Tensor(shape=(5, 3, 20, 20, 20), dtype=float32)
E             • target=tf.Tensor(shape=(5, 1, 20, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
kornia.losses.HausdorffERLoss3D
________________________________________________________________________________ test_MS_SSIMLoss[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MS_SSIMLoss(target_framework, mode, backend_compile):
        print("kornia.losses.MS_SSIMLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_loss_fn = kornia.losses.MS_SSIMLoss()
        transpiled_loss_fn = transpiled_kornia.losses.MS_SSIMLoss()
    
        torch_args = (
            torch.rand(1, 3, 5, 5),
            torch.rand(1, 3, 5, 5),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:546: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
     ...98738426, 0.96772504],
         [0.78137285, 0.54828477, 0.4968087 , 0.59947723, 0.9008075 ]]]],
      dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5603879d4190, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e...98738426, 0.96772504],
         [0.78137285, 0.54828477, 0.4968087 , 0.59947723, 0.9008075 ]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
     ...98738426, 0.96772504],
         [0.78137285, 0.54828477, 0.4968087 , 0.59947723, 0.9008075 ]]]],
      dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e...98738426, 0.96772504],
         [0.78137285, 0.54828477, 0.4968087 , 0.59947723, 0.9008075 ]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
     ...98738426, 0.96772504],
         [0.78137285, 0.54828477, 0.4968087 , 0.59947723, 0.9008075 ]]]],
      dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
      ...         [9.53505635e-02, 9.96536195e-01, 7.31110573e-04,
          3.17522168e-01, 8.89976978e-01]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img1, img2)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(),)
kwargs = {'img1': <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-0...98738426, 0.96772504],
         [0.78137285, 0.54828477, 0.4968087 , 0.59947723, 0.9008075 ]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
img1 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
      ...         [9.53505635e-02, 9.96536195e-01, 7.31110573e-04,
          3.17522168e-01, 8.89976978e-01]]]], dtype=float32)>
img2 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.36907655, 0.6989273 , 0.07325655, 0.04938978, 0.7999....98738426, 0.96772504],
         [0.78137285, 0.54828477, 0.4968087 , 0.59947723, 0.9008075 ]]]],
      dtype=float32)>

    def call(self, img1, img2):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.jit._jit_internal import (
            tensorflow_annotate_frnt,
        )
        from ...ivy.functional.frontends.torch.nn.functional.convolution_functions import (
            tensorflow_conv2d_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_prod_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.loss_functions import (
            tensorflow_l1_loss_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
    
        if not isinstance(img1, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a torch.Tensor. Got {type(img1)}")
        if not isinstance(img2, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Output type is not a torch.Tensor. Got {type(img2)}")
        if not len(tensorflow_shape_frnt_(img1)) == len(tensorflow_shape_frnt_(img2)):
            raise ValueError(
                f"Input shapes should be same. Got {type(img1)} and {type(img2)}."
            )
        g_masks: typing.Any = tensorflow_annotate_frnt(tensorflow.Tensor, self._g_masks)
        CH: typing.Any = tensorflow_shape_frnt_(img1)[-3]
>       mux = tensorflow_conv2d_frnt(img1, g_masks, groups=CH, padding=self.pad)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/ms_ssim.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
      ...         [9.53505635e-02, 9.96536195e-01, 7.31110573e-04,
          3.17522168e-01, 8.89976978e-01]]]], dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = 16, dilation = 1, groups = 3

    def tensorflow_conv2d_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
>       return tensorflow__conv_frnt(
            input,
            weight,
            bias=bias,
            stride=stride,
            padding=padding,
            dilation=dilation,
            groups=groups,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
      ...         [9.53505635e-02, 9.96536195e-01, 7.31110573e-04,
          3.17522168e-01, 8.89976978e-01]]]], dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = [(16, 16), (16, 16)], dilation = 1, groups = 3

    def tensorflow__conv_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
        from ...tensor import tensorflow_shape_frnt_
        from .....backends.tensorflow.layers import tensorflow_conv_general_dilated
    
        dims = len(tensorflow_shape_frnt_(input)) - 2
        if isinstance(padding, (str,)):
            padding = padding.upper()
        elif isinstance(padding, (int,)):
            padding = [*[(padding, padding) for _ in range(dims)]]
        else:
            padding = [*[(p, p) for p in padding]]
>       ret = tensorflow_conv_general_dilated(
            input,
            weight,
            stride,
            padding,
            dims=dims,
            data_format="channel_last",
            filter_format="channel_last",
            dilations=dilation,
            feature_group_count=groups,
            bias=bias,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
     ....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'bias': None, 'data_format': 'channel_last', 'dilations': 1, 'dims': 2, ...}, tensorflow_set_item = <function tensorflow_set_item at 0x7f37add8a950>
tensorflow_get_item = <function tensorflow_get_item at 0x7f37add8a7a0>, DATA_FORMAT = 'channels_last'

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
     ....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)]]
kwargs = {'bias': None, 'data_format': 'channel_last', 'dilations': 1, 'dims': 2, ...}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f37add88550>
tensorflow_set_item = <function tensorflow_set_item at 0x7f37add8a950>, tensorflow_asarray = <function tensorflow_asarray at 0x7f37add891b0>
tensorflow_get_item = <function tensorflow_get_item at 0x7f37add8a7a0>, num_args = 4
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'filters', 'strides', 'padding', 'dims', 'data_format', ...]
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[tenso...le[int, int, int]], typing.Union[str, int, typing.Sequence[typing.Tuple[int, int]]], <class 'int'>, <class 'str'>, ...]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 3

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[2.46956110e-01, 1.46817863e-01, 9.98160422e-01,
      ...         [9.53505635e-02, 9.96536195e-01, 7.31110573e-04,
          3.17522168e-01, 8.89976978e-01]]]], dtype=float32)>
filters = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
strides = 1, padding = [(16, 16), (16, 16)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    @tensorflow_handle_array_like_without_promotion
    def tensorflow_conv_general_dilated(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        dims: int = 2,
        data_format: str = "channel_last",
        filter_format: str = "channel_last",
        feature_group_count: int = 1,
        x_dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        bias: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
        from ...ivy.layers import tensorflow__get_x_data_format_bknd
    
        if filter_format == "channel_first":
            filters = tensorflow.transpose(filters, (*range(2, dims + 2), 1, 0))
        num_channels = x.shape[1] if data_format == "channel_first" else x.shape[-1]
        if filters.shape[-2] != num_channels // feature_group_count:
>           raise Exception(
                f"given feature_group_count {feature_group_count} expected input channel of the filter to be {num_channels // feature_group_count} but got {filters.shape[-2]}"
            )
E           Exception: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
E           
E           [1mgiven feature_group_count 3 expected input channel of the filter to be 1 but got 33[0m
E           
E           Arguments received by tensorflow_MS_SSIMLoss.call():
E             • img1=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)
E             • img2=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:170: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.MS_SSIMLoss
kornia.losses.MS_SSIMLoss
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
FAILED kornia/test_losses.py::test_MS_SSIMLoss[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
============================================================================== 3 failed, 32 passed in 2407.22s (0:40:07) ===============================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ........F....FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomResizedCrop[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomResizedCrop(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomResizedCrop")
    
        init_args = ()
        init_kwargs = {"size": (3, 3), "scale": (3., 3.), "ratio": (2., 2.), "p": 1., "cropping_mode": "resample"}
        call_args = (torch.tensor([[[0., 1., 2.],
                                    [3., 4., 5.],
                                    [6., 7., 8.]]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomResizedCrop,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resized_crop.RandomResizedCrop'>, target = 'tensorflow', init_args = ()
init_kwargs = {'cropping_mode': 'resample', 'p': 1.0, 'ratio': (2.0, 2.0), 'scale': (3.0, 3.0), ...}, call_args = (tensor([[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff0e951d640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, replace_v = False, replace_buffers = False
call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
input = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, params = None, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7ff0dc1b4040>, tensorflow_set_item = <function tensorflow_set_item at 0x7ff0eeec5b40>
tensor = <function tensorflow_tensor_frnt at 0x7ff0eed6e440>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3), dtype=float32, numpy=
array([[[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = (1, 1, 3, 3)

    def generate_parameters(self, batch_shape):
        if self._param_generator is not None:
>           return self._param_generator(batch_shape, self.same_on_batch)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), args = ((1, 1, 3, 3), False), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff0e9572240, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}, replace_v = False, replace_buffers = False
call_signature = <Signature (batch_shape, same_on_batch=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), batch_shape = (1, 1, 3, 3), same_on_batch = False

    def call(self, batch_shape, same_on_batch=False):
        from ....utils.helpers import tensorflow__extract_device_dtype
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...utils.helpers import tensorflow__adapted_rsampling
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_exp_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_floor_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_round_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_sqrt_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_cumsum_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_bool_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_arange_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_round_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_where_frnt_
        from .....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ....core._backend import tensor
        from ....core._backend import zeros
    
        batch_size = batch_shape[0]
        size = batch_shape[-2], batch_shape[-1]
        _device, _dtype = tensorflow__extract_device_dtype([self.scale, self.ratio])
        if batch_size == 0:
            return {
                "src": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "dst": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "size": zeros([0, 2], device=_device, dtype=_dtype),
            }
        rand = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.rand_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        area = (
            (rand * (self.scale[1] - self.scale[0]) + self.scale[0]) * size[0] * size[1]
        )
        log_ratio = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.log_ratio_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        aspect_ratio = tensorflow_exp_frnt(log_ratio)
        w = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area * aspect_ratio))
        )
        h = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area / aspect_ratio))
        )
>       cond = tensorflow_int_frnt_((0 < w) * (w < size[0]) * (0 < h) * (h < size[1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/random_generator/_2d/crop.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
rhs = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
x2 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ResizedCropGenerator.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ResizedCropGenerator.call():
E         • batch_shape=('1', '1', '3', '3')
E         • same_on_batch=False

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:353: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomResizedCrop
______________________________________________________________________________ test_RandomCutMixV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:355: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.6574, 0.4229, 0.8555],
          [0.8061, 0.0557, 0.8465],
          [0.9894, 0.6855, 0.1088]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
>       transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)

kornia/augmentation/test_augmentation3.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:312: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eea201c0>, node = <gast.gast.Module object at 0x7ff0dc53c6a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eea201c0>, node = <gast.gast.Module object at 0x7ff0dc53c6a0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eea201c0>, node = <gast.gast.ClassDef object at 0x7ff0dc53d960>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eea201c0>, node = <gast.gast.FunctionDef object at 0x7ff0dc53f2e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eea201c0>, node = <gast.gast.AnnAssign object at 0x7ff0e7fe1930>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eea201c0>, node = <gast.gast.Call object at 0x7ff0e8134a60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eea201c0>, node = <gast.gast.Call object at 0x7ff0e8134a60>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eea201c0>, node = <gast.gast.Attribute object at 0x7ff0e8135630>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.Module object at 0x7ff0e85c7610>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.Module object at 0x7ff0e85c7610>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.ClassDef object at 0x7ff0e85c5450>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.FunctionDef object at 0x7ff0dcf20970>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.Assign object at 0x7ff0e7ae7280>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.Assign object at 0x7ff0e7ae7280>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.Call object at 0x7ff0e7ae4490>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.Call object at 0x7ff0e7ae4490>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7f0a0>, node = <gast.gast.Attribute object at 0x7ff0e7ff4550>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.Module object at 0x7ff0c8b8df30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.Module object at 0x7ff0c8b8df30>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.ClassDef object at 0x7ff0c8b8e0b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.FunctionDef object at 0x7ff0c8b8c910>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.Assign object at 0x7ff0c8b8dbd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.Assign object at 0x7ff0c8b8dbd0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.Call object at 0x7ff0c8b8e1a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.Call object at 0x7ff0c8b8e1a0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7a735b0>, node = <gast.gast.Attribute object at 0x7ff0eeda13c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Module object at 0x7ff0e7b49f00>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Module object at 0x7ff0e7b49f00>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.ClassDef object at 0x7ff0e7b48a90>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.FunctionDef object at 0x7ff0e857e1a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Return object at 0x7ff0dceed990>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Return object at 0x7ff0dceed990>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Call object at 0x7ff0dceee7d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Call object at 0x7ff0dceee7d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Attribute object at 0x7ff0dceef0a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Attribute object at 0x7ff0dceef0a0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eeb95810>, node = <gast.gast.Name object at 0x7ff0dceefe80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7c3d0>, node = <gast.gast.Module object at 0x7ff0dc476f80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7c3d0>, node = <gast.gast.Module object at 0x7ff0dc476f80>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0e7c7c3d0>, node = <gast.gast.ClassDef object at 0x7ff0dc475150>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0ee8ba2f0>, node = <gast.gast.Module object at 0x7ff0dc469b40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0ee8ba2f0>, node = <gast.gast.Module object at 0x7ff0dc469b40>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0ee8ba2f0>, node = <gast.gast.ClassDef object at 0x7ff0dc46bf40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eed8ff70>, node = <gast.gast.Module object at 0x7ff0dc3f93c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eed8ff70>, node = <gast.gast.Module object at 0x7ff0dc3f93c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff0eed8ff70>, node = <gast.gast.ClassDef object at 0x7ff0dc3fac20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IM.pyx:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
_______________________________________________________________________________ test_RandomJigsaw[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'tensorflow', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[ 1.3434e+00,  1.1797e-01, -1.6699e+00,  ...,  7.8067e-01,
            1.8692e+00, -6.9657e-01],
          ...4e-01],
          [-9.1148e-01, -1.4375e+00, -4.1832e-01,  ..., -1.3415e+00,
           -2.6400e-01,  2.2064e-01]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4))
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 1.34340382e+00,  1.17966123e-01, -1.66985595e+00...620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff0ea289c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...0620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 1.34340382e+00,  1.17966123e-01, -1.66985595e+00...620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...0620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 1.34340382e+00,  1.17966123e-01, -1.66985595e+00...620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 1.34340382e+00,  1.17966123e-01, -1.66985595e+00,...50620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 1.34340382e+00,  1.17966123e-01, -1.669...0620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 1.34340382e+00,  1.17966123e-01, -1.669...0620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[ 1.34340382e+00,  1.17966123e-01, -1.669...0620e+00, -4.18324500e-01, ...,
          -1.34152067e+00, -2.64000326e-01,  2.20638260e-01]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
_______________________________________________________________________________ test_RandomMixUpV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:395: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.5598, 0.3041, 0.0042],
          [0.9272, 0.9440, 0.5063],
          [0.1456, 0.3660, 0.0355]]],


        [[[0.3773, 0.7638, 0.4894],
          [0.0036, 0.6812, 0.3115],
          [0.8744, 0.1993, 0.2479]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5597855 , 0.3041398 , 0.00417769],
         [0.9271...   [0.8744003 , 0.199292  , 0.24790913]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x560c9843f390, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.8744003 , 0.199292  , 0.24790913]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5597855 , 0.3041398 , 0.00417769],
         [0.9271...   [0.8744003 , 0.199292  , 0.24790913]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.8744003 , 0.199292  , 0.24790913]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5597855 , 0.3041398 , 0.00417769],
         [0.9271...   [0.8744003 , 0.199292  , 0.24790913]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5597855 , 0.3041398 , 0.00417769],
         [0.92716...1278],
         [0.00356919, 0.6811737 , 0.31150246],
         [0.8744003 , 0.199292  , 0.24790913]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5597855 , 0.3041398 , 0.00417769],
       ...003 , 0.199292  , 0.24790913]]]], dtype=float32)>, 'params': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5597855 , 0.3041398 , 0.00417769],
       ...278],
         [0.00356919, 0.6811737 , 0.31150246],
         [0.8744003 , 0.199292  , 0.24790913]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.5597855 , 0.3041398 , 0.00417769],
       ...278],
         [0.00356919, 0.6811737 , 0.31150246],
         [0.8744003 , 0.199292  , 0.24790913]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomResizedCrop[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling ten...
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[tensorflow-s2s-False] - OSError: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
============================================================================== 4 failed, 12 passed in 3354.32s (0:55:54) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py .............FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_RandomCutMixV2[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:355: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.1258, 0.2044, 0.1378],
          [0.6369, 0.5683, 0.9477],
          [0.2238, 0.4766, 0.0185]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
>       transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)

kornia/augmentation/test_augmentation3.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:312: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bbfc5d50>, node = <gast.gast.Module object at 0x7fb87dba8700>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bbfc5d50>, node = <gast.gast.Module object at 0x7fb87dba8700>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bbfc5d50>, node = <gast.gast.ClassDef object at 0x7fb87dba9660>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bbfc5d50>, node = <gast.gast.FunctionDef object at 0x7fb87dbaa140>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bbfc5d50>, node = <gast.gast.AnnAssign object at 0x7fb890a298d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bbfc5d50>, node = <gast.gast.Call object at 0x7fb890a2bcd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bbfc5d50>, node = <gast.gast.Call object at 0x7fb890a2bcd0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bbfc5d50>, node = <gast.gast.Attribute object at 0x7fb890a2ac20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.Module object at 0x7fb8907842b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.Module object at 0x7fb8907842b0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.ClassDef object at 0x7fb8907842e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.FunctionDef object at 0x7fb87c9d46d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.Assign object at 0x7fb8b0d72c20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.Assign object at 0x7fb8b0d72c20>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.Call object at 0x7fb8b0d72260>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.Call object at 0x7fb8b0d72260>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b0062920>, node = <gast.gast.Attribute object at 0x7fb8bcbd4b20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.Module object at 0x7fb8bb776e60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.Module object at 0x7fb8bb776e60>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.ClassDef object at 0x7fb8bb777370>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.FunctionDef object at 0x7fb87dd77e50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.Assign object at 0x7fb87dd75e40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.Assign object at 0x7fb87dd75e40>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.Call object at 0x7fb87dd774f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.Call object at 0x7fb87dd774f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8b081b5b0>, node = <gast.gast.Attribute object at 0x7fb8b0062410>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Module object at 0x7fb8908478b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Module object at 0x7fb8908478b0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.ClassDef object at 0x7fb890845000>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.FunctionDef object at 0x7fb8908475b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Return object at 0x7fb87dd75120>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Return object at 0x7fb87dd75120>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Call object at 0x7fb87dd770d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Call object at 0x7fb87dd770d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Attribute object at 0x7fb87dd74580>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Attribute object at 0x7fb87dd74580>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd8b10f0>, node = <gast.gast.Name object at 0x7fb87dd74850>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb87c9d4fd0>, node = <gast.gast.Module object at 0x7fb8bdd060e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb87c9d4fd0>, node = <gast.gast.Module object at 0x7fb8bdd060e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb87c9d4fd0>, node = <gast.gast.ClassDef object at 0x7fb8bdd06b60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb87dead810>, node = <gast.gast.Module object at 0x7fb890ac5840>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb87dead810>, node = <gast.gast.Module object at 0x7fb890ac5840>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb87dead810>, node = <gast.gast.ClassDef object at 0x7fb890ac4ac0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd396320>, node = <gast.gast.Module object at 0x7fb8b0058310>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd396320>, node = <gast.gast.Module object at 0x7fb8b0058310>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fb8bd396320>, node = <gast.gast.ClassDef object at 0x7fb87deaf730>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IM.pyx:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
___________________________________________________________________________________ test_RandomJigsaw[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'jax', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[ 1.3102e+00,  3.5081e-02, -1.0496e+00,  ..., -1.2684e+00,
            5.1214e-01,  5.1065e-01],
          ...2e-01],
          [-3.1436e-01,  3.9929e-01, -1.0291e+00,  ...,  5.0915e-01,
           -1.4606e+00, -1.0037e+00]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), params = None, data_keys = None
input = (Array([[[[ 1.31022680e+00,  3.50812599e-02, -1.04955006e+00, ...,
          -1.26838303e+00,  5.12137175e-01,  5.1064...85972e-01, -1.02909505e+00, ...,
           5.09146214e-01, -1.46057332e+00, -1.00366497e+00]]]],      dtype=float32),)
tensor = <function jax_tensor_frnt at 0x7fb8b05281f0>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
__________________________________________________________________________________ test_RandomMixUpV2[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:395: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.8851, 0.7648, 0.9436],
          [0.9625, 0.0964, 0.9060],
          [0.2512, 0.3025, 0.7279]]],


        [[[0.9031, 0.5734, 0.9466],
          [0.3171, 0.7380, 0.3270],
          [0.9668, 0.3669, 0.4303]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), params = None, data_keys = None
input = (Array([[[[0.8851225 , 0.76476544, 0.9436168 ],
         [0.96250457, 0.09642231, 0.9059732 ],
         [0.25123417, 0... 0.73799974, 0.3269502 ],
         [0.96677667, 0.366862  , 0.4302715 ]]]], dtype=float32), Array([0, 1], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7fb890d2d120>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[jax-s2s-False] - OSError: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[jax-s2s-False] - KeyError: '2'
============================================================================== 3 failed, 13 passed in 3346.71s (0:55:46) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F............                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_upscale_double[jax-s2s-False] __________________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7fd79b4215a0>
trace_args = (tensor([[[[0.6458, 0.1170, 0.7584, 0.4119],
          [0.9383, 0.5216, 0.8275, 0.5858],
          [0.0200, 0.1974, 0...., 0.0575, 0.5033, 0.6767],
          [0.6389, 0.6624, 0.0271, 0.7746],
          [0.1104, 0.6669, 0.0387, 0.5603]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[1.9856e-01, 7.2032e-01, 8.5234e-01, 6.3490e-01, 9.9221e-01,
           6.4155e-01, 2.5335e-01, 1.4057e-01]...      [5.9579e-01, 9.5898e-01, 1.5823e-01, 2.1427e-01, 1.9712e-02,
           8.1928e-01, 7.1737e-01, 4.5749e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7fd79b4215a0>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.6458, 0.1170, 0.7584, 0.4119],
          [0.9383, 0.5216, 0.8275, 0.5858],
          [0.0200, 0.1974, 0...., 0.0575, 0.5033, 0.6767],
          [0.6389, 0.6624, 0.0271, 0.7746],
          [0.1104, 0.6669, 0.0387, 0.5603]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[1.9856e-01, 7.2032e-01, 8.5234e-01, 6.3490e-01, 9.9221e-01,
           6.4155e-01, 2.5335e-01, 1.4057e-01]...      [5.9579e-01, 9.5898e-01, 1.5823e-01, 2.1427e-01, 1.9712e-02,
           8.1928e-01, 7.1737e-01, 4.5749e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.6458    , 0.11696231, 0.75844604, 0.4118598 ],
         [0.9383411 , 0.5215692 , 0.82749826, 0.5858268 ],
... 0.6623852 , 0.02707154, 0.77461505],
         [0.1103766 , 0.6669484 , 0.03867233, 0.5602851 ]]]],      dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.6458    , 0.        , 0.11696231, 0.        , 0.75844604,
          0.        , 0.4118598 , 0.        ],
 ...     , 0.        , 0.        , 0.        , 0.        ,
          0.        , 0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.38138115, 0.43770418, 0.5851529 , 0.        ],
         [0.72995514, 0.6745337 , 0.70666254, 0.        ],
... 0.34472838, 0.4008433 , 0.        ],
         [0.3886625 , 0.35281035, 0.2994787 , 0.        ]]]],      dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("JAX arrays are immutable and do not support in-place item assignment."
             " Instead of x[idx] = y, use x = x.at[idx].set(y) or another .at[] method:"
             " https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: JAX arrays are immutable and do not support in-place item assignment. Instead of x[idx] = y, use x = x.at[idx].set(y) or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:586: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
______________________________________________________________________________________ test_Shear[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = transpiled_kornia.geometry.transform.Shear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Shear()
input = Array([[[[0.46734494, 0.7721855 , 0.05148274, 0.8004765 ],
         [0.46383905, 0.7695084 , 0.7917115 , 0.9558119 ],
... 0.2302919 , 0.43642217, 0.9639169 ],
         [0.21074569, 0.59578   , 0.8478014 , 0.756724  ]]]],      dtype=float32)

    def __call__(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: name 'shear' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/affwarp.py:52: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
kornia.geometry.transform.Shear
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[jax-s2s-False] - TypeError: JAX arrays are immutable and do not support in-place item assignment. Instead of x[idx] = y, use x = x.at[i...
FAILED kornia/geometry/test_transform.py::test_Shear[jax-s2s-False] - NameError: name 'shear' is not defined
============================================================================== 2 failed, 54 passed in 5198.09s (1:26:38) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ..                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 147.28s (0:02:27) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py FFFF.F.F                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_find_homography_dlt[numpy-s2s-False] _______________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4), 'solver': 'svd'}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4), 'solver': 'svd'}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7fac18abb370>
trace_args = (tensor([[[0.1311, 0.1437],
         [0.5080, 0.1875],
         [0.3778, 0.1330],
         [0.1480, 0.6080]]]), tensor([[[0.8224, 0.2405],
         [0.3451, 0.4481],
         [0.1339, 0.4231],
         [0.1502, 0.1503]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.2083, 0.9184, 0.5024, 0.7059]])}
test_args = (tensor([[[0.2661, 0.4629],
         [0.8446, 0.1900],
         [0.9151, 0.1008],
         [0.4920, 0.8342]],

       ...8978]],

        [[0.5373, 0.8719],
         [0.4675, 0.1881],
         [0.2867, 0.6358],
         [0.8254, 0.6926]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[5.4077e-01, 7.3181e-01, 9.3461e-01, 9.4340e-01],
        [1.9211e-04, 7.9433e-01...,
        [7.1070e-01, 5.9544e-01, 1.2434e-01, 7.3923e-01],
        [6.1915e-02, 7.0304e-01, 5.6637e-02, 6.7638e-01]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7fac18abb370>, fn_name = 'kornia.geometry.homography.find_homography_dlt'
trace_args = (tensor([[[0.1311, 0.1437],
         [0.5080, 0.1875],
         [0.3778, 0.1330],
         [0.1480, 0.6080]]]), tensor([[[0.8224, 0.2405],
         [0.3451, 0.4481],
         [0.1339, 0.4231],
         [0.1502, 0.1503]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.2083, 0.9184, 0.5024, 0.7059]])}
test_args = (tensor([[[0.2661, 0.4629],
         [0.8446, 0.1900],
         [0.9151, 0.1008],
         [0.4920, 0.8342]],

       ...8978]],

        [[0.5373, 0.8719],
         [0.4675, 0.1881],
         [0.2867, 0.6358],
         [0.8254, 0.6926]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[5.4077e-01, 7.3181e-01, 9.3461e-01, 9.4340e-01],
        [1.9211e-04, 7.9433e-01...,
        [7.1070e-01, 5.9544e-01, 1.2434e-01, 7.3923e-01],
        [6.1915e-02, 7.0304e-01, 5.6637e-02, 6.7638e-01]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.1310885 , 0.14369845],
        [0.5079516 , 0.18750346],
        [0.37775815, 0.13296586],
        [0.1480267 , 0.60804206]]], dtype=float32)
points2 = array([[[0.8223901 , 0.24054766],
        [0.345101  , 0.44814354],
        [0.13386804, 0.423065  ],
        [0.1501677 , 0.15029305]]], dtype=float32)
weights = array([[0.2083453, 0.9183966, 0.5023576, 0.7059352]], dtype=float32), solver = 'svd'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.2083453, 0.2083453, 0.9183966, 0.9183966, 0.5023576,
         0.5023576, 0.7059352, 0.7059352]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
__________________________________________________________________________ test_find_homography_dlt_iterated[numpy-s2s-False] __________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7fac18abb490>
trace_args = (tensor([[[0.7680, 0.6742],
         [0.4077, 0.6990],
         [0.0820, 0.7992],
         [0.8299, 0.9107]]]), tensor... [0.1115, 0.4434],
         [0.0585, 0.3333],
         [0.3127, 0.0282]]]), tensor([[0.6454, 0.8767, 0.4820, 0.8430]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.8765, 0.5520],
         [0.0264, 0.8461],
         [0.1615, 0.2807],
         [0.8694, 0.3469]],

       ...[0.3762, 0.1072, 0.9990, 0.9424],
        [0.2035, 0.8299, 0.8159, 0.5588],
        [0.3301, 0.0977, 0.3899, 0.8183]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7fac18abb490>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.7680, 0.6742],
         [0.4077, 0.6990],
         [0.0820, 0.7992],
         [0.8299, 0.9107]]]), tensor... [0.1115, 0.4434],
         [0.0585, 0.3333],
         [0.3127, 0.0282]]]), tensor([[0.6454, 0.8767, 0.4820, 0.8430]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.8765, 0.5520],
         [0.0264, 0.8461],
         [0.1615, 0.2807],
         [0.8694, 0.3469]],

       ...[0.3762, 0.1072, 0.9990, 0.9424],
        [0.2035, 0.8299, 0.8159, 0.5588],
        [0.3301, 0.0977, 0.3899, 0.8183]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7679844 , 0.67415386],
        [0.40768027, 0.69897157],
        [0.081967  , 0.7991569 ],
        [0.82993805, 0.9107145 ]]], dtype=float32)
points2 = array([[[0.17820632, 0.7991602 ],
        [0.11149597, 0.44336766],
        [0.0584541 , 0.33330327],
        [0.31267607, 0.02821559]]], dtype=float32)
weights = array([[0.64537644, 0.87669176, 0.4820153 , 0.8429868 ]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def numpy_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:183: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7679844 , 0.67415386],
        [0.40768027, 0.69897157],
        [0.081967  , 0.7991569 ],
        [0.82993805, 0.9107145 ]]], dtype=float32)
points2 = array([[[0.17820632, 0.7991602 ],
        [0.11149597, 0.44336766],
        [0.0584541 , 0.33330327],
        [0.31267607, 0.02821559]]], dtype=float32)
weights = array([[0.64537644, 0.87669176, 0.4820153 , 0.8429868 ]], dtype=float32), solver = 'lu'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.64537644, 0.64537644, 0.87669176, 0.87669176, 0.4820153 ,
         0.4820153 , 0.8429868 , 0.8429868 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
___________________________________________________________________________ test_find_homography_lines_dlt[numpy-s2s-False] ____________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4)}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4)}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7fac18abb5b0>
trace_args = (tensor([[[[6.2477e-01, 4.5034e-01],
          [3.8370e-01, 6.6941e-02]],

         [[3.4022e-01, 9.4814e-01],
       ...

         [[0.0767, 0.7677],
          [0.6592, 0.9350]],

         [[0.5278, 0.5992],
          [0.4692, 0.5186]]]]))
trace_kwargs = {'weights': tensor([[0.2944, 0.2279, 0.7553, 0.7748]])}
test_args = (tensor([[[[0.9976, 0.3169],
          [0.5583, 0.3184]],

         [[0.1741, 0.2363],
          [0.1111, 0.9884]],

 ...

         [[0.1312, 0.7904],
          [0.5768, 0.6350]],

         [[0.3495, 0.2205],
          [0.1033, 0.6520]]]]))
test_kwargs = {'weights': tensor([[0.5021, 0.3937, 0.3242, 0.9948],
        [0.2998, 0.9107, 0.7822, 0.9142],
        [0.1761, 0.9847, 0.5206, 0.6413],
        [0.5515, 0.5945, 0.0279, 0.3852],
        [0.4721, 0.6357, 0.1372, 0.5588]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7fac18abb5b0>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt'
trace_args = (tensor([[[[6.2477e-01, 4.5034e-01],
          [3.8370e-01, 6.6941e-02]],

         [[3.4022e-01, 9.4814e-01],
       ...

         [[0.0767, 0.7677],
          [0.6592, 0.9350]],

         [[0.5278, 0.5992],
          [0.4692, 0.5186]]]]))
trace_kwargs = {'weights': tensor([[0.2944, 0.2279, 0.7553, 0.7748]])}
test_args = (tensor([[[[0.9976, 0.3169],
          [0.5583, 0.3184]],

         [[0.1741, 0.2363],
          [0.1111, 0.9884]],

 ...

         [[0.1312, 0.7904],
          [0.5768, 0.6350]],

         [[0.3495, 0.2205],
          [0.1033, 0.6520]]]]))
test_kwargs = {'weights': tensor([[0.5021, 0.3937, 0.3242, 0.9948],
        [0.2998, 0.9107, 0.7822, 0.9142],
        [0.1761, 0.9847, 0.5206, 0.6413],
        [0.5515, 0.5945, 0.0279, 0.3852],
        [0.4721, 0.6357, 0.1372, 0.5588]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[6.2477213e-01, 4.5034200e-01],
         [3.8370126e-01, 6.6941321e-02]],

        [[3.4021741e-01, 9.4814467..., 1.9165170e-01]],

        [[2.1023095e-02, 1.8964708e-01],
         [2.9516041e-02, 3.6161423e-02]]]], dtype=float32)
ls2 = array([[[[0.7669272 , 0.6393055 ],
         [0.4041078 , 0.37945044]],

        [[0.44736773, 0.56218344],
         [0...    [0.659174  , 0.93499625]],

        [[0.52783346, 0.59919024],
         [0.46919125, 0.5186464 ]]]], dtype=float32)
weights = array([[0.29443616, 0.22794873, 0.75528914, 0.7748055 ]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.29443616, 0.29443616, 0.22794873, 0.22794873, 0.75528914,
         0.75528914, 0.7748055 , 0.7748055 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
_______________________________________________________________________ test_find_homography_lines_dlt_iterated[numpy-s2s-False] _______________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7fac18abb6d0>
trace_args = (tensor([[[[0.0158, 0.1780],
          [0.1133, 0.4812]],

         [[0.2344, 0.1211],
          [0.6290, 0.0329]],

 ...430, 0.7500]],

         [[0.5472, 0.6455],
          [0.9946, 0.3188]]]]), tensor([[0.9469, 0.1259, 0.7533, 0.1640]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.1770, 0.5593],
          [0.8095, 0.8024]],

         [[0.6666, 0.1264],
          [0.1747, 0.6414]],

 ...[0.2935, 0.2734, 0.0637, 0.7104],
        [0.3742, 0.0993, 0.9549, 0.6268],
        [0.4465, 0.0239, 0.1213, 0.6966]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7fac18abb6d0>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt_iterated'
trace_args = (tensor([[[[0.0158, 0.1780],
          [0.1133, 0.4812]],

         [[0.2344, 0.1211],
          [0.6290, 0.0329]],

 ...430, 0.7500]],

         [[0.5472, 0.6455],
          [0.9946, 0.3188]]]]), tensor([[0.9469, 0.1259, 0.7533, 0.1640]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.1770, 0.5593],
          [0.8095, 0.8024]],

         [[0.6666, 0.1264],
          [0.1747, 0.6414]],

 ...[0.2935, 0.2734, 0.0637, 0.7104],
        [0.3742, 0.0993, 0.9549, 0.6268],
        [0.4465, 0.0239, 0.1213, 0.6966]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.0157572 , 0.17796844],
         [0.11330736, 0.48115408]],

        [[0.23439932, 0.12106794],
         [0...    [0.46202064, 0.63301176]],

        [[0.18929768, 0.54436255],
         [0.29222065, 0.89762414]]]], dtype=float32)
ls2 = array([[[[0.9054478 , 0.61323416],
         [0.13563538, 0.35918975]],

        [[0.57846546, 0.87485445],
         [0...    [0.04296577, 0.75000787]],

        [[0.54724115, 0.64549744],
         [0.9945983 , 0.3188408 ]]]], dtype=float32)
weights = array([[0.9469095 , 0.12589908, 0.7532838 , 0.16400033]], dtype=float32), soft_inl_th = 4.0, n_iter = 5

    def numpy_find_homography_lines_dlt_iterated(
        ls1, ls2, weights, soft_inl_th=4.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_lines_dlt(ls1, ls2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.0157572 , 0.17796844],
         [0.11330736, 0.48115408]],

        [[0.23439932, 0.12106794],
         [0...    [0.46202064, 0.63301176]],

        [[0.18929768, 0.54436255],
         [0.29222065, 0.89762414]]]], dtype=float32)
ls2 = array([[[[0.9054478 , 0.61323416],
         [0.13563538, 0.35918975]],

        [[0.57846546, 0.87485445],
         [0...    [0.04296577, 0.75000787]],

        [[0.54724115, 0.64549744],
         [0.9945983 , 0.3188408 ]]]], dtype=float32)
weights = array([[0.9469095 , 0.12589908, 0.7532838 , 0.16400033]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.9469095 , 0.9469095 , 0.12589908, 0.12589908, 0.7532838 ,
         0.7532838 , 0.16400033, 0.16400033]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
_____________________________________________________________________________ test_oneway_transfer_error[numpy-s2s-False] ______________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_oneway_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': False, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': False, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.oneway_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7fac18abb130>
trace_args = (tensor([[[0.5424, 0.8339],
         [0.5297, 0.3348],
         [0.6759, 0.2252],
         [0.4422, 0.4620]]]), tensor...0.7315]]]), tensor([[[0.6208, 0.5224, 0.3579],
         [0.9296, 0.8962, 0.7699],
         [0.4748, 0.2426, 0.6710]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.6084, 0.3951],
         [0.6208, 0.2045],
         [0.6684, 0.0386],
         [0.9167, 0.4287]],

       ... 0.0022]],

        [[0.9017, 0.6173, 0.4587],
         [0.8610, 0.6204, 0.0184],
         [0.8507, 0.7746, 0.0276]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7fac18abb130>, fn_name = 'kornia.geometry.homography.oneway_transfer_error'
trace_args = (tensor([[[0.5424, 0.8339],
         [0.5297, 0.3348],
         [0.6759, 0.2252],
         [0.4422, 0.4620]]]), tensor...0.7315]]]), tensor([[[0.6208, 0.5224, 0.3579],
         [0.9296, 0.8962, 0.7699],
         [0.4748, 0.2426, 0.6710]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.6084, 0.3951],
         [0.6208, 0.2045],
         [0.6684, 0.0386],
         [0.9167, 0.4287]],

       ... 0.0022]],

        [[0.9017, 0.6173, 0.4587],
         [0.8610, 0.6204, 0.0184],
         [0.8507, 0.7746, 0.0276]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.5423919 , 0.83388627],
        [0.529734  , 0.33479375],
        [0.6759245 , 0.22516495],
        [0.44216615, 0.46203458]]], dtype=float32)
pts2 = array([[[0.26139086, 0.05837095],
        [0.05333567, 0.5845827 ],
        [0.00106335, 0.47795486],
        [0.948788  , 0.73145163]]], dtype=float32)
H = array([[[0.6208114 , 0.5223955 , 0.3579182 ],
        [0.929571  , 0.89618576, 0.7699486 ],
        [0.47484052, 0.2426433 , 0.67098254]]], dtype=float32), squared = False, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 0.73807025,  1.7291543 ],
        [ 0.80511683,  0.9719802 ],
        [ 0.8542658 ,  1.0508989 ],
        [-0.06888843,  0.87475276]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fabc037f1c0>
array_like = array([[[ 0.73807025,  1.7291543 ],
        [ 0.80511683,  0.9719802 ],
        [ 0.8542658 ,  1.0508989 ],
        [-0.06888843,  0.87475276]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 0.73807025,  1.7291543 ],
        [ 0.80511683,  0.9719802 ],
        [ 0.8542658 ,  1.0508989 ],
        [-0.06888843,  0.87475276]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 0.73807025,  1.7291543 ],
        [ 0.80511683,  0.9719802 ],
        [ 0.8542658 ,  1.0508989 ],
        [-0.06888843,  0.87475276]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fabc037f1c0>
array_like = array([[[ 0.73807025,  1.7291543 ],
        [ 0.80511683,  0.9719802 ],
        [ 0.8542658 ,  1.0508989 ],
        [-0.06888843,  0.87475276]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 0.73807025,  1.7291543 ],
        [ 0.80511683,  0.9719802 ],
        [ 0.8542658 ,  1.0508989 ],
        [-0.06888843,  0.87475276]]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 0.73807025,  1.7291543 ],
        [ 0.80511683,  0.9719802 ],
        [ 0.8542658 ,  1.0508989 ],
        [-0.06888843,  0.87475276]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.oneway_transfer_error
____________________________________________________________________________ test_symmetric_transfer_error[numpy-s2s-False] ____________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetric_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.symmetric_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7fac18abb250>
trace_args = (tensor([[[0.2834, 0.0110],
         [0.8104, 0.2857],
         [0.9525, 0.4284],
         [0.3413, 0.4202]]]), tensor...0.1253]]]), tensor([[[0.1236, 0.1885, 0.1196],
         [0.2156, 0.1465, 0.0935],
         [0.9563, 0.9989, 0.6930]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.1287, 0.2345],
         [0.7690, 0.4681],
         [0.5860, 0.6035],
         [0.0382, 0.3122]],

       ... 0.7951]],

        [[0.1423, 0.5896, 0.0767],
         [0.4839, 0.2794, 0.2206],
         [0.5092, 0.5650, 0.8330]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7fac18abb250>, fn_name = 'kornia.geometry.homography.symmetric_transfer_error'
trace_args = (tensor([[[0.2834, 0.0110],
         [0.8104, 0.2857],
         [0.9525, 0.4284],
         [0.3413, 0.4202]]]), tensor...0.1253]]]), tensor([[[0.1236, 0.1885, 0.1196],
         [0.2156, 0.1465, 0.0935],
         [0.9563, 0.9989, 0.6930]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.1287, 0.2345],
         [0.7690, 0.4681],
         [0.5860, 0.6035],
         [0.0382, 0.3122]],

       ... 0.7951]],

        [[0.1423, 0.5896, 0.0767],
         [0.4839, 0.2794, 0.2206],
         [0.5092, 0.5650, 0.8330]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.28341442, 0.0109756 ],
        [0.8104237 , 0.28567678],
        [0.9524573 , 0.42844075],
        [0.34133935, 0.4202336 ]]], dtype=float32)
pts2 = array([[[0.43971616, 0.74641734],
        [0.8284398 , 0.41604573],
        [0.7749241 , 0.98734355],
        [0.52003646, 0.1253227 ]]], dtype=float32)
H = array([[[0.12357789, 0.18848366, 0.11960447],
        [0.21560252, 0.14652485, 0.09354293],
        [0.9563496 , 0.9988744 , 0.6930204 ]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetric_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from ...ivy.functional.frontends.torch.miscellaneous_ops import numpy_finfo_frnt
        from ..utils.helpers import numpy_safe_inverse_with_mask
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        max_num = numpy_finfo_frnt(pts1.dtype).max
        H_inv, good_H = numpy_safe_inverse_with_mask(H)
>       there: typing.Any = numpy_oneway_transfer_error(pts1, pts2, H, True, eps)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.28341442, 0.0109756 ],
        [0.8104237 , 0.28567678],
        [0.9524573 , 0.42844075],
        [0.34133935, 0.4202336 ]]], dtype=float32)
pts2 = array([[[0.43971616, 0.74641734],
        [0.8284398 , 0.41604573],
        [0.7749241 , 0.98734355],
        [0.52003646, 0.1253227 ]]], dtype=float32)
H = array([[[0.12357789, 0.18848366, 0.11960447],
        [0.21560252, 0.14652485, 0.09354293],
        [0.9563496 , 0.9988744 , 0.6930204 ]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[-0.27900577, -0.5861592 ],
        [-0.672402  , -0.23917402],
        [-0.6183872 , -0.80934304],
        [-0.35258916,  0.03359053]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fabc0719fc0>
array_like = array([[[-0.27900577, -0.5861592 ],
        [-0.672402  , -0.23917402],
        [-0.6183872 , -0.80934304],
        [-0.35258916,  0.03359053]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[-0.27900577, -0.5861592 ],
        [-0.672402  , -0.23917402],
        [-0.6183872 , -0.80934304],
        [-0.35258916,  0.03359053]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:272: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[-0.27900577, -0.5861592 ],
        [-0.672402  , -0.23917402],
        [-0.6183872 , -0.80934304],
        [-0.35258916,  0.03359053]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fabc0719fc0>
array_like = array([[[-0.27900577, -0.5861592 ],
        [-0.672402  , -0.23917402],
        [-0.6183872 , -0.80934304],
        [-0.35258916,  0.03359053]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[-0.27900577, -0.5861592 ],
        [-0.672402  , -0.23917402],
        [-0.6183872 , -0.80934304],
        [-0.35258916,  0.03359053]]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[-0.27900577, -0.5861592 ],
        [-0.672402  , -0.23917402],
        [-0.6183872 , -0.80934304],
        [-0.35258916,  0.03359053]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.symmetric_transfer_error
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_oneway_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_homography.py::test_symmetric_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 6 failed, 2 passed in 622.01s (0:10:22) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ..                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 138.73s (0:02:18) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.....ssss                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_mean_average_precision[numpy-s2s-False] _____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f37017c6680>
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f37017c6680>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [array([1.], dtype=float32)], pred_scores = [array([0.7], dtype=float32)]
gt_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[numpy-s2s-False] - TypeError: 'int' object is not callable
========================================================================== 1 failed, 8 passed, 4 skipped in 502.80s (0:08:22) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 306.02s (0:05:06) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F.......F..FF                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_upscale_double[tensorflow-s2s-False] _______________________________________________________________________________

>   ???
E   TypeError: 'NoneType' object is not iterable

IXC.pyx:328: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f559a4f15a0>
trace_args = (tensor([[[[0.1726, 0.7676, 0.0246, 0.1901],
          [0.3130, 0.1532, 0.1579, 0.0803],
          [0.7827, 0.1305, 0...., 0.2728, 0.2689, 0.1925],
          [0.3091, 0.5662, 0.0606, 0.2374],
          [0.3426, 0.9215, 0.0832, 0.5483]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[7.9194e-01, 2.7008e-01, 1.1263e-01, 7.7687e-02, 9.6685e-01,
           9.7956e-01, 8.2455e-02, 3.4126e-01]...      [8.6365e-01, 8.9388e-01, 4.8161e-01, 1.5718e-01, 8.3473e-01,
           6.6145e-01, 5.6592e-01, 6.3987e-01]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f559a4f15a0>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.1726, 0.7676, 0.0246, 0.1901],
          [0.3130, 0.1532, 0.1579, 0.0803],
          [0.7827, 0.1305, 0...., 0.2728, 0.2689, 0.1925],
          [0.3091, 0.5662, 0.0606, 0.2374],
          [0.3426, 0.9215, 0.0832, 0.5483]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[7.9194e-01, 2.7008e-01, 1.1263e-01, 7.7687e-02, 9.6685e-01,
           9.7956e-01, 8.2455e-02, 3.4126e-01]...      [8.6365e-01, 8.9388e-01, 4.8161e-01, 1.5718e-01, 8.3473e-01,
           6.6145e-01, 5.6592e-01, 6.3987e-01]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 4, 4), dtype=float32, numpy=
array([[[[0.17263478, 0.7675691 , 0.02458203, 0.19008982],
     ....5661939 , 0.06055748, 0.23740244],
         [0.3426023 , 0.92154056, 0.08317757, 0.5482536 ]]]],
      dtype=float32)>

    def tensorflow_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK_IS_TENSOR(x)
        tensorflow_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = tensorflow_shape_frnt_(x)[:-2] + (
            tensorflow_shape_frnt_(x)[-2] * 2,
            tensorflow_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = tensorflow_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = tensorflow_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )
E       TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/pyramid.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
___________________________________________________________________________________ test_Shear[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = transpiled_kornia.geometry.transform.Shear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.94684094, 0.99941164, 0.7651494 , 0.37434155],
    ...5515552, 0.8116734 , 0.3029734 ],
         [0.7818839 , 0.55170584, 0.08314544, 0.22732615]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f55471a3490, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.94684094, 0.99941164, 0.7651494...05515552, 0.8116734 , 0.3029734 ],
         [0.7818839 , 0.55170584, 0.08314544, 0.22732615]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.94684094, 0.99941164, 0.7651494 , 0.37434155],
    ...5515552, 0.8116734 , 0.3029734 ],
         [0.7818839 , 0.55170584, 0.08314544, 0.22732615]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.94684094, 0.99941164, 0.7651494...05515552, 0.8116734 , 0.3029734 ],
         [0.7818839 , 0.55170584, 0.08314544, 0.22732615]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.94684094, 0.99941164, 0.7651494 , 0.37434155],
    ...5515552, 0.8116734 , 0.3029734 ],
         [0.7818839 , 0.55170584, 0.08314544, 0.22732615]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.94684094, 0.99941164, 0.7651494 , 0.37434155],
     ....05515552, 0.8116734 , 0.3029734 ],
         [0.7818839 , 0.55170584, 0.08314544, 0.22732615]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.94684094, 0.99941164, 0.7651494 , 0.374341...05515552, 0.8116734 , 0.3029734 ],
         [0.7818839 , 0.55170584, 0.08314544, 0.22732615]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
input = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.94684094, 0.99941164, 0.7651494 , 0.37434155],
     ....05515552, 0.8116734 , 0.3029734 ],
         [0.7818839 , 0.55170584, 0.08314544, 0.22732615]]]],
      dtype=float32)>

    def call(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: Exception encountered when calling tensorflow_Shear.call().
E       
E       [1mname 'shear' is not defined[0m
E       
E       Arguments received by tensorflow_Shear.call():
E         • input=tf.Tensor(shape=(2, 3, 4, 4), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/affwarp.py:55: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
kornia.geometry.transform.Shear
__________________________________________________________________________________ test_Rescale[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Rescale(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Rescale")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 4, 4)
        torch_out = kornia.geometry.transform.Rescale((2.0, 3.0))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_out = transpiled_kornia.geometry.transform.Rescale((2.0, 3.0))(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/geometry/test_transform.py:1294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.3739, 0.3849, 0.3959, 0.4069, 0.3799, 0.2770, 0.1741, 0.0712,
           0.1996, 0.4437, 0.6877, 0.9318],...        [0.6581, 0.6537, 0.6493, 0.6448, 0.6546, 0.6927, 0.7309, 0.7690,
           0.7754, 0.7658, 0.7563, 0.7467]]]])
transpiled_x = <tf.Tensor: shape=(1, 3, 8, 12), dtype=float32, numpy=
array([[[[0.37386233, 0.37386233, 0.3873162 , 0.4007701 , 0.414...      0.6885046 , 0.7351121 , 0.7817195 , 0.7700482 , 0.75837684,
          0.74670553, 0.74670553]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.37386233, 0.38487005, 0.39587775, 0.4068855 , 0.3799242 ,
          0.27702492, 0.17412561, 0.07122635, 0....       0.69274163, 0.730875  , 0.7690084 , 0.7753533 , 0.76580405,
          0.7562548 , 0.74670553]]]], dtype=float32)
y = array([[[[0.37386233, 0.37386233, 0.3873162 , 0.4007701 , 0.41422397,
          0.28845817, 0.16269237, 0.03692663, 0....       0.6885046 , 0.7351121 , 0.7817195 , 0.7700482 , 0.75837684,
          0.74670553, 0.74670553]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Rescale
kornia.geometry.transform.Rescale
________________________________________________________________________________ test_Homography[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Homography(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Homography")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_out = kornia.geometry.transform.image_registrator.Homography()()
>       transpiled_out = transpiled_kornia.geometry.transform.image_registrator.Homography()()

kornia/geometry/test_transform.py:1350: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable_1>), args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f550af822b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable_1>),), kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable_1>), v = None, buffers = None, args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable_1>),), kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable_1>), v = None, buffers = None, args = (), kwargs = {}, first_arr = None, replace_v = False
replace_buffers = False, call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable_1>),), kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7f5538349a20>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Homography
kornia.geometry.transform.Homography
________________________________________________________________________________ test_Similarity[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Similarity(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Similarity")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        torch_out = kornia.geometry.transform.image_registrator.Similarity()()
>       transpiled_out = transpiled_kornia.geometry.transform.image_registrator.Similarity()()

kornia/geometry/test_transform.py:1386: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_5>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_6>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_7>)
args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55e5a98b00c0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_5>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_6>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_7>),)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_5>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_6>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_7>)
v = None, buffers = None, args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_5>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_6>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_7>),)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_5>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_6>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_7>)
v = None, buffers = None, args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False, call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_5>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_6>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_7>),)
kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7f55286bb700>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Similarity
kornia.geometry.transform.Similarity
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/geometry/test_transform.py::test_Shear[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_Shear.call().
FAILED kornia/geometry/test_transform.py::test_Rescale[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_transform.py::test_Homography[tensorflow-s2s-False] - IndexError: list index out of range
FAILED kornia/geometry/test_transform.py::test_Similarity[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 5 failed, 51 passed in 5843.82s (1:37:23) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 462.53s (0:07:42) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.16s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py .........F...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_ScaleSpaceDetector[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = transpiled_kornia.feature.ScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature3.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[10.7274,  0.0000, 13.9216],
          [ 0.0000, 10.7274, 12.0147]],

         [[10.7035,  0.0000, 13.0872]...00, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]))
transpiled_x = (Array([[[[10.727388 ,  0.       , 13.921583 ],
         [ 0.       , 10.727388 , 12.01469  ]],

        [[10.703481 ,...   , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],      dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[10.727388 ,  0.       , 13.921583 ],
         [ 0.       , 10.727388 , 12.01469  ]],

        [[10.703481 ,...        ,  0.        ,
         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],
      dtype=float32))
y = (array([[[[10.727388 ,  0.       , 13.921583 ],
         [ 0.       , 10.727388 , 12.01469  ]],

        [[10.703481 ,...  , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f4785c74b80>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[10.727388 ,  0.       , 13.921583 ],
         [ 0.       , 10.727388 , 12.01469  ]],

        [[10.703481 , ...405]],

        [[54.31358  ,  0.       , 22.002934 ],
         [ 0.       , 54.31358  , 26.003061 ]]]], dtype=float32)
y = array([[[[10.727388 ,  0.       , 13.921583 ],
         [ 0.       , 10.727388 , 12.01469  ]],

        [[10.703481 , ...37 ]],

        [[12.142689 ,  0.       , 25.978964 ],
         [ 0.       , 12.142689 , 23.033215 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
kornia.feature.ScaleSpaceDetector
All parameters and buffers are now synced!
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[jax-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 1 failed, 12 passed in 1832.24s (0:30:32) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py .F                                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_write_image[numpy-s2s-False] ___________________________________________________________________________________

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs'

VM.pyx:244: ModuleNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_write_image(target_framework, mode, backend_compile):
        print("kornia.io.write_image")
    
        if backend_compile:
            pytest.skip()
    
>       transpiled_load_image = ivy.transpile(kornia.io.write_image, source="torch", target=target_framework)

kornia/test_io.py:27: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <function write_image at 0x7fc0740c0ee0>, source = 'torch', target = 'numpy', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ImportError: Error loading module ivy_transpiled_outputs.torch_frontend_outputs.__init__: No module named 'ivy_transpiled_outputs'

VM.pyx:247: ImportError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.io.write_image
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_io.py::test_write_image[numpy-s2s-False] - ImportError: Error loading module ivy_transpiled_outputs.torch_frontend_outputs.__init__: No module named 'ivy_transpiled_outputs'
================================================================================ 1 failed, 1 passed in 67.53s (0:01:07) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 423.22s (0:07:03) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomClahe[jax-s2s-False] ____________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 3, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4461: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'jax', init_args = (), init_kwargs = {}
call_args = (tensor([[[[0.1379, 0.3981, 0.3647,  ..., 0.2910, 0.1105, 0.1034],
          [0.4342, 0.5694, 0.8106,  ..., 0.9044, 0...., 0.8490, 0.9509,  ..., 0.0484, 0.5943, 0.6012],
          [0.5434, 0.7494, 0.5514,  ..., 0.2428, 0.5062, 0.0347]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[0.13791877, 0.3980562 , 0.36467034, ..., 0.29100853,
          0.1105327 , 0.10337114],
         [0.43424153...6],
         [0.5433886 , 0.74944067, 0.5513799 , ..., 0.24277395,
          0.5061823 , 0.03474855]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fd4b24ad1b0>, jax_set_item = <function jax_set_item at 0x7fd48483c670>, tensor = <function jax_tensor_frnt at 0x7fd47cfc69e0>
in_tensor = Array([[[[0.13791877, 0.3980562 , 0.36467034, ..., 0.29100853,
          0.1105327 , 0.10337114],
         [0.43424153...6],
         [0.5433886 , 0.74944067, 0.5513799 , ..., 0.24277395,
          0.5061823 , 0.03474855]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = Array([[[[0.13791877, 0.3980562 , 0.36467034, ..., 0.29100853,
          0.1105327 , 0.10337114],
         [0.43424153...6],
         [0.5433886 , 0.74944067, 0.5513799 , ..., 0.24277395,
          0.5061823 , 0.03474855]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[0.13791877, 0.3980562 , 0.36467034, ..., 0.29100853,
          0.1105327 , 0.10337114],
         [0.43424153...6],
         [0.5433886 , 0.74944067, 0.5513799 , ..., 0.24277395,
          0.5061823 , 0.03474855]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fd4b24ad1b0>, jax_all_frnt_ = <function jax_all_frnt_ at 0x7fd4b20f3250>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7fd47cfe7d00>
jax_get_item = <function jax_get_item at 0x7fd48483c4c0>, jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7fd484e12c20>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7fd47cfe6c20>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7fd47cfe6560>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not jax_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                jax_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else jax_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[4.48828757e-01, 8.18243504e-01, 4.70538676e-01,
          2.50376940e-01, 7.69342005e-01, 9.63012755e-01,
  ...
          6.24840975e-01, 8.72114003e-01, 2.42773950e-01,
          5.06182313e-01, 3.47485542e-02]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import jax_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return jax_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/clahe.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[4.48828757e-01, 8.18243504e-01, 4.70538676e-01,
          2.50376940e-01, 7.69342005e-01, 9.63012755e-01,
  ...
          6.24840975e-01, 8.72114003e-01, 2.42773950e-01,
          5.06182313e-01, 3.47485542e-02]]]], dtype=float32)
args = (40.0, (8, 8), False), kwargs = {}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7fd4b20f01f0>, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fd4b24ad1b0>
jax_view_frnt_ = <function jax_view_frnt_ at 0x7fd4b8d22290>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[4.48828757e-01, 8.18243504e-01, 4.70538676e-01,
          2.50376940e-01, 7.69342005e-01, 9.63012755e-01,
  ...
          6.24840975e-01, 8.72114003e-01, 2.42773950e-01,
          5.06182313e-01, 3.47485542e-02]]]], dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:487: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[4.48828757e-01, 8.18243504e-01, 4.70538676e-01,
          2.50376940e-01, 7.69342005e-01, 9.63012755e-01,
  ...
          6.24840975e-01, 8.72114003e-01, 2.42773950e-01,
          5.06182313e-01, 3.47485542e-02]]]], dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
>               jax_unfold_frnt_(
                    jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[[4.4882876e-01, 8.1824350e-01, 4.7053868e-01, ...,
            4.3176597e-01, 4.2989177e-01, 7.6867068e-01...1e-01, 3.2134372e-01, ...,
            2.8567660e-01, 5.2400786e-01, 3.7828058e-01]]]]]],      dtype=float32), 3, 4, 4)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fd47cfdb0a0>
array_like = Array([[[[[[4.4882876e-01, 8.1824350e-01, 4.7053868e-01, ...,
            4.3176597e-01, 4.2989177e-01, 7.6867068e-01]..., 1.3607621e-01, 3.2134372e-01, ...,
            2.8567660e-01, 5.2400786e-01, 3.7828058e-01]]]]]],      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[[4.4882876e-01, 8.1824350e-01, 4.7053868e-01, ...,
            4.3176597e-01, 4.2989177e-01, 7.6867068e-01]..., 1.3607621e-01, 3.2134372e-01, ...,
            2.8567660e-01, 5.2400786e-01, 3.7828058e-01]]]]]],      dtype=float32)
dimension = 3, size = 4, step = 4

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:149: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[jax-s2s-False] - Exception: Need at least one array to stack.
============================================================================== 1 failed, 17 passed in 3298.72s (0:54:58) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...........ssssss                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 11 passed, 6 skipped in 649.16s (0:10:49) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py .......F..                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_DeDoDe[jax-s2s-False] ______________________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
>       transpiled_model = transpiled_kornia.feature.DeDoDe(amp_dtype=ivy.as_native_dtype("float32"))

kornia/test_feature5.py:182: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}, node = jax_DeDoDe()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, self = jax_DeDoDe(), args = (), kwargs = {'amp_dtype': dtype('float32')}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DeDoDe(), detector_model = 'L', descriptor_model = 'G', amp_dtype = dtype('float32')

    def __init__(self, detector_model="L", descriptor_model="G", amp_dtype=jnp.float16):
        from .dedode_models import jax_get_detector
        from .dedode_models import jax_get_descriptor
        from ...enhance.normalize import jax_Normalize
        from ....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
    
        self.super___init__(
            detector_model=detector_model,
            descriptor_model=descriptor_model,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.detector: typing.Any = jax_get_detector(detector_model, amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kind = 'L', amp_dtype = dtype('float32')

    def jax_get_detector(kind="L", amp_dtype=jnp.float16):
        if kind == "L":
>           return jax_dedode_detector_L(amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amp_dtype = dtype('float32')

    def jax_dedode_detector_L(amp_dtype=jnp.float16):
        from ....torch.nn.modules.container import jax_ModuleDict
        from .decoder import jax_ConvRefiner
        from .encoder import jax_VGG19
        from .decoder import jax_Decoder
        from .detector import jax_DeDoDeDetector
    
        NUM_PROTOTYPES = 1
        residual = True
        hidden_blocks = 8
        amp = True
        conv_refiner = jax_ModuleDict(
            {
>               "8": jax_ConvRefiner(
                    512,
                    512,
                    256 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "4": jax_ConvRefiner(
                    256 + 256,
                    256,
                    128 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "2": jax_ConvRefiner(
                    128 + 128,
                    128,
                    64 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "1": jax_ConvRefiner(
                    64 + 64,
                    64,
                    1 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
            }
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}, node = jax_ConvRefiner()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, self = jax_ConvRefiner(), args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), args = (512, 512, 257), kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, hidden_dim = 512, out_dim = 257, dw = True, kernel_size = 5, hidden_blocks = 8, amp = True, residual = True, amp_dtype = dtype('float32')

    @jax_store_config_info
    def __init__(
        self,
        in_dim=6,
        hidden_dim=16,
        out_dim=2,
        dw=True,
        kernel_size=5,
        hidden_blocks=5,
        amp=True,
        residual=False,
        amp_dtype=jnp.float16,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....jax__stateful_layers import FlaxConv
    
        self.super___init__(
            in_dim=in_dim,
            hidden_dim=hidden_dim,
            out_dim=out_dim,
            dw=dw,
            kernel_size=kernel_size,
            hidden_blocks=hidden_blocks,
            amp=amp,
            residual=residual,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.block1 = self.create_block(in_dim, hidden_dim, dw=False, kernel_size=1)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, out_dim = 512, dw = False, kernel_size = 1, bias = True, norm_type = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>

    def create_block(
        self,
        in_dim,
        out_dim,
        dw=True,
        kernel_size=5,
        bias=True,
        norm_type=FlaxBatchNorm,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....torch.nn.modules.activation import jax_ReLU
        from ....jax__stateful_layers import FlaxConv
        from ....jax__stateful_layers import FlaxBatchNorm
    
        num_groups = 1 if not dw else in_dim
        if dw:
            if out_dim % in_dim != 0:
                raise Exception("outdim must be divisible by indim for depthwise")
        conv1 = FlaxConv(
            in_features=in_dim,
            out_features=out_dim,
            kernel_size=kernel_size,
            strides=1,
            padding=kernel_size // 2,
            padding_mode="zeros",
            use_bias=bias,
            feature_group_count=num_groups,
            input_dilation=1,
            kernel_dilation=1,
        )
        norm = (
>           norm_type(out_dim)
            if norm_type is FlaxBatchNorm
            else norm_type(num_channels=out_dim)
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}
node = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fa4fe79a020>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>
self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fa4fe79a020>, args = (512,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fa4fe79a020>, args = (512,), kwargs = {}

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
>       num_features = kwargs.pop("num_features")
E       KeyError: 'num_features'

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:428: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
>       transpiled_model = transpiled_kornia.feature.DeDoDe(amp_dtype=ivy.as_native_dtype("float32"))

kornia/test_feature5.py:182: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}, node = jax_DeDoDe()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, self = jax_DeDoDe(), args = (), kwargs = {'amp_dtype': dtype('float32')}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DeDoDe(), detector_model = 'L', descriptor_model = 'G', amp_dtype = dtype('float32')

    def __init__(self, detector_model="L", descriptor_model="G", amp_dtype=jnp.float16):
        from .dedode_models import jax_get_detector
        from .dedode_models import jax_get_descriptor
        from ...enhance.normalize import jax_Normalize
        from ....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
    
        self.super___init__(
            detector_model=detector_model,
            descriptor_model=descriptor_model,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.detector: typing.Any = jax_get_detector(detector_model, amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kind = 'L', amp_dtype = dtype('float32')

    def jax_get_detector(kind="L", amp_dtype=jnp.float16):
        if kind == "L":
>           return jax_dedode_detector_L(amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amp_dtype = dtype('float32')

    def jax_dedode_detector_L(amp_dtype=jnp.float16):
        from ....torch.nn.modules.container import jax_ModuleDict
        from .decoder import jax_ConvRefiner
        from .encoder import jax_VGG19
        from .decoder import jax_Decoder
        from .detector import jax_DeDoDeDetector
    
        NUM_PROTOTYPES = 1
        residual = True
        hidden_blocks = 8
        amp = True
        conv_refiner = jax_ModuleDict(
            {
>               "8": jax_ConvRefiner(
                    512,
                    512,
                    256 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "4": jax_ConvRefiner(
                    256 + 256,
                    256,
                    128 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "2": jax_ConvRefiner(
                    128 + 128,
                    128,
                    64 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "1": jax_ConvRefiner(
                    64 + 64,
                    64,
                    1 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
            }
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}, node = jax_ConvRefiner()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, self = jax_ConvRefiner(), args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), args = (512, 512, 257), kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, hidden_dim = 512, out_dim = 257, dw = True, kernel_size = 5, hidden_blocks = 8, amp = True, residual = True, amp_dtype = dtype('float32')

    @jax_store_config_info
    def __init__(
        self,
        in_dim=6,
        hidden_dim=16,
        out_dim=2,
        dw=True,
        kernel_size=5,
        hidden_blocks=5,
        amp=True,
        residual=False,
        amp_dtype=jnp.float16,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....jax__stateful_layers import FlaxConv
    
        self.super___init__(
            in_dim=in_dim,
            hidden_dim=hidden_dim,
            out_dim=out_dim,
            dw=dw,
            kernel_size=kernel_size,
            hidden_blocks=hidden_blocks,
            amp=amp,
            residual=residual,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.block1 = self.create_block(in_dim, hidden_dim, dw=False, kernel_size=1)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, out_dim = 512, dw = False, kernel_size = 1, bias = True, norm_type = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>

    def create_block(
        self,
        in_dim,
        out_dim,
        dw=True,
        kernel_size=5,
        bias=True,
        norm_type=FlaxBatchNorm,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....torch.nn.modules.activation import jax_ReLU
        from ....jax__stateful_layers import FlaxConv
        from ....jax__stateful_layers import FlaxBatchNorm
    
        num_groups = 1 if not dw else in_dim
        if dw:
            if out_dim % in_dim != 0:
                raise Exception("outdim must be divisible by indim for depthwise")
        conv1 = FlaxConv(
            in_features=in_dim,
            out_features=out_dim,
            kernel_size=kernel_size,
            strides=1,
            padding=kernel_size // 2,
            padding_mode="zeros",
            use_bias=bias,
            feature_group_count=num_groups,
            input_dilation=1,
            kernel_dilation=1,
        )
        norm = (
>           norm_type(out_dim)
            if norm_type is FlaxBatchNorm
            else norm_type(num_channels=out_dim)
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}
node = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fa4fcf833d0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>
self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fa4fcf833d0>, args = (512,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fa4fcf833d0>, args = (512,), kwargs = {}

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
>       num_features = kwargs.pop("num_features")
E       KeyError: 'num_features'

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:428: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  0%|          | 5.25M/1.13G [00:00<00:22, 53.7MB/s]
  1%|          | 12.5M/1.13G [00:00<00:18, 66.4MB/s]
  2%|▏         | 21.2M/1.13G [00:00<00:15, 75.1MB/s]
  3%|▎         | 31.2M/1.13G [00:00<00:14, 84.6MB/s]
  4%|▎         | 41.8M/1.13G [00:00<00:12, 93.0MB/s]
  5%|▍         | 56.1M/1.13G [00:00<00:10, 112MB/s] 
  6%|▋         | 73.8M/1.13G [00:00<00:08, 135MB/s]
  8%|▊         | 94.1M/1.13G [00:00<00:06, 160MB/s]
 10%|▉         | 114M/1.13G [00:00<00:06, 176MB/s] 
 12%|█▏        | 134M/1.13G [00:01<00:05, 185MB/s]
 13%|█▎        | 154M/1.13G [00:01<00:05, 194MB/s]
 15%|█▌        | 175M/1.13G [00:01<00:05, 200MB/s]
 17%|█▋        | 196M/1.13G [00:01<00:04, 204MB/s]
 19%|█▊        | 215M/1.13G [00:01<00:04, 204MB/s]
 20%|██        | 236M/1.13G [00:01<00:04, 207MB/s]
 22%|██▏       | 256M/1.13G [00:01<00:04, 197MB/s]
 24%|██▎       | 274M/1.13G [00:01<00:04, 197MB/s]
 25%|██▌       | 293M/1.13G [00:01<00:04, 189MB/s]
 27%|██▋       | 312M/1.13G [00:01<00:04, 182MB/s]
 29%|██▊       | 332M/1.13G [00:02<00:04, 190MB/s]
 30%|███       | 351M/1.13G [00:02<00:04, 193MB/s]
 32%|███▏      | 371M/1.13G [00:02<00:04, 198MB/s]
 34%|███▎      | 390M/1.13G [00:02<00:04, 195MB/s]
 35%|███▌      | 411M/1.13G [00:02<00:03, 201MB/s]
 37%|███▋      | 431M/1.13G [00:02<00:03, 204MB/s]
 39%|███▉      | 452M/1.13G [00:02<00:03, 207MB/s]
 41%|████      | 472M/1.13G [00:02<00:03, 209MB/s]
 42%|████▏     | 492M/1.13G [00:02<00:03, 210MB/s]
 44%|████▍     | 512M/1.13G [00:02<00:03, 205MB/s]
 46%|████▌     | 532M/1.13G [00:03<00:03, 206MB/s]
 48%|████▊     | 553M/1.13G [00:03<00:03, 209MB/s]
 49%|████▉     | 574M/1.13G [00:03<00:02, 211MB/s]
 51%|█████     | 594M/1.13G [00:03<00:02, 210MB/s]
 53%|█████▎    | 614M/1.13G [00:03<00:02, 211MB/s]
 55%|█████▍    | 635M/1.13G [00:03<00:02, 211MB/s]
 56%|█████▋    | 655M/1.13G [00:03<00:02, 212MB/s]
 58%|█████▊    | 675M/1.13G [00:03<00:02, 211MB/s]
 60%|█████▉    | 696M/1.13G [00:03<00:02, 213MB/s]
 62%|██████▏   | 716M/1.13G [00:03<00:02, 212MB/s]
 63%|██████▎   | 736M/1.13G [00:04<00:02, 212MB/s]
 65%|██████▌   | 757M/1.13G [00:04<00:02, 209MB/s]
 67%|██████▋   | 777M/1.13G [00:04<00:01, 203MB/s]
 69%|██████▊   | 796M/1.13G [00:04<00:01, 202MB/s]
 70%|███████   | 816M/1.13G [00:04<00:01, 195MB/s]
 72%|███████▏  | 834M/1.13G [00:04<00:01, 192MB/s]
 73%|███████▎  | 853M/1.13G [00:04<00:01, 193MB/s]
 75%|███████▌  | 871M/1.13G [00:04<00:01, 178MB/s]
 77%|███████▋  | 888M/1.13G [00:04<00:01, 170MB/s]
 78%|███████▊  | 909M/1.13G [00:05<00:01, 181MB/s]
 80%|███████▉  | 928M/1.13G [00:05<00:01, 187MB/s]
 82%|████████▏ | 948M/1.13G [00:05<00:01, 193MB/s]
 83%|████████▎ | 968M/1.13G [00:05<00:01, 199MB/s]
 85%|████████▌ | 989M/1.13G [00:05<00:00, 204MB/s]
 87%|████████▋ | 0.98G/1.13G [00:05<00:00, 198MB/s]
 89%|████████▊ | 1.01G/1.13G [00:05<00:00, 203MB/s]
 90%|█████████ | 1.02G/1.13G [00:05<00:00, 204MB/s]
 92%|█████████▏| 1.04G/1.13G [00:05<00:00, 202MB/s]
 94%|█████████▎| 1.06G/1.13G [00:06<00:00, 197MB/s]
 95%|█████████▌| 1.08G/1.13G [00:06<00:00, 199MB/s]
 97%|█████████▋| 1.10G/1.13G [00:06<00:00, 203MB/s]
 99%|█████████▉| 1.12G/1.13G [00:06<00:00, 206MB/s]
100%|██████████| 1.13G/1.13G [00:06<00:00, 191MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_DeDoDe[jax-s2s-False] - KeyError: 'num_features'
=============================================================================== 1 failed, 9 passed in 1569.33s (0:26:09) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 5.23s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ...........................sssssssssssssssss                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 27 passed, 17 skipped in 1939.65s (0:32:19) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_mean_average_precision[jax-s2s-False] ______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f9be4e8a680>
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f9be4e8a680>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [Array([1.], dtype=float32)], pred_scores = [Array([0.7], dtype=float32)]
gt_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [Array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 1 failed, 12 passed in 757.31s (0:12:37) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py .................ss                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 17 passed, 2 skipped in 925.22s (0:15:25) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_bbox_to_mask[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7fe318378310>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7fe318378310>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001
deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[jax-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 486.58s (0:08:06) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ........                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 749.87s (0:12:29) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_HomographyTracker[tensorflow-s2s-False] _____________________________________________________________________________

>   ???

IXC.pyx:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   FileNotFoundError: [Errno 2] No such file or directory: '<string>'

IXC.pyx:243: FileNotFoundError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = transpiled_kornia.tracking.HomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HomographyTracker(), initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import tensorflow_LocalFeatureMatcher
        from ..feature.integrated import tensorflow_GFTTAffNetHardNet
        from ..feature.matching import tensorflow_DescriptorMatcher
        from ..feature.loftr.loftr import tensorflow_LoFTR
        from ..geometry.ransac import tensorflow_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or tensorflow_LocalFeatureMatcher(
>           tensorflow_GFTTAffNetHardNet(3000),
            tensorflow_DescriptorMatcher("smnn", 0.95),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/tracking/planar_tracker.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f09721279d0>, args = (3000,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f09721279d0>, num_features = 3000, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    @tensorflow_store_config_info
    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f0972127d60>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f0972127d60>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError

During handling of the above exception, another exception occurred:

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = transpiled_kornia.tracking.HomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HomographyTracker(), initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import tensorflow_LocalFeatureMatcher
        from ..feature.integrated import tensorflow_GFTTAffNetHardNet
        from ..feature.matching import tensorflow_DescriptorMatcher
        from ..feature.loftr.loftr import tensorflow_LoFTR
        from ..geometry.ransac import tensorflow_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or tensorflow_LocalFeatureMatcher(
>           tensorflow_GFTTAffNetHardNet(3000),
            tensorflow_DescriptorMatcher("smnn", 0.95),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/tracking/planar_tracker.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f096b62a3b0>, args = (3000,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f096b62a3b0>, num_features = 3000, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    @tensorflow_store_config_info
    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f096b6294b0>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f096b6294b0>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 47.3MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 199MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:59, 387kB/s]
  1%|          | 256k/44.2M [00:00<01:12, 636kB/s]
  1%|          | 512k/44.2M [00:00<00:39, 1.17MB/s]
  2%|▏         | 896k/44.2M [00:00<00:24, 1.89MB/s]
  4%|▍         | 1.75M/44.2M [00:00<00:11, 3.81MB/s]
  8%|▊         | 3.50M/44.2M [00:00<00:05, 7.61MB/s]
 14%|█▍        | 6.12M/44.2M [00:01<00:03, 12.7MB/s]
 21%|██        | 9.12M/44.2M [00:01<00:02, 17.3MB/s]
 27%|██▋       | 12.1M/44.2M [00:01<00:01, 20.4MB/s]
 34%|███▍      | 15.1M/44.2M [00:01<00:01, 22.6MB/s]
 41%|████      | 18.1M/44.2M [00:01<00:01, 24.2MB/s]
 47%|████▋     | 20.9M/44.2M [00:01<00:00, 24.5MB/s]
 54%|█████▍    | 23.9M/44.2M [00:01<00:00, 25.5MB/s]
 61%|██████    | 26.9M/44.2M [00:01<00:00, 26.1MB/s]
 67%|██████▋   | 29.8M/44.2M [00:01<00:00, 26.4MB/s]
 74%|███████▍  | 32.8M/44.2M [00:02<00:00, 26.9MB/s]
 81%|████████  | 35.8M/44.2M [00:02<00:00, 27.1MB/s]
 87%|████████▋ | 38.4M/44.2M [00:02<00:00, 26.3MB/s]
 93%|█████████▎| 41.2M/44.2M [00:02<00:00, 26.5MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 26.7MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 18.6MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
==================================================================================== 1 failed in 480.97s (0:08:00) =====================================================================================

