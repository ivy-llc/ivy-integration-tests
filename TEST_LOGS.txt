========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 1910.96s (0:31:50) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_Boxes[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes = ivy.transpile(kornia.geometry.boxes.Boxes, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
        transpiled_boxes = TranspiledBoxes.from_tensor(*transpiled_args, mode="xyxy")
        _check_boxes_same(torch_boxes, transpiled_boxes)
    
        # test .compute_area
        torch_area = torch_boxes.compute_area()
        transpiled_area = transpiled_boxes.compute_area()
        _to_numpy_and_allclose(torch_area, transpiled_area)
    
        # test .get_boxes_shape
        torch_heights, torch_widths = torch_boxes.get_boxes_shape()
        transpiled_heights, transpiled_widths = transpiled_boxes.get_boxes_shape()
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .merge
        torch_x = torch.as_tensor([[6, 6, 10, 10], [6, 6, 10, 10]])
        transpiled_x = _nest_torch_tensor_to_new_framework(torch_x, target_framework)
        merge_boxes = kornia.geometry.boxes.Boxes.from_tensor(torch_x, mode="xyxy")
        transpiled_merge_boxes = TranspiledBoxes.from_tensor(transpiled_x, mode="xyxy")
        torch_merged_boxes = torch_boxes.merge(merge_boxes)
        transpiled_merged_boxes = transpiled_boxes.merge(transpiled_merge_boxes)
        _check_boxes_same(torch_merged_boxes, transpiled_merged_boxes)
    
        # test .to_mask
        height, width = 10, 10
        torch_mask = torch_boxes.to_mask(height, width)
        transpiled_mask = transpiled_boxes.to_mask(height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0....., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(2, 10, 10), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0....,
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
__________________________________________________________________________________ test_Boxes3D[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes3D = ivy.transpile(kornia.geometry.boxes.Boxes3D, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
        transpiled_boxes3d = TranspiledBoxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
        _check_boxes_same(torch_boxes3d, transpiled_boxes3d)
    
        # test .get_boxes_shape
        torch_depths, torch_heights, torch_widths = torch_boxes3d.get_boxes_shape()
        transpiled_depths, transpiled_heights, transpiled_widths = transpiled_boxes3d.get_boxes_shape()
        _to_numpy_and_allclose(torch_depths, transpiled_depths)
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .to_mask
        depth, height, width = 10, 10, 10
        torch_mask = torch_boxes3d.to_mask(depth, height, width)
        transpiled_mask = transpiled_boxes3d.to_mask(depth, height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0... [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
transpiled_x = <tf.Tensor: shape=(2, 10, 10, 10), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0.,...., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
y = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
==================================================================================== 2 failed in 233.28s (0:03:53) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py F                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_Quaternion[jax-s2s-False] ____________________________________________________________________________________

args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f64a4545f30>
array_like = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), pattern = '_bknd_|_bknd|_frnt_|_frnt', fn_name = 'data', new_fn = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
            return fn(*args, **kwargs)
        else:
            pattern = "_bknd_|_bknd|_frnt_|_frnt"
            fn_name = extract_function_name(re.sub(pattern, "", fn.__name__))
            try:
                new_fn = getattr(array_like, fn_name)
                if not callable(new_fn):
                    return new_fn
>               return new_fn(*args[1:], **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), args = (), kwargs = {}

    def __call__(self, *args, **kwargs) -> tp.Any:
>     return self.value(*args, **kwargs)  # type: ignore
E     TypeError: 'jaxlib.xla_extension.ArrayImpl' object is not callable

/opt/fw/jax/flax/nnx/variablelib.py:435: TypeError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py", line 208, in wrapper
    return new_fn(*args[1:], **kwargs)
  File "/opt/fw/jax/flax/nnx/variablelib.py", line 435, in __call__
    return self.value(*args, **kwargs)  # type: ignore
TypeError: 'jaxlib.xla_extension.ArrayImpl' object is not callable

During handling of the above exception, another exception occurred:

TypeError: float() argument must be a string or a real number, not 'jax_Quaternion'

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Quaternion(target_framework, mode, backend_compile):
        print("kornia.geometry.quaternion.Quaternion")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledQuaternion = ivy.transpile(Quaternion, source="torch", target=target_framework)
    
        # test Quaternion.identity
    
        torch_q = Quaternion.identity(batch_size=4)
        transpiled_q = TranspiledQuaternion.identity(batch_size=4)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__add__
    
        torch_q1 = Quaternion.identity()
        torch_q2 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q3 = torch_q1 + torch_q2
        transpiled_q1 = TranspiledQuaternion.identity()
        transpiled_q2 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
>       transpiled_q3 = transpiled_q1 + transpiled_q2

kornia/geometry/test_quaternion.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([1., 0., 0., 0.], dtype=float32)
), right = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    def __add__(self, right):
        from ..core.check import jax_KORNIA_CHECK_TYPE
        from ...ivy.functional.frontends.torch.tensor import jax_data_frnt_
    
        jax_KORNIA_CHECK_TYPE(right, jax_Quaternion)
>       return jax_Quaternion(self.data + jax_data_frnt_(right))

ivy_transpiled_outputs/jax_outputs/kornia/geometry/quaternion.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f64a4545f30>
array_like = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), pattern = '_bknd_|_bknd|_frnt_|_frnt', fn_name = 'data', new_fn = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
            return fn(*args, **kwargs)
        else:
            pattern = "_bknd_|_bknd|_frnt_|_frnt"
            fn_name = extract_function_name(re.sub(pattern, "", fn.__name__))
            try:
                new_fn = getattr(array_like, fn_name)
                if not callable(new_fn):
                    return new_fn
                return new_fn(*args[1:], **kwargs)
            except Exception:
>               return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @jax_handle_methods
    def jax_data_frnt_(tensor):
        from .creation_ops import jax_tensor_frnt
        from ...backends.jax.gradients import jax_stop_gradient
    
>       return jax_tensor_frnt(jax_stop_gradient(tensor, preserve_type=False))

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)], kwargs = {'preserve_type': False}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f64a4545f30>
jax_set_item = <function jax_set_item at 0x7f64a45612d0>, jax_asarray = <function jax_asarray at 0x7f64a4546830>, jax_get_item = <function jax_get_item at 0x7f64a4561120>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('preserve_type', <Parameter "preserve_type: bool = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'preserve_type', 'out'], annotations = [<class 'jax.Array'>, <class 'bool'>, typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
>                       args = jax_set_item(args, i, jax_asarray(arg, device=device))

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)], kwargs = {'device': CpuDevice(id=0)}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f64a4545f30>
jax_set_item = <function jax_set_item at 0x7f64a45612d0>, jax_asarray = <function jax_asarray at 0x7f64a4546830>, jax_get_item = <function jax_get_item at 0x7f64a4561120>, num_args = 1
type_hints = mappingproxy(OrderedDict([('obj', <Parameter "obj: Union[jax.Array, bool, int, float, tuple, ivy_transpiled_outputs.ja...', <Parameter "device: jaxlib.xla_extension.Device = None">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['obj', 'copy', 'dtype', 'device', 'out']
annotations = [typing.Union[jax.Array, bool, int, float, tuple, ivy_transpiled_outputs.jax_outputs.ivy.functional.ivy.creation.jax_N...typing.Optional[bool], typing.Optional[numpy.dtype], <class 'jaxlib.xla_extension.Device'>, typing.Optional[jax.Array]]
device = None, i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = None, args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {'device': CpuDevice(id=0)}, jax_default_dtype_bknd = <function jax_default_dtype_bknd at 0x7f64a4545480>
jax_to_ivy_bknd_ = <function jax_to_ivy_bknd_ at 0x7f64a45397e0>, new_arg = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)
new_args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),)

    @functools.wraps(fn)
    def _asarray_to_native_arrays_and_back_wrapper(*args, dtype=None, **kwargs):
        from .data_type import jax_default_dtype_bknd
        from ...data_classes.array.conversions import jax_to_ivy_bknd_
    
        new_arg = args[0]
        new_args = (new_arg,) + args[1:]
        if dtype is not None:
            dtype = jax_default_dtype_bknd(dtype=dtype, as_native=True)
>       return jax_to_ivy_bknd_(fn(*new_args, dtype=dtype, **kwargs))

ivy_transpiled_outputs/jax_outputs/ivy/functional/ivy/creation.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = <class 'jax.numpy.float32'>, args = (Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
),), kwargs = {'device': CpuDevice(id=0)}
jax_default_float_dtype_bknd = <function jax_default_float_dtype_bknd at 0x7f64a4545360>, jax_as_native_dtype = <function jax_as_native_dtype at 0x7f64a4547760>
jax_exists_bknd = <function jax_exists_bknd at 0x7f64a4546050>, jax_nested_map_bknd = <function jax_nested_map_bknd at 0x7f64a4546440>
jax_promote_types_bknd = <function jax_promote_types_bknd at 0x7f64a4545990>, arr = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype_list = [<class 'jax.numpy.float32'>]

    @functools.wraps(fn)
    def _asarray_infer_dtype_wrapper(*args, dtype=None, **kwargs):
        from .data_type import jax_default_float_dtype_bknd
        from ..backends.jax.data_type import jax_as_native_dtype
        from .general import jax_exists_bknd
        from .nest import jax_nested_map_bknd
        from .data_type import jax_promote_types_bknd
    
        def _infer_dtype(obj):
            from .data_type import jax_default_dtype_bknd
    
            if isinstance(obj, tuple):
                obj = list(obj)
            if hasattr(obj, "dtype"):
                return obj.dtype.name if isinstance(obj, np.ndarray) else obj.dtype
            else:
                return jax_default_dtype_bknd(item=obj)
    
        if not jax_exists_bknd(dtype):
            arr = args[0]
            dtype_list = [
                jax_nested_map_bknd(lambda x: _infer_dtype(x), arr, shallow=False)
            ]
            dtype_list = jax__flatten_nest_bknd(dtype_list)
            dtype_list = list(set(dtype_list))
            if len(dtype_list) != 0:
                dtype = dtype_list[0]
                for dt in dtype_list[1:]:
                    dtype = jax_promote_types_bknd(dtype, dt)
            else:
                dtype = jax_default_float_dtype_bknd()
            dtype = jax_as_native_dtype(dtype)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/functional/ivy/creation.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
)

    @jax_handle_array_like_without_promotion
    @jax__asarray_to_native_arrays_and_back_bknd
    @jax__asarray_infer_dtype_bknd
    def jax_asarray(
        obj: Union[
            jax.Array,
            bool,
            int,
            float,
            tuple,
            jax_NestedSequence_bknd,
            SupportsBufferProtocol,
            np.ndarray,
        ],
        /,
        *,
        copy: Optional[bool] = None,
        dtype: Optional[jax.numpy.dtype] = None,
        device: jaxlib.xla_extension.Device = None,
        out: Optional[jax.Array] = None,
    ):
        from ...ivy.device import jax_dev_bknd
    
>       ret = jax.numpy.asarray(obj, dtype=dtype)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/creation.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype = dtype('float32'), order = None

    def asarray(a: Any, dtype: DTypeLike | None = None, order: str | None = None,
                *, copy: bool | None = None,
                device: xc.Device | Sharding | None = None) -> Array:
      """Convert an object to a JAX array.
    
      JAX implementation of :func:`numpy.asarray`.
    
      Args:
        a: an object that is convertible to an array. This includes JAX
          arrays, NumPy arrays, Python scalars, Python collections like lists
          and tuples, objects with an ``__array__`` method, and objects
          supporting the Python buffer protocol.
        dtype: optionally specify the dtype of the output array. If not
          specified it will be inferred from the input.
        order: not implemented in JAX
        copy: optional boolean specifying the copy mode. If True, then always
          return a copy. If False, then error if a copy is necessary. Default is
          None, which will only copy when necessary.
        device: optional :class:`~jax.Device` or :class:`~jax.sharding.Sharding`
          to which the created array will be committed.
    
      Returns:
        A JAX array constructed from the input.
    
      See also:
        - :func:`jax.numpy.array`: like `asarray`, but defaults to `copy=True`.
        - :func:`jax.numpy.from_dlpack`: construct a JAX array from an object
          that implements the dlpack interface.
        - :func:`jax.numpy.frombuffer`: construct a JAX array from an object
          that implements the buffer interface.
    
      Examples:
        Constructing JAX arrays from Python scalars:
    
        >>> jnp.asarray(True)
        Array(True, dtype=bool)
        >>> jnp.asarray(42)
        Array(42, dtype=int32, weak_type=True)
        >>> jnp.asarray(3.5)
        Array(3.5, dtype=float32, weak_type=True)
        >>> jnp.asarray(1 + 1j)
        Array(1.+1.j, dtype=complex64, weak_type=True)
    
        Constructing JAX arrays from Python collections:
    
        >>> jnp.asarray([1, 2, 3])  # list of ints -> 1D array
        Array([1, 2, 3], dtype=int32)
        >>> jnp.asarray([(1, 2, 3), (4, 5, 6)])  # list of tuples of ints -> 2D array
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.asarray(range(5))
        Array([0, 1, 2, 3, 4], dtype=int32)
    
        Constructing JAX arrays from NumPy arrays:
    
        >>> jnp.asarray(np.linspace(0, 2, 5))
        Array([0. , 0.5, 1. , 1.5, 2. ], dtype=float32)
    
        Constructing a JAX array via the Python buffer interface, using Python's
        built-in :mod:`array` module.
    
        >>> from array import array
        >>> pybuffer = array('i', [2, 3, 5, 7])
        >>> jnp.asarray(pybuffer)
        Array([2, 3, 5, 7], dtype=int32)
      """
      # For copy=False, the array API specifies that we raise a ValueError if the input supports
      # the buffer protocol but a copy is required. Since array() supports the buffer protocol
      # via numpy, this is only the case when the default device is not 'cpu'
      if (copy is False and not isinstance(a, Array)
          and jax.default_backend() != 'cpu'
          and _supports_buffer_protocol(a)):
        raise ValueError(f"jnp.asarray: cannot convert object of type {type(a)} to JAX Array "
                         f"on backend={jax.default_backend()!r} with copy=False. "
                          "Consider using copy=None or copy=True instead.")
      dtypes.check_user_dtype_supported(dtype, "asarray")
      if dtype is not None:
        dtype = dtypes.canonicalize_dtype(dtype, allow_extended_dtype=True)  # type: ignore[assignment]
>     return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = Param(
  value=Array([2., 0., 1., 1.], dtype=float32)
), dtype = dtype('float32'), copy = False, order = None, ndmin = 0

    def array(object: Any, dtype: DTypeLike | None = None, copy: bool = True,
              order: str | None = "K", ndmin: int = 0,
              *, device: xc.Device | Sharding | None = None) -> Array:
      """Convert an object to a JAX array.
    
      JAX implementation of :func:`numpy.array`.
    
      Args:
        object: an object that is convertible to an array. This includes JAX
          arrays, NumPy arrays, Python scalars, Python collections like lists
          and tuples, objects with an ``__array__`` method, and objects
          supporting the Python buffer protocol.
        dtype: optionally specify the dtype of the output array. If not
          specified it will be inferred from the input.
        copy: specify whether to force a copy of the input. Default: True.
        order: not implemented in JAX
        ndmin: integer specifying the minimum number of dimensions in the
          output array.
        device: optional :class:`~jax.Device` or :class:`~jax.sharding.Sharding`
          to which the created array will be committed.
    
      Returns:
        A JAX array constructed from the input.
    
      See also:
        - :func:`jax.numpy.asarray`: like `array`, but by default only copies
          when necessary.
        - :func:`jax.numpy.from_dlpack`: construct a JAX array from an object
          that implements the dlpack interface.
        - :func:`jax.numpy.frombuffer`: construct a JAX array from an object
          that implements the buffer interface.
    
      Examples:
        Constructing JAX arrays from Python scalars:
    
        >>> jnp.array(True)
        Array(True, dtype=bool)
        >>> jnp.array(42)
        Array(42, dtype=int32, weak_type=True)
        >>> jnp.array(3.5)
        Array(3.5, dtype=float32, weak_type=True)
        >>> jnp.array(1 + 1j)
        Array(1.+1.j, dtype=complex64, weak_type=True)
    
        Constructing JAX arrays from Python collections:
    
        >>> jnp.array([1, 2, 3])  # list of ints -> 1D array
        Array([1, 2, 3], dtype=int32)
        >>> jnp.array([(1, 2, 3), (4, 5, 6)])  # list of tuples of ints -> 2D array
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.array(range(5))
        Array([0, 1, 2, 3, 4], dtype=int32)
    
        Constructing JAX arrays from NumPy arrays:
    
        >>> jnp.array(np.linspace(0, 2, 5))
        Array([0. , 0.5, 1. , 1.5, 2. ], dtype=float32)
    
        Constructing a JAX array via the Python buffer interface, using Python's
        built-in :mod:`array` module.
    
        >>> from array import array
        >>> pybuffer = array('i', [2, 3, 5, 7])
        >>> jnp.array(pybuffer)
        Array([2, 3, 5, 7], dtype=int32)
      """
      if order is not None and order != "K":
        raise NotImplementedError("Only implemented for order='K'")
    
      # check if the given dtype is compatible with JAX
      dtypes.check_user_dtype_supported(dtype, "array")
    
      # Here we make a judgment call: we only return a weakly-typed array when the
      # input object itself is weakly typed. That ensures asarray(x) is a no-op
      # whenever x is weak, but avoids introducing weak types with something like
      # array([1, 2, 3])
      weak_type = dtype is None and dtypes.is_weakly_typed(object)
      sharding = canonicalize_device_to_sharding(device)
    
      # Use device_put to avoid a copy for ndarray inputs.
      if (not copy and isinstance(object, np.ndarray) and
          (dtype is None or dtype == object.dtype) and (ndmin <= object.ndim) and
          device is None):
        # Keep the output uncommitted.
        return jax.device_put(object)
    
      # For Python scalar literals, call coerce_to_array to catch any overflow
      # errors. We don't use dtypes.is_python_scalar because we don't want this
      # triggering for traced values. We do this here because it matters whether or
      # not dtype is None. We don't assign the result because we want the raw object
      # to be used for type inference below.
      if isinstance(object, (bool, int, float, complex)):
        _ = dtypes.coerce_to_array(object, dtype)
      elif not isinstance(object, Array):
        # Check if object supports any of the data exchange protocols
        # (except dlpack, see data-apis/array-api#301). If it does,
        # consume the object as jax array and continue (but not return) so
        # that other array() arguments get processed against the input
        # object.
        #
        # Notice that data exchange protocols define dtype in the
        # corresponding data structures and it may not be available as
        # object.dtype. So, we'll resolve the protocols here before
        # evaluating object.dtype.
        if hasattr(object, '__jax_array__'):
          object = object.__jax_array__()
        elif hasattr(object, '__cuda_array_interface__'):
          cai = object.__cuda_array_interface__
          backend = xla_bridge.get_backend("cuda")
          if cuda_plugin_extension is None:
            device_id = None
          else:
            device_id = cuda_plugin_extension.get_device_ordinal(cai["data"][0])
          object = xc._xla.cuda_array_interface_to_buffer(
              cai=cai, gpu_backend=backend, device_id=device_id)
    
      object = tree_map(lambda leaf: leaf.__jax_array__()
                        if hasattr(leaf, "__jax_array__") else leaf, object)
      leaves = tree_leaves(object, is_leaf=lambda x: x is None)
      if any(leaf is None for leaf in leaves):
        # Added Nov 16 2023
        if deprecations.is_accelerated("jax-numpy-array-none"):
          raise TypeError("None is not a valid value for jnp.array")
        warnings.warn(
          "None encountered in jnp.array(); this is currently treated as NaN. "
          "In the future this will result in an error.",
          FutureWarning, stacklevel=2)
        leaves = tree_leaves(object)
      if dtype is None:
        # Use lattice_result_type rather than result_type to avoid canonicalization.
        # Otherwise, weakly-typed inputs would have their dtypes canonicalized.
        try:
          dtype = dtypes._lattice_result_type(*leaves)[0] if leaves else dtypes.float_
        except TypeError:
          # This happens if, e.g. one of the entries is a memoryview object.
          # This is rare, so we only handle it if the normal path fails.
          leaves = [_convert_to_array_if_dtype_fails(leaf) for leaf in leaves]
          dtype = dtypes._lattice_result_type(*leaves)[0]
    
      if not weak_type:
        dtype = dtypes.canonicalize_dtype(dtype, allow_extended_dtype=True)  # type: ignore[assignment]
    
      out: ArrayLike
    
      if all(not isinstance(leaf, Array) for leaf in leaves):
        # TODO(jakevdp): falling back to numpy here fails to overflow for lists
        # containing large integers; see discussion in
        # https://github.com/jax-ml/jax/pull/6047. More correct would be to call
        # coerce_to_array on each leaf, but this may have performance implications.
>       out = np.asarray(object, dtype=dtype)
E       ValueError: setting an array element with a sequence.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5010: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.quaternion.Quaternion
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_quaternion.py::test_Quaternion[jax-s2s-False] - ValueError: setting an array element with a sequence.
===================================================================================== 1 failed in 98.01s (0:01:38) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_solve_pnp_dlt[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fad52488af0>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fad52488af0>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = Array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]], dtype=float64)
img_points = Array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]], dtype=float64)
intrinsics = Array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]], dtype=float64), weights = None, svd_eps = 0.001

    def jax_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...utils.helpers import jax__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import jax_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_inverse_frnt
        from ..conversions import jax_convert_points_to_homogeneous
        from ..linalg import jax_transform_points
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            jax_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...utils.misc import jax_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import jax_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import jax_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import jax_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = jnp.float32, jnp.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if len(jax_shape_frnt_(world_points)) != 3 or jax_shape_frnt_(world_points)[2] != 3:
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {jax_shape_frnt_(world_points)}."
            )
        if len(jax_shape_frnt_(img_points)) != 3 or jax_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {jax_shape_frnt_(img_points)}."
            )
        if len(jax_shape_frnt_(intrinsics)) != 3 or jax_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {jax_shape_frnt_(intrinsics)}."
            )
        if jax_shape_frnt_(world_points)[1] != jax_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(img_points)[0]
            or jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if jax_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {jax_shape_frnt_(world_points)[1]} points."
            )
        B, N = jax_shape_frnt_(world_points)[:2][0], jax_shape_frnt_(world_points)[:2][1]
        world_points_norm, world_transform_norm = jax__mean_isotropic_scale_normalize(
            world_points
        )
        s = jax__torch_linalg_svdvals(world_points_norm)
        if jax_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = jax_inverse_frnt(intrinsics)
        world_points_norm_h = jax_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = jax_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = jax__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = jax_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = jax_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = jax_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = jax_eye_like(4, solution)
        solution_4x4 = jax_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = jax_bmm_frnt(solution_4x4, world_transform_norm)
        solution = jax_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = jax_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = jax_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/calibration/pnp.py:217: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': Array([[0.0754885 , 0.02388222, 0.0574928 ]], dtype=float64), 'p': 2}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7facd0422290>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[jax-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 302.85s (0:05:02) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py s                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.14s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 5 skipped in 5.00s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_get_laf_descriptors[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f244ad99b40>
trace_args = (tensor([[[[0.7522, 0.4132, 0.8719,  ..., 0.8984, 0.2291, 0.5237],
          [0.1222, 0.6994, 0.3753,  ..., 0.1973, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.6195, 0.9099, 0.7745,  ..., 0.0294, 0.5017, 0.6430],
          [0.0609, 0.6197, 0.3575,  ..., 0.0544, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7f244ad99b40>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.7522, 0.4132, 0.8719,  ..., 0.8984, 0.2291, 0.5237],
          [0.1222, 0.6994, 0.3753,  ..., 0.1973, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.6195, 0.9099, 0.7745,  ..., 0.0294, 0.5017, 0.6430],
          [0.0609, 0.6197, 0.3575,  ..., 0.0544, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
>       transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]

helpers.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <enumerate object at 0x7f23c4405640>

    transpiled_trace_args = [
>       transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
        for i, arg in enumerate(trace_args)
    ]

helpers.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arg = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
arg_class_info = {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}

    def transpile_and_instantiate(arg, arg_class_info=None):
        if arg_class_info:
            # If we have class info, transpile the class and instantiate it
            transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
            args = arg_class_info.get('args', ())
            kwargs = arg_class_info.get('kwargs', {})
            transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
            transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
>           return transpiled_class(*transpiled_args, **transpiled_kwargs)

helpers.py:282: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, args = (), kwargs = {'pretrained': False}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, args = (), kwargs = {'pretrained': False}, node = jax_OriNet()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, self = jax_OriNet(), args = (), kwargs = {'pretrained': False}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_OriNet(), pretrained = False, eps = 1e-08

    def __init__(self, pretrained=False, eps=1e-08):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.activation import jax_Tanh
        from ...torch.nn.modules.pooling import jax_AdaptiveAvgPool2d
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=32,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.25),
            FlaxConv(
                in_features=64,
                out_features=2,
                kernel_size=8,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=True,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_Tanh(),
            jax_AdaptiveAvgPool2d(1),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/orientation.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}
node = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 16, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
============================================================================== 1 failed, 18 passed in 1352.14s (0:22:32) ===============================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ........                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 454.37s (0:07:34) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py .........F...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_ScaleSpaceDetector[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledScaleSpaceDetector = ivy.transpile(kornia.feature.ScaleSpaceDetector, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = TranspiledScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature3.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[1.339249  , 1.9840789 , 0.9330517 , ..., 6.9339056 ...
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f0c6dbc19a0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[1.339249  , 1.9840789 , 0.9330517 , ..., 6.9339056 ...
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[1.339249  , 1.9840789 , 0.9330517 , ..., 6.9339056 ...
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[1.339249  , 1.9840789 , 0.9330517 , ..., 6.9339056 ,...],
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img, mask=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...es=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF()),)
kwargs = {'img': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[1.339249  , 1.9840789 , 0.9330517 , ..., 6.9...,
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[1.339249  , 1.9840789 , 0.9330517 , ..., 6.9339056 ,...],
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>
mask = None

    def call(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[1.339249  , 1.9840789 , 0.9330517 , ..., 6.9339056 ,...],
         [0.80800235, 4.962482  , 2.7780242 , ..., 2.3440468 ,
          4.7432942 , 7.9673867 ]]]], dtype=float32)>
num_feats = 500, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import (
            tensorflow_topk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from .laf import tensorflow_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
        sp, sigmas, _ = self.scale_pyr(img)
        all_responses: typing.Any = []
        all_lafs: typing.Any = []
        px_size = 0.5 if self.scale_pyr.double_image else 1.0
        for oct_idx, octave in enumerate(sp):
            sigmas_oct = tensorflow_get_item(sigmas, oct_idx)
            B, CH, L, H, W = tensorflow_size_frnt_(octave)
            if self.scale_space_response:
                oct_resp = self.resp(octave, tensorflow_view_frnt_(sigmas_oct, -1))
            else:
                oct_resp = tensorflow_view_frnt_(
                    self.resp(
                        tensorflow_reshape_frnt_(
                            tensorflow_permute_frnt_(octave, 0, 2, 1, 3, 4),
                            B * L,
                            CH,
                            H,
                            W,
                        ),
                        tensorflow_view_frnt_(sigmas_oct, -1),
                    ),
                    B,
                    L,
                    CH,
                    H,
                    W,
                )
                oct_resp = tensorflow_permute_frnt_(oct_resp, 0, 2, 1, 3, 4)
                if (
                    isinstance(
                        self.scale_pyr.extra_levels,
                        (tensorflow.Tensor, tensorflow.keras.Variable),
                    )
                    and self.scale_pyr.extra_levels % 2 != 0
                ):
                    oct_resp = oct_resp[:, :, :-1]
            if mask is not None:
                oct_mask: typing.Any = tensorflow__create_octave_mask(
                    mask, tensorflow_shape_frnt_(oct_resp)
                )
                oct_resp = oct_mask * oct_resp
            coord_max: typing.Any
            response_max: typing.Any
            coord_max, response_max = self.nms(oct_resp)
            if self.minima_are_also_good:
                coord_min, response_min = self.nms(-oct_resp)
                take_min_mask = tensorflow_to_frnt_(
                    response_min > response_max, response_max.dtype
                )
                response_max = (
                    response_min * take_min_mask + (1 - take_min_mask) * response_max
                )
                coord_max = (
                    coord_min * tensorflow_unsqueeze_frnt_(take_min_mask, 2)
                    + (1 - tensorflow_unsqueeze_frnt_(take_min_mask, 2)) * coord_max
                )
            responses_flatten = tensorflow_view_frnt_(
                response_max, tensorflow_size_frnt_(response_max, 0), -1
            )
            max_coords_flatten = tensorflow_permute_frnt_(
                tensorflow_view_frnt_(
                    coord_max, tensorflow_size_frnt_(response_max, 0), 3, -1
                ),
                0,
                2,
                1,
            )
            if tensorflow_size_frnt_(responses_flatten, 1) > num_feats:
                resp_flat_best, idxs = tensorflow_topk_frnt(
                    responses_flatten, k=num_feats, dim=1
                )
                max_coords_best = tensorflow_gather_frnt(
                    max_coords_flatten,
                    1,
                    tensorflow_repeat_frnt_(
                        tensorflow_unsqueeze_frnt_(idxs, -1), 1, 1, 3
                    ),
                )
            else:
                resp_flat_best = responses_flatten
                max_coords_best = max_coords_flatten
            B, N = tensorflow_size_frnt_(resp_flat_best)
            if isinstance(
                self.scale_pyr.n_levels, (tensorflow.Tensor, tensorflow.keras.Variable)
            ):
                num_levels = int(tensorflow_item_frnt_(self.scale_pyr.n_levels))
            elif isinstance(self.scale_pyr.n_levels, (int,)):
                num_levels = self.scale_pyr.n_levels
            else:
                raise TypeError(
                    f"Expected the scale pyramid module to have `n_levels` as a Tensor or int.Gotcha {type(self.scale_pyr.n_levels)}"
                )
            max_coords_best = tensorflow__scale_index_to_scale(
                max_coords_best, sigmas_oct, num_levels
            )
            rotmat = tensorflow_view_frnt_(eye(2, dtype=dtype, device=dev), 1, 1, 2, 2)
            current_lafs = concatenate(
                [
                    self.mr_size
                    * tensorflow_view_frnt_(max_coords_best[:, :, 0], B, N, 1, 1)
                    * rotmat,
                    tensorflow_view_frnt_(max_coords_best[:, :, 1:3], B, N, 2, 1),
                ],
                3,
            )
>           good_mask = tensorflow_laf_is_inside_image(current_lafs, octave[:, 0])

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:252: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 500, 2, 3), dtype=float32, numpy=
array([[[[10.725073 ,  0.       ,  7.073131 ],
         [ 0.  ...98]],

        [[27.115978 ,  0.       , 25.001326 ],
         [ 0.       , 27.115978 , 25.002047 ]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 6, 32, 32), dtype=float32, numpy=
array([[[[4.8743625, 4.976531 , 5.2145896, ..., 4.221934 , 4.2...68314 ],
         [4.920193 , 4.9250436, 4.938759 , ..., 5.2834496, 5.2745004,
          5.2711678]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ..., False,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False,  True,  True],
        [ True,  True,  True, ..., False,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True, False, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ..., False,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False,  True,  True],
        [ True,  True,  True, ..., False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True, False, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ..., False,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False,  True,  True],
        [ True,  True,  True, ..., False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True, False, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ..., False,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False,  True,  True],
        [ True,  True,  True, ..., False,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True, False, ...,  True,  True,  True],
        [ True,  True, False, ...,  True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpaceDetector.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ScaleSpaceDetector.call():
E         • img=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)
E         • mask=None

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:239: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpac...
============================================================================== 1 failed, 12 passed in 1968.65s (0:32:48) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 804.85s (0:13:24) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .F...F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_NerfModelRenderer[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
_________________________________________________________________________________ test_RandomRaySampler[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7febc09d4070>
cameras = <ivy_transpiled_outputs.jax_outputs.kornia.geometry.camera.pinhole.jax_PinholeCamera object at 0x7febc09d7640>, num_img_rays = Array([1], dtype=int64)

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != jax_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {jax_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:359: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7febc09d4070>, heights = Array([256], dtype=int64), widths = Array([256], dtype=int64)
num_img_rays = Array([1], dtype=int32)

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_trunc_frnt
        from ...ivy.functional.frontends.torch.random_sampling import jax_rand_frnt
    
        num_img_rays = jax_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                jax_tolist_frnt_(heights),
                jax_tolist_frnt_(widths),
                jax_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = jax_trunc_frnt(
>               jax_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
jax_random_uniform = <function jax_random_uniform at 0x7feba0aa7400>, seed = None

    def jax_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.jax.random import jax_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return jax_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/random_sampling.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, jax_exists_bknd = <function jax_exists_bknd at 0x7feba0b23640>
jax_default_dtype_bknd = <function jax_default_dtype_bknd at 0x7feba0b22a70>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import jax_exists_bknd
        from .functional.ivy.data_type import jax_default_dtype_bknd
    
        arr = None if jax_exists_bknd(dtype) else jax__get_first_array(*args, **kwargs)
        dtype = jax_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @jax_infer_dtype
    def jax_random_uniform(
        *,
        low: Union[float, jax.Array] = 0.0,
        high: Union[float, jax.Array, None] = 1.0,
        shape: Optional[Union[tuple, Sequence[int]]] = None,
        device: jaxlib.xla_extension.Device = None,
        dtype: jax.numpy.dtype,
        seed: Optional[int] = None,
        out: Optional[jax.Array] = None,
    ):
        from ...ivy.random import jax__check_bounds_and_get_shape_bknd
    
        if high is None:
            high = float(
                jax.numpy.finfo(dtype).max
                if dtype is not None
                else jax.numpy.finfo(jax.numpy.float32).max
            )
        shape = jax__check_bounds_and_get_shape_bknd(low, high, shape)
        if seed:
            rng_input = jax.random.PRNGKey(seed)
        else:
            RNG_, rng_input = jax.random.split(jax__getRNG())
            jax__setRNG(RNG_)
>       return jax.numpy.astype(
            jax.random.uniform(
                rng_input, shape, minval=low, maxval=high, dtype=jax.numpy.float32
            ),
            dtype,
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/random.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([0.10536897], dtype=float32), dtype = torch.float32

    def astype(x: ArrayLike, dtype: DTypeLike | None,
               /, *, copy: bool = False,
               device: xc.Device | Sharding | None = None) -> Array:
      """Convert an array to a specified dtype.
    
      JAX imlementation of :func:`numpy.astype`.
    
      This is implemented via :func:`jax.lax.convert_element_type`, which may
      have slightly different behavior than :func:`numpy.astype` in some cases.
      In particular, the details of float-to-int and int-to-float casts are
      implementation dependent.
    
      Args:
        x: input array to convert
        dtype: output dtype
        copy: if True, then always return a copy. If False (default) then only
          return a copy if necessary.
        device: optionally specify the device to which the output will be committed.
    
      Returns:
        An array with the same shape as ``x``, containing values of the specified
        dtype.
    
      See Also:
        - :func:`jax.lax.convert_element_type`: lower-level function for XLA-style
          dtype conversions.
    
      Examples:
        >>> x = jnp.array([0, 1, 2, 3])
        >>> x
        Array([0, 1, 2, 3], dtype=int32)
        >>> x.astype('float32')
        Array([0.0, 1.0, 2.0, 3.0], dtype=float32)
    
        >>> y = jnp.array([0.0, 0.5, 1.0])
        >>> y.astype(int)  # truncates fractional values
        Array([0, 0, 1], dtype=int32)
      """
      util.check_arraylike("astype", x)
      x_arr = asarray(x)
    
      if dtype is None:
        dtype = dtypes.canonicalize_dtype(float_)
>     dtypes.check_user_dtype_supported(dtype, "astype")

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5091: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, fun_name = 'astype'

    def check_user_dtype_supported(dtype, fun_name=None):
      if isinstance(dtype, Array):
        # Deprecation warning added 2024 June 13.
        warnings.warn("Passing an array as a dtype argument is deprecated; "
                      "instead of dtype=arr use dtype=arr.dtype.",
                      category=DeprecationWarning, stacklevel=3)
        return  # no further check needed, as array dtypes have already been validated.
>     if issubdtype(dtype, extended):

/opt/fw/jax/jax/_src/dtypes.py:776: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = torch.float32, b = <class 'jax.dtypes.extended'>

    def issubdtype(a: DTypeLike | ExtendedDType | None,
                   b: DTypeLike | ExtendedDType | None) -> bool:
      """Returns True if first argument is a typecode lower/equal in type hierarchy.
    
      This is like :func:`numpy.issubdtype`, but can handle dtype extensions such as
      :obj:`jax.dtypes.bfloat16` and `jax.dtypes.prng_key`.
      """
      # Main departures from np.issubdtype are:
      # - "extended" dtypes (like prng key types) are not normal numpy dtypes, so we
      #   need to handle them specifically. However, their scalar types do conform to
      #   the numpy scalar type hierarchy.
      # - custom dtypes (like bfloat16, int4, etc.) are normal numpy dtypes, but they
      #   don't conform to the standard numpy type hierarchy (e.g. the bfloat16 scalar
      #   type is not a subclass of np.floating) so we must also handle these specially.
    
      # We cannot use the cached version directly for all inputs, because some may be
      # unhashable (e.g. custom objects with a dtype attribute). The following check is
      # fast and covers the majority of calls to this function within JAX library code.
      return _issubdtype_cached(
>       a if isinstance(a, (type, np.dtype, ExtendedDType)) else np.dtype(a),  # type: ignore[arg-type]
        b if isinstance(b, (type, np.dtype, ExtendedDType)) else np.dtype(b),  # type: ignore[arg-type]
      )
E     TypeError: Cannot interpret 'torch.float32' as a data type

/opt/fw/jax/jax/_src/dtypes.py:363: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[jax-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_RandomRaySampler[jax-s2s-False] - TypeError: Cannot interpret 'torch.float32' as a data type
=============================================================================== 2 failed, 4 passed in 331.86s (0:05:31) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 172.80s (0:02:52) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_conv_quad_interp3d[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f8df1c5add0>
trace_args = (tensor([[[[[0.2490, 0.4837, 0.6035, 0.9476, 0.6639],
           [0.5828, 0.5368, 0.8226, 0.3019, 0.9470],
           ....3126],
           [0.1426, 0.3403, 0.6176, 0.4425, 0.1330],
           [0.7988, 0.8661, 0.4031, 0.3508, 0.1126]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.6562, 0.7867, 0.4575, 0.2931, 0.6455],
           [0.1481, 0.3977, 0.9763, 0.8240, 0.5938],
           ....7235],
           [0.7114, 0.3368, 0.1802, 0.1134, 0.4898],
           [0.2380, 0.7137, 0.1738, 0.7264, 0.3577]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f8df1c5add0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.2490, 0.4837, 0.6035, 0.9476, 0.6639],
           [0.5828, 0.5368, 0.8226, 0.3019, 0.9470],
           ....3126],
           [0.1426, 0.3403, 0.6176, 0.4425, 0.1330],
           [0.7988, 0.8661, 0.4031, 0.3508, 0.1126]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.6562, 0.7867, 0.4575, 0.2931, 0.6455],
           [0.1481, 0.3977, 0.9763, 0.8240, 0.5938],
           ....7235],
           [0.7114, 0.3368, 0.1802, 0.1134, 0.4898],
           [0.2380, 0.7137, 0.1738, 0.7264, 0.3577]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=float32, numpy=
array([[[[[0.24901813, 0.48367018, 0.6034889 , 0.9475703 , 0....4252628, 0.13298863],
          [0.79876196, 0.8660833 , 0.4030546 , 0.3508011 , 0.11258924]]]]],
      dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=bool, numpy=
array([[[[[False, False, False, False, False],
          [False,...alse, False, False],
          [False, False, False, False, False],
          [False, False, False, False, False]]]]])>
name = 'view'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________ test_ConvQuadInterp3d[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledConvQuadInterp3d = ivy.transpile(
            kornia.geometry.subpix.ConvQuadInterp3d, source="torch", target=target_framework
        )
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = TranspiledConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:371: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.680066  , -0.1182724 , -0.5563427 ,  1.390903 ...986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x555ba9f19d70, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...5986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.680066  , -0.1182724 , -0.5563427 ,  1.390903 ...986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...5986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.680066  , -0.1182724 , -0.5563427 ,  1.390903 ...986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.680066  , -0.1182724 , -0.5563427 ,  1.390903  ....5986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.680066  , -0.1182724 , -0.5563427 ,  1.39...5986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.680066  , -0.1182724 , -0.5563427 ,  1.390903  ....5986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>

    def call(self, x):
>       return tensorflow_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.680066  , -0.1182724 , -0.5563427 ,  1.390903  ....5986676 ],
          [-0.32200018,  0.23187046,  1.0921917 ,  0.03817286,
           -1.6551665 ]]]]], dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )
E       AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'[0m
E       
E       Arguments received by tensorflow_ConvQuadInterp3d.call():
E         • x=tf.Tensor(shape=(1, 1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:114: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
============================================================================== 2 failed, 13 passed in 1286.45s (0:21:26) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py .F......                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________ test_find_homography_dlt_iterated[jax-s2s-False] ___________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f020374b250>
trace_args = (tensor([[[0.5477, 0.1640],
         [0.0840, 0.1344],
         [0.7011, 0.9058],
         [0.9631, 0.3869]]]), tensor... [0.8373, 0.4931],
         [0.8894, 0.2972],
         [0.5817, 0.9097]]]), tensor([[0.4243, 0.2331, 0.8811, 0.1097]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.7104, 0.1322],
         [0.6404, 0.8792],
         [0.6956, 0.7122],
         [0.5693, 0.8633]],

       ...[0.5262, 0.0690, 0.4003, 0.3450],
        [0.8258, 0.0884, 0.9992, 0.1081],
        [0.9805, 0.4240, 0.0181, 0.8662]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f020374b250>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.5477, 0.1640],
         [0.0840, 0.1344],
         [0.7011, 0.9058],
         [0.9631, 0.3869]]]), tensor... [0.8373, 0.4931],
         [0.8894, 0.2972],
         [0.5817, 0.9097]]]), tensor([[0.4243, 0.2331, 0.8811, 0.1097]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.7104, 0.1322],
         [0.6404, 0.8792],
         [0.6956, 0.7122],
         [0.5693, 0.8633]],

       ...[0.5262, 0.0690, 0.4003, 0.3450],
        [0.8258, 0.0884, 0.9992, 0.1081],
        [0.9805, 0.4240, 0.0181, 0.8662]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.5477266 , 0.1639688 ],
        [0.08398956, 0.13435924],
        [0.70114654, 0.90582836],
        [0.9631189 , 0.38689464]]], dtype=float32)
points2 = Array([[[0.44826663, 0.8166738 ],
        [0.8373124 , 0.4930641 ],
        [0.88935244, 0.29716194],
        [0.58169085, 0.9097493 ]]], dtype=float32)
weights = Array([[0.42431402, 0.23306292, 0.88110596, 0.10970545]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def jax_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_exp_frnt
    
>       H: typing.Any = jax_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.5477266 , 0.1639688 ],
        [0.08398956, 0.13435924],
        [0.70114654, 0.90582836],
        [0.9631189 , 0.38689464]]], dtype=float32)
points2 = Array([[[0.44826663, 0.8166738 ],
        [0.8373124 , 0.4930641 ],
        [0.88935244, 0.29716194],
        [0.58169085, 0.9097493 ]]], dtype=float32)
weights = Array([[0.42431402, 0.23306292, 0.88110596, 0.10970545]], dtype=float32), solver = 'lu'

    def jax_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ..utils.helpers import jax__extract_device_dtype
        from .epipolar.fundamental import jax_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import jax_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import jax_diag_embed_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ..utils.helpers import jax__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import jax_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ..utils.helpers import jax_safe_solve_with_mask
        from ..utils.helpers import jax_safe_inverse_with_mask
    
        if jax_shape_frnt_(points1) != jax_shape_frnt_(points2):
            raise AssertionError(jax_shape_frnt_(points1))
        if jax_shape_frnt_(points1)[1] < 4:
            raise AssertionError(jax_shape_frnt_(points1))
        jax_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        jax_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = jax__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = jax_normalize_points(points1)
        points2_norm, transform2 = jax_normalize_points(points2)
        x1, y1 = jax_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = jax_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = jax_ones_like_v_0p4p0_and_above_frnt(x1), jax_zeros_like_frnt(x1)
        ax = jax_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = jax_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = jax_reshape_frnt_(
            jax_cat_frnt((ax, ay), dim=-1),
            jax_shape_frnt_(ax)[0],
            -1,
            jax_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = jax_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(jax_shape_frnt_(weights)) == 2
                and jax_shape_frnt_(weights) == jax_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(jax_shape_frnt_(weights))
            w_diag = jax_diag_embed_frnt(
                jax_reshape_frnt_(
                    jax_repeat_frnt_(jax_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    jax_shape_frnt_(weights)[0],
                    -1,
                )
            )
            A = jax_transpose_frnt_(A, -2, -1) @ w_diag @ A
        if solver == "svd":
            try:
                _, _, V = jax__torch_svd_cast(A)
            except RuntimeError:
                warnings.warn("SVD did not converge", RuntimeWarning)
                return jax_empty_frnt(
                    (jax_size_frnt_(points1_norm, 0), 3, 3), device=device, dtype=dtype
                )
            H = jax_view_frnt_(V[..., -1], -1, 3, 3)
        elif solver == "lu":
            B = jax_ones_frnt(
                jax_shape_frnt_(A)[0], jax_shape_frnt_(A)[1], device=device, dtype=dtype
            )
>           sol, _, _ = jax_safe_solve_with_mask(B, A)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)
A = Array([[[ 0.95934063,  0.98174834,  0.09748134,  0.        ,
          0.        ,  0.        , -0.48432666, -0.796562...6316,  0.18487746,
          2.5018568 ,  1.0128994 ,  1.1186106 ,  4.1261587 ,
          4.2898808 ]]], dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([[[ 0.95934063,  0.98174834,  0.09748134,  0.        ,
          0.        ,  0.        , -0.48432666, -0.796562...6316,  0.18487746,
          2.5018568 ,  1.0128994 ,  1.1186106 ,  4.1261587 ,
          4.2898808 ]]], dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([[[ 0.95934063,  0.98174834,  0.09748134,  0.        ,
          0.        ,  0.        , -0.48432666, -0.79656...316,  0.18487746,
          2.5018568 ,  1.0128994 ,  1.1186106 ,  4.1261587 ,
          4.2898808 ]]], dtype=float32)]
kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f017dda6680>, jax_set_item = <function jax_set_item at 0x7f017db35c60>
jax_asarray = <function jax_asarray at 0x7f017dda70a0>, jax_get_item = <function jax_get_item at 0x7f017db35ab0>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[ 0.95934063,  0.98174834,  0.09748134,  0.        ,
          0.        ,  0.        , -0.48432666, -0.796562...6316,  0.18487746,
          2.5018568 ,  1.0128994 ,  1.1186106 ,  4.1261587 ,
          4.2898808 ]]], dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
=============================================================================== 1 failed, 7 passed in 572.17s (0:09:32) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ssssssss                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 8 skipped in 5.32s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF......F..                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_diamond_square[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f05d2c612d0>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f05eafe68c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f05eafe68c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f05d2c612d0>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f05eafe68c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f05eafe68c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = Array([[[[0.5]]]], dtype=float64), random_scale = Array([[[[1.]]]], dtype=float64), random_fn = <built-in method ones of type object at 0x7f05eafe68c0>
normalize_range = (0.0, 1.0), device = None, dtype = None

    def jax_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=jax_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_expand_frnt_
        from ..core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..enhance.normalize import jax_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
    
        jax_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (jax.Array, nnx.Param)):
            random_scale = jax_to_frnt_(jnp.asarray([[[[random_scale]]]]), device, dtype)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            jax_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = jax_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = jax_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (jax.Array, nnx.Param)):
            roughness = jax_to_frnt_(jnp.asarray([[[[roughness]]]]), device, dtype)
            roughness = jax_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = jax_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = jax_expand_frnt_(roughness, [output_size[0], output_size[1], 1, 1])
            roughness = jax_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * jax__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )
E       TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'

ivy_transpiled_outputs/jax_outputs/kornia/contrib/diamond_square.py:225: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
___________________________________________________________________________________ test_EdgeDetector[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
        transpiled_detector = transpiled_kornia.contrib.EdgeDetector()
    
        torch_args = (
            torch.rand(1, 3, 320, 320),
        )
        torch_out = torch_detector(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_detector(*transpiled_args)

kornia/test_contrib.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_EdgeDetector(
  (model): jax_DexiNed(
    (block_1): jax_DoubleConvBlock(
      (conv1): FlaxConv(in_features=3, o..., 1), padding=0, padding_mode=zeros)
      (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
    )
  )
)
image = Array([[[[0.2172715 , 0.7614934 , 0.92014974, ..., 0.61573625,
          0.57620037, 0.14166588],
         [0.12614578...1],
         [0.5948425 , 0.3967188 , 0.08347821, ..., 0.69068503,
          0.6012295 , 0.32693255]]]], dtype=float32)

    def __call__(self, image):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
    
        jax_KORNIA_CHECK_SHAPE(image, ["B", "3", "H", "W"])
        img = self.preprocess(image)
>       out = self.model(img)

ivy_transpiled_outputs/jax_outputs/kornia/contrib/edge_detection.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DexiNed(
  (block_1): jax_DoubleConvBlock(
    (conv1): FlaxConv(in_features=3, out_features=32, kernel_size=(3, 3...rides=(1, 1), padding=0, padding_mode=zeros)
    (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
  )
)
x = Array([[[[0.2172715 , 0.7614934 , 0.92014974, ..., 0.61573625,
          0.57620037, 0.14166588],
         [0.12614578...1],
         [0.5948425 , 0.3967188 , 0.08347821, ..., 0.69068503,
          0.6012295 , 0.32693255]]]], dtype=float32)

    def __call__(self, x):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core._backend import concatenate
    
        block_1 = self.block_1(x)
>       block_1_side = self.side_1(block_1)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SingleConvBlock(
  (conv): FlaxConv(in_features=64, out_features=128, kernel_size=(1, 1), strides=(2, 2), padding=0, padding_mode=zeros)
  (bn): FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
)
x = Array([[[[-0.00948071,  0.03314681, -0.04360859, ..., -0.10233232,
           0.02474894, -0.03414265],
         [-0.0...       [ 0.07187597, -0.03409389,  0.0371651 , ..., -0.11455362,
           0.00706864,  0.12988041]]]], dtype=float32)

    def __call__(self, x):
        x = self.conv(x)
        if self.use_bn:
>           x = self.bn(x)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-0.00948071,  0.03314681, -0.04360859, ..., -0.10233232,
           0.02474894, -0.03414265],
         [-0....     [ 0.07187597, -0.03409389,  0.0371651 , ..., -0.11455362,
           0.00706864,  0.12988041]]]], dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55a2d3142410, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...y', lineno=159, function='pytest_pyfunc_call', code_context=['    result = testfunction(**testargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-0.00948071,  0.03314681, -0.04360859, ..., -0.10233232,
           0.02474894, -0.03414265],
         [-0....     [ 0.07187597, -0.03409389,  0.0371651 , ..., -0.11455362,
           0.00706864,  0.12988041]]]], dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7f053c52b520>, jax_set_item = <function jax_set_item at 0x7f053c52b6d0>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[-0.00948071,  0.07961645, -0.10234613, ...,  0.1860611 ,
          -0.20221227,  0.07944565],
   ...      [ 0.15515195,  0.18590339, -0.21088396, ..., -0.08153155,
          -0.32902315,  0.12988041]]]], dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f053e248280>, next_call_in_seq = None, conv_block_continued = None
arg_name = 'inputs'
input = Array([[[[-0.00948071,  0.03314681, -0.04360859, ..., -0.10233232,
           0.02474894, -0.03414265],
         [-0.0...       [ 0.07187597, -0.03409389,  0.0371651 , ..., -0.11455362,
           0.00706864,  0.12988041]]]], dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
inputs = Array([[[[-0.00948071,  0.07961645, -0.10234613, ...,  0.1860611 ,
          -0.20221227,  0.07944565],
         [ 0.0...       [ 0.15515195,  0.18590339, -0.21088396, ..., -0.08153155,
          -0.32902315,  0.12988041]]]], dtype=float32)
use_running_average = None

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs, use_running_average=None, *, mask=None):
        self._built = True
>       logits = super().__call__(
            inputs, use_running_average=use_running_average, mask=mask
        )

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
x = Array([[[[-0.00948071,  0.07961645, -0.10234613, ...,  0.1860611 ,
          -0.20221227,  0.07944565],
         [ 0.0...       [ 0.15515195,  0.18590339, -0.21088396, ..., -0.08153155,
          -0.32902315,  0.12988041]]]], dtype=float32)
use_running_average = True

    def __call__(
      self,
      x,
      use_running_average: tp.Optional[bool] = None,
      *,
      mask: tp.Optional[jax.Array] = None,
    ):
      """Normalizes the input using batch statistics.
    
      Args:
        x: the input to be normalized.
        use_running_average: if true, the stored batch statistics will be
          used instead of computing the batch statistics on the input. The
          ``use_running_average`` flag passed into the call method will take
          precedence over the ``use_running_average`` flag passed into the
          constructor.
    
      Returns:
        Normalized inputs (the same shape as inputs).
      """
    
      use_running_average = first_from(
        use_running_average,
        self.use_running_average,
        error_msg="""No `use_running_average` argument was provided to BatchNorm
          as either a __call__ argument, class attribute, or nnx.flag.""",
      )
      feature_axes = _canonicalize_axes(x.ndim, self.axis)
      reduction_axes = tuple(i for i in range(x.ndim) if i not in feature_axes)
    
      if use_running_average:
        mean, var = self.mean.value, self.var.value
      else:
        mean, var = _compute_stats(
          x,
          reduction_axes,
          dtype=self.dtype,
          axis_name=self.axis_name,
          axis_index_groups=self.axis_index_groups,
          use_fast_variance=self.use_fast_variance,
          mask=mask,
        )
    
        self.mean.value = (
          self.momentum * self.mean.value + (1 - self.momentum) * mean
        )
        self.var.value = (
          self.momentum * self.var.value + (1 - self.momentum) * var
        )
    
>     return _normalize(
        x,
        mean,
        var,
        self.scale.value,
        self.bias.value,
        reduction_axes,
        feature_axes,
        self.dtype,
        self.epsilon,
      )

/opt/fw/jax/flax/nnx/nn/normalization.py:367: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[-0.00948071,  0.07961645, -0.10234613, ...,  0.1860611 ,
          -0.20221227,  0.07944565],
         [ 0.0...       [ 0.15515195,  0.18590339, -0.21088396, ..., -0.08153155,
          -0.32902315,  0.12988041]]]], dtype=float32)
mean = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
var = Param(
  value=Array([0.2625539 , 0.27113461, 0.21946596, 0.15521275, 0.25643   ,
         0.21336786, 0.39907008, 0.2...8342604, 0.5336697 , 0.19832538, 0.22804523, 0.6139669 ,
         0.32740036, 0.37694854, 0.2545803 ], dtype=float32)
)
scale = Array([0.9180028 , 0.85888755, 0.83077097, 0.8763835 , 0.96300054,
       0.8625907 , 0.8677793 , 0.9038065 , 0.968281... 0.9293163 , 0.97165966, 0.9689161 , 0.9450734 , 0.8873313 ,
       0.88254374, 0.99936277, 0.848198  ], dtype=float32)
bias = Array([-0.07675791, -0.03457952, -0.06084337,  0.0461219 , -0.04142413,
        0.07173445, -0.01962172,  0.00044565, ...8167, -0.02156175, -0.02820837,  0.02331718, -0.01897949,
        0.0239033 ,  0.00923689, -0.05559541], dtype=float32)
reduction_axes = (0, 1, 2), feature_axes = (3,), dtype = None, epsilon = 1e-05

    def _normalize(
      x: Array,
      mean: Array,
      var: Array,
      scale: tp.Optional[Array],
      bias: tp.Optional[Array],
      reduction_axes: Axes,
      feature_axes: Axes,
      dtype: tp.Optional[Dtype],
      epsilon: float,
    ):
      """ "Normalizes the input of a normalization layer and optionally applies a learned scale and bias.
    
      Arguments:
        x: The input.
        mean: Mean to use for normalization.
        var: Variance to use for normalization.
        reduction_axes: The axes in ``x`` to reduce.
        feature_axes: Axes containing features. A separate bias and scale is learned
          for each specified feature.
        dtype: The dtype of the result (default: infer from input and params).
        epsilon: Normalization epsilon.
    
      Returns:
        The normalized input.
      """
      reduction_axes = _canonicalize_axes(x.ndim, reduction_axes)
      feature_axes = _canonicalize_axes(x.ndim, feature_axes)
      stats_shape = list(x.shape)
      for axis in reduction_axes:
        stats_shape[axis] = 1
>     mean = mean.reshape(stats_shape)

/opt/fw/jax/flax/nnx/nn/normalization.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
name = 'reshape'

    def custom_getattr(self, name):
        if name in ("shape", "device", "dtype", "ndim", "size", "itemsize", "T"):
            value = getattr(self, "value")
            if value is not None:
                # Attempt to retrieve the attribute from the wrapped object (`value`)
                return getattr(value, name)
>       return object.__getattribute__(self, name)
E       AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?

ivy_transpiled_outputs/jax_outputs/__init__.py:91: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<05:45, 408kB/s]
  0%|          | 256k/135M [00:00<03:29, 672kB/s]
  0%|          | 512k/135M [00:00<01:53, 1.23MB/s]
  1%|          | 896k/135M [00:00<01:09, 2.01MB/s]
  1%|▏         | 1.75M/135M [00:00<00:34, 4.05MB/s]
  3%|▎         | 3.50M/135M [00:00<00:17, 8.08MB/s]
  5%|▍         | 6.12M/135M [00:00<00:10, 13.5MB/s]
  7%|▋         | 9.12M/135M [00:01<00:07, 18.2MB/s]
  9%|▉         | 12.1M/135M [00:01<00:05, 21.6MB/s]
 11%|█         | 15.1M/135M [00:01<00:05, 24.0MB/s]
 13%|█▎        | 18.1M/135M [00:01<00:04, 25.6MB/s]
 16%|█▌        | 21.1M/135M [00:01<00:04, 26.8MB/s]
 18%|█▊        | 24.0M/135M [00:01<00:04, 27.1MB/s]
 20%|██        | 27.0M/135M [00:01<00:04, 27.8MB/s]
 22%|██▏       | 30.0M/135M [00:01<00:03, 28.3MB/s]
 25%|██▍       | 33.0M/135M [00:01<00:03, 28.6MB/s]
 27%|██▋       | 36.0M/135M [00:02<00:03, 28.9MB/s]
 29%|██▉       | 38.9M/135M [00:02<00:03, 28.8MB/s]
 31%|███       | 41.9M/135M [00:02<00:03, 29.0MB/s]
 33%|███▎      | 44.8M/135M [00:02<00:03, 28.8MB/s]
 35%|███▌      | 47.5M/135M [00:02<00:03, 28.2MB/s]
 38%|███▊      | 50.5M/135M [00:02<00:03, 28.6MB/s]
 40%|███▉      | 53.5M/135M [00:02<00:02, 28.8MB/s]
 42%|████▏     | 56.5M/135M [00:02<00:02, 29.0MB/s]
 44%|████▍     | 59.5M/135M [00:02<00:02, 29.1MB/s]
 46%|████▋     | 62.4M/135M [00:02<00:02, 29.0MB/s]
 49%|████▊     | 65.2M/135M [00:03<00:02, 28.6MB/s]
 51%|█████     | 68.0M/135M [00:03<00:02, 28.1MB/s]
 53%|█████▎    | 71.0M/135M [00:03<00:02, 28.5MB/s]
 55%|█████▌    | 74.0M/135M [00:03<00:02, 28.8MB/s]
 57%|█████▋    | 77.0M/135M [00:03<00:02, 28.9MB/s]
 59%|█████▉    | 80.0M/135M [00:03<00:01, 28.9MB/s]
 62%|██████▏   | 82.9M/135M [00:03<00:01, 28.6MB/s]
 64%|██████▎   | 85.8M/135M [00:03<00:01, 28.5MB/s]
 66%|██████▌   | 88.6M/135M [00:03<00:01, 28.4MB/s]
 68%|██████▊   | 91.6M/135M [00:04<00:01, 28.7MB/s]
 70%|███████   | 94.5M/135M [00:04<00:01, 27.8MB/s]
 72%|███████▏  | 97.5M/135M [00:04<00:01, 28.3MB/s]
 75%|███████▍  | 100M/135M [00:04<00:01, 28.6MB/s] 
 77%|███████▋  | 103M/135M [00:04<00:01, 28.6MB/s]
 79%|███████▉  | 106M/135M [00:04<00:01, 28.8MB/s]
 81%|████████  | 109M/135M [00:04<00:00, 28.3MB/s]
 83%|████████▎ | 112M/135M [00:04<00:00, 28.0MB/s]
 85%|████████▌ | 115M/135M [00:04<00:00, 28.3MB/s]
 88%|████████▊ | 118M/135M [00:05<00:00, 28.7MB/s]
 90%|████████▉ | 121M/135M [00:05<00:00, 28.9MB/s]
 92%|█████████▏| 124M/135M [00:05<00:00, 29.0MB/s]
 94%|█████████▍| 127M/135M [00:05<00:00, 29.2MB/s]
 97%|█████████▋| 130M/135M [00:05<00:00, 29.2MB/s]
 99%|█████████▉| 133M/135M [00:05<00:00, 29.3MB/s]
100%|██████████| 135M/135M [00:05<00:00, 25.2MB/s]
__________________________________________________________________________________ test_ImageStitcher[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = transpiled_kornia.feature.LoFTR(pretrained='outdoor')

kornia/test_contrib.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = (), kwargs = {'pretrained': 'outdoor'}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:53, 409kB/s]
  1%|          | 256k/44.2M [00:00<01:08, 672kB/s]
  1%|          | 512k/44.2M [00:00<00:37, 1.23MB/s]
  2%|▏         | 896k/44.2M [00:00<00:22, 2.00MB/s]
  4%|▍         | 1.75M/44.2M [00:00<00:11, 4.02MB/s]
  8%|▊         | 3.50M/44.2M [00:00<00:05, 8.03MB/s]
 14%|█▍        | 6.25M/44.2M [00:00<00:02, 13.8MB/s]
 21%|██        | 9.25M/44.2M [00:01<00:01, 18.5MB/s]
 27%|██▋       | 12.1M/44.2M [00:01<00:01, 21.3MB/s]
 34%|███▎      | 14.9M/44.2M [00:01<00:01, 23.1MB/s]
 40%|████      | 17.9M/44.2M [00:01<00:01, 25.0MB/s]
 47%|████▋     | 20.8M/44.2M [00:01<00:00, 26.0MB/s]
 53%|█████▎    | 23.4M/44.2M [00:01<00:00, 25.9MB/s]
 60%|█████▉    | 26.4M/44.2M [00:01<00:00, 27.0MB/s]
 66%|██████▋   | 29.4M/44.2M [00:01<00:00, 27.5MB/s]
 73%|███████▎  | 32.2M/44.2M [00:01<00:00, 27.6MB/s]
 79%|███████▉  | 35.0M/44.2M [00:02<00:00, 27.2MB/s]
 86%|████████▌ | 37.9M/44.2M [00:02<00:00, 27.5MB/s]
 92%|█████████▏| 40.9M/44.2M [00:02<00:00, 28.0MB/s]
 99%|█████████▉| 43.9M/44.2M [00:02<00:00, 27.9MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 19.6MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[jax-s2s-False] - TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'
FAILED kornia/test_contrib.py::test_EdgeDetector[jax-s2s-False] - AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?
FAILED kornia/test_contrib.py::test_ImageStitcher[jax-s2s-False] - NameError: name 'kornia' is not defined
============================================================================== 3 failed, 12 passed in 1445.14s (0:24:05) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py FF.....F...F..FFF                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_RandomMosaic[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'tensorflow', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[-0.5308, -0.1500, -1.1047,  ...,  0.9267,  0.3735, -0.7795],
          [-1.1277,  1.0801, -0.9317,  ..., -...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-0.53077525, -0.15002388, -1.1046578 , ...,  0.92... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f238a462040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-0.53077525, -0.15002388, -1.1046578 , ...,  0.92... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-0.53077525, -0.15002388, -1.1046578 , ...,  0.92... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-0.53077525, -0.15002388, -1.1046578 , ...,  0.926...      [-0.3820631 , -0.9722672 , -0.30146188, ..., -0.31288016,
           0.1405836 ,  0.6229892 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,...ize=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-0.53077525, -0.15002388, -1.1046578 , .... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-0.53077525, -0.15002388, -1.1046578 , ....     [-0.3820631 , -0.9722672 , -0.30146188, ..., -0.31288016,
           0.1405836 ,  0.6229892 ]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[-0.53077525, -0.15002388, -1.1046578 , ....     [-0.3820631 , -0.9722672 , -0.30146188, ..., -0.31288016,
           0.1405836 ,  0.6229892 ]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
___________________________________________________________________________ test_RandomTransplantation[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.transplantation.RandomTransplantation'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[-0.1391, -0.7845,  0.2166,  0.3476,  1.0910],
          [-0.6438,  0.3935,  1.1270,  0.1585,  0.7916],
   ...0, 0, 0, 1],
         [0, 0, 0, 2, 1],
         [1, 1, 2, 1, 2],
         [0, 2, 1, 1, 2],
         [2, 1, 1, 2, 0]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.13905258, -0.78453064,  0.21656772,  0.34758392,
 ...0, 0, 0, 0, 1],
        [0, 0, 0, 2, 1],
        [1, 1, 2, 1, 2],
        [0, 2, 1, 1, 2],
        [2, 1, 1, 2, 0]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f238a461440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...0, 0, 0, 0, 1],
        [0, 0, 0, 2, 1],
        [1, 1, 2, 1, 2],
        [0, 2, 1, 1, 2],
        [2, 1, 1, 2, 0]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.13905258, -0.78453064,  0.21656772,  0.34758392,
 ...0, 0, 0, 0, 1],
        [0, 0, 0, 2, 1],
        [1, 1, 2, 1, 2],
        [0, 2, 1, 1, 2],
        [2, 1, 1, 2, 0]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...0, 0, 0, 0, 1],
        [0, 0, 0, 2, 1],
        [1, 1, 2, 1, 2],
        [0, 2, 1, 1, 2],
        [2, 1, 1, 2, 0]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.13905258, -0.78453064,  0.21656772,  0.34758392,
 ...0, 0, 0, 0, 1],
        [0, 0, 0, 2, 1],
        [1, 1, 2, 1, 2],
        [0, 2, 1, 1, 2],
        [2, 1, 1, 2, 0]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.13905258, -0.78453064,  0.21656772,  0.34758392,
  ... -0.7559194 ],
         [ 2.124746  , -1.0935698 , -0.62430227,  1.0968165 ,
           0.5293473 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.13905258, -0.78453064,  0.21656772,  0.34...0, 0, 0, 0, 1],
        [0, 0, 0, 2, 1],
        [1, 1, 2, 1, 2],
        [0, 2, 1, 1, 2],
        [2, 1, 1, 2, 0]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[2, 2, 0, 2, 2],
        [1, 1, 2, 1, 0],
        [1, 1, 2, 0...[0, 0, 0, 0, 1],
        [0, 0, 0, 2, 1],
        [1, 1, 2, 1, 2],
        [0, 2, 1, 1, 2],
        [2, 1, 1, 2, 0]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.13905258, -0.78453064,  0.21656772,  0.34...-0.7559194 ],
         [ 2.124746  , -1.0935698 , -0.62430227,  1.0968165 ,
           0.5293473 ]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f2388fbc040>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f2383a8c3a0>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7f23894e7910>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7f238947b010>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f2383918430>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7f238892be50>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 2, 0, 2, 2],
       [1, 1, 2, 1, 0],
       [1, 1, 2, 0, 1],
       [2, 2, 0, 0, 0],
       [2, 1, 2, 1, 1]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 2, 0, 2, 2],
       [1, 1, 2, 1, 0],
       [1, 1, 2, 0, 1],
       [2, 2, 0, 0, 0],
       [2, 1, 2, 1, 1]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 2, 0, 2, 2],
       [1, 1, 2, 1, 0],
       [1, 1, 2, 0, 1],
       [2, 2, 0, 0, 0],
       [2, 1, 2, 1, 1]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 2, 0, 2, 2],
       [1, 1, 2, 1, 0],
       [1, 1, 2, 0, 1],
       [2, 2, 0, 0, 0],
       [2, 1, 2, 1, 1]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation.call():
E                 • input=<class 'inspect._empty'>
E                 • params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                 • data_keys=None
E                 • kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation
_____________________________________________________________________________ test_RandomRotation3D[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRotation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation3D")
    
        init_args = ((15., 20., 20.),)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.geometric.rotation.RandomRotation3D'>, target = 'tensorflow', init_args = ((15.0, 20.0, 20.0),), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[[0.8545, 0.9049, 0.1015],
           [0.3981, 0.0267, 0.6545],
           [0.9849, 0.2711, 0.4252]],

    ...,

          [[0.3771, 0.3018, 0.4086],
           [0.2726, 0.4707, 0.4430],
           [0.3530, 0.1678, 0.7437]]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0...,
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f2388f48440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, a...],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0...,
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, a...],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0...,
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0....7],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
   ...],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0....7],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...37613], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-17.513176], dtype=float32)>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f238f8e49d0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f238352c280>
tensor = <function tensorflow_tensor_frnt at 0x7f238f6068c0>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0....7],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0....7],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...37613], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-17.513176], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/base.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0....7],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...37613], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-17.513176], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not tensorflow_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif tensorflow_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/base.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.8545354 , 0.9048824 , 0.101524  ],
          [0....7],
          [0.27262253, 0.47068793, 0.44299215],
          [0.35298514, 0.16780573, 0.74368674]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...37613], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-17.513176], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ....geometry.transform.affwarp import tensorflow__compute_tensor_center3d
        from ....geometry.transform.affwarp import tensorflow__compute_rotation_matrix3d
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....utils.misc import tensorflow_eye_like
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        yaw: typing.Any = tensorflow_to_frnt_(params["yaw"], input)
        pitch: typing.Any = tensorflow_to_frnt_(params["pitch"], input)
        roll: typing.Any = tensorflow_to_frnt_(params["roll"], input)
        center: typing.Any = tensorflow__compute_tensor_center3d(input)
        rotation_mat: typing.Any = tensorflow__compute_rotation_matrix3d(
>           yaw, pitch, roll, center.expand(tensorflow_shape_frnt_(yaw)[0], -1)
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomRotation3D.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'expand'[0m
E       
E       Arguments received by tensorflow_RandomRotation3D.call():
E         • input=tf.Tensor(shape=(1, 1, 3, 3, 3), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/geometric/rotation.py:68: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation3D
__________________________________________________________________________ test_RandomTransplantation3D[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation3D")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.mix.transplantation.RandomTransplantation3D'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[-0.3158,  0.0477, -1.7184, -0.4019, -0.2048],
          [-0.0640,  0.7095, -1.1850,  0.5452, -0.3363],
   ...1, 1, 0, 1],
         [2, 2, 0, 2, 2],
         [2, 0, 2, 1, 0],
         [2, 0, 2, 1, 2],
         [2, 1, 2, 0, 1]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.3158118 ,  0.04769002, -1.7184167 , -0.40190032,
 ...0, 1, 1, 0, 1],
        [2, 2, 0, 2, 2],
        [2, 0, 2, 1, 0],
        [2, 0, 2, 1, 2],
        [2, 1, 2, 0, 1]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f2389d01c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...0, 1, 1, 0, 1],
        [2, 2, 0, 2, 2],
        [2, 0, 2, 1, 0],
        [2, 0, 2, 1, 2],
        [2, 1, 2, 0, 1]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.3158118 ,  0.04769002, -1.7184167 , -0.40190032,
 ...0, 1, 1, 0, 1],
        [2, 2, 0, 2, 2],
        [2, 0, 2, 1, 0],
        [2, 0, 2, 1, 2],
        [2, 1, 2, 0, 1]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...0, 1, 1, 0, 1],
        [2, 2, 0, 2, 2],
        [2, 0, 2, 1, 0],
        [2, 0, 2, 1, 2],
        [2, 1, 2, 0, 1]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.3158118 ,  0.04769002, -1.7184167 , -0.40190032,
 ...0, 1, 1, 0, 1],
        [2, 2, 0, 2, 2],
        [2, 0, 2, 1, 0],
        [2, 0, 2, 1, 2],
        [2, 1, 2, 0, 1]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.3158118 ,  0.04769002, -1.7184167 , -0.40190032,
  ...  1.101742  ],
         [-0.45819926,  0.24680313, -0.16165085, -0.09739614,
          -0.16382775]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.3158118 ,  0.04769002, -1.7184167 , -0.40...0, 1, 1, 0, 1],
        [2, 2, 0, 2, 2],
        [2, 0, 2, 1, 0],
        [2, 0, 2, 1, 2],
        [2, 1, 2, 0, 1]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[2, 2, 0, 0, 2],
        [2, 1, 1, 0, 1],
        [1, 1, 2, 1...[0, 1, 1, 0, 1],
        [2, 2, 0, 2, 2],
        [2, 0, 2, 1, 0],
        [2, 0, 2, 1, 2],
        [2, 1, 2, 0, 1]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[-0.3158118 ,  0.04769002, -1.7184167 , -0.40... 1.101742  ],
         [-0.45819926,  0.24680313, -0.16165085, -0.09739614,
          -0.16382775]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f2382efdbd0>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f23803e8b80>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7f2380728ee0>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7f2382e3e710>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f2380382a70>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7f238373a020>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:249: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 2, 0, 0, 2],
       [2, 1, 1, 0, 1],
       [1, 1, 2, 1, 2],
       [1, 0, 1, 1, 1],
       [2, 0, 0, 2, 2]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 2, 0, 0, 2],
       [2, 1, 1, 0, 1],
       [1, 1, 2, 1, 2],
       [1, 0, 1, 1, 1],
       [2, 0, 0, 2, 2]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 2, 0, 0, 2],
       [2, 1, 1, 0, 1],
       [1, 1, 2, 1, 2],
       [1, 0, 1, 1, 1],
       [2, 0, 0, 2, 2]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 2, 0, 0, 2],
       [2, 1, 1, 0, 1],
       [1, 1, 2, 1, 2],
       [1, 0, 1, 1, 1],
       [2, 0, 0, 2, 2]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation3D.call():
E                 • input=<class 'inspect._empty'>
E                 • params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                 • data_keys=None
E                 • kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation3D
______________________________________________________________________________ test_LongestMaxSize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LongestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.LongestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 200, 200),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.LongestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:360: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.LongestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[1.4266e-02, 7.2826e-01, 4.0408e-01,  ..., 1.1223e-01,
           5.1592e-01, 6.4664e-01],
          [3.516... 5.1426e-01],
          [7.1132e-01, 1.9826e-01, 7.0610e-01,  ..., 7.1205e-01,
           5.7002e-01, 1.6864e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.01426566, 0.40821084, 0.84957707, ..., 0.4675453 ,
          0.11695894, 0.64664006],
         [0.8183541 ...8],
         [0.7113173 , 0.7050459 , 0.5846515 , ..., 0.42728794,
          0.7117338 , 0.16863543]]]], dtype=float32)
y = array([[[[0.4829728 , 0.4759592 , 0.6327433 , ..., 0.49614823,
          0.41001004, 0.39086443],
         [0.68318963...4],
         [0.413186  , 0.50835556, 0.42676926, ..., 0.39233986,
          0.497105  , 0.5116713 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.LongestMaxSize
__________________________________________________________________________________ test_Resize[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Resize(target_framework, mode, backend_compile):
        print("kornia.augmentation.Resize")
    
        init_args = ((100, 100),)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.Resize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.Resize'>, target = 'tensorflow', init_args = ((100, 100),), init_kwargs = {}
call_args = (tensor([[[[8.5345e-01, 9.6507e-01, 6.1378e-01,  ..., 7.5634e-01,
           1.4876e-01, 9.5081e-01],
          [9.498... 4.1409e-01],
          [5.3314e-01, 5.7786e-03, 2.9200e-01,  ..., 8.1554e-02,
           3.5097e-01, 9.3750e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.8534498 , 0.90869623, 0.96394265, ..., 0.15686318,
          0.5538358 , 0.95080847],
         [0.90117234... ],
         [0.5331432 , 0.27212435, 0.01110547, ..., 0.35689908,
          0.6472008 , 0.9375026 ]]]], dtype=float32)
y = array([[[[0.8534498 , 0.8813549 , 0.937165  , ..., 0.3492732 ,
          0.7502967 , 0.95080847],
         [0.87755454... ],
         [0.5331432 , 0.40130204, 0.13761973, ..., 0.49760646,
          0.79087055, 0.9375026 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.Resize
______________________________________________________________________________ test_SmallestMaxSize[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SmallestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.SmallestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.SmallestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.SmallestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[4.1768e-01, 7.2882e-01, 7.3489e-01,  ..., 2.2827e-01,
           8.9716e-01, 9.4044e-02],
          [5.000... 4.3239e-01],
          [4.0609e-01, 6.6535e-03, 6.4087e-01,  ..., 4.2835e-02,
           3.3665e-01, 1.1564e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[4.17683840e-01, 5.71680784e-01, 7.25677669e-01, ...,
          8.89050066e-01, 4.91547167e-01, 9.40442681e-0...2.08388939e-01, 1.06882593e-02, ...,
          3.34420204e-01, 2.25031376e-01, 1.15642548e-01]]]],
      dtype=float32)
y = array([[[[4.17683840e-01, 4.95467991e-01, 6.51036263e-01, ...,
          6.96382999e-01, 2.94823825e-01, 9.40442681e-0...3.06230605e-01, 1.06512547e-01, ...,
          2.81400144e-01, 1.70895085e-01, 1.15642548e-01]]]],
      dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.SmallestMaxSize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomRotation3D[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomRotation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation3D[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_LongestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_Resize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_SmallestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 7 failed, 10 passed in 3654.36s (1:00:54) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 420.59s (0:07:00) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py .FFFF..FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_SIFTFeatureScaleSpace[jax-s2s-False] _______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeatureScaleSpace = ivy.transpile(kornia.feature.SIFTFeatureScaleSpace, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
        transpiled_model = TranspiledSIFTFeatureScaleSpace(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
>       transpiled_out = transpiled_model(transpiled_x)

kornia/test_feature4.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SIFTFeatureScaleSpace(
  (detector): jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyram...ng_bins=8, num_spatial_bins=4, patch_size=41, rootsift=True, clipval=0.2), patch_size=41, grayscale_descriptor='True)
)
img = Array([[[[0.2853462 , 0.67687905, 0.9336922 , ..., 0.12738568,
          0.15847003, 0.8521458 ],
         [0.28156412... ],
         [0.7345889 , 0.58548915, 0.8008115 , ..., 0.34781307,
          0.3045379 , 0.6862272 ]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
        from .laf import jax_scale_laf
    
>       lafs, responses = self.detector(img, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.2853462 , 0.67687905, 0.9336922 , ..., 0.12738568,
          0.15847003, 0.8521458 ],
         [0.28156412... ],
         [0.7345889 , 0.58548915, 0.8008115 , ..., 0.34781307,
          0.3045379 , 0.6862272 ]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.2853462 , 0.67687905, 0.9336922 , ..., 0.12738568,
          0.15847003, 0.8521458 ],
         [0.28156412... ],
         [0.7345889 , 0.58548915, 0.8008115 , ..., 0.34781307,
          0.3045379 , 0.6862272 ]]]], dtype=float32)
num_feats = 10, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import jax_topk_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from .laf import jax_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
>       sp, sigmas, _ = self.scale_pyr(img)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
x = Array([[[[0.2853462 , 0.67687905, 0.9336922 , ..., 0.12738568,
          0.15847003, 0.8521458 ],
         [0.28156412... ],
         [0.7345889 , 0.58548915, 0.8008115 , ..., 0.34781307,
          0.3045379 , 0.6862272 ]]]], dtype=float32)

    def __call__(self, x):
        from ...filters.gaussian import jax_gaussian_blur2d
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...core._backend import ones
        from ...core._backend import stack
    
        bs, _, _, _ = jax_size_frnt_(x)
>       cur_level, cur_sigma, pixel_distance = self.get_first_level(x)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
input = Array([[[[0.2853462 , 0.67687905, 0.9336922 , ..., 0.12738568,
          0.15847003, 0.8521458 ],
         [0.28156412... ],
         [0.7345889 , 0.58548915, 0.8008115 , ..., 0.34781307,
          0.3045379 , 0.6862272 ]]]], dtype=float32)

    def get_first_level(self, input):
        from ...filters.gaussian import jax_gaussian_blur2d
    
        pixel_distance = 1.0
        cur_sigma = 0.5
        if self.double_image:
>           x = jax_upscale_double(input)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.2853462 , 0.67687905, 0.9336922 , ..., 0.12738568,
          0.15847003, 0.8521458 ],
         [0.28156412... ],
         [0.7345889 , 0.58548915, 0.8008115 , ..., 0.34781307,
          0.3045379 , 0.6862272 ]]]], dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.2853462 , 0.        , 0.67687905, ..., 0.        ,
          0.8521458 , 0.        ],
         [0.        ... ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.48111263, 0.80528563, 0.74100995, ..., 0.14292786,
          0.5053079 , 0.        ],
         [0.2641402 ... ],
         [0.66003907, 0.69315034, 0.44151512, ..., 0.32617548,
          0.49538255, 0.        ]]]], dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("'{}' object does not support item assignment. JAX arrays are "
             "immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` "
             "or another .at[] method: "
             "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:587: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
All parameters and buffers are now synced!
________________________________________________________________________________ test_GFTTAffNetHardNet[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_GFTTAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.GFTTAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.GFTTAffNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledGFTTAffNetHardNet(num_features=10)

kornia/test_feature4.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_GFTTAffNetHardNet'>, args = (), kwargs = {'num_features': 10}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_GFTTAffNetHardNet'>, args = (), kwargs = {'num_features': 10}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_GFTTAffNetHardNet object at 0x7ff3c53eb5b0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_GFTTAffNetHardNet'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_GFTTAffNetHardNet object at 0x7ff3c53eb5b0>, args = (), kwargs = {'num_features': 10}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_GFTTAffNetHardNet object at 0x7ff3c53eb5b0>, num_features = 10, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=jax_device_frnt("cpu"),
        config=jax_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from .scale_space_detector import jax_MultiResolutionDetector
        from .responses import jax_CornerGFTT
        from .orientation import jax_PassLAF
        from .orientation import jax_LAFOrienter
        from .affine_shape import jax_LAFAffNetShapeEstimator
    
        detector = jax_to_frnt_(
            jax_MultiResolutionDetector(
                jax_CornerGFTT(),
                num_features,
                config,
                ori_module=jax_PassLAF() if upright else jax_LAFOrienter(19),
>               aff_module=jax_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, args = (True,), kwargs = {}, node = jax_LAFAffNetShapeEstimator()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, self = jax_LAFAffNetShapeEstimator(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LAFAffNetShapeEstimator(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LAFAffNetShapeEstimator(), pretrained = True, preserve_orientation = True

    @jax_store_config_info
    def __init__(self, pretrained=False, preserve_orientation=True):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.activation import jax_Tanh
        from ...torch.nn.modules.pooling import jax_AdaptiveAvgPool2d
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            preserve_orientation=preserve_orientation,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=32,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.25),
            FlaxConv(
                in_features=64,
                out_features=3,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=True,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_Tanh(),
            jax_AdaptiveAvgPool2d(1),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/affine_shape.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}
node = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 16, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.GFTTAffNetHardNet
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 19.7MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 126MB/s]
_______________________________________________________________________________ test_KeyNetAffNetHardNet[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_KeyNetAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.KeyNetAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledKeyNetAffNetHardNet = ivy.transpile(kornia.feature.KeyNetAffNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.KeyNetAffNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledKeyNetAffNetHardNet(num_features=10)

kornia/test_feature4.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_KeyNetAffNetHardNet'>, args = (), kwargs = {'num_features': 10}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_KeyNetAffNetHardNet'>, args = (), kwargs = {'num_features': 10}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_KeyNetAffNetHardNet object at 0x7ff3c4d688e0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_KeyNetAffNetHardNet'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_KeyNetAffNetHardNet object at 0x7ff3c4d688e0>, args = (), kwargs = {'num_features': 10}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_KeyNetAffNetHardNet object at 0x7ff3c4d688e0>, num_features = 10, upright = False, device = 'cpu'
scale_laf = 1.0

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=jax_device_frnt("cpu"),
        scale_laf=1.0,
    ):
        from .orientation import jax_PassLAF
        from .orientation import jax_LAFOrienter
        from .orientation import jax_OriNet
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from .keynet import jax_KeyNetDetector
        from .affine_shape import jax_LAFAffNetShapeEstimator
    
        ori_module = (
            jax_PassLAF()
            if upright
>           else jax_LAFOrienter(angle_detector=jax_OriNet(True))
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, args = (True,), kwargs = {}, node = jax_OriNet()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, self = jax_OriNet(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_OriNet(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_OriNet(), pretrained = True, eps = 1e-08

    @jax_store_config_info
    def __init__(self, pretrained=False, eps=1e-08):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.activation import jax_Tanh
        from ...torch.nn.modules.pooling import jax_AdaptiveAvgPool2d
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=32,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.25),
            FlaxConv(
                in_features=64,
                out_features=2,
                kernel_size=8,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=True,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_Tanh(),
            jax_AdaptiveAvgPool2d(1),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/orientation.py:385: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}
node = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 16, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.KeyNetAffNetHardNet
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/OriNet.pth" to /root/.cache/torch/hub/checkpoints/OriNet.pth

  0%|          | 0.00/316k [00:00<?, ?B/s]
100%|██████████| 316k/316k [00:00<00:00, 18.9MB/s]
Downloading: "https://github.com/axelBarroso/Key.Net-Pytorch/raw/main/model/weights/keynet_pytorch.pth" to /root/.cache/torch/hub/checkpoints/keynet_pytorch.pth

  0%|          | 0.00/78.0k [00:00<?, ?B/s]
100%|██████████| 78.0k/78.0k [00:00<00:00, 11.0MB/s]
__________________________________________________________________________________ test_KeyNetHardNet[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_KeyNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.KeyNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledKeyNetHardNet = ivy.transpile(kornia.feature.KeyNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.KeyNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledKeyNetHardNet(num_features=10)

kornia/test_feature4.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_KeyNetHardNet'>, args = (), kwargs = {'num_features': 10}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_KeyNetHardNet'>, args = (), kwargs = {'num_features': 10}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_KeyNetHardNet object at 0x7ff3c58d7bb0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_KeyNetHardNet'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_KeyNetHardNet object at 0x7ff3c58d7bb0>, args = (), kwargs = {'num_features': 10}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_KeyNetHardNet object at 0x7ff3c58d7bb0>, num_features = 10, upright = False, device = 'cpu', scale_laf = 1.0

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=jax_device_frnt("cpu"),
        scale_laf=1.0,
    ):
        from .orientation import jax_PassLAF
        from .orientation import jax_LAFOrienter
        from .orientation import jax_OriNet
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from .keynet import jax_KeyNetDetector
    
        ori_module = (
            jax_PassLAF()
            if upright
>           else jax_LAFOrienter(angle_detector=jax_OriNet(True))
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:332: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, args = (True,), kwargs = {}, node = jax_OriNet()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, self = jax_OriNet(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_OriNet(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_OriNet(), pretrained = True, eps = 1e-08

    @jax_store_config_info
    def __init__(self, pretrained=False, eps=1e-08):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.activation import jax_Tanh
        from ...torch.nn.modules.pooling import jax_AdaptiveAvgPool2d
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=32,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.25),
            FlaxConv(
                in_features=64,
                out_features=2,
                kernel_size=8,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=True,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_Tanh(),
            jax_AdaptiveAvgPool2d(1),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/orientation.py:385: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}
node = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 16, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.KeyNetHardNet
_______________________________________________________________________________ test_LocalFeatureMatcher[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
        TranspiledDescriptorMatcher = ivy.transpile(kornia.feature.DescriptorMatcher, source="torch", target=target_framework)
        TranspiledLocalFeatureMatcher = ivy.transpile(kornia.feature.LocalFeatureMatcher, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857...
         [0.9130239 , 0.62204176, 0.19668001, ..., 0.48675686,
          0.47504407, 0.39251953]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857...
         [0.9130239 , 0.62204176, 0.19668001, ..., 0.48675686,
          0.47504407, 0.39251953]]]], dtype=float32)},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.48578...],
         [0.9130239 , 0.62204176, 0.19668001, ..., 0.48675686,
          0.47504407, 0.39251953]]]], dtype=float32)}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
  ...05393e-01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32)
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
 ...01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
 ...01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32), None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
  ...05393e-01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
 ...01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
 ...01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32), None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
  ...05393e-01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
  ...05393e-01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32)
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[6.7545176e-02, 6.0073596e-01, 3.2063681e-01, ...,
          7.8005111e-01, 7.7081013e-01, 7.4857843e-01],
  ...05393e-01, 5.2489835e-01, 6.9727838e-02, ...,
          1.7714500e-02, 1.9864005e-01, 1.4408654e-01]]]], dtype=float32)
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_________________________________________________________________________________ test_LightGlueMatcher[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlueMatcher = ivy.transpile(kornia.feature.LightGlueMatcher, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = TranspiledLightGlueMatcher('disk')

kornia/test_feature4.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}, node = jax_LightGlueMatcher()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, self = jax_LightGlueMatcher(), args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import jax_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = jax_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}
node = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>
self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
features = 'disk', conf_ = {}, jax_KORNIA_CHECK = <function jax_KORNIA_CHECK at 0x7ff3bbd53d00>, jax_get_item = <function jax_get_item at 0x7ff3bbd065f0>
jax_Identity = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.linear.jax_Identity'>, jax_load_state_dict_from_url_frnt = <function jax_load_state_dict_from_url_frnt at 0x7ff40ff9a8c0>
jax_load_frnt = <function jax_load_frnt at 0x7ff3c4d63c70>, ModuleList = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.container.jax_ModuleList'>
FlaxLinear = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxLinear'>

    @jax_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...torch.nn.modules.linear import jax_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            jax_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            jax_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in jax_get_item(self.features, features).items():
                setattr(conf, k, v)
        jax_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = FlaxLinear(
                in_features=conf.input_dim,
                out_features=conf.descriptor_dim,
                use_bias=True,
            )
        else:
            self.input_proj = jax_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = jax_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = jax_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:1389: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}, node = jax_TransformerLayer()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @jax_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = jax_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:944: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}
node = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)
args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @jax_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import jax_KORNIA_CHECK
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.normalization import jax_LayerNorm
        from ...torch.nn.modules.activation import jax_GELU
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        jax_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = FlaxLinear(
            in_features=embed_dim, out_features=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = jax_Attention(flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}, node = jax_Attention()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, self = jax_Attention(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), allow_flash = True

    @jax_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:398: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 58%|█████▊    | 26.4M/45.4M [00:00<00:00, 276MB/s]
100%|██████████| 45.4M/45.4M [00:00<00:00, 311MB/s]
____________________________________________________________________________________ test_LightGlue[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlue = ivy.transpile(kornia.feature.LightGlue, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.473903  , 0.53058004, 0.28182727, ..., 0.7592097 ,
         0.29877335, 0.80799...97328269e-01],
        [7.43759394e-01, 2.89540291e-02],
        [8.45312655e-01, 1.50073230e-01]]], dtype=float32)}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.473903  , 0.53058004, 0.28182727, ..., 0.7592097 ,
         0.29877335, 0.80799...97328269e-01],
        [7.43759394e-01, 2.89540291e-02],
        [8.45312655e-01, 1.50073230e-01]]], dtype=float32)}},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.473903  , 0.53058004, 0.28182727, ..., 0.7592097 ,
         0.29877335, 0.807990...1.97328269e-01],
        [7.43759394e-01, 2.89540291e-02],
        [8.45312655e-01, 1.50073230e-01]]], dtype=float32)}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.473903  , 0.53058004, 0.28182727, ..., 0.7592097 ,
         0.29877335, 0.807990...1.97328269e-01],
        [7.43759394e-01, 2.89540291e-02],
        [8.45312655e-01, 1.50073230e-01]]], dtype=float32)}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[0.20491773, 0.01587266],
        [0.8884673 , 0.13125217],
        [0.17667705, 0.11170411],
        [0.0563...        [0.8943653 , 0.62139684],
        [0.6942703 , 0.5176054 ]]], dtype=float32), Array([[640, 480]], dtype=int64))
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = Array([[[0.20491773, 0.01587266],
        [0.8884673 , 0.13125217],
        [0.17667705, 0.11170411],
        [0.05631...
        [0.3722492 , 0.59022933],
        [0.8943653 , 0.62139684],
        [0.6942703 , 0.5176054 ]]], dtype=float32)
size = Array([[640, 480]], dtype=int64)

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 44%|████▍     | 20.1M/45.3M [00:00<00:00, 183MB/s]
 97%|█████████▋| 43.9M/45.3M [00:00<00:00, 219MB/s]
100%|██████████| 45.3M/45.3M [00:00<00:00, 216MB/s]
______________________________________________________________________________________ test_LoFTR[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[0.04857922, 0.7754466 , 0.11574775, ..., 0.06388378,
          0.7506276 , 0.67877007],
        ...
         [0.76976836, 0.22700012, 0.53217477, ..., 0.7708082 ,
          0.20816195, 0.07668799]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[0.04857922, 0.7754466 , 0.11574775, ..., 0.06388378,
          0.7506276 , 0.67877007],
        ...
         [0.76976836, 0.22700012, 0.53217477, ..., 0.7708082 ,
          0.20816195, 0.07668799]]]], dtype=float32)},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': Array([[[[0.04857922, 0.7754466 , 0.11574775, ..., 0.06388378,
          0.7506276 , 0.67877007],
         ...],
         [0.76976836, 0.22700012, 0.53217477, ..., 0.7708082 ,
          0.20816195, 0.07668799]]]], dtype=float32)}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[jax-s2s-False] - TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. ...
FAILED kornia/test_feature4.py::test_GFTTAffNetHardNet[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature4.py::test_KeyNetAffNetHardNet[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature4.py::test_KeyNetHardNet[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[jax-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[jax-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?
FAILED kornia/test_feature4.py::test_LoFTR[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 8 failed, 6 passed in 2776.77s (0:46:16) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py FFFF...FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_SIFTFeature[tensorflow-s2s-False] ________________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeature(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeature")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeature = ivy.transpile(kornia.feature.SIFTFeature, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeature(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledSIFTFeature(num_features=10)

kornia/test_feature4.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeature object at 0x7f994aaab430>, num_features = 10, upright = False, rootsift = True
device = 'cpu', config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_BlobDoGSingle
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_BlobDoGSingle(1.0, 1.6),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_PassLAF(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f994aaaa920>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f994aaaa920>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeature
___________________________________________________________________________ test_SIFTFeatureScaleSpace[tensorflow-s2s-False] ___________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeatureScaleSpace = ivy.transpile(kornia.feature.SIFTFeatureScaleSpace, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledSIFTFeatureScaleSpace(num_features=10)

kornia/test_feature4.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeatureScaleSpace object at 0x7f9949d66650>, num_features = 10, upright = False, rootsift = True
device = 'cpu'

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_ScaleSpaceDetector
        from .responses import tensorflow_BlobDoG
        from ..geometry.subpix.spatial_soft_argmax import tensorflow_ConvQuadInterp3d
        from ..geometry.transform.pyramid import tensorflow_ScalePyramid
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_ScaleSpaceDetector(
                num_features,
                resp_module=tensorflow_BlobDoG(),
                nms_module=tensorflow_ConvQuadInterp3d(10),
                scale_pyr_module=tensorflow_ScalePyramid(3, 1.6, 32, double_image=True),
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                scale_space_response=True,
                minima_are_also_good=True,
                mr_size=6.0,
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f9949d65990>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f9949d65990>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
_____________________________________________________________________________ test_GFTTAffNetHardNet[tensorflow-s2s-False] _____________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_GFTTAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.GFTTAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.GFTTAffNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledGFTTAffNetHardNet(num_features=10)

kornia/test_feature4.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f994a5a97e0>, num_features = 10, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:351: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f994a5a8760>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f994a5a8760>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_2>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.GFTTAffNetHardNet
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 19.5MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 124MB/s]
____________________________________________________________________________ test_KeyNetAffNetHardNet[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KeyNetAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.KeyNetAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledKeyNetAffNetHardNet = ivy.transpile(kornia.feature.KeyNetAffNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.KeyNetAffNetHardNet(num_features=10)
        torch_out = model(x)
    
        transpiled_model = TranspiledKeyNetAffNetHardNet(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature4.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[ -1.3092,  12.9720, 174.6740],
          [-18.5283,  -1.2999, 237.6133]],

         [[ -9.8764,  -9.6756, ...76, -0.0138],
         [ 0.0417,  0.0095, -0.1608,  ...,  0.0466,  0.0441, -0.0417]]],
       grad_fn=<ViewBackward0>))
transpiled_x = (<tf.Tensor: shape=(1, 10, 2, 3), dtype=float32, numpy=
array([[[[ -1.3093455,  12.972008 , 174.67404  ],
         [-1...       [ 0.04171085,  0.0095612 , -0.16082422, ...,  0.04659799,
          0.04403294, -0.04174801]]], dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[ -1.3091915 ,  12.972029  , 174.67404   ],
         [-18.528318  ,  -1.2999053 , 237.61327   ]],

        [...        [ 0.04168997,  0.00954867, -0.16082439, ...,  0.04660875,
          0.04406153, -0.04173749]]], dtype=float32))
y = (array([[[[ -1.3093455,  12.972008 , 174.67404  ],
         [-18.528309 ,  -1.3001351, 237.61327  ]],

        [[ -9.8...        [ 0.04171085,  0.0095612 , -0.16082422, ...,  0.04659799,
          0.04403294, -0.04174801]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f994a1b8740>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ -1.3091915 ,  12.972029  , 174.67404   ],
         [-18.528318  ,  -1.2999053 , 237.61327   ]],

        [[...    [[-15.472251  ,  12.491982  , 179.        ],
         [-16.726124  , -17.777475  , 167.        ]]]], dtype=float32)
y = array([[[[ -1.3093455,  12.972008 , 174.67404  ],
         [-18.528309 ,  -1.3001351, 237.61327  ]],

        [[ -9.87...

        [[-15.472112 ,  12.492158 , 179.       ],
         [-16.726324 , -17.777287 , 167.       ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.KeyNetAffNetHardNet
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/OriNet.pth" to /root/.cache/torch/hub/checkpoints/OriNet.pth

  0%|          | 0.00/316k [00:00<?, ?B/s]
100%|██████████| 316k/316k [00:00<00:00, 17.6MB/s]
Downloading: "https://github.com/axelBarroso/Key.Net-Pytorch/raw/main/model/weights/keynet_pytorch.pth" to /root/.cache/torch/hub/checkpoints/keynet_pytorch.pth

  0%|          | 0.00/78.0k [00:00<?, ?B/s]
100%|██████████| 78.0k/78.0k [00:00<00:00, 10.6MB/s]
____________________________________________________________________________ test_LocalFeatureMatcher[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
        TranspiledDescriptorMatcher = ivy.transpile(kornia.feature.DescriptorMatcher, source="torch", target=target_framework)
        TranspiledLocalFeatureMatcher = ivy.transpile(kornia.feature.LocalFeatureMatcher, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, .....         [0.1581111 , 0.41119617, 0.7954573 , ..., 0.80907375,
          0.61668277, 0.3419881 ]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, .....         [0.1581111 , 0.41119617, 0.7954573 , ..., 0.80907375,
          0.61668277, 0.3419881 ]]]], dtype=float32)>},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ......,
         [0.1581111 , 0.41119617, 0.7954573 , ..., 0.80907375,
          0.61668277, 0.3419881 ]]]], dtype=float32)>}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.0455117...],
         [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.045511...     [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.045511...     [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>, None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.0455117...],
         [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.045511...     [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.045511...     [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>, None)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.0455117...],
         [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.0455117...],
         [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.38306332, 0.83509064, 0.68844146, ..., 0.0455117...],
         [0.43877888, 0.08691645, 0.16786194, ..., 0.7766601 ,
          0.31859326, 0.64644045]]]], dtype=float32)>
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_____________________________________________________________________________ test_LightGlueMatcher[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlueMatcher = ivy.transpile(kornia.feature.LightGlueMatcher, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = TranspiledLightGlueMatcher('disk')

kornia/test_feature4.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import tensorflow_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = tensorflow_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), features = 'disk', conf_ = {}
tensorflow_KORNIA_CHECK = <function tensorflow_KORNIA_CHECK at 0x7f99349dc700>, tensorflow_get_item = <function tensorflow_get_item at 0x7f99349a5fc0>
tensorflow_Identity = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.linear.tensorflow_Identity'>
tensorflow_load_state_dict_from_url_frnt = <function tensorflow_load_state_dict_from_url_frnt at 0x7f99348031c0>, tensorflow_load_frnt = <function tensorflow_load_frnt at 0x7f9934803d00>
ModuleList = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.container.tensorflow_ModuleList'>
KerasDense = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful_layers.KerasDense'>

    @tensorflow_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...torch.nn.modules.linear import tensorflow_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            tensorflow_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            tensorflow_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in tensorflow_get_item(self.features, features).items():
                setattr(conf, k, v)
        tensorflow_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = KerasDense(
                in_features=conf.input_dim, units=conf.descriptor_dim, use_bias=True
            )
        else:
            self.input_proj = tensorflow_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = tensorflow_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = tensorflow_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:1433: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @tensorflow_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = tensorflow_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:976: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @tensorflow_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...torch.nn.modules.normalization import tensorflow_LayerNorm
        from ...torch.nn.modules.activation import tensorflow_GELU
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        tensorflow_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = KerasDense(
            in_features=embed_dim, units=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = tensorflow_Attention(flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), allow_flash = True

    @tensorflow_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:411: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 58%|█████▊    | 26.5M/45.4M [00:00<00:00, 277MB/s]
100%|██████████| 45.4M/45.4M [00:00<00:00, 311MB/s]
_________________________________________________________________________________ test_LightGlue[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlue = ivy.transpile(kornia.feature.LightGlue, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.6419377 , 0.6634963 , 0....    [0.12309176, 0.4191308 ],
        [0.55481726, 0.92854637],
        [0.34086633, 0.42079866]]], dtype=float32)>}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.6419377 , 0.6634963 , 0....    [0.12309176, 0.4191308 ],
        [0.55481726, 0.92854637],
        [0.34086633, 0.42079866]]], dtype=float32)>}},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.6419377 , 0.6634963 , 0.8...      [0.12309176, 0.4191308 ],
        [0.55481726, 0.92854637],
        [0.34086633, 0.42079866]]], dtype=float32)>}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.6419377 , 0.6634963 , 0.8...      [0.12309176, 0.4191308 ],
        [0.55481726, 0.92854637],
        [0.34086633, 0.42079866]]], dtype=float32)>}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[0.11710399, 0.6049852 ],
        [0.87775993, 0.8336779...        [0.8085388 , 0.8183534 ]]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>)
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = <tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[0.11710399, 0.6049852 ],
        [0.87775993, 0.83367795...        [0.3435641 , 0.6662723 ],
        [0.68650013, 0.9815547 ],
        [0.8085388 , 0.8183534 ]]], dtype=float32)>
size = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>, name = 'float'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 58%|█████▊    | 26.1M/45.3M [00:00<00:00, 274MB/s]
100%|██████████| 45.3M/45.3M [00:00<00:00, 301MB/s]
___________________________________________________________________________________ test_LoFTR[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.2209183 , 0.44508523, 0.85423684, .....         [0.09508556, 0.8241233 , 0.71046084, ..., 0.06611419,
          0.22332627, 0.34865636]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.2209183 , 0.44508523, 0.85423684, .....         [0.09508556, 0.8241233 , 0.71046084, ..., 0.06611419,
          0.22332627, 0.34865636]]]], dtype=float32)>},)
kwargs = {}

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1747: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.2209183 , 0.44508523, 0.85423684, ......,
         [0.09508556, 0.8241233 , 0.71046084, ..., 0.06611419,
          0.22332627, 0.34865636]]]], dtype=float32)>}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeature[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_GFTTAffNetHardNet[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_KeyNetAffNetHardNet[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[tensorflow-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[tensorflow-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'
FAILED kornia/test_feature4.py::test_LoFTR[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 8 failed, 6 passed in 2906.25s (0:48:26) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F...                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_RandomMotionBlur[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'jax', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32), params = None
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f280882f250>, jax_set_item = <function jax_set_item at 0x7f2808ffb5b0>, tensor = <function jax_tensor_frnt at 0x7f2808f8cee0>
in_tensor = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple((int(jax_item_frnt_(jax_sum_frnt_(to_apply))), *batch_shape[1:]))
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.jax.general import jax_set_item
        from .....ivy.functional.frontends.torch.random_sampling import jax_randint_frnt
    
        params = super().generate_parameters(batch_shape)
        params = jax_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else jax_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:66: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_____________________________________________________________________________ test_RandomSaltAndPepperNoise[jax-s2s-False] _____________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'jax', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.3512, 0.8077, 0.1871],
          [0.0567, 0.3397, 0.7406],
          [0.2654, 0.0687, 0.4390]],

       ...63]],

         [[0.8178, 0.4600, 0.6508],
          [0.0709, 0.5278, 0.5870],
          [0.6469, 0.4493, 0.0670]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.35123062, 0.8077239 , 0.18711746],
         [0.05665433, 0.3396691 , 0.7406232 ],
         [0.26537323, 0....82467],
         [0.07093924, 0.52776885, 0.5869999 ],
         [0.64689255, 0.44934398, 0.06698889]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f28317aeef0>, jax_set_item = <function jax_set_item at 0x7f2800a38f70>, tensor = <function jax_tensor_frnt at 0x7f28001d15a0>
in_tensor = Array([[[[0.35123062, 0.8077239 , 0.18711746],
         [0.05665433, 0.3396691 , 0.7406232 ],
         [0.26537323, 0....82467],
         [0.07093924, 0.52776885, 0.5869999 ],
         [0.64689255, 0.44934398, 0.06698889]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.35123062, 0.8077239 , 0.18711746],
         [0.05665433, 0.3396691 , 0.7406232 ],
         [0.26537323, 0....82467],
         [0.07093924, 0.52776885, 0.5869999 ],
         [0.64689255, 0.44934398, 0.06698889]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.35123062, 0.8077239 , 0.18711746],
         [0.05665433, 0.3396691 , 0.7406232 ],
         [0.26537323, 0....82467],
         [0.07093924, 0.52776885, 0.5869999 ],
         [0.64689255, 0.44934398, 0.06698889]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f28317aeef0>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7f28317c7d90>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7f28001c63b0>, jax_get_item = <function jax_get_item at 0x7f2800a38dc0>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7f2800a6e3b0>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7f28001c7640>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7f28001c52d0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.35123062, 0.8077239 , 0.18711746],
         [0.05665433, 0.3396691 , 0.7406232 ],
         [0.26537323, 0....82467],
         [0.07093924, 0.52776885, 0.5869999 ],
         [0.64689255, 0.44934398, 0.06698889]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import jax_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import jax_clone_frnt_
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK(
            len(jax_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(jax_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        jax_KORNIA_CHECK(
            jax_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = jax_clone_frnt_(input)
        noisy_image = jax_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:92: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
_________________________________________________________________________________ test_RandomSharpness[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:334: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'jax', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.4064, 0.7973, 0.0267, 0.5602, 0.6523],
          [0.5281, 0.1247, 0.4631, 0.5983, 0.7852],
          [0...., 0.7593],
          [0.5705, 0.7904, 0.2847, 0.2449, 0.9540],
          [0.4627, 0.8864, 0.8191, 0.7682, 0.0962]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.40636843, 0.79734975, 0.0266844 , 0.5602034 , 0.65231276],
         [0.5281449 , 0.12466282, 0.46310997, 0... 0.24494487, 0.9540272 ],
         [0.46269286, 0.88643456, 0.81906277, 0.7682431 , 0.0962252 ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f27ec8257e0>, jax_set_item = <function jax_set_item at 0x7f2837d7a7a0>, tensor = <function jax_tensor_frnt at 0x7f28088913f0>
in_tensor = Array([[[[0.40636843, 0.79734975, 0.0266844 , 0.5602034 , 0.65231276],
         [0.5281449 , 0.12466282, 0.46310997, 0... 0.24494487, 0.9540272 ],
         [0.46269286, 0.88643456, 0.81906277, 0.7682431 , 0.0962252 ]]]],      dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.40636843, 0.79734975, 0.0266844 , 0.5602034 , 0.65231276],
         [0.5281449 , 0.12466282, 0.46310997, 0... 0.24494487, 0.9540272 ],
         [0.46269286, 0.88643456, 0.81906277, 0.7682431 , 0.0962252 ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.40636843, 0.79734975, 0.0266844 , 0.5602034 , 0.65231276],
         [0.5281449 , 0.12466282, 0.46310997, 0... 0.24494487, 0.9540272 ],
         [0.46269286, 0.88643456, 0.81906277, 0.7682431 , 0.0962252 ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f27ec8257e0>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7f27ec8edbd0>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7f27ec8ee0e0>, jax_get_item = <function jax_get_item at 0x7f2837d7a5f0>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7f282817f880>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7f27ec8764d0>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7f27ec875fc0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.40636843, 0.79734975, 0.0266844 , 0.5602034 , 0.65231276],
         [0.5281449 , 0.12466282, 0.46310997, 0... 0.24494487, 0.9540272 ],
         [0.46269286, 0.88643456, 0.81906277, 0.7682431 , 0.0962252 ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: name 'sharpness' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/sharpness.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[jax-s2s-False] - TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[jax-s2s-False] - NameError: name 'sharpness' is not defined
============================================================================== 3 failed, 14 passed in 3276.63s (0:54:36) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py Fs                                                                                                                                                                  [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_fit_line[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_fit_line(target_framework, mode, backend_compile):
        print("kornia.geometry.line.fit_line")
    
        if backend_compile:
            pytest.skip()
    
>       transpiled_fit_line = ivy.transpile(kornia.geometry.line.fit_line, source="torch", target=target_framework)

kornia/geometry/test_line.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <function fit_line at 0x7f60e3d732e0>, source = 'torch', target = 'numpy', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f608bc04e50>, node = <gast.gast.Module object at 0x7f608b7f4be0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f608bc04e50>, node = <gast.gast.Module object at 0x7f608b7f4be0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f608bc04e50>, node = <gast.gast.FunctionDef object at 0x7f608b7f4f40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f608bc04e50>, node = <gast.gast.Return object at 0x7f608aebe980>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f608bc04e50>, node = <gast.gast.Return object at 0x7f608aebe980>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f608bc04e50>, node = <gast.gast.Call object at 0x7f608aebc580>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f608bc04e50>, node = <gast.gast.Call object at 0x7f608aebc580>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f608bc04e50>, node = <gast.gast.Name object at 0x7f608aebec50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_ParametrizedLine'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.line.fit_line
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_line.py::test_fit_line[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_Para...
=============================================================================== 1 failed, 1 skipped in 67.41s (0:01:07) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 284.10s (0:04:44) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF...F............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_HausdorffERLoss[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss = ivy.transpile(kornia.losses.HausdorffERLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = TranspiledHausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 2.43788913e-01, -1.45596871e-03, -2.09641671e+00, ...,
           2.82072425e-01, -1.64924085e+00, -2.31899...0392979e-02,  1.29487729e+00, ...,
          -1.71592331e-03, -1.04292542e-01, -2.05986118e+00]]]],      dtype=float32)
target = Array([[[[0, 0, 0, ..., 1, 1, 0],
         [0, 0, 1, ..., 0, 0, 0],
         [1, 1, 0, ..., 1, 0, 0],
         ...,
  ...,
         [1, 0, 0, ..., 1, 1, 1],
         [1, 1, 1, ..., 0, 0, 1],
         [1, 0, 0, ..., 1, 0, 1]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_min_frnt_
    
        if jax_dim_frnt_(pred) != 4:
            raise ValueError(f"Only 2D images supported. Got {jax_dim_frnt_(pred)}.")
        if not (
            jax_max_frnt_(target) < jax_size_frnt_(pred, 1)
            and jax_min_frnt_(target) >= 0
            and target.dtype == jnp.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {jax_size_frnt_(pred, 1)}). ({jax_min_frnt_(target)}, {jax_max_frnt_(target)})"
            )
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 2.43788913e-01, -1.45596871e-03, -2.09641671e+00, ...,
           2.82072425e-01, -1.64924085e+00, -2.31899...0392979e-02,  1.29487729e+00, ...,
          -1.71592331e-03, -1.04292542e-01, -2.05986118e+00]]]],      dtype=float32)
target = Array([[[[0, 0, 0, ..., 1, 1, 0],
         [0, 0, 1, ..., 0, 0, 0],
         [1, 1, 0, ..., 1, 0, 0],
         ...,
  ...,
         [1, 0, 0, ..., 1, 1, 1],
         [1, 1, 1, ..., 0, 0, 1],
         [1, 0, 0, ..., 1, 0, 1]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f642138b600>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[ 2.43788913e-01, -1.45596871e-03, -2.09641671e+00, ...,
           2.82072425e-01, -1.64924085e+00, -2.31899...6048673e-01,  1.16464472e+00, ...,
          -2.86292639e-02, -8.99510562e-01, -8.09553981e-01]]]],      dtype=float32)
target = Array([[[[1, 1, 1, ..., 0, 0, 1],
         [1, 1, 0, ..., 1, 1, 1],
         [0, 0, 1, ..., 0, 1, 1],
         ...,
  ...,
         [0, 1, 1, ..., 0, 0, 0],
         [0, 0, 0, ..., 1, 1, 0],
         [0, 1, 1, ..., 0, 1, 0]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
________________________________________________________________________________ test_HausdorffERLoss3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss3D = ivy.transpile(kornia.losses.HausdorffERLoss3D, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = TranspiledHausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 4.77280915e-01,  4.71282363e-01,  1.09997296e+00, ...,
           -5.61380506e-01,  1.44613349e+00, -1.260...76193e-01, -1.18768859e+00, ...,
           -4.27800387e-01, -1.08361602e+00, -5.76855242e-01]]]]],      dtype=float32)
target = Array([[[[[0, 0, 0, ..., 1, 0, 0],
          [1, 0, 1, ..., 1, 0, 1],
          [1, 0, 0, ..., 0, 0, 0],
          ......        [0, 1, 0, ..., 1, 1, 1],
          [0, 0, 0, ..., 0, 1, 0],
          [1, 1, 1, ..., 0, 1, 1]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
    
        if jax_dim_frnt_(pred) != 5:
            raise ValueError(f"Only 3D images supported. Got {jax_dim_frnt_(pred)}.")
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 4.77280915e-01,  4.71282363e-01,  1.09997296e+00, ...,
           -5.61380506e-01,  1.44613349e+00, -1.260...76193e-01, -1.18768859e+00, ...,
           -4.27800387e-01, -1.08361602e+00, -5.76855242e-01]]]]],      dtype=float32)
target = Array([[[[[0, 0, 0, ..., 1, 0, 0],
          [1, 0, 1, ..., 1, 0, 1],
          [1, 0, 0, ..., 0, 0, 0],
          ......        [0, 1, 0, ..., 1, 1, 1],
          [0, 0, 0, ..., 0, 1, 0],
          [1, 1, 1, ..., 0, 1, 1]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f640e17e4c0>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[ 4.77280915e-01,  4.71282363e-01,  1.09997296e+00, ...,
           -5.61380506e-01,  1.44613349e+00, -1.260...47335e+00, -1.65701568e+00, ...,
           -1.55377999e-01, -6.16578579e-01,  9.82687235e-01]]]]],      dtype=float32)
target = Array([[[[[1, 1, 1, ..., 0, 1, 1],
          [0, 1, 0, ..., 0, 1, 0],
          [0, 1, 1, ..., 1, 1, 1],
          ......        [1, 0, 1, ..., 0, 0, 0],
          [1, 1, 1, ..., 1, 0, 1],
          [0, 0, 0, ..., 1, 0, 0]]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
__________________________________________________________________________________ test_TotalVariation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TotalVariation(target_framework, mode, backend_compile):
        print("kornia.losses.TotalVariation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTotalVariation = ivy.transpile(kornia.losses.TotalVariation, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.TotalVariation()
        transpiled_loss_fn = TranspiledTotalVariation()
    
        torch_args = (
            torch.ones((2, 3, 4, 4)),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args).data
>       transpiled_res = transpiled_loss_fn(*transpiled_args).data
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'

kornia/test_losses.py:570: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.TotalVariation
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[jax-s2s-False] - TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[jax-s2s-False] - TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_TotalVariation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'
============================================================================== 3 failed, 32 passed in 2552.88s (0:42:32) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .FF..F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_NerfModelRenderer[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
____________________________________________________________________________________ test_MLP[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MLP(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.MLP")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMLP = ivy.transpile(nerf_model.MLP, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(5, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_mlp = nerf_model.MLP(num_dims=3)
        transpiled_mlp = TranspiledMLP(num_dims=3)
    
        torch_out = torch_mlp(*torch_args)
>       transpiled_out = transpiled_mlp(*transpiled_args)

kornia/test_nerf.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
)
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.88...9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fc0083e2bc0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      ....9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.88...9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      ....9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.88...9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.886...0.9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
),)
kwargs = {'x': <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 ,....9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
)
x = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.886...0.9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
)
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.88...9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x56243ef01950, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.88...9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.88...9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.04345065, 0.15580136, 0.19757664],
       [0.9744334 , 0.886...0.9648627 ],
       [0.41087383, 0.68052876, 0.75623673],
       [0.007631  , 0.29085135, 0.8303409 ]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
)
input = <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[ 2.41724756e-02,  2.37698574e-02, -2.55673099e-02,
        -...
         6.37577400e-02,  1.44555449e-01, -1.01209886e-01,
        -2.36365888e-02, -1.38436139e-01]], dtype=float32)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU()
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[ 2.41724756e-02,  2.37698574e-02, -2.55673099e-02,
        ...        6.37577400e-02,  1.44555449e-01, -1.01209886e-01,
        -2.36365888e-02, -1.38436139e-01]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fbffedfd590, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[ 2.41724756e-02,  2.37698574e-02, -2.55673099e-02,
        ...        6.37577400e-02,  1.44555449e-01, -1.01209886e-01,
        -2.36365888e-02, -1.38436139e-01]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[ 2.41724756e-02,  2.37698574e-02, -2.55673099e-02,
        ...        6.37577400e-02,  1.44555449e-01, -1.01209886e-01,
        -2.36365888e-02, -1.38436139e-01]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[ 2.41724756e-02,  2.37698574e-02, -2.55673099e-02,
        -...
         6.37577400e-02,  1.44555449e-01, -1.01209886e-01,
        -2.36365888e-02, -1.38436139e-01]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), args = ()
kwargs = {'input': <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[ 2.41724756e-02,  2.37698574e-02, -2.55673099e-02,...         6.37577400e-02,  1.44555449e-01, -1.01209886e-01,
        -2.36365888e-02, -1.38436139e-01]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7fbfff8a5ab0>, tensorflow_set_item = <function tensorflow_set_item at 0x7fbfff8a5c60>, DATA_FORMAT = 'channels_first'
fn_args_and_kwargs = {'input': <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[ 2.41724756e-02,  2.37698574e-02, -2.55673099e-02,...         6.37577400e-02,  1.44555449e-01, -1.01209886e-01,
        -2.36365888e-02, -1.38436139e-01]], dtype=float32)>}
conv_block_start = <function tensorflow_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7fbfffca04c0>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = tensorflow_ReLU()

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <frame at 0x56243e5c5780, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py', line 77, code call>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <frame at 0x56243e5c5780, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py', line 77, code call>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
                raise OSError('source code not available')
    
        module = getmodule(object, file)
        if module:
            lines = linecache.getlines(file, module.__dict__)
        else:
            lines = linecache.getlines(file)
        if not lines:
>           raise OSError('could not get source code')
E           OSError: Exception encountered when calling tensorflow_ReLU.call().
E           
E           [1mcould not get source code[0m
E           
E           Arguments received by tensorflow_ReLU.call():
E             • input=tf.Tensor(shape=(5, 128), dtype=float32)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:958: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.MLP
_____________________________________________________________________________ test_RandomRaySampler[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7fbff49d0730>
cameras = <ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.camera.pinhole.tensorflow_PinholeCamera object at 0x7fbff49d0ca0>
num_img_rays = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != tensorflow_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {tensorflow_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7fbff49d0730>, heights = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>
widths = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>, num_img_rays = <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_trunc_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_rand_frnt,
        )
    
        num_img_rays = tensorflow_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                tensorflow_tolist_frnt_(heights),
                tensorflow_tolist_frnt_(widths),
                tensorflow_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = tensorflow_trunc_frnt(
>               tensorflow_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:364: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
tensorflow_random_uniform = <function tensorflow_random_uniform at 0x7fbffe4ea5f0>, seed = None

    def tensorflow_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.tensorflow.random import tensorflow_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return tensorflow_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/random_sampling.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, tensorflow_exists_bknd = <function tensorflow_exists_bknd at 0x7fbffe408b80>
tensorflow_default_dtype_bknd = <function tensorflow_default_dtype_bknd at 0x7fbffe4081f0>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import tensorflow_exists_bknd
        from .functional.ivy.data_type import tensorflow_default_dtype_bknd
    
        arr = (
            None
            if tensorflow_exists_bknd(dtype)
            else tensorflow__get_first_array(*args, **kwargs)
        )
        dtype = tensorflow_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @tensorflow_infer_dtype
    def tensorflow_random_uniform(
        *,
        low: Union[float, tensorflow.Tensor, tensorflow.Variable] = 0.0,
        high: Union[float, tensorflow.Tensor, tensorflow.Variable, None] = 1.0,
        shape: Optional[Union[tf.TensorShape, Sequence[int], tensorflow.Tensor]] = None,
        dtype: tf.DType,
        device: Optional[str] = None,
        seed: Optional[int] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.random import tensorflow__check_bounds_and_get_shape_bknd
    
        shape = tensorflow__check_bounds_and_get_shape_bknd(
            low,
            float(
                tensorflow.experimental.numpy.finfo(tensorflow.float32).max
                if dtype is None
                else tensorflow.experimental.numpy.finfo(dtype).max
            )
            if high is None
            else high,
            shape,
        )
>       low = tensorflow.cast(low, dtype)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/random.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (0.0, torch.float32), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type_value = torch.float32

    @tf_export("dtypes.as_dtype", "as_dtype")
    def as_dtype(type_value):
      """Converts the given `type_value` to a `tf.DType`.
    
      Inputs can be existing `tf.DType` objects, a [`DataType`
      enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),
      a string type name, or a
      [`numpy.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html).
    
      Examples:
      >>> tf.as_dtype(2)  # Enum value for float64.
      tf.float64
    
      >>> tf.as_dtype('float')
      tf.float32
    
      >>> tf.as_dtype(np.int32)
      tf.int32
    
      Note: `DType` values are interned (i.e. a single instance of each dtype is
      stored in a map). When passed a new `DType` object, `as_dtype` always returns
      the interned value.
    
      Args:
        type_value: A value that can be converted to a `tf.DType` object.
    
      Returns:
        A `DType` corresponding to `type_value`.
    
      Raises:
        TypeError: If `type_value` cannot be converted to a `DType`.
      """
      if isinstance(type_value, DType):
        if type_value._handle_data is None:  # pylint:disable=protected-access
          return _INTERN_TABLE[type_value.as_datatype_enum]
        else:
          return type_value
    
      if isinstance(type_value, np.dtype):
        try:
          return _NP_TO_TF[type_value.type]
        except KeyError:
          pass
    
      try:
        return _ANY_TO_TF[type_value]
      except (KeyError, TypeError):
        # TypeError indicates that type_value is not hashable.
        pass
    
      if hasattr(type_value, "dtype"):
        try:
          return _NP_TO_TF[np.dtype(type_value.dtype).type]
        except (KeyError, TypeError):
          pass
    
      if isinstance(type_value, _dtypes.DType):
        return _INTERN_TABLE[type_value.as_datatype_enum]
    
>     raise TypeError(f"Cannot convert the argument `type_value`: {type_value!r} "
                      "to a TensorFlow DType.")
E     TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.

/opt/fw/tensorflow/tensorflow/python/framework/dtypes.py:852: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[tensorflow-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_MLP[tensorflow-s2s-False] - OSError: Exception encountered when calling tensorflow_ReLU.call().
FAILED kornia/test_nerf.py::test_RandomRaySampler[tensorflow-s2s-False] - TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.
=============================================================================== 3 failed, 3 passed in 352.31s (0:05:52) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py .......F.....F..F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_laf_is_inside_image[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_laf_is_inside_image(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 5, 2, 3),
            torch.rand(1, 1, 32, 32),
        )
        trace_kwargs = {'border': 0}
        test_args = (
            torch.rand(2, 10, 2, 3),
            torch.rand(2, 1, 64, 64),
        )
        test_kwargs = {'border': 1}
>       _test_function(
            kornia.feature.laf_is_inside_image,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_feature2.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7f2cce4c0790>
trace_args = (tensor([[[[0.7925, 0.2943, 0.2621],
          [0.3445, 0.1637, 0.1797]],

         [[0.9693, 0.6451, 0.9702],
       ...0, 0.9514, 0.1514,  ..., 0.8714, 0.7790, 0.3486],
          [0.4564, 0.2761, 0.3284,  ..., 0.4203, 0.2487, 0.7854]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.2572, 0.0182, 0.4799],
          [0.2493, 0.4286, 0.2871]],

         [[0.2912, 0.0035, 0.3890],
       ...4, 0.5006, 0.6972,  ..., 0.3117, 0.0622, 0.9705],
          [0.2645, 0.6976, 0.9212,  ..., 0.4117, 0.0292, 0.8196]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7f2cce4c0790>, fn_name = 'kornia.feature.laf_is_inside_image'
trace_args = (tensor([[[[0.7925, 0.2943, 0.2621],
          [0.3445, 0.1637, 0.1797]],

         [[0.9693, 0.6451, 0.9702],
       ...0, 0.9514, 0.1514,  ..., 0.8714, 0.7790, 0.3486],
          [0.4564, 0.2761, 0.3284,  ..., 0.4203, 0.2487, 0.7854]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.2572, 0.0182, 0.4799],
          [0.2493, 0.4286, 0.2871]],

         [[0.2912, 0.0035, 0.3890],
       ...4, 0.5006, 0.6972,  ..., 0.3117, 0.0622, 0.9705],
          [0.2645, 0.6976, 0.9212,  ..., 0.4117, 0.0292, 0.8196]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 5, 2, 3), dtype=float32, numpy=
array([[[[0.79254097, 0.29429138, 0.26212496],
         [0.34452...13]],

        [[0.6754405 , 0.681297  , 0.132267  ],
         [0.20396554, 0.179578  , 0.88774484]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0732671 , 0.31629997, 0.00663048, ..., 0.93251055,...],
         [0.45637083, 0.2761268 , 0.32844198, ..., 0.42031944,
          0.2487433 , 0.785415  ]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True, False, False, False, False,
         False,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True, False, False, False, False,
         False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True, False, False, False, False,
         False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fals...True,  True],
        [ True,  True,  True,  True,  True, False, False, False, False,
         False,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:151: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fal...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      if not ops.is_auto_dtype_conversion_enabled():
>       return op(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/ops/weak_tensor_ops.py:142: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True, False, False, Fal...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

e = _NotOkStatusException(), name = None

    def raise_from_not_ok_status(e, name) -> NoReturn:
      e.message += (" name: " + str(name if name is not None else ""))
>     raise core._status_to_exception(e) from None  # pylint: disable=protected-access
E     tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E     	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name:

/opt/fw/tensorflow/tensorflow/python/framework/ops.py:5983: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.laf.laf_is_inside_image
_______________________________________________________________________________ test_MKDDescriptor[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MKDDescriptor(target_framework, mode, backend_compile):
        print("kornia.feature.MKDDescriptor")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMKDDescriptor = ivy.transpile(kornia.feature.MKDDescriptor, source="torch", target=target_framework)
    
        x = torch.rand(23, 1, 32, 32)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.MKDDescriptor()
        torch_out = model(x)
    
>       transpiled_model = TranspiledMKDDescriptor()

kornia/test_feature2.py:339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_MKDDescriptor' object has no attribute 'output_dims'") raised in repr()] tensorflow_MKDDescriptor object at 0x7f2c4a5025f0>, patch_size = 32
kernel_type = 'concat', whitening = 'pcawt', training_set = 'liberty', output_dims = 128

    def __init__(
        self,
        patch_size=32,
        kernel_type="concat",
        whitening="pcawt",
        training_set="liberty",
        output_dims=128,
    ):
        from ..filters.gaussian import tensorflow_GaussianBlur2d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            patch_size=patch_size,
            kernel_type=kernel_type,
            whitening=whitening,
            training_set=training_set,
            output_dims=output_dims,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size: typing.Any = patch_size
        self.kernel_type: typing.Any = kernel_type
        self.whitening: typing.Any = whitening
        self.training_set: typing.Any = training_set
        self.sigma = 1.4 * (patch_size / 64)
        self.smoothing = tensorflow_GaussianBlur2d(
            (5, 5), (self.sigma, self.sigma), "replicate"
        )
        self.gradients = tensorflow_MKDGradients()
        polar_s: typing.Any = "polar"
        cart_s: typing.Any = "cart"
        self.parametrizations = (
            [polar_s, cart_s] if self.kernel_type == "concat" else [self.kernel_type]
        )
        self.odims: typing.Any = 0
        relative_orientations = {polar_s: True, cart_s: False}
        self.feats = {}
        for parametrization in self.parametrizations:
            gradient_embedding = tensorflow_EmbedGradients(
                patch_size=patch_size,
                relative=tensorflow_get_item(relative_orientations, parametrization),
            )
>           spatial_encoding = tensorflow_ExplicitSpacialEncoding(
                kernel_type=parametrization,
                fmap_size=patch_size,
                in_dims=gradient_embedding.kernel.d,
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:989: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7f2c4a500b80>, args = ()
kwargs = {'fmap_size': 32, 'in_dims': 7, 'kernel_type': 'polar'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7f2c4a500b80>, kernel_type = 'polar'
fmap_size = 32, in_dims = 7, do_gmask = True, do_l2 = True

    @tensorflow_store_config_info
    def __init__(
        self, kernel_type="polar", fmap_size=32, in_dims=7, do_gmask=True, do_l2=True
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        self.super___init__(
            kernel_type=kernel_type,
            fmap_size=fmap_size,
            in_dims=in_dims,
            do_gmask=do_gmask,
            do_l2=do_l2,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if kernel_type not in ["polar", "cart"]:
            raise NotImplementedError(
                f"{kernel_type} is not valid, use polar or cart)."
            )
        self.kernel_type = kernel_type
        self.fmap_size = fmap_size
        self.in_dims = in_dims
        self.do_gmask = do_gmask
        self.do_l2 = do_l2
        self.grid = tensorflow_get_grid_dict(fmap_size)
        self.gmask = None
>       emb = tensorflow_spatial_kernel_embedding(self.kernel_type, self.grid)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:575: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kernel_type = 'polar'
grids = {'x': <tf.Tensor: shape=(32, 32), dtype=float32, numpy=
array([[-1.        , -0.9354839 , -0.87096775, ...,  0.8709677...,
       [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
         0.81871915,  0.7853981 ]], dtype=float32)>}

    def tensorflow_spatial_kernel_embedding(kernel_type, grids):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_select_frnt_
        from ..constants import pi
    
        factors = {"phi": 1.0, "rho": pi / sqrt2, "x": pi / 2, "y": pi / 2}
        if kernel_type == "cart":
            coeffs_ = "xy"
            params_ = ["x", "y"]
        elif kernel_type == "polar":
            coeffs_ = "rhophi"
            params_ = ["phi", "rho"]
        keys = list(grids.keys())
        patch_size = tensorflow_shape_frnt_(tensorflow_get_item(grids, keys[0]))[-1]
        grids_normed = {k: (v * tensorflow_get_item(factors, k)) for k, v in grids.items()}
        grids_normed = {
            k: tensorflow_float_frnt_(
                tensorflow_unsqueeze_frnt_(tensorflow_unsqueeze_frnt_(v, 0), 0)
            )
            for k, v in grids_normed.items()
        }
        vm_a = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        vm_b = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        emb_a = tensorflow_squeeze_frnt_(
>           vm_a(tensorflow_get_item(grids_normed, params_[0]))
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:534: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55a3674756e0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...339, function='test_MKDDescriptor', code_context=['    transpiled_model = TranspiledMKDDescriptor()\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
x = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ..core._backend import cos
        from ..core._backend import sin
    
        if not isinstance(x, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(x)}")
        if not len(tensorflow_shape_frnt_(x)) == 4 or tensorflow_shape_frnt_(x)[1] != 1:
            raise ValueError(
                f"Invalid input shape, we expect Bx1xHxW. Got: {tensorflow_shape_frnt_(x)}"
            )
        if not isinstance(self.emb0, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Emb0 type is not a Tensor. Got {type(x)}")
        emb0 = tensorflow_repeat_frnt_(
            tensorflow_to_frnt_(self.emb0, x), tensorflow_size_frnt_(x, 0), 1, 1, 1
        )
        frange = tensorflow_to_frnt_(self.frange, x) * x
        emb1 = cos(frange)
        emb2 = sin(frange)
        embedding = tensorflow_cat_frnt([emb0, emb1, emb2], dim=1)
>       embedding = self.pt_weights * embedding

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), name = 'pt_weights'

    @tf.autograph.experimental.do_not_convert
    def __getattr__(self, name):
        if name == "v":
            if not super().__getattribute__("_v") and not getattr(  # noqa: E501
                self, "_built", False
            ):
                return self._build_and_return_v(
                    *self._args, dynamic_backend=self._dynamic_backend, **self._kwargs
                )
    
        _dict = super().__getattribute__("__dict__")
        if name in _dict:
            return _dict[name]
    
        elif "_v" in _dict and name in _dict["_v"]:
            return _dict["_v"][name]
    
>       return super().__getattribute__(name)
E       AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
E       
E       [1m'tensorflow_VonMisesKernel' object has no attribute 'pt_weights'[0m
E       
E       Arguments received by tensorflow_VonMisesKernel.call():
E         • x=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1343: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.MKDDescriptor
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/manyids2/mkd_pytorch/raw/master/mkd_pytorch/mkd-concat-64.pth" to /root/.cache/torch/hub/checkpoints/mkd-concat-64.pth

  0%|          | 0.00/1.31M [00:00<?, ?B/s]
100%|██████████| 1.31M/1.31M [00:00<00:00, 175MB/s]
___________________________________________________________________________________ test_HyNet[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HyNet(target_framework, mode, backend_compile):
        print("kornia.feature.HyNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHyNet = ivy.transpile(kornia.feature.HyNet, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HyNet()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledHyNet()(transpiled_x)

kornia/test_feature2.py:397: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.01439106, 0.62552994, 0.10658407, ..., 0.1260811...
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f2c49caa820, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...,
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.01439106, 0.62552994, 0.10658407, ..., 0.1260811...
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...,
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.01439106, 0.62552994, 0.10658407, ..., 0.1260811...
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_T...flow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
),)
kwargs = {'x': <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.01439106, 0.62552994, 0.10658407, ..., 0.12...,
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HyNet(
  (layer1): tensorflow_Sequential(
    (0): tensorflow_FilterResponseNorm2d()
    (1): tensorflow_TL...orflow_Dropout()
    (1): KerasConv2D()
    (2): KerasBatchNorm2D()
  )
  (desc_norm): tensorflow_LocalResponseNorm()
)
x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.01439106, 0.62552994, 0.10658407, ..., 0.12608111...],
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
    
>       x = self.layer1(x)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:543: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
)
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.01439106, 0.62552994, 0.10658407, ..., 0.1260811...
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55a367398ea0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
), v = None
buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.01439106, 0.62552994, 0.10658407, ..., 0.1260811...
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
), v = None
buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.01439106, 0.62552994, 0.10658407, ..., 0.1260811...
         [0.4035266 , 0.501746  , 0.5203674 , ..., 0.6107291 ,
          0.9856202 , 0.58965397]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): tensorflow_FilterResponseNorm2d()
  (1): tensorflow_TLU()
  (2): KerasConv2D()
  (3): tensorflow_FilterResponseNorm2d()
  (4): tensorflow_TLU()
)
input = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0247493 , 1.0757664 , 0.1832999 , ..., 0.21683028...],
         [0.71349484, 0.88716125, 0.9200866 , ..., 1.0798595 ,
          1.7427225 , 1.0425956 ]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0247493 , 1.0757664 , 0.1832999 , ..., 0.2168302...
         [0.71349484, 0.88716125, 0.9200866 , ..., 1.0798595 ,
          1.7427225 , 1.0425956 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55a369cf40e0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0247493 , 1.0757664 , 0.1832999 , ..., 0.2168302...
         [0.71349484, 0.88716125, 0.9200866 , ..., 1.0798595 ,
          1.7427225 , 1.0425956 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0247493 , 1.0757664 , 0.1832999 , ..., 0.2168302...
         [0.71349484, 0.88716125, 0.9200866 , ..., 1.0798595 ,
          1.7427225 , 1.0425956 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0247493 , 1.0757664 , 0.1832999 , ..., 0.21683028...],
         [0.71349484, 0.88716125, 0.9200866 , ..., 1.0798595 ,
          1.7427225 , 1.0425956 ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_max_frnt
    
>       return tensorflow_max_frnt(x, self.tau)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dim = <KerasVariable shape=(1, 1, 1, 1), dtype=float32, path=variable_13>, keepdim = False, out = None
input = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0247493 , 1.0757664 , 0.1832999 , ..., 0.21683028...],
         [0.71349484, 0.88716125, 0.9200866 , ..., 1.0798595 ,
          1.7427225 , 1.0425956 ]]]], dtype=float32)>

    def tensorflow_max_frnt(*input, dim=None, keepdim=False, out=None):
        from ...ivy.general import tensorflow_is_array_bknd
        from .comparison_ops import tensorflow_maximum_frnt
        from ...backends.tensorflow.statistical import tensorflow_max
        from ...backends.tensorflow.searching import tensorflow_argmax
    
        if len(input) == 1:
            input = input[0]
        elif len(input) == 2:
            input_0 = input[0]
            input_1 = input[1]
            if tensorflow_is_array_bknd(input_1):
                return tensorflow_maximum_frnt(*input)
            else:
                input = input_0
                dim = input_1
        else:
            input = input[0]
            dim = input[1]
            keepdim = input[2]
        if dim is None:
            return tensorflow_max(input, axis=dim, keepdims=keepdim, out=out)
        elif out is not None:
            tensorflow_max(input, axis=dim, keepdims=keepdim, out=out[0])
            tensorflow_argmax(input, axis=dim, keepdims=keepdim, out=out[1])
            return out
        else:
            max_tuple = namedtuple("max", ["values", "indices"])
            return max_tuple(
>               tensorflow_max(input, axis=dim, keepdims=keepdim),
                tensorflow_argmax(input, axis=dim, keepdims=keepdim),
            )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/reduction_ops.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0247493 , 1.0757664 , 0.1832999 , ..., 0.2168302...,
         [0.71349484, 0.88716125, 0.9200866 , ..., 1.0798595 ,
          1.7427225 , 1.0425956 ]]]], dtype=float32)>]
kwargs = {'axis': <KerasVariable shape=(1, 1, 1, 1), dtype=float32, path=variable_13>, 'keepdims': False}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f2c49f44a60>
tensorflow_set_item = <function tensorflow_set_item at 0x7f2c49ec1e10>, tensorflow_asarray = <function tensorflow_asarray at 0x7f2c49f46e60>
tensorflow_get_item = <function tensorflow_get_item at 0x7f2c49ec1c60>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'axis', 'keepdims', 'out']
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[int, ...s 'bool'>, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType]]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(16, 1, 32, 32), dtype=float32, numpy=
array([[[[0.0247493 , 1.0757664 , 0.1832999 , ..., 0.21683028...],
         [0.71349484, 0.88716125, 0.9200866 , ..., 1.0798595 ,
          1.7427225 , 1.0425956 ]]]], dtype=float32)>

    @tensorflow_handle_array_like_without_promotion
    def tensorflow_max(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        axis: Optional[Union[int, Sequence[int]]] = None,
        keepdims: bool = False,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        if "complex" in str(x.dtype):
            real = tensorflow.math.real(x)
            img = tensorflow.math.imag(x)
            const = tensorflow.constant(1.0j, dtype=x.dtype)
            real_max = tensorflow.reduce_max(real, axis=axis, keepdims=keepdims)
            imag = tensorflow.where(
                real == real_max, img, tensorflow.experimental.numpy.finfo(img.dtype).min
            )
            img_max = tensorflow.reduce_max(imag, axis=axis, keepdims=keepdims)
            img_max = tensorflow.cast(img_max, x.dtype)
            return tensorflow.add(
                tensorflow.cast(real_max, x.dtype), tensorflow.multiply(img_max, const)
            )
        axis = tuple(axis) if isinstance(axis, list) else axis
>       return tensorflow.math.reduce_max(x, axis=axis, keepdims=keepdims)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
E       
E       [1mValue for attr 'Tidx' of float is not in the list of allowed values: int32, int64
E       	; NodeDef: {{node Max}}; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Max][0m
E       
E       Arguments received by tensorflow_TLU.call():
E         • x=tf.Tensor(shape=(16, 1, 32, 32), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/statistical.py:95: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HyNet
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_laf_is_inside_image[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allow...
FAILED kornia/test_feature2.py::test_MKDDescriptor[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
FAILED kornia/test_feature2.py::test_HyNet[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
============================================================================== 3 failed, 14 passed in 1347.30s (0:22:27) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ...F.F                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_ImageSequential[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
        TranspiledMedianBlur = ivy.transpile(
            kornia.filters.MedianBlur,
            source="torch",
            target=target_framework,
        )
        TranspiledInvert = ivy.transpile(
            kornia.enhance.Invert,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomMixUpV2 = ivy.transpile(
            kornia.augmentation.RandomMixUpV2,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledImageSequential(
            TranspiledBgrToRgb(),
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledMedianBlur((3, 3)),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledInvert(),
            TranspiledRandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}
node = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7ff9e05ffa90>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>
self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7ff9e05ffa90>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7ff9e05ffa90>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7ff9e05ffa90>, brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.1
same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.random_generator._2d.color_jiggle'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:43: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
_________________________________________________________________________________ test_VideoSequential[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledVideoSequential = ivy.transpile(
            kornia.augmentation.container.VideoSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
        transpiled_aug_list =  TranspiledVideoSequential(
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledBgrToRgb(),
            TranspiledRandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}
node = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7ffa0be3b4c0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>
self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7ffa0be3b4c0>, args = (0.1, 0.1, 0.1, 0.1)
kwargs = {'p': 1.0}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7ffa0be3b4c0>, args = (0.1, 0.1, 0.1, 0.1)
kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7ffa0be3b4c0>, brightness = 0.1, contrast = 0.1
saturation = 0.1, hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:43: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_ImageSequential[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.random_generator._2d...
FAILED kornia/augmentation/test_container.py::test_VideoSequential[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'
=============================================================================== 2 failed, 4 passed in 2192.24s (0:36:32) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ..............FFF                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________________ test_HardNet[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HardNet(target_framework, mode, backend_compile):
        print("kornia.feature.HardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHardNet = ivy.transpile(kornia.feature.HardNet, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HardNet()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledHardNet()(transpiled_x)

kornia/test_feature2.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, args = (), kwargs = {}, node = jax_HardNet()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, self = jax_HardNet(), args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet(), pretrained = False

    def __init__(self, pretrained=False):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=128,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.3),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/hardnet.py:75: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}
node = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 32, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HardNet
_____________________________________________________________________________________ test_HardNet8[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HardNet8(target_framework, mode, backend_compile):
        print("kornia.feature.HardNet8")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHardNet8 = ivy.transpile(kornia.feature.HardNet8, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HardNet8()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledHardNet8()(transpiled_x)

kornia/test_feature2.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet8'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet8'>, args = (), kwargs = {}, node = jax_HardNet8()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet8'>, self = jax_HardNet8(), args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet8(), pretrained = False

    def __init__(self, pretrained=False):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.creation_ops import jax_zeros_frnt
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=128,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=128,
                out_features=256,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=256,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.3),
            FlaxConv(
                in_features=256,
                out_features=512,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=512,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/hardnet.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}
node = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 32, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HardNet8
______________________________________________________________________________________ test_HyNet[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HyNet(target_framework, mode, backend_compile):
        print("kornia.feature.HyNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHyNet = ivy.transpile(kornia.feature.HyNet, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HyNet()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledHyNet()(transpiled_x)

kornia/test_feature2.py:397: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hynet.jax_HyNet'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hynet.jax_HyNet'>, args = (), kwargs = {}
node = jax_HyNet(
  (layer1): jax_Sequential(
    (0): jax_FilterResponseNorm2d()
    (1): jax_TLU()
    (2): FlaxConv(in_fea...ize=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
    (1): jax_FilterResponseNorm2d()
    (2): jax_TLU()
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hynet.jax_HyNet'>
self = jax_HyNet(
  (layer1): jax_Sequential(
    (0): jax_FilterResponseNorm2d()
    (1): jax_TLU()
    (2): FlaxConv(in_fea...ize=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
    (1): jax_FilterResponseNorm2d()
    (2): jax_TLU()
  )
)
args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HyNet(
  (layer1): jax_Sequential(
    (0): jax_FilterResponseNorm2d()
    (1): jax_TLU()
    (2): FlaxConv(in_fea...ize=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
    (1): jax_FilterResponseNorm2d()
    (2): jax_TLU()
  )
)
pretrained = False, is_bias = True, is_bias_FRN = True, dim_desc = 128, drop_rate = 0.3, eps_l2_norm = 1e-10

    def __init__(
        self,
        pretrained=False,
        is_bias=True,
        is_bias_FRN=True,
        dim_desc=128,
        drop_rate=0.3,
        eps_l2_norm=1e-10,
    ):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.normalization import jax_LocalResponseNorm
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            is_bias=is_bias,
            is_bias_FRN=is_bias_FRN,
            dim_desc=dim_desc,
            drop_rate=drop_rate,
            eps_l2_norm=eps_l2_norm,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.eps_l2_norm = eps_l2_norm
        self.dim_desc = dim_desc
        self.drop_rate = drop_rate
        self.layer1 = jax_Sequential(
            jax_FilterResponseNorm2d(1, is_bias=is_bias_FRN),
            jax_TLU(1),
            FlaxConv(
                in_features=1,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=is_bias,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_FilterResponseNorm2d(32, is_bias=is_bias_FRN),
            jax_TLU(32),
        )
        self.layer2 = jax_Sequential(
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=is_bias,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_FilterResponseNorm2d(32, is_bias=is_bias_FRN),
            jax_TLU(32),
        )
        self.layer3 = jax_Sequential(
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=is_bias,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_FilterResponseNorm2d(64, is_bias=is_bias_FRN),
            jax_TLU(64),
        )
        self.layer4 = jax_Sequential(
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=is_bias,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_FilterResponseNorm2d(64, is_bias=is_bias_FRN),
            jax_TLU(64),
        )
        self.layer5 = jax_Sequential(
            FlaxConv(
                in_features=64,
                out_features=128,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=is_bias,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_FilterResponseNorm2d(128, is_bias=is_bias_FRN),
            jax_TLU(128),
        )
        self.layer6 = jax_Sequential(
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=is_bias,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_FilterResponseNorm2d(128, is_bias=is_bias_FRN),
            jax_TLU(128),
        )
        self.layer7 = jax_Sequential(
            jax_Dropout(self.drop_rate),
            FlaxConv(
                in_features=128,
                out_features=self.dim_desc,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=self.dim_desc,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/hynet.py:500: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 128, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 128, ...}
node = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 128, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 128, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HyNet
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_HardNet[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature2.py::test_HardNet8[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature2.py::test_HyNet[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
============================================================================== 3 failed, 14 passed in 1361.17s (0:22:41) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 342.69s (0:05:42) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ........                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 370.99s (0:06:10) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py ss                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 5.37s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_bbox_to_mask[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7ff81f5e40d0>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7ff81f5e40d0>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(1, 5, 5), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 472.18s (0:07:52) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py sssssssssssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 13 skipped in 5.35s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 4 passed in 81.88s (0:01:21) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ss                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 5.01s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ..FF                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_So2[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_So2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        real_part = torch.tensor([1.0], requires_grad=True)
        imaginary_part = torch.tensor([2.0], requires_grad=True)
        complex_number = torch.complex(real_part, imaginary_part)
        torch_so2 = kornia.geometry.liegroup.So2(complex_number)
    
        TranspiledSo2 = ivy.transpile(kornia.geometry.liegroup.So2, source="torch", target=target_framework)
        transpiled_complex_number = _nest_torch_tensor_to_new_framework(complex_number, target_framework)
>       transpiled_so2 = TranspiledSo2(transpiled_complex_number)

kornia/geometry/test_liegroup.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_So2' object has no attribute '_z'") raised in repr()] tensorflow_So2 object at 0x7fd71ad5d840>
z = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

    def __init__(self, z):
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ._utils import tensorflow_check_so2_z_shape
    
        self.super___init__(
            z,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        tensorflow_KORNIA_CHECK_IS_TENSOR(z)
        tensorflow_check_so2_z_shape(z)
>       self._z = tensorflow.keras.Variable(z)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_26>, initializer = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>, shape = None, dtype = 'float32'
trainable = True, autocast = True, aggregation = 'mean', name = 'variable_26'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_26>, value = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>)
kwargs = {'dtype': 'float32', 'name': 'variable_26', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So2
____________________________________________________________________________________ test_Se2[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Se2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.Se2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        so2_rotation = kornia.geometry.liegroup.So2.identity(1)
        translation_vector = torch.ones((1, 2), requires_grad=True)
        torch_se2 = kornia.geometry.liegroup.Se2(so2_rotation, translation_vector)
    
        TranspiledSe2 = ivy.transpile(kornia.geometry.liegroup.Se2, source="torch", target=target_framework)
        TranspiledSo2 = ivy.transpile(kornia.geometry.liegroup.So2, source="torch", target=target_framework)
    
>       transpiled_so2_rotation = TranspiledSo2.identity(1)

kornia/geometry/test_liegroup.py:252: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.liegroup.so2.tensorflow_So2'>, batch_size = 1, device = None, dtype = None

    @classmethod
    def identity(cls, batch_size=None, device=None, dtype=None):
        from ...core._backend import complex
        from ...core._backend import tensor
        from ...core.check import tensorflow_KORNIA_CHECK
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        real_data = tensor(1.0, device=device, dtype=dtype)
        imag_data = tensor(0.0, device=device, dtype=dtype)
        if batch_size is not None:
            tensorflow_KORNIA_CHECK(batch_size >= 1, msg="batch_size must be positive")
            real_data = tensorflow_repeat_frnt_(real_data, batch_size)
            imag_data = tensorflow_repeat_frnt_(imag_data, batch_size)
>       return cls(complex(real_data, imag_data))

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:174: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_So2' object has no attribute '_z'") raised in repr()] tensorflow_So2 object at 0x7fd71a5a9000>
args = (<tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_So2' object has no attribute '_z'") raised in repr()] tensorflow_So2 object at 0x7fd71a5a9000>
z = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>

    @tensorflow_store_config_info
    def __init__(self, z):
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ._utils import tensorflow_check_so2_z_shape
    
        self.super___init__(
            z,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        tensorflow_KORNIA_CHECK_IS_TENSOR(z)
        tensorflow_check_so2_z_shape(z)
>       self._z = tensorflow.keras.Variable(z)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_27>, initializer = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>, shape = None, dtype = 'float32'
trainable = True, autocast = True, aggregation = 'mean', name = 'variable_27'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_27>, value = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>)
kwargs = {'dtype': 'float32', 'name': 'variable_27', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,), dtype=complex64, numpy=array([1.+0.j], dtype=complex64)>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.Se2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_liegroup.py::test_So2[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,...
FAILED kornia/geometry/test_liegroup.py::test_Se2[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype complex64: <tf.Tensor: shape=(1,...
=============================================================================== 2 failed, 2 passed in 438.46s (0:07:18) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1073.20s (0:17:53) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F.F.                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomMotionBlur[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'tensorflow', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f5d4ba07440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
params = None, kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f5d4bdf72e0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f5d4bd2e680>
tensor = <function tensorflow_tensor_frnt at 0x7f5d4bda6b00>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .....ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
    
        params = super().generate_parameters(batch_shape)
        params = tensorflow_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else tensorflow_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
E       
E       [1mtensorflow_randint_frnt() missing 1 required positional argument: 'size'[0m
E       
E       Arguments received by tensorflow_RandomMotionBlur.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:73: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_________________________________________________________________________ test_RandomSaltAndPepperNoise[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'tensorflow', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.4608, 0.8259, 0.5580],
          [0.9045, 0.6811, 0.7794],
          [0.3578, 0.8465, 0.0815]],

       ...48]],

         [[0.5308, 0.2203, 0.7599],
          [0.8341, 0.2456, 0.4287],
          [0.3783, 0.6359, 0.3728]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.9044...1 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f5d51845240, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...71 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.9044...1 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...71 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.9044...1 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.90445...871 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
       ...71 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.90445...871 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se,  True]],

        [[False, False, False],
         [False,  True, False],
         [False, False,  True]]]])>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f5d38414ca0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f5d38338dc0>
tensor = <function tensorflow_tensor_frnt at 0x7f5d30d1fe20>
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.90445...871 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.90445...871 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se,  True]],

        [[False, False, False],
         [False,  True, False],
         [False, False,  True]]]])>, ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.90445...871 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se,  True]],

        [[False, False, False],
         [False,  True, False],
         [False, False,  True]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f5d38414ca0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f5d38417e20>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f5d57585e10>, tensorflow_get_item = <function tensorflow_get_item at 0x7f5d38338c10>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f5d3815e5f0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f5d575844c0>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f5d57584550>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.46081316, 0.825928  , 0.5579613 ],
         [0.90445...871 ],
         [0.8340761 , 0.24556601, 0.42872566],
         [0.37828642, 0.6359382 , 0.37277704]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se,  True]],

        [[False, False, False],
         [False,  True, False],
         [False, False,  True]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import tensorflow_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK(
            len(tensorflow_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(tensorflow_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        tensorflow_KORNIA_CHECK(
            tensorflow_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = tensorflow_clone_frnt_(input)
        noisy_image = tensorflow_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'to'[0m
E       
E       Arguments received by tensorflow_RandomSaltAndPepperNoise.call():
E         • input=tf.Tensor(shape=(1, 3, 3, 3), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:99: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
______________________________________________________________________________ test_RandomSharpness[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:334: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'tensorflow', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.4630, 0.7673, 0.2085, 0.8716, 0.6042],
          [0.6446, 0.2366, 0.0818, 0.1918, 0.1770],
          [0...., 0.1578],
          [0.7988, 0.3834, 0.2190, 0.7718, 0.9782],
          [0.5038, 0.2393, 0.9517, 0.4755, 0.4738]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.604...717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f5d51844a40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.604...717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.604...717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.6041....7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.871617...7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.6041....7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.42582834], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f5d30e18a60>, tensorflow_set_item = <function tensorflow_set_item at 0x7f5d30b67e20>
tensor = <function tensorflow_tensor_frnt at 0x7f5d30c01240>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.6041....7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.6041....7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.42582834], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.6041....7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.42582834], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f5d30e18a60>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f5d30e1a560>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f5d30cefa30>, tensorflow_get_item = <function tensorflow_get_item at 0x7f5d30b67c70>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f5d575253f0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f5d30cef910>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f5d30cef370>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.4630342 , 0.76725566, 0.20852762, 0.87161744, 0.6041....7717982 , 0.97818303],
         [0.50385   , 0.23926985, 0.9516754 , 0.47549933, 0.47378385]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...py=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.42582834], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
E       
E       [1mname 'sharpness' is not defined[0m
E       
E       Arguments received by tensorflow_RandomSharpness.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/sharpness.py:46: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
______________________________________________________________________________ test_RandomSolarize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSolarize(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSolarize")
    
        init_args = (0.1, 0.1)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSolarize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.solarize.RandomSolarize'>, target = 'tensorflow', init_args = (0.1, 0.1), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.7620, 0.4247, 0.1464, 0.8903, 0.9592],
          [0.8969, 0.9351, 0.8321, 0.7196, 0.7463],
          [0...., 0.8395],
          [0.4545, 0.7391, 0.5619, 0.3356, 0.8834],
          [0.7005, 0.9050, 0.5308, 0.4273, 0.7096]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.959...356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f5d38af8c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.959...356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.959...356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.9591....3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.890282...3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.9591....3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.06186759], dtype=float32)>, 'batch_prob': <tf.Ten...y=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.56078285], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f5d5347f5b0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f5d38d50550>
tensor = <function tensorflow_tensor_frnt at 0x7f5d38d59e10>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.9591....3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.9591....3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.06186759], dtype=float32)>, 'batch_prob': <tf.Ten...y=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.56078285], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.9591....3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.06186759], dtype=float32)>, 'batch_prob': <tf.Ten...y=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.56078285], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f5d5347f5b0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f5d5347d900>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f5d30d330a0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f5d38d503a0>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f5d4b4c5e10>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f5d3892eb90>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f5d3892eb00>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.9591....3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.06186759], dtype=float32)>, 'batch_prob': <tf.Ten...y=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.56078285], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.adjust import tensorflow_solarize
    
        thresholds = params["thresholds"]
        additions: typing.Any
        if "additions" in params:
            additions = params["additions"]
        else:
            additions = None
>       return tensorflow_solarize(input, thresholds, additions)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/solarize.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.7619954 , 0.42472106, 0.14639556, 0.89028203, 0.9591....3356369 , 0.8833641 ],
         [0.7004634 , 0.90503937, 0.530757  , 0.4272694 , 0.7095665 ]]]],
      dtype=float32)>
thresholds = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.56078285], dtype=float32)>, additions = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.06186759], dtype=float32)>

    def tensorflow_solarize(input, thresholds=0.5, additions=None):
        from ...ivy.functional.frontends.torch.creation_ops import tensorflow_as_tensor_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_all_frnt
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clamp_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(
            thresholds, (float, tensorflow.Tensor, tensorflow.keras.Variable)
        ):
            raise TypeError(
                f"The factor should be either a float or Tensor. Got {type(thresholds)}"
            )
        if isinstance(thresholds, (float,)):
            thresholds = tensorflow_as_tensor_frnt(thresholds)
        if additions is not None:
            if not isinstance(
                additions, (float, tensorflow.Tensor, tensorflow.keras.Variable)
            ):
                raise TypeError(
                    f"The factor should be either a float or Tensor. Got {type(additions)}"
                )
            if isinstance(additions, (float,)):
                additions = tensorflow_as_tensor_frnt(additions)
>           if not tensorflow_all_frnt((additions < 0.5) * (additions > -0.5)):

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/adjust.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, rhs = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, x2 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_RandomSolarize.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_RandomSolarize.call():
E         • input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:299: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSolarize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSolarize[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensor...
============================================================================== 4 failed, 13 passed in 3624.70s (1:00:24) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 118.57s (0:01:58) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py ........                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 735.18s (0:12:15) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py FF...F.FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_LAFOrienter[tensorflow-s2s-False] ________________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LAFOrienter(target_framework, mode, backend_compile):
        print("kornia.feature.LAFOrienter")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLAFOrienter = ivy.transpile(kornia.feature.LAFOrienter, source="torch", target=target_framework)
    
        laf = torch.rand(1, 2, 2, 3)
        img = torch.rand(1, 1, 32, 32)
        transpiled_laf = _nest_torch_tensor_to_new_framework(laf, target_framework)
        transpiled_img = _nest_torch_tensor_to_new_framework(img, target_framework)
    
        model = kornia.feature.LAFOrienter()
        torch_out = model(laf, img)
    
>       transpiled_model = TranspiledLAFOrienter()

kornia/test_feature5.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f020e053610>, patch_size = 32, num_angular_bins = 36
angle_detector = None

    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (32, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LAFOrienter
_____________________________________________________________________ test_PatchDominantGradientOrientation[tensorflow-s2s-False] ______________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

>   ???
E   AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PatchDominantGradientOrientation(target_framework, mode, backend_compile):
        print("kornia.feature.PatchDominantGradientOrientation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPatchDominantGradientOrientation = ivy.transpile(kornia.feature.PatchDominantGradientOrientation, source="torch", target=target_framework)
    
        patch = torch.rand(10, 1, 32, 32)
        transpiled_patch = _nest_torch_tensor_to_new_framework(patch, target_framework)
    
        model = kornia.feature.PatchDominantGradientOrientation()
        torch_out = model(patch)
    
>       transpiled_model = TranspiledPatchDominantGradientOrientation()

kornia/test_feature5.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (), kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable_1>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

>   ???
E   ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.PatchDominantGradientOrientation
____________________________________________________________________________________ test_TLU[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TLU(target_framework, mode, backend_compile):
        print("kornia.feature.TLU")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTLU = ivy.transpile(kornia.feature.TLU, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 8, 8)
        torch_out = kornia.feature.TLU(3)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledTLU(3)(transpiled_x)

kornia/test_feature5.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
     ...        4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5589de76b0a0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(), <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.3...         4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
     ...        4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(), <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.3...         4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
     ...        4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
      ...          4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_TLU(),)
kwargs = {'x': <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
...         4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TLU()
x = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
      ...          4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_max_frnt
    
>       return tensorflow_max_frnt(x, self.tau)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/hynet.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dim = <KerasVariable shape=(1, 3, 1, 1), dtype=float32, path=variable_16>, keepdim = False, out = None
input = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
      ...          4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>

    def tensorflow_max_frnt(*input, dim=None, keepdim=False, out=None):
        from ...ivy.general import tensorflow_is_array_bknd
        from .comparison_ops import tensorflow_maximum_frnt
        from ...backends.tensorflow.statistical import tensorflow_max
        from ...backends.tensorflow.searching import tensorflow_argmax
    
        if len(input) == 1:
            input = input[0]
        elif len(input) == 2:
            input_0 = input[0]
            input_1 = input[1]
            if tensorflow_is_array_bknd(input_1):
                return tensorflow_maximum_frnt(*input)
            else:
                input = input_0
                dim = input_1
        else:
            input = input[0]
            dim = input[1]
            keepdim = input[2]
        if dim is None:
            return tensorflow_max(input, axis=dim, keepdims=keepdim, out=out)
        elif out is not None:
            tensorflow_max(input, axis=dim, keepdims=keepdim, out=out[0])
            tensorflow_argmax(input, axis=dim, keepdims=keepdim, out=out[1])
            return out
        else:
            max_tuple = namedtuple("max", ["values", "indices"])
            return max_tuple(
>               tensorflow_max(input, axis=dim, keepdims=keepdim),
                tensorflow_argmax(input, axis=dim, keepdims=keepdim),
            )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/reduction_ops.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
     ...         4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>]
kwargs = {'axis': <KerasVariable shape=(1, 3, 1, 1), dtype=float32, path=variable_16>, 'keepdims': False}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f020dd4d870>
tensorflow_set_item = <function tensorflow_set_item at 0x7f020dd4f910>, tensorflow_asarray = <function tensorflow_asarray at 0x7f020dd4e170>
tensorflow_get_item = <function tensorflow_get_item at 0x7f020dd4f760>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'axis', 'keepdims', 'out']
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[int, ...s 'bool'>, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType]]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 8, 8), dtype=float32, numpy=
array([[[[6.78599298e-01, 3.11643779e-01, 1.31748557e-01,
      ...          4.07910645e-01, 1.57100558e-02, 4.91055250e-02,
          7.36419559e-01, 9.38529968e-02]]]], dtype=float32)>

    @tensorflow_handle_array_like_without_promotion
    def tensorflow_max(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        axis: Optional[Union[int, Sequence[int]]] = None,
        keepdims: bool = False,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        if "complex" in str(x.dtype):
            real = tensorflow.math.real(x)
            img = tensorflow.math.imag(x)
            const = tensorflow.constant(1.0j, dtype=x.dtype)
            real_max = tensorflow.reduce_max(real, axis=axis, keepdims=keepdims)
            imag = tensorflow.where(
                real == real_max, img, tensorflow.experimental.numpy.finfo(img.dtype).min
            )
            img_max = tensorflow.reduce_max(imag, axis=axis, keepdims=keepdims)
            img_max = tensorflow.cast(img_max, x.dtype)
            return tensorflow.add(
                tensorflow.cast(real_max, x.dtype), tensorflow.multiply(img_max, const)
            )
        axis = tuple(axis) if isinstance(axis, list) else axis
>       return tensorflow.math.reduce_max(x, axis=axis, keepdims=keepdims)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
E       
E       [1mValue for attr 'Tidx' of float is not in the list of allowed values: int32, int64
E       	; NodeDef: {{node Max}}; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Max][0m
E       
E       Arguments received by tensorflow_TLU.call():
E         • x=tf.Tensor(shape=(1, 3, 8, 8), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/statistical.py:60: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.TLU
__________________________________________________________________________________ test_DeDoDe[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDeDoDe = ivy.transpile(kornia.feature.DeDoDe, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
        transpiled_model = TranspiledDeDoDe(amp_dtype=ivy.as_native_dtype("float32"))
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.20126605, 0.93811816, 0.9415419 , ..., 0.001728...
         [0.7824816 , 0.39838195, 0.78369355, ..., 0.35200197,
          0.9887623 , 0.11688173]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x558a2af8ea20, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.7824816 , 0.39838195, 0.78369355, ..., 0.35200197,
          0.9887623 , 0.11688173]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.20126605, 0.93811816, 0.9415419 , ..., 0.001728...
         [0.7824816 , 0.39838195, 0.78369355, ..., 0.35200197,
          0.9887623 , 0.11688173]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.7824816 , 0.39838195, 0.78369355, ..., 0.35200197,
          0.9887623 , 0.11688173]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.20126605, 0.93811816, 0.9415419 , ..., 0.001728...
         [0.7824816 , 0.39838195, 0.78369355, ..., 0.35200197,
          0.9887623 , 0.11688173]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.20126605, 0.93811816, 0.9415419 , ..., 0.0017287...],
         [0.7824816 , 0.39838195, 0.78369355, ..., 0.35200197,
          0.9887623 , 0.11688173]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=10000, apply_imagenet_normalization=True, pad_if_not_divisible=True)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.20126605, 0.93811816, 0.9415419 , ......,
         [0.7824816 , 0.39838195, 0.78369355, ..., 0.35200197,
          0.9887623 , 0.11688173]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.239013  ,  1.9786818 ,  1.9936327 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = True, pad_if_not_divisible = True

    def call(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...geometry.conversions import tensorflow_denormalize_pixel_coordinates
    
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       keypoints, scores = self.detect(
            images, n=n, apply_imagenet_normalization=False, crop_h=h, crop_w=w
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.239013  ,  1.9786818 ,  1.9936327 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = False, pad_if_not_divisible = True, crop_h = 256, crop_w = 256

    def detect(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
        crop_h=None,
        crop_w=None,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_softmax_frnt_
        from .utils import tensorflow_sample_keypoints
    
        tensorflow_KORNIA_CHECK_SHAPE(images, ["B", "3", "H", "W"])
        self.train(False)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
>       logits = self.detector.call(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDeDetector(
  (encoder): tensorflow_VGG19(
    (pt_layers): tensorflow_ModuleList(
      (0): KerasConv...rflow_ReLU()
            (3): KerasConv2D()
          )
        )
        (out_conv): KerasConv2D()
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.239013  ,  1.9786818 ,  1.9936327 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>

    def call(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_interpolate_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
    
        dtype = images.dtype
        features, sizes = self.encoder(images)
        context = None
        logits = None
        scales = ["8", "4", "2", "1"]
        for idx, (feature_map, scale) in enumerate(zip(reversed(features), scales)):
>           delta_logits, context = self.decoder(
                feature_map, context=context, scale=scale
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/detector.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}
stack = [FrameInfo(frame=<frame at 0x7f021404c040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}, replace_v = False, replace_buffers = False, call_signature = <Signature (features, context=None, scale=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
features = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,
...0000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>
context = None, scale = '8'

    def call(self, features, context=None, scale=None):
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        if context is not None:
            features = tensorflow_cat_frnt((features, context), dim=1)
>       stuff = tensorflow_get_item(self.pt_layers, scale)(features)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f020fdf2480, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (feats)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
feats = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,
...0000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>

    def call(self, feats):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        b, c, hs, ws = tensorflow_shape_frnt_(feats)
>       x0 = self.block1(feats)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:298: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x558a871d13a0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[2.2934853e-04, 0.0000000e+00, 0.0000000e+00, ...,...00e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[ 1.40540232e-03,  1.63289381e-03,  1.61071157e-03,...10052e-03, -4.07272717e-04, ...,
          -7.22368015e-04, -2.57605757e-03, -1.08824112e-03]]]],
      dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[ 1.40540232e-03,  1.63289381e-03,  1.61071157e-03...052e-03, -4.07272717e-04, ...,
          -7.22368015e-04, -2.57605757e-03, -1.08824112e-03]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x558a30d5d010, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[ 1.40540232e-03,  1.63289381e-03,  1.61071157e-03...052e-03, -4.07272717e-04, ...,
          -7.22368015e-04, -2.57605757e-03, -1.08824112e-03]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    def __call__(self, *args, **kwargs):
        if not self.built:
>           res = super().__call__(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1010: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D(), input_shape = (1, 33, 33, 512)

    def build(self, input_shape):
        _, ch, _, _ = input_shape
        if (
            not self.built
            and self.axis == -1
            and os.environ.get("DATA_FORMAT", "channels_first") == "channels_first"
        ):
            order = (0, 2, 3, 1)
            new_shape = tuple(input_shape[i] for i in order)
            input_shape = tf.TensorShape(new_shape)
    
>       super().build(input_shape)
E       IndexError: Exception encountered when calling tensorflow_Sequential.call().
E       
E       [1mtuple index out of range[0m
E       
E       Arguments received by tensorflow_Sequential.call():
E         • input=tf.Tensor(shape=(1, 512, 33, 33), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1030: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  2%|▏         | 26.1M/1.13G [00:00<00:04, 274MB/s]
  5%|▍         | 52.6M/1.13G [00:00<00:04, 276MB/s]
  7%|▋         | 79.0M/1.13G [00:00<00:04, 275MB/s]
  9%|▉         | 108M/1.13G [00:00<00:03, 286MB/s] 
 12%|█▏        | 135M/1.13G [00:00<00:03, 281MB/s]
 14%|█▍        | 164M/1.13G [00:00<00:03, 286MB/s]
 16%|█▋        | 191M/1.13G [00:00<00:03, 286MB/s]
 19%|█▉        | 220M/1.13G [00:00<00:03, 293MB/s]
 21%|██▏       | 248M/1.13G [00:00<00:03, 271MB/s]
 24%|██▎       | 275M/1.13G [00:01<00:03, 258MB/s]
 26%|██▌       | 300M/1.13G [00:01<00:03, 248MB/s]
 29%|██▊       | 332M/1.13G [00:01<00:03, 272MB/s]
 31%|███       | 360M/1.13G [00:01<00:02, 280MB/s]
 33%|███▎      | 388M/1.13G [00:01<00:02, 280MB/s]
 36%|███▋      | 422M/1.13G [00:01<00:02, 304MB/s]
 39%|███▉      | 452M/1.13G [00:01<00:02, 306MB/s]
 41%|████▏     | 481M/1.13G [00:01<00:02, 306MB/s]
 44%|████▍     | 514M/1.13G [00:01<00:02, 317MB/s]
 47%|████▋     | 546M/1.13G [00:01<00:01, 323MB/s]
 50%|████▉     | 577M/1.13G [00:02<00:01, 316MB/s]
 52%|█████▏    | 607M/1.13G [00:02<00:01, 314MB/s]
 55%|█████▍    | 637M/1.13G [00:02<00:01, 308MB/s]
 57%|█████▋    | 667M/1.13G [00:02<00:01, 310MB/s]
 60%|██████    | 697M/1.13G [00:02<00:01, 308MB/s]
 63%|██████▎   | 726M/1.13G [00:02<00:01, 306MB/s]
 65%|██████▌   | 756M/1.13G [00:02<00:01, 300MB/s]
 68%|██████▊   | 784M/1.13G [00:02<00:01, 300MB/s]
 70%|███████   | 814M/1.13G [00:02<00:01, 304MB/s]
 73%|███████▎  | 843M/1.13G [00:03<00:01, 301MB/s]
 75%|███████▌  | 872M/1.13G [00:03<00:01, 301MB/s]
 78%|███████▊  | 901M/1.13G [00:03<00:00, 293MB/s]
 80%|████████  | 932M/1.13G [00:03<00:00, 303MB/s]
 83%|████████▎ | 963M/1.13G [00:03<00:00, 308MB/s]
 85%|████████▌ | 992M/1.13G [00:03<00:00, 305MB/s]
 88%|████████▊ | 1.00G/1.13G [00:03<00:00, 306MB/s]
 91%|█████████ | 1.03G/1.13G [00:03<00:00, 323MB/s]
 94%|█████████▎| 1.06G/1.13G [00:03<00:00, 320MB/s]
 96%|█████████▋| 1.09G/1.13G [00:03<00:00, 300MB/s]
 99%|█████████▉| 1.13G/1.13G [00:04<00:00, 321MB/s]
100%|██████████| 1.13G/1.13G [00:04<00:00, 299MB/s]
2024-10-18 09:23:36.331654: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-18 09:23:36.716597: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-18 09:23:37.319460: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-18 09:23:37.414904: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-18 09:23:37.590419: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
___________________________________________________________________________________ test_DISK[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDISK = ivy.transpile(kornia.feature.DISK, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DISK()
        torch_out = model(x)
    
        transpiled_model = TranspiledDISK()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,...96e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f020e168ec0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow...796e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,...96e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow...796e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,...96e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,
...7796e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=None, window_size=5, score_threshold=0.0, pad_if_not_divisible=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow... tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864...796e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,
...7796e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>
n = None, window_size = 5, score_threshold = 0.0, pad_if_not_divisible = False

    def call(
        self,
        images,
        n=None,
        window_size=5,
        score_threshold=0.0,
        pad_if_not_divisible=False,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from .detector import tensorflow_heatmap_to_keypoints
    
        B = tensorflow_shape_frnt_(images)[0]
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 16 - h % 16 if h % 16 > 0 else 0
            pd_w = 16 - w % 16 if w % 16 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       heatmaps, descriptors = self.heatmap_and_dense_descriptors(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,
...7796e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>

    def heatmap_and_dense_descriptors(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
>       unet_output = self.unet(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,...96e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f02141f20e0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ls.py', lineno=117, function='error_handler', code_context=['            return fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,...96e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,...96e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (inp)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
inp = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[8.8640410e-01, 8.8682878e-01, 4.6326864e-01, ...,
...7796e-01, 4.9145162e-02, 2.8334057e-01, ...,
          9.4839036e-01, 6.2946367e-01, 5.8873457e-01]]]], dtype=float32)>

    def call(self, inp):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
    
        if tensorflow_size_frnt_(inp, 1) != self.in_features:
            fmt = "Expected {} feature channels in input, got {}"
            msg = fmt.format(self.in_features, tensorflow_size_frnt_(inp, 1))
            raise ValueError(msg)
        input_size_divisor = 2 ** len(self.up)
        if (
            tensorflow_size_frnt_(inp, 2) % input_size_divisor != 0
            or tensorflow_size_frnt_(inp, 3) % input_size_divisor != 0
        ):
            raise ValueError(
                f"Input image shape must be divisible by {input_size_divisor} (got {tensorflow_size_frnt_(inp)}). This is not inherent to DISK, but to the U-Net architecture used in pretrained models. Please pad if necessary."
            )
        features = [inp]
        for layer in self.path_down:
>           features.append(layer(features[-1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/_unets/unet.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 0.09563321,  0.26726666,  0.13431522, ...,  0.2...    [-0.17490661, -0.42405495, -0.5612648 , ..., -0.34199196,
          -0.749701  , -0.48351002]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5589e5f045e0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 0.09563321,  0.26726666,  0.13431522, ...,  0.2...    [-0.17490661, -0.42405495, -0.5612648 , ..., -0.34199196,
          -0.749701  , -0.48351002]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 0.09563321,  0.26726666,  0.13431522, ...,  0.2...    [-0.17490661, -0.42405495, -0.5612648 , ..., -0.34199196,
          -0.749701  , -0.48351002]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
input = <tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.16056012,  0.11125031,  0.2304708 , ...,  0.16...      [-0.3482602 , -0.53293025, -0.56555766, ..., -0.4995824 ,
          -0.5174386 , -0.5506585 ]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.16056012,  0.11125031,  0.2304708 , ...,  0.1...    [-0.3482602 , -0.53293025, -0.56555766, ..., -0.4995824 ,
          -0.5174386 , -0.5506585 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f020f0f8b20, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.16056012,  0.11125031,  0.2304708 , ...,  0.1...    [-0.3482602 , -0.53293025, -0.56555766, ..., -0.4995824 ,
          -0.5174386 , -0.5506585 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.16056012,  0.11125031,  0.2304708 , ...,  0.1...    [-0.3482602 , -0.53293025, -0.56555766, ..., -0.4995824 ,
          -0.5174386 , -0.5506585 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 2.9634247 ,  1.9825168 , -0.79569435, ...,  0.05...      [-1.4187015 , -2.4102886 ,  1.3074152 , ..., -1.2212143 ,
          -2.839571  ,  0.07760286]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU()
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 2.9634247 ,  1.9825168 , -0.79569435, ...,  0.0...    [-1.4187015 , -2.4102886 ,  1.3074152 , ..., -1.2212143 ,
          -2.839571  ,  0.07760286]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5589e517c960, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 2.9634247 ,  1.9825168 , -0.79569435, ...,  0.0...    [-1.4187015 , -2.4102886 ,  1.3074152 , ..., -1.2212143 ,
          -2.839571  ,  0.07760286]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 2.9634247 ,  1.9825168 , -0.79569435, ...,  0.0...    [-1.4187015 , -2.4102886 ,  1.3074152 , ..., -1.2212143 ,
          -2.839571  ,  0.07760286]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), args = ()
kwargs = {'input': <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 2.9634247 ,  1.9825168 , -0.79569435, ...     [-1.4187015 , -2.4102886 ,  1.3074152 , ..., -1.2212143 ,
          -2.839571  ,  0.07760286]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f020d958820>, tensorflow_set_item = <function tensorflow_set_item at 0x7f020d9589d0>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'input': <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 2.9634247 ,  1.9825168 , -0.79569435, ...     [-1.4187015 , -2.4102886 ,  1.3074152 , ..., -1.2212143 ,
          -2.839571  ,  0.07760286]]]], dtype=float32)>}
conv_block_start = <function tensorflow_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f020fb8c8b0>, next_call_in_seq = tensorflow_Sequential()
conv_block_continued = tensorflow_Sequential(), arg_name = 'input'

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_get_item
        from ..functional.backends.tensorflow.general import tensorflow_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = tensorflow_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = tensorflow_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = tensorflow_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = tensorflow_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = tensorflow_TransposeType.CONV1D
            else:
                transpose = tensorflow_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = tensorflow_set_item(
                fn_args_and_kwargs,
                arg_name,
                tensorflow_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:414: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU()
input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 2.9634247 ,  1.9825168 , -0.79569435, ...,  0.05...      [-1.4187015 , -2.4102886 ,  1.3074152 , ..., -1.2212143 ,
          -2.839571  ,  0.07760286]]]], dtype=float32)>

    @tensorflow_handle_transpose_in_input_and_output
    def call(self, input):
        from ....ivy.functional.frontends.torch.nn.functional.non_linear_activation_functions import (
            tensorflow_prelu_frnt,
        )
    
>       return tensorflow_prelu_frnt(input, self.weight)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/activation.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[ 2.9634247 ,  1.9825168 , -0.79569435, ...,  0.05...      [-1.4187015 , -2.4102886 ,  1.3074152 , ..., -1.2212143 ,
          -2.839571  ,  0.07760286]]]], dtype=float32)>
weight = <KerasVariable shape=(16,), dtype=float32, path=variable_665>

    def tensorflow_prelu_frnt(input, weight):
        from ...tensor import tensorflow_ndim_frnt_
        from ...tensor import tensorflow_shape_frnt_
        from ......data_classes.array.manipulation import tensorflow_expand_dims_bknd_
        from .....backends.tensorflow.elementwise import tensorflow_add
        from .....backends.tensorflow.elementwise import tensorflow_maximum
        from .....backends.tensorflow.elementwise import tensorflow_multiply
        from .....backends.tensorflow.elementwise import tensorflow_minimum
    
        input_dim = tensorflow_ndim_frnt_(input)
        weight_dim = tensorflow_ndim_frnt_(weight)
        if weight_dim == 0:
            pass
        elif weight_dim == 1:
            if input_dim >= 2:
>               assert (
                    tensorflow_shape_frnt_(weight)[0] == tensorflow_shape_frnt_(input)[1]
                ), "Weight size must match input channels"
E               AssertionError: Exception encountered when calling tensorflow_PReLU.call().
E               
E               [1mWeight size must match input channels[0m
E               
E               Arguments received by tensorflow_PReLU.call():
E                 • input=tf.Tensor(shape=(1, 128, 128, 16), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/non_linear_activation_functions.py:61: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/instancenorm.py:134: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_LAFOrienter[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_PatchDominantGradientOrientation[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_TLU[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_TLU.call().
FAILED kornia/test_feature5.py::test_DeDoDe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_Sequential.call().
FAILED kornia/test_feature5.py::test_DISK[tensorflow-s2s-False] - AssertionError: Exception encountered when calling tensorflow_PReLU.call().
=============================================================================== 5 failed, 5 passed in 1394.17s (0:23:14) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py F......F.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomMosaic[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'jax', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[ 1.7765e-01, -8.7408e-01,  5.0518e-01,  ..., -7.7651e-01,
           -3.7231e-01, -6.8178e-01],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, same_on..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
params = None, data_keys = None
input = (Array([[[[ 1.77647218e-01, -8.74083221e-01,  5.05181074e-01, ...,
          -7.76508629e-01, -3.72312933e-01, -6.8178... 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7f5b93503370>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
_________________________________________________________________________________ test_RandomRotation3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRotation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation3D")
    
        init_args = ((15., 20., 20.),)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.geometric.rotation.RandomRotation3D'>, target = 'jax', init_args = ((15.0, 20.0, 20.0),), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[[0.2417, 0.5227, 0.2155],
           [0.4166, 0.2503, 0.8244],
           [0.8401, 0.7964, 0.9564]],

    ...,

          [[0.7718, 0.6721, 0.5768],
           [0.7674, 0.5226, 0.7245],
           [0.3084, 0.7752, 0.9259]]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.24172759, 0.5226707 , 0.21549726],
          [0.41656613, 0.2502532 , 0.8243724 ],
          [0.8400983 ,...5 ],
          [0.76735884, 0.52261734, 0.7244793 ],
          [0.3083774 , 0.77521956, 0.9259268 ]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f5b9d95c8b0>, jax_set_item = <function jax_set_item at 0x7f5b60bfb2e0>, tensor = <function jax_tensor_frnt at 0x7f5b68670700>
in_tensor = Array([[[[[0.24172759, 0.5226707 , 0.21549726],
          [0.41656613, 0.2502532 , 0.8243724 ],
          [0.8400983 ,...5 ],
          [0.76735884, 0.52261734, 0.7244793 ],
          [0.3083774 , 0.77521956, 0.9259268 ]]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
in_tensor = Array([[[[[0.24172759, 0.5226707 , 0.21549726],
          [0.41656613, 0.2502532 , 0.8243724 ],
          [0.8400983 ,...5 ],
          [0.76735884, 0.52261734, 0.7244793 ],
          [0.3083774 , 0.77521956, 0.9259268 ]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/base.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.24172759, 0.5226707 , 0.21549726],
          [0.41656613, 0.2502532 , 0.8243724 ],
          [0.8400983 ,...5 ],
          [0.76735884, 0.52261734, 0.7244793 ],
          [0.3083774 , 0.77521956, 0.9259268 ]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from ....ivy.functional.backends.jax.general import jax_get_item
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not jax_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif jax_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/base.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.24172759, 0.5226707 , 0.21549726],
          [0.41656613, 0.2502532 , 0.8243724 ],
          [0.8400983 ,...5 ],
          [0.76735884, 0.52261734, 0.7244793 ],
          [0.3083774 , 0.77521956, 0.9259268 ]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....geometry.transform.affwarp import jax__compute_tensor_center3d
        from ....geometry.transform.affwarp import jax__compute_rotation_matrix3d
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....utils.misc import jax_eye_like
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        yaw: typing.Any = jax_to_frnt_(params["yaw"], input)
        pitch: typing.Any = jax_to_frnt_(params["pitch"], input)
        roll: typing.Any = jax_to_frnt_(params["roll"], input)
        center: typing.Any = jax__compute_tensor_center3d(input)
        rotation_mat: typing.Any = jax__compute_rotation_matrix3d(
>           yaw, pitch, roll, center.expand(jax_shape_frnt_(yaw)[0], -1)
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/geometric/rotation.py:66: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomRotation3D[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'
============================================================================== 2 failed, 15 passed in 3403.45s (0:56:43) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F.............F..........                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_equalize_clahe[jax-s2s-False] __________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4094: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f32de58fa30>
trace_args = (tensor([[[0.6475, 0.9398, 0.9466, 0.1624, 0.0064, 0.0121, 0.5352, 0.0836,
          0.0146, 0.9310, 0.3111, 0.5044, 0...         0.0964, 0.3715, 0.8006, 0.5794, 0.5061, 0.7273, 0.7688, 0.5298,
          0.3547, 0.3679, 0.9224, 0.2637]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.2382, 0.1975, 0.3833,  ..., 0.7471, 0.0178, 0.2972],
          [0.7344, 0.2072, 0.9638,  ..., 0.4539, 0...., 0.1949, 0.6647,  ..., 0.5387, 0.8914, 0.0143],
          [0.1362, 0.9789, 0.8217,  ..., 0.0839, 0.0453, 0.6861]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f32de58fa30>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.6475, 0.9398, 0.9466, 0.1624, 0.0064, 0.0121, 0.5352, 0.0836,
          0.0146, 0.9310, 0.3111, 0.5044, 0...         0.0964, 0.3715, 0.8006, 0.5794, 0.5061, 0.7273, 0.7688, 0.5298,
          0.3547, 0.3679, 0.9224, 0.2637]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.2382, 0.1975, 0.3833,  ..., 0.7471, 0.0178, 0.2972],
          [0.7344, 0.2072, 0.9638,  ..., 0.4539, 0...., 0.1949, 0.6647,  ..., 0.5387, 0.8914, 0.0143],
          [0.1362, 0.9789, 0.8217,  ..., 0.0839, 0.0453, 0.6861]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.6474752 , 0.93978673, 0.9466296 , 0.16239327, 0.00641817,
          0.01213986, 0.53524554, 0.08355826, 0...., 0.7273227 , 0.76883435,
          0.5297724 , 0.3546855 , 0.36789244, 0.9224267 , 0.2636968 ]]]],      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7f3248a2feb0>
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3248a2fac0>, jax_view_frnt_ = <function jax_view_frnt_ at 0x7f3248a2fd90>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.6474752 , 0.93978673, 0.9466296 , 0.16239327, 0.00641817,
          0.01213986, 0.53524554, 0.08355826, 0...., 0.7273227 , 0.76883435,
          0.5297724 , 0.3546855 , 0.36789244, 0.9224267 , 0.2636968 ]]]],      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:487: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[0.6474752 , 0.93978673, 0.9466296 , 0.16239327, 0.00641817,
          0.01213986, 0.53524554, 0.08355826, 0...., 0.7273227 , 0.76883435,
          0.5297724 , 0.3546855 , 0.36789244, 0.9224267 , 0.2636968 ]]]],      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
                jax_unfold_frnt_(
>                   jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[0.6474752 , 0.23444563, 0.28040737, 0.76315725, 0.2876169 ,
           0.95764506, 0.20162088, 0.6964158 ,...       0.9131637 , 0.08442116, 0.5182164 , 0.6601774 , 0.8201246 ,
           0.25443894]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f3237d5dd80>
array_like = Array([[[[[0.6474752 , 0.23444563, 0.28040737, 0.76315725, 0.2876169 ,
           0.95764506, 0.20162088, 0.6964158 , ...882 ,
           0.9131637 , 0.08442116, 0.5182164 , 0.6601774 , 0.8201246 ,
           0.25443894]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[0.6474752 , 0.23444563, 0.28040737, 0.76315725, 0.2876169 ,
           0.95764506, 0.20162088, 0.6964158 , ...882 ,
           0.9131637 , 0.08442116, 0.5182164 , 0.6601774 , 0.8201246 ,
           0.25443894]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:127: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_ZCAWhitening[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ZCAWhitening(target_framework, mode, backend_compile):
        print("kornia.enhance.ZCAWhitening")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        x = torch.tensor([[0,1],[1,0],[-1,0],[0,-1]], dtype = torch.float32)
        zca = kornia.enhance.ZCAWhitening().fit(x)
        torch_out = zca(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_zca = transpiled_kornia.enhance.ZCAWhitening().fit(transpiled_x)
>       transpiled_out = transpiled_zca(x)

kornia/test_enhance.py:697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ZCAWhitening(), x = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), include_fit = False

    def __call__(self, x, include_fit=False):
        if include_fit:
            self.fit(x)
        if not self.fitted:
            raise RuntimeError(
                "Needs to be fitted first before running. Please call fit or set include_fit to True."
            )
>       x_whiten = jax_linear_transform(
            x, self.transform_matrix, self.mean_vector, self.dim
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), transform_matrix = Array([[1.224744, 0.      ],
       [0.      , 1.224744]], dtype=float32)
mean_vector = Array([[0., 0.]], dtype=float32), dim = 0

    def jax_linear_transform(inp, transform_matrix, mean_vector, dim=0):
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_arange_frnt
        from ...ivy.functional.frontends.torch.comparison_ops import jax_argsort_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import jax_prod_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_mm_frnt_
        from ..core._backend import concatenate
        from ..core._backend import tensor
    
        inp_size = jax_size_frnt_(inp)
        if dim >= len(inp_size) or dim < -len(inp_size):
            raise IndexError(
                f"Dimension out of range (expected to be in range of [{-len(inp_size)},{len(inp_size) - 1}], but got {dim}"
            )
        if dim < 0:
            dim = len(inp_size) + dim
        feat_dims = concatenate(
            [jax_arange_frnt(0, dim), jax_arange_frnt(dim + 1, len(inp_size))]
        )
        perm = concatenate([tensor([dim]), feat_dims])
        perm_inv = jax_argsort_frnt(perm)
        new_order: typing.Any = jax_tolist_frnt_(perm)
        inv_order: typing.Any = jax_tolist_frnt_(perm_inv)
        feature_sizes = tensor(
            jax_get_item(inp_size, slice(0, dim, None))
            + jax_get_item(inp_size, slice(dim + 1, None, None))
        )
        num_features: typing.Any = int(jax_item_frnt_(jax_prod_frnt(feature_sizes)))
        inp_permute = jax_permute_frnt_(inp, new_order)
        inp_flat = jax_reshape_frnt_(inp_permute, (-1, num_features))
>       inp_center = inp_flat - mean_vector
E       TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:318: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.ZCAWhitening
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[jax-s2s-False] - Exception: Need at least one array to stack.
FAILED kornia/test_enhance.py::test_ZCAWhitening[jax-s2s-False] - TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'
============================================================================== 2 failed, 37 passed in 2597.48s (0:43:17) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py F......F.......FF.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_find_essential[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_essential(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 8, 2),
            torch.rand(1, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 8)}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8)}
>       _test_function(
            kornia.geometry.epipolar.find_essential,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_epipolar.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7fe1392e6200>
trace_args = (tensor([[[0.0266, 0.9142],
         [0.3820, 0.0822],
         [0.7910, 0.4780],
         [0.8603, 0.1344],
         ...0.8697],
         [0.5424, 0.5478],
         [0.0894, 0.7837],
         [0.5170, 0.9679],
         [0.9397, 0.9171]]]))
trace_kwargs = {'weights': tensor([[0.3181, 0.4710, 0.8709, 0.5870, 0.2612, 0.7911, 0.6219, 0.8576]])}
test_args = (tensor([[[0.8172, 0.4070],
         [0.4903, 0.6056],
         [0.4698, 0.5296],
         [0.0469, 0.1128],
         ....4866e-01],
         [6.8126e-01, 5.9386e-01],
         [4.4254e-01, 5.9457e-01],
         [9.6525e-01, 4.1075e-01]]]))
test_kwargs = {'weights': tensor([[0.4790, 0.3858, 0.7320, 0.3987, 0.9103, 0.2589, 0.4979, 0.2987],
        [0.8660, 0.6308, 0.9728,...3, 0.6600, 0.8053, 0.4912, 0.4444, 0.2901],
        [0.4890, 0.6464, 0.0505, 0.1161, 0.2216, 0.8294, 0.2878, 0.4395]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7fe1392e6200>, fn_name = 'kornia.geometry.epipolar.find_essential'
trace_args = (tensor([[[0.0266, 0.9142],
         [0.3820, 0.0822],
         [0.7910, 0.4780],
         [0.8603, 0.1344],
         ...0.8697],
         [0.5424, 0.5478],
         [0.0894, 0.7837],
         [0.5170, 0.9679],
         [0.9397, 0.9171]]]))
trace_kwargs = {'weights': tensor([[0.3181, 0.4710, 0.8709, 0.5870, 0.2612, 0.7911, 0.6219, 0.8576]])}
test_args = (tensor([[[0.8172, 0.4070],
         [0.4903, 0.6056],
         [0.4698, 0.5296],
         [0.0469, 0.1128],
         ....4866e-01],
         [6.8126e-01, 5.9386e-01],
         [4.4254e-01, 5.9457e-01],
         [9.6525e-01, 4.1075e-01]]]))
test_kwargs = {'weights': tensor([[0.4790, 0.3858, 0.7320, 0.3987, 0.9103, 0.2589, 0.4979, 0.2987],
        [0.8660, 0.6308, 0.9728,...3, 0.6600, 0.8053, 0.4912, 0.4444, 0.2901],
        [0.4890, 0.6464, 0.0505, 0.1161, 0.2216, 0.8294, 0.2878, 0.4395]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.02656698, 0.9142257 ],
        [0.38202155, 0.08217114],
        [0.7910208 , 0.47801614],
        [0.86025...
        [0.91297776, 0.8277101 ],
        [0.19095021, 0.6058846 ],
        [0.2983684 , 0.12044275]]], dtype=float32)
points2 = array([[[0.5206205 , 0.01877862],
        [0.19621634, 0.891849  ],
        [0.89296895, 0.16530716],
        [0.36615...
        [0.08935356, 0.78367203],
        [0.5169698 , 0.9679057 ],
        [0.939743  , 0.91706604]]], dtype=float32)
weights = array([[0.31807268, 0.47101265, 0.8709166 , 0.58700174, 0.26118797,
        0.7910961 , 0.6218874 , 0.85763854]], dtype=float32)

    def numpy_find_essential(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_to_frnt_
    
>       E = numpy_to_frnt_(numpy_run_5point(points1, points2, weights), points1.dtype)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.02656698, 0.9142257 ],
        [0.38202155, 0.08217114],
        [0.7910208 , 0.47801614],
        [0.86025...
        [0.91297776, 0.8277101 ],
        [0.19095021, 0.6058846 ],
        [0.2983684 , 0.12044275]]], dtype=float32)
points2 = array([[[0.5206205 , 0.01877862],
        [0.19621634, 0.891849  ],
        [0.89296895, 0.16530716],
        [0.36615...
        [0.08935356, 0.78367203],
        [0.5169698 , 0.9679057 ],
        [0.939743  , 0.91706604]]], dtype=float32)
weights = array([[0.31807268, 0.47101265, 0.8709166 , 0.58700174, 0.26118797,
        0.7910961 , 0.6218874 , 0.85763854]], dtype=float32)

    def numpy_run_5point(points1, points2, weights=None):
        from ...core.check import numpy_KORNIA_CHECK_SHAPE
        from ...core.check import numpy_KORNIA_CHECK_SAME_SHAPE
        from ...core.check import numpy_KORNIA_CHECK
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...core._backend import ones_like
    
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SAME_SHAPE(points1, points2)
        numpy_KORNIA_CHECK(
            numpy_shape_frnt_(points1)[1] >= 5, "Number of points should be >=5"
        )
        if weights is not None:
            numpy_KORNIA_CHECK_SAME_SHAPE(points1[:, :, 0], weights)
        batch_size, _, _ = numpy_shape_frnt_(points1)
        x1, y1 = numpy_chunk_frnt(points1, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x1 * x2, x1 * y2, x1, y1 * x2, y1 * y2, y1, x2, y2, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.31807268, 0.47101265, 0.8709166 , 0.58700174, 0.26118797,
         0.7910961 , 0.6218874 , 0.85763854]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.essential.find_essential
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
________________________________________________________________________________ test_find_fundamental[numpy-s2s-False] ________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_fundamental(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 8, 2),
            torch.rand(2, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(2, 8), 'method': '8POINT'}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8), 'method': '8POINT'}
>       _test_function(
            kornia.geometry.epipolar.find_fundamental,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=3e-2,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7fe1392e67a0>
trace_args = (tensor([[[0.7774, 0.5557],
         [0.8816, 0.6603],
         [0.2387, 0.5621],
         [0.8149, 0.8028],
         ...0.5705],
         [0.2575, 0.8716],
         [0.8903, 0.9395],
         [0.0306, 0.7348],
         [0.4265, 0.2177]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.9873, 0.4644, 0.8214, 0.6442, 0.3960, 0.4554, 0.0955, 0.4233],
        [0.4383, 0.4426, 0.3210, 0.5915, 0.7472, 0.8720, 0.4388, 0.4050]])}
test_args = (tensor([[[1.5685e-01, 6.4980e-01],
         [5.0638e-02, 6.1988e-01],
         [2.9780e-01, 5.0318e-01],
         [1....0.0051],
         [0.4872, 0.1317],
         [0.1254, 0.5033],
         [0.7356, 0.8268],
         [0.6321, 0.9885]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.5765, 0.3437, 0.5155, 0.4742, 0.5647, 0.7326, 0.9358, 0.9377],
        [0.3...2, 0.8407, 0.8479, 0.0554, 0.4627, 0.4361],
        [0.1871, 0.5737, 0.9210, 0.1172, 0.9928, 0.5989, 0.8209, 0.1713]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7fe1392e67a0>, fn_name = 'kornia.geometry.epipolar.find_fundamental'
trace_args = (tensor([[[0.7774, 0.5557],
         [0.8816, 0.6603],
         [0.2387, 0.5621],
         [0.8149, 0.8028],
         ...0.5705],
         [0.2575, 0.8716],
         [0.8903, 0.9395],
         [0.0306, 0.7348],
         [0.4265, 0.2177]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.9873, 0.4644, 0.8214, 0.6442, 0.3960, 0.4554, 0.0955, 0.4233],
        [0.4383, 0.4426, 0.3210, 0.5915, 0.7472, 0.8720, 0.4388, 0.4050]])}
test_args = (tensor([[[1.5685e-01, 6.4980e-01],
         [5.0638e-02, 6.1988e-01],
         [2.9780e-01, 5.0318e-01],
         [1....0.0051],
         [0.4872, 0.1317],
         [0.1254, 0.5033],
         [0.7356, 0.8268],
         [0.6321, 0.9885]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.5765, 0.3437, 0.5155, 0.4742, 0.5647, 0.7326, 0.9358, 0.9377],
        [0.3...2, 0.8407, 0.8479, 0.0554, 0.4627, 0.4361],
        [0.1871, 0.5737, 0.9210, 0.1172, 0.9928, 0.5989, 0.8209, 0.1713]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7773987 , 0.55567944],
        [0.881587  , 0.6603383 ],
        [0.23869318, 0.5621411 ],
        [0.81494...
        [0.39535302, 0.6181658 ],
        [0.60493845, 0.21306968],
        [0.3290612 , 0.6852147 ]]], dtype=float32)
points2 = array([[[0.3667662 , 0.00622469],
        [0.6440535 , 0.9418265 ],
        [0.50658685, 0.09624052],
        [0.89628...
        [0.89030343, 0.9395195 ],
        [0.03057742, 0.73484546],
        [0.4264909 , 0.21773493]]], dtype=float32)
weights = array([[0.987317  , 0.46438152, 0.8213776 , 0.64417845, 0.39603758,
        0.45543063, 0.09553021, 0.4233395 ],
     ....43832386, 0.44259548, 0.32102478, 0.59150875, 0.74723613,
        0.8720208 , 0.43883967, 0.4049917 ]], dtype=float32)
method = '8POINT'

    def numpy_find_fundamental(points1, points2, weights=None, method="8POINT"):
        if method.upper() == "7POINT":
            result = numpy_run_7point(points1, points2)
        elif method.upper() == "8POINT":
>           result = numpy_run_8point(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.7773987 , 0.55567944],
        [0.881587  , 0.6603383 ],
        [0.23869318, 0.5621411 ],
        [0.81494...
        [0.39535302, 0.6181658 ],
        [0.60493845, 0.21306968],
        [0.3290612 , 0.6852147 ]]], dtype=float32)
points2 = array([[[0.3667662 , 0.00622469],
        [0.6440535 , 0.9418265 ],
        [0.50658685, 0.09624052],
        [0.89628...
        [0.89030343, 0.9395195 ],
        [0.03057742, 0.73484546],
        [0.4264909 , 0.21773493]]], dtype=float32)
weights = array([[0.987317  , 0.46438152, 0.8213776 , 0.64417845, 0.39603758,
        0.45543063, 0.09553021, 0.4233395 ],
     ....43832386, 0.44259548, 0.32102478, 0.59150875, 0.74723613,
        0.8720208 , 0.43883967, 0.4049917 ]], dtype=float32)

    def numpy_run_8point(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...utils.helpers import numpy__torch_svd_cast
        from ....ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ....ivy.functional.frontends.torch.creation_ops import numpy_tensor_frnt
        from ...core._backend import ones_like
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1), numpy_shape_frnt_(points2))
        if numpy_shape_frnt_(points1)[1] < 8:
            raise AssertionError(numpy_shape_frnt_(points1))
        if weights is not None:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights)[1] == numpy_shape_frnt_(points1)[1]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x2 * x1, x2 * y1, x2, y2 * x1, y2 * y1, y2, x1, y1, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.987317  , 0.46438152, 0.8213776 , 0.64417845, 0.39603758,
         0.45543063, 0.09553021, 0.4233395 ]],

 ...3832386, 0.44259548, 0.32102478, 0.59150875, 0.74723613,
         0.8720208 , 0.43883967, 0.4049917 ]]], dtype=float32)
offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.fundamental.find_fundamental
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  cond = numpy_reshape_frnt_(cond, cond_shape)
___________________________________________________________________________ test_sampson_epipolar_distance[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_sampson_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.sampson_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7fe1392e45e0>
trace_args = (tensor([[[0.2600, 0.8687],
         [0.0253, 0.2519],
         [0.5836, 0.9270],
         [0.4671, 0.3015]]]), tensor...0.1028]]]), tensor([[[0.5412, 0.9460, 0.0869],
         [0.3866, 0.8297, 0.7453],
         [0.7418, 0.7427, 0.1614]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.0121, 0.7352],
         [0.6904, 0.2658],
         [0.3257, 0.6480],
         [0.4075, 0.8808]],

       ... 0.9843]],

        [[0.1769, 0.5921, 0.0930],
         [0.9290, 0.0658, 0.2319],
         [0.0865, 0.8815, 0.5513]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7fe1392e45e0>, fn_name = 'kornia.geometry.epipolar.sampson_epipolar_distance'
trace_args = (tensor([[[0.2600, 0.8687],
         [0.0253, 0.2519],
         [0.5836, 0.9270],
         [0.4671, 0.3015]]]), tensor...0.1028]]]), tensor([[[0.5412, 0.9460, 0.0869],
         [0.3866, 0.8297, 0.7453],
         [0.7418, 0.7427, 0.1614]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.0121, 0.7352],
         [0.6904, 0.2658],
         [0.3257, 0.6480],
         [0.4075, 0.8808]],

       ... 0.9843]],

        [[0.1769, 0.5921, 0.0930],
         [0.9290, 0.0658, 0.2319],
         [0.0865, 0.8815, 0.5513]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.26000667, 0.8687376 , 1.        ],
        [0.02530533, 0.25190383, 1.        ],
        [0.5835747 , 0.927017  , 1.        ],
        [0.46714395, 0.30145198, 1.        ]]], dtype=float32)
pts2 = array([[[0.23124051, 0.73645496, 1.        ],
        [0.5240247 , 0.9424988 , 1.        ],
        [0.6293176 , 0.20894736, 1.        ],
        [0.6562004 , 0.10279769, 1.        ]]], dtype=float32)
Fm = array([[[0.541163  , 0.9459793 , 0.08694082],
        [0.38663495, 0.8296952 , 0.74532807],
        [0.7418336 , 0.7426926 , 0.16135257]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_sampson_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[2.3958778, 1.4534979, 2.4516766, 1.2627432]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fe0daf5ed40>
array_like = array([[2.3958778, 1.4534979, 2.4516766, 1.2627432]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[2.3958778, 1.4534979, 2.4516766, 1.2627432]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[2.3958778, 1.4534979, 2.4516766, 1.2627432]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fe0daf5ed40>
array_like = array([[2.3958778, 1.4534979, 2.4516766, 1.2627432]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[2.3958778, 1.4534979, 2.4516766, 1.2627432]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[2.3958778, 1.4534979, 2.4516766, 1.2627432]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.sampson_epipolar_distance
_________________________________________________________________________ test_symmetrical_epipolar_distance[numpy-s2s-False] __________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetrical_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.symmetrical_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:426: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7fe1392e4700>
trace_args = (tensor([[[0.3679, 0.5305],
         [0.7145, 0.3341],
         [0.9743, 0.4728],
         [0.7318, 0.1148]]]), tensor...0.3411]]]), tensor([[[0.1881, 0.2137, 0.0456],
         [0.7874, 0.8815, 0.9980],
         [0.4259, 0.2768, 0.6759]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.2311, 0.7100],
         [0.6866, 0.4818],
         [0.5416, 0.9334],
         [0.3382, 0.0771]],

       ... 0.9786]],

        [[0.9846, 0.8804, 0.3209],
         [0.9472, 0.3595, 0.9116],
         [0.6671, 0.9120, 0.0885]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7fe1392e4700>, fn_name = 'kornia.geometry.epipolar.symmetrical_epipolar_distance'
trace_args = (tensor([[[0.3679, 0.5305],
         [0.7145, 0.3341],
         [0.9743, 0.4728],
         [0.7318, 0.1148]]]), tensor...0.3411]]]), tensor([[[0.1881, 0.2137, 0.0456],
         [0.7874, 0.8815, 0.9980],
         [0.4259, 0.2768, 0.6759]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.2311, 0.7100],
         [0.6866, 0.4818],
         [0.5416, 0.9334],
         [0.3382, 0.0771]],

       ... 0.9786]],

        [[0.9846, 0.8804, 0.3209],
         [0.9472, 0.3595, 0.9116],
         [0.6671, 0.9120, 0.0885]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.36787695, 0.5304717 , 1.        ],
        [0.71453017, 0.33405697, 1.        ],
        [0.97427946, 0.47275072, 1.        ],
        [0.73181534, 0.11483377, 1.        ]]], dtype=float32)
pts2 = array([[[0.50902224, 0.77052057, 1.        ],
        [0.39550412, 0.8520327 , 1.        ],
        [0.11789954, 0.50842893, 1.        ],
        [0.04497087, 0.34114772, 1.        ]]], dtype=float32)
Fm = array([[[0.18806672, 0.21371311, 0.0455637 ],
        [0.78741616, 0.88152057, 0.99802655],
        [0.42590767, 0.27678668, 0.67588824]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetrical_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[2.448025 , 2.7527165, 2.3699348, 1.6002928]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fe0db6963b0>
array_like = array([[2.448025 , 2.7527165, 2.3699348, 1.6002928]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[2.448025 , 2.7527165, 2.3699348, 1.6002928]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[2.448025 , 2.7527165, 2.3699348, 1.6002928]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fe0db6963b0>
array_like = array([[2.448025 , 2.7527165, 2.3699348, 1.6002928]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[2.448025 , 2.7527165, 2.3699348, 1.6002928]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[2.448025 , 2.7527165, 2.3699348, 1.6002928]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.symmetrical_epipolar_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_epipolar.py::test_find_essential[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_find_fundamental[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_sampson_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_epipolar.py::test_symmetrical_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
============================================================================== 4 failed, 22 passed in 1566.99s (0:26:06) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_RandomClahe[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'tensorflow', init_args = (), init_kwargs = {}
call_args = (tensor([[[[0.5139, 0.5446, 0.5370,  ..., 0.0679, 0.6246, 0.5308],
          [0.7990, 0.7100, 0.1579,  ..., 0.8624, 0...., 0.6230, 0.9940,  ..., 0.5872, 0.8277, 0.8195],
          [0.8133, 0.6326, 0.8995,  ..., 0.4232, 0.6547, 0.5435]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0.0678618 ...
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f6107316440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slo...,
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0.0678618 ...
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slo...,
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0.0678618 ...
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0.0678618 ,...],
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0...,
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0.0678618 ,...],
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f610d1d64d0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f6104542dd0>
tensor = <function tensorflow_tensor_frnt at 0x7f610cd75750>
in_tensor = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0.0678618 ,...],
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0.0678618 ,...],
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(2, 3, 10, 20), dtype=float32, numpy=
array([[[[0.51385045, 0.5446001 , 0.53696024, ..., 0.0678618 ,...],
         [0.8133485 , 0.6325655 , 0.8994826 , ..., 0.42320532,
          0.6546583 , 0.5435042 ]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f610d1d64d0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f610d1dfbe0>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f610ccc1ea0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f6104542c20>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f61044f9c60>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f610ccc0b80>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f610ccc1d80>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not tensorflow_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                tensorflow_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else tensorflow_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[0.4791546 , 0.52271646, 0.1492083 , 0.5477985 , 0.13...0.46165907, 0.667005  ,
          0.06536371, 0.29993683, 0.42320532, 0.6546583 , 0.5435042 ]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, 'clip_limit_factor': <tf....ray([40.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 2,  3, 10, 20])>}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import tensorflow_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return tensorflow_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/clahe.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[0.4791546 , 0.52271646, 0.1492083 , 0.5477985 , 0.13...0.46165907, 0.667005  ,
          0.06536371, 0.29993683, 0.42320532, 0.6546583 , 0.5435042 ]]]],
      dtype=float32)>
args = (40.0, (8, 8), False), kwargs = {}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7f610d1df910>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f610d1d64d0>
tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7f610ccc2200>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[0.4791546 , 0.52271646, 0.1492083 , 0.5477985 , 0.13...0.46165907, 0.667005  ,
          0.06536371, 0.29993683, 0.42320532, 0.6546583 , 0.5435042 ]]]],
      dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 3, 10, 20), dtype=float32, numpy=
array([[[[0.4791546 , 0.52271646, 0.1492083 , 0.5477985 , 0.13...0.46165907, 0.667005  ,
          0.06536371, 0.29993683, 0.42320532, 0.6546583 , 0.5435042 ]]]],
      dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
>               tensorflow_unfold_frnt_(
                    tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.4791546 , 0.52271646, 0.1492083 , ..., 0.....4696861 , 0.6772828 , 0.46577787, ..., 0.8246354 ,
            0.33139324, 0.30929202]]]]]], dtype=float32)>, 3, 4, 4)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f610ca7d6c0>
array_like = <tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.4791546 , 0.52271646, 0.1492083 , ..., 0.1...        [0.4696861 , 0.6772828 , 0.46577787, ..., 0.8246354 ,
            0.33139324, 0.30929202]]]]]], dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 2, 16, 32), dtype=float32, numpy=
array([[[[[[0.4791546 , 0.52271646, 0.1492083 , ..., 0.1...        [0.4696861 , 0.6772828 , 0.46577787, ..., 0.8246354 ,
            0.33139324, 0.30929202]]]]]], dtype=float32)>
dimension = 3, size = 4, step = 4

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:660: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)
E           IndexError: Exception encountered when calling tensorflow_RandomClahe.call().
E           
E           [1mlist index out of range[0m
E           
E           Arguments received by tensorflow_RandomClahe.call():
E             • input=tf.Tensor(shape=(2, 3, 10, 20), dtype=float32)
E             • params=None
E             • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:260: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_RandomClahe.call().
============================================================================== 1 failed, 17 passed in 3601.32s (1:00:01) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py s                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.08s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py ..                                                                                                                                                                  [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 2 passed in 80.47s (0:01:20) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ssssss                                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.07s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 445.60s (0:07:25) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py sss                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 3 skipped in 4.99s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_solve_pnp_dlt[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fee081e4af0>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fee081e4af0>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])
img_points = array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])
intrinsics = array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]]), weights = None, svd_eps = 0.001

    def numpy_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...utils.helpers import numpy__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_inverse_frnt,
        )
        from ..conversions import numpy_convert_points_to_homogeneous
        from ..linalg import numpy_transform_points
        from ....ivy.functional.backends.numpy.general import numpy_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...utils.misc import numpy_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import numpy_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import numpy_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = np.float32, np.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(numpy_shape_frnt_(world_points)) != 3
            or numpy_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {numpy_shape_frnt_(world_points)}."
            )
        if len(numpy_shape_frnt_(img_points)) != 3 or numpy_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {numpy_shape_frnt_(img_points)}."
            )
        if len(numpy_shape_frnt_(intrinsics)) != 3 or numpy_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {numpy_shape_frnt_(intrinsics)}."
            )
        if numpy_shape_frnt_(world_points)[1] != numpy_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(img_points)[0]
            or numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if numpy_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {numpy_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            numpy_shape_frnt_(world_points)[:2][0],
            numpy_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = numpy__mean_isotropic_scale_normalize(
            world_points
        )
        s = numpy__torch_linalg_svdvals(world_points_norm)
        if numpy_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = numpy_inverse_frnt(intrinsics)
        world_points_norm_h = numpy_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = numpy_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = numpy__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = numpy_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=None)
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = numpy_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = numpy_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = numpy_eye_like(4, solution)
        solution_4x4 = numpy_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = numpy_bmm_frnt(solution_4x4, world_transform_norm)
        solution = numpy_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = numpy_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = numpy_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/calibration/pnp.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': array([[0.0754885 , 0.02388223, 0.0574928 ]]), 'p': 2}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fedaf06b490>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[numpy-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 300.50s (0:05:00) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3755.89s (1:02:35) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1681.48s (0:28:01) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1650.77s (0:27:30) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F........................                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_equalize_clahe[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7fb7dea6fa30>
trace_args = (tensor([[[0.2465, 0.2684, 0.9914, 0.5492, 0.7530, 0.0403, 0.3081, 0.9275,
          0.1274, 0.7653, 0.9479, 0.3950, 0...         0.3545, 0.3930, 0.9039, 0.6978, 0.1396, 0.4222, 0.0184, 0.7698,
          0.8675, 0.3810, 0.1535, 0.8204]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.5552, 0.6692, 0.6063,  ..., 0.9435, 0.3267, 0.6696],
          [0.8875, 0.3355, 0.9939,  ..., 0.9340, 0...., 0.2230, 0.5271,  ..., 0.7361, 0.9641, 0.1359],
          [0.1646, 0.8149, 0.7920,  ..., 0.6069, 0.2603, 0.9320]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True
deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7fb7dea6fa30>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.2465, 0.2684, 0.9914, 0.5492, 0.7530, 0.0403, 0.3081, 0.9275,
          0.1274, 0.7653, 0.9479, 0.3950, 0...         0.3545, 0.3930, 0.9039, 0.6978, 0.1396, 0.4222, 0.0184, 0.7698,
          0.8675, 0.3810, 0.1535, 0.8204]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.5552, 0.6692, 0.6063,  ..., 0.9435, 0.3267, 0.6696],
          [0.8875, 0.3355, 0.9939,  ..., 0.9340, 0...., 0.2230, 0.5271,  ..., 0.7361, 0.9641, 0.1359],
          [0.1646, 0.8149, 0.7920,  ..., 0.6069, 0.2603, 0.9320]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.24649364, 0.2684058 , 0.9913911 , 0.54918045, 0.75...0.42216575, 0.01840425,
          0.76984507, 0.8675362 , 0.38100553, 0.15349168, 0.8204334 ]]]],
      dtype=float32)>
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7fb77c182c20>
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fb77c181510>, tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7fb77c1800d0>
input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.24649364, 0.2684058 , 0.9913911 , 0.54918045, 0.75...0.42216575, 0.01840425,
          0.76984507, 0.8675362 , 0.38100553, 0.15349168, 0.8204334 ]]]],
      dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.24649364, 0.2684058 , 0.9913911 , 0.54918045, 0.75...0.42216575, 0.01840425,
          0.76984507, 0.8675362 , 0.38100553, 0.15349168, 0.8204334 ]]]],
      dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
                tensorflow_unfold_frnt_(
>                   tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.24649364, 0.00183302, 0.47804046, 0.44597358,...      0.5523101 , 0.98702157, 0.07616901, 0.87505955, 0.41836333,
           0.77401346]]]]], dtype=float32)>, 2, 2, 2)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7fb768801630>
array_like = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.24649364, 0.00183302, 0.47804046, 0.44597358, ...736,
           0.5523101 , 0.98702157, 0.07616901, 0.87505955, 0.41836333,
           0.77401346]]]]], dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.24649364, 0.00183302, 0.47804046, 0.44597358, ...736,
           0.5523101 , 0.98702157, 0.07616901, 0.87505955, 0.41836333,
           0.77401346]]]]], dtype=float32)>
dimension = 2, size = 2, step = 2

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2

    @tf_export.tf_export('experimental.numpy.stack', v1=[])
    @np_utils.np_doc('stack')
    def stack(arrays, axis=0):  # pylint: disable=missing-function-docstring
      if isinstance(arrays, (np_arrays.ndarray, tensor_lib.Tensor)):
        arrays = asarray(arrays)
        if axis == 0:
          return arrays
        else:
          return swapaxes(arrays, 0, axis)
      arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access
      unwrapped_arrays = [
          a if isinstance(a, np_arrays.ndarray) else a for a in arrays
      ]
>     return asarray(array_ops_stack.stack(unwrapped_arrays, axis))

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_array_ops.py:1211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ([], 2), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = [], axis = 2, name = 'stack'

    @tf_export("stack")
    @dispatch.add_dispatch_support
    def stack(values, axis=0, name="stack"):
      """Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.
    
      See also `tf.concat`, `tf.tile`, `tf.repeat`.
    
      Packs the list of tensors in `values` into a tensor with rank one higher than
      each tensor in `values`, by packing them along the `axis` dimension.
      Given a list of length `N` of tensors of shape `(A, B, C)`;
    
      if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
      if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
      Etc.
    
      For example:
    
      >>> x = tf.constant([1, 4])
      >>> y = tf.constant([2, 5])
      >>> z = tf.constant([3, 6])
      >>> tf.stack([x, y, z])
      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=
      array([[1, 4],
             [2, 5],
             [3, 6]], dtype=int32)>
      >>> tf.stack([x, y, z], axis=1)
      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=
      array([[1, 2, 3],
             [4, 5, 6]], dtype=int32)>
    
      This is the opposite of unstack.  The numpy equivalent is `np.stack`
    
      >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))
      True
    
      Args:
        values: A list of `Tensor` objects with the same shape and type.
        axis: An `int`. The axis to stack along. Defaults to the first dimension.
          Negative values wrap around, so the valid range is `[-(R+1), R+1)`.
        name: A name for this operation (optional).
    
      Returns:
        output: A stacked `Tensor` with the same type as `values`.
    
      Raises:
        ValueError: If `axis` is out of the range [-(R+1), R+1).
      """
      if axis == 0:
        try:
          # If the input is a constant list, it can be converted to a constant op
          return ops.convert_to_tensor(values, name=name)
        except (TypeError, ValueError, NotImplementedError):
          pass  # Input list contains non-constant tensors
    
>     value_shape = ops.convert_to_tensor(values[0], name=name)._shape_tuple()  # pylint: disable=protected-access
E     IndexError: list index out of range

/opt/fw/tensorflow/tensorflow/python/ops/array_ops_stack.py:78: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 1 failed, 38 passed in 2551.07s (0:42:31) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F.........sssssssssssssssssssssssssssssssss.ss                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_rgb_to_hls[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fa08e97c040>
trace_args = (tensor([[[[0.7709, 0.5047, 0.2274, 0.0148, 0.5315],
          [0.5734, 0.8722, 0.2095, 0.1609, 0.5429],
          [0.... [0.5077, 0.6845, 0.1226, 0.0097, 0.2649],
          [0.4577, 0.6711, 0.1126, 0.5233, 0.2730]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.7834, 0.6708, 0.0178, 0.8763, 0.7500],
          [0.2137, 0.4104, 0.0311, 0.1615, 0.0220],
          [0.... [0.1165, 0.4958, 0.8225, 0.2441, 0.5906],
          [0.3497, 0.1462, 0.6636, 0.4600, 0.6983]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7fa08e97c040>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.7709, 0.5047, 0.2274, 0.0148, 0.5315],
          [0.5734, 0.8722, 0.2095, 0.1609, 0.5429],
          [0.... [0.5077, 0.6845, 0.1226, 0.0097, 0.2649],
          [0.4577, 0.6711, 0.1126, 0.5233, 0.2730]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.7834, 0.6708, 0.0178, 0.8763, 0.7500],
          [0.2137, 0.4104, 0.0311, 0.1615, 0.0220],
          [0.... [0.1165, 0.4958, 0.8225, 0.2441, 0.5906],
          [0.3497, 0.1462, 0.6636, 0.4600, 0.6983]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = array([[[[0.77085066, 0.50474614, 0.22743225, 0.01475096, 0.5314612 ],
         [0.57340384, 0.87216663, 0.2094723 , 0...0.00971901, 0.26490837],
         [0.45767123, 0.6711157 , 0.11261851, 0.52326185, 0.27300584]]]],
      dtype=float32)
eps = 1e-08

    def numpy_rgb_to_hls(image, eps=1e-08):
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.pointwise_ops import sub
        from ..core._backend import where
        from ..core._backend import stack
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_requires_grad_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_like_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_add_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_mul_frnt
    
        if not isinstance(image, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(image)}")
        if len(numpy_shape_frnt_(image)) < 3 or numpy_shape_frnt_(image)[-3] != 3:
            raise ValueError(
                f"Input size must have a shape of (*, 3, H, W). Got {numpy_shape_frnt_(image)}"
            )
        _RGB2HSL_IDX = tensor([[[0.0]], [[1.0]], [[2.0]]], device=None, dtype=image.dtype)
        _img_max: typing.Any = numpy_max_frnt_(image, -3)
        maxc = _img_max[0]
        imax = _img_max[1]
        minc: typing.Any = numpy_min_frnt_(image, -3)[0]
        if numpy_requires_grad_frnt_(image):
            l_ = maxc + minc
            s = maxc - minc
            h = l_
            image_hls = l_
        else:
            image_hls = numpy_empty_like_frnt(image)
            h, l_, s = (
                image_hls[..., 0, :, :],
                image_hls[..., 1, :, :],
                image_hls[..., 2, :, :],
            )
            numpy_add_frnt(maxc, minc, out=l_)
            sub(maxc, minc, out=s)
        im = image / numpy_unsqueeze_frnt_(s + eps, -3)
        s = s / (where(l_ < 1.0, l_, 2.0 - l_) + eps)
        l_ = l_ / 2
        r, g, b = im[..., 0, :, :], im[..., 1, :, :], im[..., 2, :, :]
        cond = imax[..., None, :, :] == _RGB2HSL_IDX
        if numpy_requires_grad_frnt_(image):
            h = (g - b) % 6 * cond[..., 0, :, :]
        else:
>           numpy_mul_frnt((g - b) % 6, cond[..., 0, :, :], out=h)

ivy_transpiled_outputs/numpy_outputs/kornia/color/hls.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[1.        , 0.99999994, 5.5083985 , 5.443595  , 0.6671347 ],
        [0.21336317, 5.9476895 , 0.16913664, 5.4..., 0.01318391, 1.        ],
        [5.011706  , 5.23346   , 1.        , 1.        , 0.6366862 ]]],
      dtype=float32)
other = array([[[False, False, False, False,  True],
        [ True,  True, False, False, False],
        [False, False, False,  True, False],
        [ True, False, False, False,  True]]])

    def numpy_mul_frnt(input, other, *, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.elementwise import numpy_multiply
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[1.        , 0.99999994, 5.5083985 , 5.443595  , 0.6671347 ],
        [0.21336317, 5.9476895 , 0.16913664, 5.4..., 0.01318391, 1.        ],
        [5.011706  , 5.23346   , 1.        , 1.        , 0.6366862 ]]],
      dtype=float32)
x2 = array([[[False, False, False, False,  True],
        [ True,  True, False, False, False],
        [False, False, False,  True, False],
        [ True, False, False, False,  True]]])

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('bool')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_________________________________________________________________________________ test_rgb_to_yuv420[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fa08e97dd80>
trace_args = (tensor([[[[4.8255e-01, 2.2568e-01, 5.1291e-01, 5.5472e-02, 6.7525e-01,
           6.0757e-01],
          [7.6284e-01,...       2.4573e-01],
          [6.5942e-01, 7.8252e-01, 9.8610e-01, 2.8459e-01, 8.9979e-02,
           4.7249e-01]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[9.7943e-02, 5.8515e-01, 6.7403e-01, 7.7858e-01, 7.3759e-02,
           7.4675e-02],
          [5.1419e-01,...       7.5854e-01],
          [4.1894e-01, 8.4882e-01, 1.6536e-01, 4.3031e-01, 8.1295e-01,
           2.3942e-01]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7fa08e97dd80>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[4.8255e-01, 2.2568e-01, 5.1291e-01, 5.5472e-02, 6.7525e-01,
           6.0757e-01],
          [7.6284e-01,...       2.4573e-01],
          [6.5942e-01, 7.8252e-01, 9.8610e-01, 2.8459e-01, 8.9979e-02,
           4.7249e-01]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[9.7943e-02, 5.8515e-01, 6.7403e-01, 7.7858e-01, 7.3759e-02,
           7.4675e-02],
          [5.1419e-01,...       7.5854e-01],
          [4.1894e-01, 8.4882e-01, 1.6536e-01, 4.3031e-01, 8.1295e-01,
           2.3942e-01]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.6349, 0.5258, 0.6354, 0.1893, 0.4668, 0.8145],
          [0.4537, 0.4950, 0.7252, 0.8962, 0.3975, 0.3919...       [ 0.0148, -0.0952, -0.1388]],

         [[-0.0811, -0.2053, -0.1043],
          [ 0.0408, -0.3348, -0.0515]]]]))
transpiled_x = (array([[[[0.6349125 , 0.52583027, 0.6354103 , 0.18930864, 0.46684712,
          0.81446236],
         [0.45367548, 0....
        [[-0.17791301,  0.08512731, -0.09595364],
         [-0.15823425, -0.11331911, -0.27587798]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.6349125 , 0.52583027, 0.6354103 , 0.18930864, 0.46684712,
          0.81446236],
         [0.45367548, 0....
        [[-0.08111855, -0.205262  , -0.10428435],
         [ 0.04077068, -0.3347836 , -0.05149285]]]], dtype=float32))
y = (array([[[[0.6349125 , 0.52583027, 0.6354103 , 0.18930864, 0.46684712,
          0.81446236],
         [0.45367548, 0....
        [[-0.17791301,  0.08512731, -0.09595364],
         [-0.15823425, -0.11331911, -0.27587798]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fa037348600>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.00925526,  0.03377922,  0.00094483],
         [ 0.01483027, -0.09521054, -0.13881934]],

        [[-0.08111855, -0.205262  , -0.10428435],
         [ 0.04077068, -0.3347836 , -0.05149285]]]], dtype=float32)
y = array([[[[-0.1290006 ,  0.05558679,  0.00871151],
         [ 0.04716484, -0.07199171, -0.0856911 ]],

        [[-0.17791301,  0.08512731, -0.09595364],
         [-0.15823425, -0.11331911, -0.27587798]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_color.py::test_rgb_to_yuv420[numpy-s2s-False] - AssertionError: numpy array values are not all close
======================================================================== 2 failed, 32 passed, 35 skipped in 1683.49s (0:28:03) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py .                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 310.14s (0:05:10) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py ssssssssssssss                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 14 skipped in 5.00s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py ssssss                                                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.15s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 265.85s (0:04:25) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 750.61s (0:12:30) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 4 passed in 86.19s (0:01:26) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py ..                                                                                                                                                                  [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 2 passed in 71.13s (0:01:11) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 4 passed in 429.85s (0:07:09) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 317.64s (0:05:17) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 274.80s (0:04:34) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py .                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 316.72s (0:05:16) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 293.41s (0:04:53) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py ssssssssssssssssss                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 18 skipped in 5.23s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 130.26s (0:02:10) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_conv_quad_interp3d[jax-s2s-False] ________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7feb2cea6dd0>
trace_args = (tensor([[[[[0.1918, 0.7374, 0.5639, 0.0959, 0.0817],
           [0.6146, 0.1024, 0.0042, 0.4778, 0.5073],
           ....3165],
           [0.1543, 0.3540, 0.3569, 0.5780, 0.9412],
           [0.9555, 0.8926, 0.6880, 0.6807, 0.4647]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.2203, 0.0019, 0.2537, 0.0125, 0.8849],
           [0.6482, 0.9551, 0.2176, 0.9825, 0.1915],
           ....3529],
           [0.6953, 0.3215, 0.9476, 0.9635, 0.2888],
           [0.4401, 0.4646, 0.1019, 0.4904, 0.1355]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7feb2cea6dd0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.1918, 0.7374, 0.5639, 0.0959, 0.0817],
           [0.6146, 0.1024, 0.0042, 0.4778, 0.5073],
           ....3165],
           [0.1543, 0.3540, 0.3569, 0.5780, 0.9412],
           [0.9555, 0.8926, 0.6880, 0.6807, 0.4647]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.2203, 0.0019, 0.2537, 0.0125, 0.8849],
           [0.6482, 0.9551, 0.2176, 0.9825, 0.1915],
           ....3529],
           [0.6953, 0.3215, 0.9476, 0.9635, 0.2888],
           [0.4401, 0.4646, 0.1019, 0.4904, 0.1355]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[0.19180489, 0.7373563 , 0.5638864 , 0.09589922, 0.08167762],
          [0.6145976 , 0.10239094, 0.00420779,....5780322 , 0.9412283 ],
          [0.95548636, 0.89255637, 0.6879683 , 0.68074334, 0.46473205]]]]],      dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([], shape=(0, 3, 1), dtype=float32), A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([], shape=(0, 3, 3), dtype=float32)], kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7feaa0372680>
jax_set_item = <function jax_set_item at 0x7feaa0305ab0>, jax_asarray = <function jax_asarray at 0x7feaa0373520>, jax_get_item = <function jax_get_item at 0x7feaa0305900>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([], shape=(0, 3, 3), dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_________________________________________________________________________________ test_ConvQuadInterp3d[jax-s2s-False] _________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledConvQuadInterp3d = ivy.transpile(
            kornia.geometry.subpix.ConvQuadInterp3d, source="torch", target=target_framework
        )
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = TranspiledConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:371: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = Array([[[[[ 0.7783318 ,  0.44635844,  0.7590952 , -0.6652459 ,
           -0.87966317],
          [ 1.570669  , -0.322...0.6233057 ],
          [-0.88878053,  0.7498868 , -0.3443151 ,  0.11752039,
            0.04412805]]]]], dtype=float32)

    def __call__(self, x):
>       return jax_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[ 0.7783318 ,  0.44635844,  0.7590952 , -0.6652459 ,
           -0.87966317],
          [ 1.570669  , -0.322...0.6233057 ],
          [-0.88878053,  0.7498868 , -0.3443151 ,  0.11752039,
            0.04412805]]]]], dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([], shape=(0, 3, 1), dtype=float32), A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([], shape=(0, 3, 3), dtype=float32)], kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fea8eb5b0a0>
jax_set_item = <function jax_set_item at 0x7fea8d4ba4d0>, jax_asarray = <function jax_asarray at 0x7fea8eb5bf40>, jax_get_item = <function jax_get_item at 0x7fea8d4ba320>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([], shape=(0, 3, 3), dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
============================================================================== 2 failed, 13 passed in 1079.77s (0:17:59) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................................ssssssssssssssss                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 40 passed, 16 skipped in 3224.87s (0:53:44) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_get_laf_descriptors[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7fe8db2c5b40>
trace_args = (tensor([[[[0.5149, 0.8465, 0.5308,  ..., 0.7971, 0.8314, 0.0557],
          [0.8595, 0.7322, 0.4120,  ..., 0.3573, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.3744, 0.7468, 0.2384,  ..., 0.9823, 0.7004, 0.7622],
          [0.6226, 0.1775, 0.2157,  ..., 0.7997, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7fe8db2c5b40>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.5149, 0.8465, 0.5308,  ..., 0.7971, 0.8314, 0.0557],
          [0.8595, 0.7322, 0.4120,  ..., 0.3573, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.3744, 0.7468, 0.2384,  ..., 0.9823, 0.7004, 0.7622],
          [0.6226, 0.1775, 0.2157,  ..., 0.7997, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
>       transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]

helpers.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <enumerate object at 0x7fe885757600>

    transpiled_trace_args = [
>       transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
        for i, arg in enumerate(trace_args)
    ]

helpers.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arg = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
arg_class_info = {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}

    def transpile_and_instantiate(arg, arg_class_info=None):
        if arg_class_info:
            # If we have class info, transpile the class and instantiate it
>           transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)

helpers.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.feature.orientation.OriNet'>, source = 'torch', target = 'numpy', reuse_existing = True, output_dir = 'ivy_transpiled_outputs/'

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
        output_dir: str = "ivy_transpiled_outputs/",
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
            output_dir (str, optional): The path to the directory where translated files will be saved.
                                        Defaults to 'ivy_transpiled_outputs/' in the current working directory.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
            output_dir=output_dir,
        )

../ivy/ivy/compiler/compiler.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientation.ivy_OriNet'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientat...
============================================================================== 1 failed, 18 passed in 1173.38s (0:19:33) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F......F.............F...........F.....F..F..F                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_rgb_to_hls[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f06b0740040>
trace_args = (tensor([[[[0.6251, 0.4148, 0.3617, 0.3836, 0.3487],
          [0.1707, 0.4683, 0.0331, 0.1896, 0.5231],
          [0.... [0.1019, 0.3307, 0.1487, 0.4005, 0.1970],
          [0.4465, 0.8395, 0.4104, 0.0949, 0.9218]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.0059, 0.3048, 0.2715, 0.5851, 0.0544],
          [0.6750, 0.5103, 0.0061, 0.8223, 0.9130],
          [0.... [0.6268, 0.2283, 0.9243, 0.2214, 0.5128],
          [0.8367, 0.3437, 0.6719, 0.3289, 0.7019]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f06b0740040>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.6251, 0.4148, 0.3617, 0.3836, 0.3487],
          [0.1707, 0.4683, 0.0331, 0.1896, 0.5231],
          [0.... [0.1019, 0.3307, 0.1487, 0.4005, 0.1970],
          [0.4465, 0.8395, 0.4104, 0.0949, 0.9218]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.0059, 0.3048, 0.2715, 0.5851, 0.0544],
          [0.6750, 0.5103, 0.0061, 0.8223, 0.9130],
          [0.... [0.6268, 0.2283, 0.9243, 0.2214, 0.5128],
          [0.8367, 0.3437, 0.6719, 0.3289, 0.7019]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.4638, 5.2495, 3.5859, 1.0464, 4.6737],
          [3.2956, 3.5360, 4.0220, 3.3592, 4.9941],
          [2.2....3180, 0.4689, 0.4328, 0.5850],
          [0.9776, 0.6064, 0.3669, 0.7712, 0.7145]]]],
       grad_fn=<StackBackward0>)
transpiled_x = <tf.Tensor: shape=(1, 3, 4, 5), dtype=float32, numpy=
array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
  ...., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.46381405, 5.24947   , 3.5859175 , 1.0464215 , 4.673729  ],
         [3.2956402 , 3.536036  , 4.0219913 , 3...0.43278185, 0.5849624 ],
         [0.9776496 , 0.60644543, 0.3669211 , 0.7712191 , 0.71452713]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_______________________________________________________________________________ test_rgb_to_yuv420[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f06b0741d80>
trace_args = (tensor([[[[0.4071, 0.3901, 0.6649, 0.4200, 0.2331, 0.8887],
          [0.6973, 0.3620, 0.3581, 0.2250, 0.9091, 0.9691...     [0.4166, 0.9266, 0.9656, 0.2908, 0.5812, 0.5725],
          [0.5812, 0.8201, 0.3894, 0.8133, 0.2793, 0.0029]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.8505, 0.7125, 0.8301, 0.3939, 0.6460, 0.0321],
          [0.7708, 0.2311, 0.8286, 0.7007, 0.5646, 0.7261...     [0.7423, 0.9865, 0.6348, 0.5242, 0.2391, 0.1827],
          [0.9874, 0.4020, 0.3373, 0.0023, 0.8065, 0.4727]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f06b0741d80>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.4071, 0.3901, 0.6649, 0.4200, 0.2331, 0.8887],
          [0.6973, 0.3620, 0.3581, 0.2250, 0.9091, 0.9691...     [0.4166, 0.9266, 0.9656, 0.2908, 0.5812, 0.5725],
          [0.5812, 0.8201, 0.3894, 0.8133, 0.2793, 0.0029]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.8505, 0.7125, 0.8301, 0.3939, 0.6460, 0.0321],
          [0.7708, 0.2311, 0.8286, 0.7007, 0.5646, 0.7261...     [0.7423, 0.9865, 0.6348, 0.5242, 0.2391, 0.1827],
          [0.9874, 0.4020, 0.3373, 0.0023, 0.8065, 0.4727]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.4037, 0.3764, 0.6224, 0.7196, 0.6486, 0.7193],
          [0.7862, 0.4768, 0.3307, 0.4007, 0.4436, 0.8790...       [ 0.1108, -0.0498, -0.0171]],

         [[-0.0409, -0.0889,  0.0679],
          [ 0.0023, -0.1108,  0.0719]]]]))
transpiled_x = (<tf.Tensor: shape=(1, 1, 4, 6), dtype=float32, numpy=
array([[[[0.40368655, 0.37644506, 0.6223717 , 0.71956867, 0.648...        [[-0.08639228, -0.05004551, -0.04522452],
         [ 0.10325843,  0.02388656, -0.04400301]]]], dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.40368655, 0.37644506, 0.6223717 , 0.71956867, 0.64864385,
          0.71931577],
         [0.78621143, 0....
        [[-0.04094224, -0.08888446,  0.06785315],
         [ 0.00230567, -0.11076218,  0.0719097 ]]]], dtype=float32))
y = (array([[[[0.40368655, 0.37644506, 0.6223717 , 0.71956867, 0.64864385,
          0.71931577],
         [0.78621143, 0....
        [[-0.08639228, -0.05004551, -0.04522452],
         [ 0.10325843,  0.02388656, -0.04400301]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f06443c0240>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.01653035,  0.0866047 , -0.10804541],
         [ 0.11079851, -0.04979304, -0.0170876 ]],

        [[-0.04094224, -0.08888446,  0.06785315],
         [ 0.00230567, -0.11076218,  0.0719097 ]]]], dtype=float32)
y = array([[[[ 0.02245143,  0.04531154, -0.01486293],
         [ 0.05984465,  0.04820869, -0.1219459 ]],

        [[-0.08639228, -0.05004551, -0.04522452],
         [ 0.10325843,  0.02388656, -0.04400301]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
________________________________________________________________________________ test_raw_to_rgb[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_raw_to_rgb(target_framework, mode, backend_compile):
        print("kornia.color.raw_to_rgb")
    
        transpiled_raw_to_rgb = ivy.transpile(kornia.color.raw_to_rgb, source="torch", target=target_framework)
        TranspiledCFA = ivy.transpile(kornia.color.CFA, source="torch", target=target_framework)
    
        torch_x = torch.rand(5, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.raw_to_rgb(torch_x, kornia.color.CFA.RG)
        transpiled_out = transpiled_raw_to_rgb(transpiled_x, TranspiledCFA.RG)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:713: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.2799, 0.2799, 0.1853, 0.0908, 0.3129, 0.5350],
          [0.2799, 0.2799, 0.1853, 0.0908, 0.3129, 0.5350]...       [0.9324, 0.6319, 0.3315, 0.4717, 0.6119, 0.6119],
          [0.9324, 0.6319, 0.3315, 0.4717, 0.6119, 0.6119]]]])
transpiled_x = <tf.Tensor: shape=(5, 3, 4, 6), dtype=float32, numpy=
array([[[[0.27986264, 0.27986264, 0.1853289 , 0.12252723, 0.3763...94015],
         [0.9324102 , 0.71778524, 0.3743853 , 0.47170025, 0.61194015,
          0.61194015]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.27986264, 0.27986264, 0.1853289 , 0.09079516, 0.31291902,
          0.5350429 ],
         [0.27986264, 0.2...194015],
         [0.9324102 , 0.63193524, 0.33146036, 0.47170025, 0.61194015,
          0.61194015]]]], dtype=float32)
y = array([[[[0.27986264, 0.27986264, 0.1853289 , 0.12252723, 0.37638307,
          0.5350429 ],
         [0.27986264, 0.2...194015],
         [0.9324102 , 0.71778524, 0.3743853 , 0.47170025, 0.61194015,
          0.61194015]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.raw_to_rgb
_________________________________________________________________________________ test_RgbToHls[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:908: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>
args = (tensor([[[[0.3922, 0.5658, 0.4821, 0.3729, 0.8479],
          [0.0053, 0.7022, 0.3721, 0.4357, 0.1596],
          [0...., 0.6534],
          [0.2128, 0.9784, 0.2241, 0.2565, 0.5694],
          [0.3569, 0.8255, 0.7815, 0.0074, 0.1811]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[1.0933236 , 1.4932677 , 4.6395087 , 1.4125179 , 5.17181   ],
         [4.1043572 , 1.0112188 , 2.465749  , 1...0.42587927, 0.35166776],
         [0.33166942, 0.95049083, 0.49731582, 0.971663  , 0.7431699 ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
________________________________________________________________________________ test_RgbToYuv420[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1064: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>
args = (tensor([[[[0.2032, 0.7691, 0.7351, 0.3991, 0.8824, 0.4213],
          [0.7965, 0.8171, 0.3836, 0.7831, 0.3631, 0.7347...     [0.0612, 0.5230, 0.2997, 0.4423, 0.3950, 0.7218],
          [0.2920, 0.5050, 0.2565, 0.0639, 0.3000, 0.2183]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.35195673, 0.5404516 , 0.4249045 , 0.52189624, 0.45346665,
          0.313219  ],
         [0.8176188 , 0....
        [[-0.06765722,  0.0836315 ,  0.00265374],
         [-0.04766416,  0.15650855, -0.02162697]]]], dtype=float32))
y = (array([[[[0.35195673, 0.5404516 , 0.4249045 , 0.52189624, 0.45346665,
          0.313219  ],
         [0.8176188 , 0....
        [[-0.01481653, -0.0190333 ,  0.00872618],
         [-0.02439521,  0.14983775,  0.00552655]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f063877b040>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.10508711,  0.01144103,  0.00620095],
         [ 0.1094629 , -0.07457435,  0.00474577]],

        [[ 0.042...

        [[-0.06765722,  0.0836315 ,  0.00265374],
         [-0.04766416,  0.15650855, -0.02162697]]]], dtype=float32)
y = array([[[[-0.03832056,  0.05062505,  0.06653769],
         [-0.06185412,  0.00928619, -0.07408509]],

        [[ 0.161...

        [[-0.01481653, -0.0190333 ,  0.00872618],
         [-0.02439521,  0.14983775,  0.00552655]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
_________________________________________________________________________________ test_RawToRgb[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RawToRgb(target_framework, mode, backend_compile):
        print("kornia.color.RawToRgb")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_RawToRgb = ivy.transpile(kornia.color.RawToRgb, source="torch", target=target_framework)
        TranspiledCFA = ivy.transpile(kornia.color.CFA, source="torch", target=target_framework)
    
        torch_x = torch.rand(2, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.RawToRgb(kornia.color.CFA.RG)(torch_x)
        transpiled_out = transpiled_RawToRgb(TranspiledCFA.RG)(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:1155: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.1228, 0.1228, 0.1245, 0.1261, 0.4220, 0.7179],
          [0.1228, 0.1228, 0.1245, 0.1261, 0.4220, 0.7179]...       [0.6596, 0.6208, 0.5820, 0.6845, 0.7870, 0.7870],
          [0.6596, 0.6208, 0.5820, 0.6845, 0.7870, 0.7870]]]])
transpiled_x = <tf.Tensor: shape=(2, 3, 4, 6), dtype=float32, numpy=
array([[[[0.12279499, 0.12279499, 0.12445828, 0.16839302, 0.5065...96996],
         [0.65955806, 0.6318452 , 0.5875045 , 0.68446594, 0.78696996,
          0.78696996]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.12279499, 0.12279499, 0.12445828, 0.12612158, 0.42202073,
          0.7179199 ],
         [0.12279499, 0.1...696996],
         [0.65955806, 0.62075996, 0.5819619 , 0.68446594, 0.78696996,
          0.78696996]]]], dtype=float32)
y = array([[[[0.12279499, 0.12279499, 0.12445828, 0.16839302, 0.5065634 ,
          0.7179199 ],
         [0.12279499, 0.1...696996],
         [0.65955806, 0.6318452 , 0.5875045 , 0.68446594, 0.78696996,
          0.78696996]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.RawToRgb
___________________________________________________________________________________ test_Sepia[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Sepia(target_framework, mode, backend_compile):
        args = (
            torch.ones(3, 1, 1),
        )
>       _test_color_class(
            kornia.color.Sepia,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1198: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.sepia.Sepia'>, args = (tensor([[[1.]],

        [[1.]],

        [[1.]]]),), target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
>       transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)

kornia/test_color.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'

<string>:1: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.sepia.Sepia
______________________________________________________________________________ test_apply_colormap[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_apply_colormap(target_framework, mode, backend_compile):
        print("kornia.color.ColorMap")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledColorMapType = ivy.transpile(kornia.color.ColorMapType, source="torch", target=target_framework)
        TranspiledColorMap = ivy.transpile(kornia.color.ColorMap, source="torch", target=target_framework)
        transpiled_apply_colormap = ivy.transpile(kornia.color.apply_colormap, source="torch", target=target_framework)
    
        torch_x = torch.tensor([[[0, 1, 2], [15, 25, 33], [128, 158, 188]]])
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        colormap = kornia.color.ColorMap(base=kornia.color.ColorMapType.autumn)
        torch_out = kornia.color.apply_colormap(torch_x, colormap)
    
>       colormap = TranspiledColorMap(base=TranspiledColorMapType.autumn)

kornia/test_color.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.color.colormap.tensorflow_ColorMap object at 0x7f0654426ce0>, base = <tensorflow_ColorMapType.autumn: 1>, num_colors = 64, device = None
dtype = None

>   ???

ivy_transpiled_outputs/tensorflow_outputs/kornia/color/colormap.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tensorflow_ColorMapType.autumn: 1>

        f"`input_tensor` must be a Tensor. Got: {type(input_tensor)}",
    )
>   valid_types = [
        tf.float16,
        tf.float32,
        tf.float64,
        tf.uint8,
        tf.int32,
        tf.int64,
        tf.int16,
    ]
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.color._colormap_data'

ivy_transpiled_outputs/tensorflow_outputs/kornia/color/colormap.py:56: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.ColorMap
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_raw_to_rgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToHls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RawToRgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_Sepia[tensorflow-s2s-False] - AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'
FAILED kornia/test_color.py::test_apply_colormap[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.color._colormap_data'
============================================================================== 8 failed, 61 passed in 3741.61s (1:02:21) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 176.61s (0:02:56) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py s                                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.13s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 837.10s (0:13:57) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 486.36s (0:08:06) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................ssssssssssssssssss                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 17 passed, 18 skipped in 1007.66s (0:16:47) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py .FF....FFssssss                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_conv_soft_argmax3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_soft_argmax3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(20, 16, 3, 50, 32),
        )
        trace_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(1.0),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
        test_args = (
            torch.rand(10, 16, 5, 50, 32),
        )
        test_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(0.5),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
>       _test_function(
            kornia.geometry.subpix.conv_soft_argmax3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7f2829182cb0>
trace_args = (tensor([[[[[1.0141e-01, 9.8559e-01, 5.6232e-01,  ..., 8.0388e-01,
            7.2310e-01, 4.7974e-01],
           [7....4635e-01],
           [2.5241e-01, 9.0618e-01, 3.2254e-01,  ..., 8.3142e-01,
            6.8945e-01, 1.3287e-02]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[3.9825e-01, 9.6499e-01, 5.3892e-01,  ..., 1.6814e-01,
            6.6905e-01, 2.7695e-01],
           [1....0090e-02],
           [4.8618e-01, 1.9785e-01, 1.2543e-01,  ..., 5.1707e-01,
            1.7606e-01, 2.5113e-01]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7f2829182cb0>, fn_name = 'kornia.geometry.subpix.conv_soft_argmax3d'
trace_args = (tensor([[[[[1.0141e-01, 9.8559e-01, 5.6232e-01,  ..., 8.0388e-01,
            7.2310e-01, 4.7974e-01],
           [7....4635e-01],
           [2.5241e-01, 9.0618e-01, 3.2254e-01,  ..., 8.3142e-01,
            6.8945e-01, 1.3287e-02]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[3.9825e-01, 9.6499e-01, 5.3892e-01,  ..., 1.6814e-01,
            6.6905e-01, 2.7695e-01],
           [1....0090e-02],
           [4.8618e-01, 1.9785e-01, 1.2543e-01,  ..., 5.1707e-01,
            1.7606e-01, 2.5113e-01]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.Module object at 0x7f27d0362c20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.Module object at 0x7f27d0362c20>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.FunctionDef object at 0x7f27d0361ea0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.If object at 0x7f27caf414e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.If object at 0x7f27caf414e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.AnnAssign object at 0x7f27ca99fc10>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.Call object at 0x7f27d05a9960>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.Call object at 0x7f27d05a9960>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.Call object at 0x7f27d05a9780>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.Call object at 0x7f27d05a9780>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d096ceb0>, node = <gast.gast.Name object at 0x7f27d05a9990>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Module object at 0x7f27cad9bee0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Module object at 0x7f27cad9bee0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.FunctionDef object at 0x7f27cad99900>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Return object at 0x7f27cad995d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Return object at 0x7f27cad995d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Call object at 0x7f27ca7de260>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Call object at 0x7f27ca7de260>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Call object at 0x7f27ca7dcf70>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Call object at 0x7f27ca7dcf70>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad232e0>, node = <gast.gast.Name object at 0x7f27ca7de170>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_soft_argmax3d
_______________________________________________________________________________ test_conv_quad_interp3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f2829182dd0>
trace_args = (tensor([[[[[0.7353, 0.8953, 0.7997, 0.5165, 0.2018],
           [0.5595, 0.1700, 0.5838, 0.4665, 0.5027],
           ....2609],
           [0.2637, 0.1010, 0.6228, 0.2281, 0.3805],
           [0.5651, 0.3682, 0.1399, 0.0131, 0.1748]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.8397, 0.2521, 0.9492, 0.5207, 0.9167],
           [0.7400, 0.0415, 0.6839, 0.5264, 0.6765],
           ....5710],
           [0.6595, 0.4215, 0.1394, 0.7920, 0.1806],
           [0.5028, 0.6020, 0.6089, 0.3207, 0.7260]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f2829182dd0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.7353, 0.8953, 0.7997, 0.5165, 0.2018],
           [0.5595, 0.1700, 0.5838, 0.4665, 0.5027],
           ....2609],
           [0.2637, 0.1010, 0.6228, 0.2281, 0.3805],
           [0.5651, 0.3682, 0.1399, 0.0131, 0.1748]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.8397, 0.2521, 0.9492, 0.5207, 0.9167],
           [0.7400, 0.0415, 0.6839, 0.5264, 0.6765],
           ....5710],
           [0.6595, 0.4215, 0.1394, 0.7920, 0.1806],
           [0.5028, 0.6020, 0.6089, 0.3207, 0.7260]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0c315d0>, node = <gast.gast.Module object at 0x7f27d0b55390>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0c315d0>, node = <gast.gast.Module object at 0x7f27d0b55390>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0c315d0>, node = <gast.gast.FunctionDef object at 0x7f27d0dd5f00>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0c315d0>, node = <gast.gast.AnnAssign object at 0x7f27d0363af0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0c315d0>, node = <gast.gast.Call object at 0x7f27ca8f8670>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0c315d0>, node = <gast.gast.Call object at 0x7f27ca8f8670>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0c315d0>, node = <gast.gast.Name object at 0x7f27ca8f84f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Module object at 0x7f27cac2fc10>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Module object at 0x7f27cac2fc10>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.FunctionDef object at 0x7f27cac2fd60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Return object at 0x7f27cac2e050>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Return object at 0x7f27cac2e050>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Call object at 0x7f27cac2c0a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Call object at 0x7f27cac2c0a0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Call object at 0x7f27cac2f460>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Call object at 0x7f27cac2f460>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27ca8f9690>, node = <gast.gast.Name object at 0x7f27cac2eda0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________________ test_nms2d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5),
            (3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5),
            (3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7f2829181fc0>
trace_args = (tensor([[[[0.7221, 0.4511, 0.5928, 0.3208, 0.8700],
          [0.0430, 0.1200, 0.2557, 0.7605, 0.7422],
          [0....3],
          [0.4819, 0.8080, 0.3371, 0.0439, 0.4217],
          [0.0595, 0.2508, 0.6688, 0.3229, 0.4675]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.7674, 0.8312, 0.9068, 0.7314, 0.0120],
          [0.2014, 0.6506, 0.4442, 0.4881, 0.9942],
          [0....5],
          [0.3741, 0.2104, 0.5979, 0.3183, 0.0272],
          [0.8051, 0.9036, 0.2258, 0.1590, 0.3211]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7f2829181fc0>, fn_name = 'kornia.geometry.subpix.nms2d'
trace_args = (tensor([[[[0.7221, 0.4511, 0.5928, 0.3208, 0.8700],
          [0.0430, 0.1200, 0.2557, 0.7605, 0.7422],
          [0....3],
          [0.4819, 0.8080, 0.3371, 0.0439, 0.4217],
          [0.0595, 0.2508, 0.6688, 0.3229, 0.4675]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.7674, 0.8312, 0.9068, 0.7314, 0.0120],
          [0.2014, 0.6506, 0.4442, 0.4881, 0.9942],
          [0....5],
          [0.3741, 0.2104, 0.5979, 0.3183, 0.0272],
          [0.8051, 0.9036, 0.2258, 0.1590, 0.3211]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Module object at 0x7f27cadebc10>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Module object at 0x7f27cadebc10>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.FunctionDef object at 0x7f27cadebd90>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Return object at 0x7f27cade9ae0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Return object at 0x7f27cade9ae0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Call object at 0x7f27cadea740>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Call object at 0x7f27cadea740>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Call object at 0x7f27cade8220>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Call object at 0x7f27cade8220>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27d0d0d690>, node = <gast.gast.Name object at 0x7f27cade81f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression2d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms2d
_____________________________________________________________________________________ test_nms3d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5, 5),
            (3, 3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5, 5),
            (3, 3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7f28291823b0>
trace_args = (tensor([[[[[0.9127, 0.8105, 0.4799, 0.0103, 0.7193],
           [0.6895, 0.3352, 0.6735, 0.8417, 0.2605],
           ...         [0.7309, 0.8993, 0.4958, 0.6056, 0.2734],
           [0.0316, 0.1841, 0.1671, 0.6392, 0.0320]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[9.9909e-01, 6.3158e-01, 5.5859e-01, 9.0018e-01, 4.9952e-01],
           [8.0547e-01, 1.2281e-01, 6.3129e-...e-01, 6.6522e-01, 4.8638e-01],
           [1.7090e-01, 6.8097e-01, 4.1683e-01, 4.9799e-01, 5.1820e-01]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7f28291823b0>, fn_name = 'kornia.geometry.subpix.nms3d'
trace_args = (tensor([[[[[0.9127, 0.8105, 0.4799, 0.0103, 0.7193],
           [0.6895, 0.3352, 0.6735, 0.8417, 0.2605],
           ...         [0.7309, 0.8993, 0.4958, 0.6056, 0.2734],
           [0.0316, 0.1841, 0.1671, 0.6392, 0.0320]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[9.9909e-01, 6.3158e-01, 5.5859e-01, 9.0018e-01, 4.9952e-01],
           [8.0547e-01, 1.2281e-01, 6.3129e-...e-01, 6.6522e-01, 4.8638e-01],
           [1.7090e-01, 6.8097e-01, 4.1683e-01, 4.9799e-01, 5.1820e-01]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Module object at 0x7f27d09852d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Module object at 0x7f27d09852d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.FunctionDef object at 0x7f27cad9a8f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Return object at 0x7f27d0497c70>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Return object at 0x7f27d0497c70>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Call object at 0x7f27d0496020>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Call object at 0x7f27d0496020>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Call object at 0x7f27d0495cc0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Call object at 0x7f27d0495cc0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f27cad98130>, node = <gast.gast.Name object at 0x7f27d0495210>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_soft_argmax3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.s...
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.s...
FAILED kornia/geometry/test_subpix.py::test_nms2d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy...
FAILED kornia/geometry/test_subpix.py::test_nms3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy...
========================================================================== 4 failed, 5 passed, 6 skipped in 628.02s (0:10:28) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1115.03s (0:18:35) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_HomographyTracker[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomographyTracker = ivy.transpile(kornia.tracking.HomographyTracker, source="torch", target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = TranspiledHomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}, node = jax_HomographyTracker()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, self = jax_HomographyTracker(), args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HomographyTracker(), initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import jax_LocalFeatureMatcher
        from ..feature.integrated import jax_GFTTAffNetHardNet
        from ..feature.matching import jax_DescriptorMatcher
        from ..feature.loftr.loftr import jax_LoFTR
        from ..geometry.ransac import jax_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or jax_LocalFeatureMatcher(
>           jax_GFTTAffNetHardNet(3000), jax_DescriptorMatcher("smnn", 0.95)
        )

ivy_transpiled_outputs/jax_outputs/kornia/tracking/planar_tracker.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_GFTTAffNetHardNet'>, args = (3000,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_GFTTAffNetHardNet'>, args = (3000,), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_GFTTAffNetHardNet object at 0x7fe8e0eac100>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_GFTTAffNetHardNet'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_GFTTAffNetHardNet object at 0x7fe8e0eac100>, args = (3000,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_GFTTAffNetHardNet object at 0x7fe8e0eac100>, args = (3000,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_GFTTAffNetHardNet object at 0x7fe8e0eac100>, num_features = 3000, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    @jax_store_config_info
    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=jax_device_frnt("cpu"),
        config=jax_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from .scale_space_detector import jax_MultiResolutionDetector
        from .responses import jax_CornerGFTT
        from .orientation import jax_PassLAF
        from .orientation import jax_LAFOrienter
        from .affine_shape import jax_LAFAffNetShapeEstimator
    
        detector = jax_to_frnt_(
            jax_MultiResolutionDetector(
                jax_CornerGFTT(),
                num_features,
                config,
                ori_module=jax_PassLAF() if upright else jax_LAFOrienter(19),
>               aff_module=jax_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, args = (True,), kwargs = {}, node = jax_LAFAffNetShapeEstimator()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, self = jax_LAFAffNetShapeEstimator(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LAFAffNetShapeEstimator(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LAFAffNetShapeEstimator(), pretrained = True, preserve_orientation = True

    @jax_store_config_info
    def __init__(self, pretrained=False, preserve_orientation=True):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.activation import jax_Tanh
        from ...torch.nn.modules.pooling import jax_AdaptiveAvgPool2d
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            preserve_orientation=preserve_orientation,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=32,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.25),
            FlaxConv(
                in_features=64,
                out_features=3,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=True,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_Tanh(),
            jax_AdaptiveAvgPool2d(1),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/affine_shape.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}
node = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 16, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 49.4MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 208MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:53, 409kB/s]
  1%|          | 256k/44.2M [00:00<01:08, 672kB/s]
  1%|          | 512k/44.2M [00:00<00:37, 1.23MB/s]
  2%|▏         | 896k/44.2M [00:00<00:22, 1.99MB/s]
  4%|▍         | 1.75M/44.2M [00:00<00:11, 3.97MB/s]
  8%|▊         | 3.50M/44.2M [00:00<00:05, 7.96MB/s]
 15%|█▍        | 6.50M/44.2M [00:00<00:02, 14.4MB/s]
 21%|██        | 9.38M/44.2M [00:01<00:01, 18.6MB/s]
 28%|██▊       | 12.2M/44.2M [00:01<00:01, 21.5MB/s]
 35%|███▍      | 15.2M/44.2M [00:01<00:01, 23.8MB/s]
 41%|████      | 18.1M/44.2M [00:01<00:01, 25.2MB/s]
 48%|████▊     | 21.1M/44.2M [00:01<00:00, 26.4MB/s]
 54%|█████▍    | 24.0M/44.2M [00:01<00:00, 27.0MB/s]
 61%|██████    | 26.9M/44.2M [00:01<00:00, 27.3MB/s]
 68%|██████▊   | 29.9M/44.2M [00:01<00:00, 27.9MB/s]
 74%|███████▍  | 32.8M/44.2M [00:01<00:00, 28.1MB/s]
 81%|████████  | 35.8M/44.2M [00:02<00:00, 28.4MB/s]
 87%|████████▋ | 38.6M/44.2M [00:02<00:00, 28.4MB/s]
 94%|█████████▍| 41.6M/44.2M [00:02<00:00, 28.7MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 20.4MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
==================================================================================== 1 failed in 476.59s (0:07:56) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_mean_average_precision[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f37cb52a4d0>
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f37cb52a4d0>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>]
pred_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], pred_scores = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.7], dtype=float32)>]
gt_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], gt_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]
n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 1 failed, 12 passed in 780.17s (0:13:00) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_solve_pnp_dlt[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f0b77160af0>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f0b77160af0>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = <tf.Tensor: shape=(1, 6, 3), dtype=float64, numpy=
array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])>
img_points = <tf.Tensor: shape=(1, 6, 2), dtype=float64, numpy=
array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
   ...92.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])>
intrinsics = <tf.Tensor: shape=(1, 3, 3), dtype=float64, numpy=
array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]])>, weights = None, svd_eps = 0.001

    def tensorflow_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...utils.helpers import tensorflow__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_inverse_frnt,
        )
        from ..conversions import tensorflow_convert_points_to_homogeneous
        from ..linalg import tensorflow_transform_points
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...utils.misc import tensorflow_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_det_frnt,
        )
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import tensorflow_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import tensorflow_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(
            weights, (tensorflow.Tensor, tensorflow.keras.Variable)
        ):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = tf.float32, tf.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(tensorflow_shape_frnt_(world_points)) != 3
            or tensorflow_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {tensorflow_shape_frnt_(world_points)}."
            )
        if (
            len(tensorflow_shape_frnt_(img_points)) != 3
            or tensorflow_shape_frnt_(img_points)[2] != 2
        ):
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {tensorflow_shape_frnt_(img_points)}."
            )
        if len(tensorflow_shape_frnt_(intrinsics)) != 3 or tensorflow_shape_frnt_(
            intrinsics
        )[1:] != (3, 3):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {tensorflow_shape_frnt_(intrinsics)}."
            )
        if tensorflow_shape_frnt_(world_points)[1] != tensorflow_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            tensorflow_shape_frnt_(world_points)[0] != tensorflow_shape_frnt_(img_points)[0]
            or tensorflow_shape_frnt_(world_points)[0]
            != tensorflow_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if tensorflow_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {tensorflow_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            tensorflow_shape_frnt_(world_points)[:2][0],
            tensorflow_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = (
            tensorflow__mean_isotropic_scale_normalize(world_points)
        )
        s = tensorflow__torch_linalg_svdvals(world_points_norm)
        if tensorflow_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = tensorflow_inverse_frnt(intrinsics)
        world_points_norm_h = tensorflow_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = tensorflow_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = tensorflow__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = tensorflow_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = tensorflow_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = tensorflow_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = tensorflow_eye_like(4, solution)
        solution_4x4 = tensorflow_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = tensorflow_bmm_frnt(solution_4x4, world_transform_norm)
        solution = tensorflow_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = tensorflow_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = tensorflow_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/calibration/pnp.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': <tf.Tensor: shape=(1, 3), dtype=float64, numpy=array([[-0.02017229,  0.02388222,  0.0574928 ]])>, 'p': 2}
tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f0b04e3e440>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:195: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[tensorflow-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 392.32s (0:06:32) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 1973.02s (0:32:53) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF..F...F..                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_diamond_square[tensorflow-s2s-False] _______________________________________________________________________________

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}, arg = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def rep_method(*args, **kwargs):
        for arg in args:
            if ivy.is_ivy_array(arg):
                return NotImplemented
>       return func(*args, **kwargs)

../ivy/ivy/functional/backends/tensorflow/__init__.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays_and_dtypes = [<class 'numpy.float32'>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])]

    def _result_type(*arrays_and_dtypes):
      """Returns the resulting type given a set of arrays."""
    
      def preprocess_float(x):
        if is_prefer_float32():
          if isinstance(x, float):
            return np.float32(x)
          elif isinstance(x, complex):
            return np.complex64(x)
        return x
    
      arrays_and_dtypes = [preprocess_float(x) for x in arrays_and_dtypes]
>     dtype = np.result_type(*arrays_and_dtypes)
E     TypeError: Cannot interpret 'tensor([[[[0.3333, 1.0000, 0.3333],
E               [1.0000, 0.3333, 1.0000],
E               [0.3333, 1.0000, 0.3333]]]])' as a data type

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_dtypes.py:190: TypeError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f308bc512d0>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f30a3fe48c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f30a3fe48c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f308bc512d0>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f30a3fe48c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f30a3fe48c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[0.5]]]], dtype=float32)>
random_scale = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, random_fn = <built-in method ones of type object at 0x7f30a3fe48c0>, normalize_range = (0.0, 1.0)
device = None, dtype = None

    def tensorflow_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=tensorflow_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ..core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..enhance.normalize import tensorflow_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
    
        tensorflow_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (tensorflow.Tensor, tensorflow.keras.Variable)):
            random_scale = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[random_scale]]]]), device, dtype
            )
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            tensorflow_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = tensorflow_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = tensorflow_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (tensorflow.Tensor, tensorflow.keras.Variable)):
            roughness = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[roughness]]]]), device, dtype
            )
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = tensorflow_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0], output_size[1], 1, 1]
            )
            roughness = tensorflow_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * tensorflow__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/diamond_square.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
_______________________________________________________________________________ test_EdgeDetector[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
>       transpiled_detector = transpiled_kornia.contrib.EdgeDetector()

kornia/test_contrib.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_EdgeDetector()

    def __init__(self):
        from ..filters.dexined import tensorflow_DexiNed
    
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.model = tensorflow_DexiNed(pretrained=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/edge_detection.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
args = (), kwargs = {'pretrained': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
pretrained = True

    @tensorflow_store_config_info
    def __init__(self, pretrained):
        from ...torch.nn.modules.pooling import tensorflow_MaxPool2d
    
        self.super___init__(
            pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.block_1 = tensorflow_DoubleConvBlock(3, 32, 64, stride=2)
        self.block_2 = tensorflow_DoubleConvBlock(64, 128, use_act=False)
        self.dblock_3 = tensorflow__DenseBlock(2, 128, 256)
        self.dblock_4 = tensorflow__DenseBlock(3, 256, 512)
        self.dblock_5 = tensorflow__DenseBlock(3, 512, 512)
        self.dblock_6 = tensorflow__DenseBlock(3, 512, 256)
        self.maxpool = tensorflow_MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.side_1 = tensorflow_SingleConvBlock(64, 128, 2)
        self.side_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.side_3 = tensorflow_SingleConvBlock(256, 512, 2)
        self.side_4 = tensorflow_SingleConvBlock(512, 512, 1)
        self.side_5 = tensorflow_SingleConvBlock(512, 256, 1)
        self.pre_dense_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.pre_dense_3 = tensorflow_SingleConvBlock(128, 256, 1)
        self.pre_dense_4 = tensorflow_SingleConvBlock(256, 512, 1)
        self.pre_dense_5 = tensorflow_SingleConvBlock(512, 512, 1)
        self.pre_dense_6 = tensorflow_SingleConvBlock(512, 256, 1)
        self.up_block_1 = tensorflow_UpConvBlock(64, 1)
        self.up_block_2 = tensorflow_UpConvBlock(128, 1)
        self.up_block_3 = tensorflow_UpConvBlock(256, 2)
        self.up_block_4 = tensorflow_UpConvBlock(512, 3)
        self.up_block_5 = tensorflow_UpConvBlock(512, 4)
        self.up_block_6 = tensorflow_UpConvBlock(256, 4)
        self.block_cat = tensorflow_SingleConvBlock(6, 1, stride=1, use_bs=False)
        if pretrained:
>           self.load_from_file(url)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
path_file = 'http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth'

    def load_from_file(self, path_file):
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        pretrained_dict = tensorflow_load_state_dict_from_url_frnt(
            path_file, map_location=tensorflow_map_location_to_cpu
        )
>       self.load_state_dict(pretrained_dict, strict=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:613: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
strict = True, assign = False

    def load_state_dict(
        self,
        state_dict: typing.Mapping[str, Any],
        strict: bool = True,
        assign: bool = False,
    ):
        r"""Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.
    
        If :attr:`strict` is ``True``, then
        the keys of :attr:`state_dict` must exactly match the keys returned
        by this module's :meth:`~Module.state_dict` function.
    
        Args:
            state_dict (dict): a dict containing parameters and
                persistent buffers.
            strict (bool, optional): whether to strictly enforce that the keys
                in :attr:`state_dict` match the keys returned by this module's
                :meth:`~Module.state_dict` function. Default: ``True``
    
        Returns:
            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:
                * **missing_keys** is a list of str containing any keys that are expected
                    by this module but missing from the provided ``state_dict``.
                * **unexpected_keys** is a list of str containing the keys that are not
                    expected by this module but present in the provided ``state_dict``.
        """
        if not isinstance(state_dict, typing.Mapping):
            raise TypeError(
                f"Expected state_dict to be dict-like, got {type(state_dict)}."
            )
    
        missing_keys: List[str] = []
        unexpected_keys: List[str] = []
        error_msgs: List[str] = []
    
        state_dict = tf.nest.map_structure(
            lambda x: tf.convert_to_tensor(x.numpy()),
            state_dict,
        )
        state_dict = OrderedDict(state_dict)
    
        def load(module, local_state_dict, prefix=""):
            module._load_from_state_dict(
                local_state_dict,
                prefix,
                strict,
                missing_keys,
                unexpected_keys,
                error_msgs,
            )
            # TODO: maybe we should implement this similar to PT
            # and make this recursive.
    
>       load(self, state_dict)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
local_state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = ''

    def load(module, local_state_dict, prefix=""):
>       module._load_from_state_dict(
            local_state_dict,
            prefix,
            strict,
            missing_keys,
            unexpected_keys,
            error_msgs,
        )

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:589: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = '', strict = True, missing_keys = [], unexpected_keys = [], error_msgs = []

    def _load_from_state_dict(
        self, state_dict, prefix, strict, missing_keys, unexpected_keys, error_msgs
    ):
        def _retrive_layer(model, key):
            if len(key.split(".")) == 1:
                return model, key
    
            module_path, weight_name = key.rsplit(".", 1)
    
            # Retrieve the layer using the module path
            layer = model
            for attr in module_path.split("."):
                layer = getattr(layer, attr)
    
            return layer, weight_name
    
        persistent_buffers = {k: v for k, v in self._buffers.items()}
        local_name_params = itertools.chain(
            self._parameters.items(), persistent_buffers.items()
        )
        local_state = {k: v for k, v in local_name_params if v is not None}
    
        for name, param in local_state.items():
            key = prefix + name
            if key in state_dict:
                input_param = state_dict[key]
                if not isinstance(input_param, tf.Tensor):
                    error_msgs.append(
                        f'While copying the parameter named "{key}", '
                        "expected ArrayLike object from checkpoint but "
                        f"received {type(input_param)}"
                    )
                    continue
    
                if not isinstance(input_param, KerasVariable):
>                   input_param = KerasVariable(input_param)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:522: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_87>, initializer = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, shape = None, dtype = 'float32', trainable = True
autocast = True, aggregation = 'mean', name = 'variable_87'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_87>, value = <tf.Tensor: shape=(), dtype=int64, numpy=79200>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(), dtype=int64, numpy=79200>), kwargs = {'dtype': 'float32', 'name': 'variable_87', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtype=int64, numpy=79200>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<05:43, 410kB/s]
  0%|          | 256k/135M [00:00<03:29, 672kB/s]
  0%|          | 512k/135M [00:00<01:53, 1.23MB/s]
  1%|          | 896k/135M [00:00<01:10, 2.00MB/s]
  1%|▏         | 1.75M/135M [00:00<00:34, 4.03MB/s]
  3%|▎         | 3.50M/135M [00:00<00:17, 8.04MB/s]
  5%|▍         | 6.50M/135M [00:00<00:09, 14.5MB/s]
  7%|▋         | 9.38M/135M [00:01<00:07, 18.7MB/s]
  9%|▉         | 12.4M/135M [00:01<00:05, 21.9MB/s]
 11%|█▏        | 15.4M/135M [00:01<00:05, 24.0MB/s]
 14%|█▎        | 18.2M/135M [00:01<00:04, 25.6MB/s]
 16%|█▌        | 21.2M/135M [00:01<00:04, 26.4MB/s]
 18%|█▊        | 23.9M/135M [00:01<00:04, 26.5MB/s]
 20%|█▉        | 26.6M/135M [00:01<00:04, 26.6MB/s]
 22%|██▏       | 29.6M/135M [00:01<00:04, 27.4MB/s]
 24%|██▍       | 32.4M/135M [00:01<00:03, 27.2MB/s]
 26%|██▌       | 35.2M/135M [00:02<00:03, 27.5MB/s]
 28%|██▊       | 38.2M/135M [00:02<00:03, 27.7MB/s]
 31%|███       | 41.1M/135M [00:02<00:03, 27.7MB/s]
 33%|███▎      | 44.1M/135M [00:02<00:03, 28.2MB/s]
 35%|███▍      | 47.0M/135M [00:02<00:03, 28.3MB/s]
 37%|███▋      | 50.0M/135M [00:02<00:03, 28.6MB/s]
 39%|███▉      | 53.0M/135M [00:02<00:02, 28.5MB/s]
 42%|████▏     | 56.0M/135M [00:02<00:02, 28.8MB/s]
 44%|████▍     | 59.0M/135M [00:02<00:02, 28.6MB/s]
 46%|████▌     | 62.0M/135M [00:03<00:02, 28.8MB/s]
 48%|████▊     | 65.0M/135M [00:03<00:02, 29.0MB/s]
 50%|█████     | 67.9M/135M [00:03<00:02, 28.7MB/s]
 52%|█████▏    | 70.6M/135M [00:03<00:02, 28.2MB/s]
 55%|█████▍    | 73.6M/135M [00:03<00:02, 28.6MB/s]
 57%|█████▋    | 76.6M/135M [00:03<00:02, 28.8MB/s]
 59%|█████▉    | 79.5M/135M [00:03<00:02, 28.7MB/s]
 61%|██████▏   | 82.5M/135M [00:03<00:01, 28.8MB/s]
 63%|██████▎   | 85.4M/135M [00:03<00:01, 28.5MB/s]
 66%|██████▌   | 88.4M/135M [00:03<00:01, 28.7MB/s]
 68%|██████▊   | 91.1M/135M [00:04<00:01, 28.2MB/s]
 70%|██████▉   | 93.9M/135M [00:04<00:01, 27.9MB/s]
 72%|███████▏  | 96.6M/135M [00:04<00:01, 27.6MB/s]
 74%|███████▍  | 99.5M/135M [00:04<00:01, 27.8MB/s]
 76%|███████▌  | 102M/135M [00:04<00:01, 28.3MB/s] 
 78%|███████▊  | 105M/135M [00:04<00:01, 28.3MB/s]
 80%|████████  | 108M/135M [00:04<00:00, 27.9MB/s]
 83%|████████▎ | 111M/135M [00:04<00:00, 28.0MB/s]
 85%|████████▍ | 114M/135M [00:04<00:00, 28.3MB/s]
 87%|████████▋ | 117M/135M [00:05<00:00, 28.2MB/s]
 89%|████████▉ | 120M/135M [00:05<00:00, 28.2MB/s]
 91%|█████████ | 123M/135M [00:05<00:00, 28.6MB/s]
 93%|█████████▎| 126M/135M [00:05<00:00, 28.8MB/s]
 96%|█████████▌| 129M/135M [00:05<00:00, 29.0MB/s]
 98%|█████████▊| 132M/135M [00:05<00:00, 29.1MB/s]
100%|██████████| 135M/135M [00:05<00:00, 25.1MB/s]
__________________________________________________________________________________ test_KMeans[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KMeans(target_framework, mode, backend_compile):
        print("kornia.contrib.KMeans")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_kmeans = kornia.contrib.KMeans(3, None, 10e-4, 100, 0)
        transpiled_kmeans = transpiled_kornia.contrib.KMeans(3, None, 10e-4, 100, 0)
    
        torch_x1 = torch.rand((1000, 5))
        torch_x2 = torch.rand((10, 5))
        transpiled_x1 = _array_to_new_backend(torch_x1, target_framework)
        transpiled_x2 = _array_to_new_backend(torch_x2, target_framework)
    
        torch_kmeans.fit(torch_x1)
        torch_predictions = torch_kmeans.predict(torch_x2)
    
>       transpiled_kmeans.fit(transpiled_x1)

kornia/test_contrib.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.contrib.kmeans.tensorflow_KMeans object at 0x7f303796bf10>
X = <tf.Tensor: shape=(1000, 5), dtype=float32, numpy=
array([[0.4962566 , 0.7682218 , 0.08847743, 0.13203049, 0.30742282]...5, 0.49248123, 0.4287302 ],
       [0.3786084 , 0.04217941, 0.28761953, 0.5166052 , 0.11317676]],
      dtype=float32)>

    def fit(self, X):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ..core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_argmin_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_nonzero_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_index_select_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import tensorflow_sqrt_frnt
    
        tensorflow_KORNIA_CHECK_SHAPE(X, ["N", "D"])
        if self._cluster_centers is None:
            self._cluster_centers = self._initialise_cluster_centers(
                X, self.num_clusters
            )
        else:
            tensorflow_KORNIA_CHECK(
                tensorflow_shape_frnt_(X)[1]
                == tensorflow_shape_frnt_(self._cluster_centers)[1],
                f"Dimensions at position 1 of X and cluster_centers do not match.                 {tensorflow_shape_frnt_(X)[1]} != {tensorflow_shape_frnt_(self._cluster_centers)[1]}",
            )
        current_centers = self._cluster_centers
        previous_centers: typing.Any = None
        iteration: typing.Any = 0
        while True:
            distance: typing.Any = self._pairwise_euclidean_distance(X, current_centers)
            cluster_assignment = tensorflow_argmin_frnt_(distance, -1)
            previous_centers = tensorflow_clone_frnt_(current_centers)
            for index in range(self.num_clusters):
                selected = tensorflow_squeeze_frnt_(
                    tensorflow_nonzero_frnt(cluster_assignment == index)
                )
                selected = tensorflow_index_select_frnt(X, 0, selected)
                if tensorflow_shape_frnt_(selected)[0] == 0:
                    selected = X[tensorflow_randint_frnt(len(X), (1,), device=X.device)]
>               current_centers[index] = tensorflow_mean_frnt_(selected, dim=0)
E               TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/kmeans.py:149: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.KMeans
_______________________________________________________________________________ test_ImageStitcher[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = transpiled_kornia.feature.LoFTR(pretrained='outdoor')

kornia/test_contrib.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .backbone.__init__ import tensorflow_build_backbone
        from .utils.position_encoding import tensorflow_PositionEncodingSine
        from .loftr_module.transformer import tensorflow_LocalFeatureTransformer
        from .utils.coarse_matching import tensorflow_CoarseMatching
        from .loftr_module.fine_preprocess import tensorflow_FinePreprocess
        from .utils.fine_matching import tensorflow_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = tensorflow_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = tensorflow_build_backbone(config)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/loftr.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def tensorflow_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/backbone/__init__.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:53, 407kB/s]
  1%|          | 256k/44.2M [00:00<01:08, 671kB/s]
  1%|          | 512k/44.2M [00:00<00:37, 1.23MB/s]
  2%|▏         | 896k/44.2M [00:00<00:22, 1.99MB/s]
  4%|▎         | 1.62M/44.2M [00:00<00:12, 3.64MB/s]
  7%|▋         | 3.12M/44.2M [00:00<00:06, 7.04MB/s]
 14%|█▍        | 6.12M/44.2M [00:00<00:02, 13.8MB/s]
 20%|██        | 9.00M/44.2M [00:01<00:02, 18.1MB/s]
 27%|██▋       | 12.0M/44.2M [00:01<00:01, 21.5MB/s]
 34%|███▍      | 15.0M/44.2M [00:01<00:01, 23.8MB/s]
 40%|████      | 17.9M/44.2M [00:01<00:01, 25.2MB/s]
 47%|████▋     | 20.6M/44.2M [00:01<00:00, 25.7MB/s]
 53%|█████▎    | 23.5M/44.2M [00:01<00:00, 26.4MB/s]
 60%|█████▉    | 26.5M/44.2M [00:01<00:00, 27.3MB/s]
 67%|██████▋   | 29.5M/44.2M [00:01<00:00, 27.9MB/s]
 74%|███████▎  | 32.5M/44.2M [00:01<00:00, 28.3MB/s]
 80%|████████  | 35.5M/44.2M [00:02<00:00, 28.6MB/s]
 87%|████████▋ | 38.4M/44.2M [00:02<00:00, 28.6MB/s]
 93%|█████████▎| 41.2M/44.2M [00:02<00:00, 28.5MB/s]
100%|█████████▉| 44.1M/44.2M [00:02<00:00, 28.1MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 19.6MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[tensorflow-s2s-False] - KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
FAILED kornia/test_contrib.py::test_EdgeDetector[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtyp...
FAILED kornia/test_contrib.py::test_KMeans[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/test_contrib.py::test_ImageStitcher[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
============================================================================== 4 failed, 11 passed in 1586.35s (0:26:26) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3518.19s (0:58:38) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 582.37s (0:09:42) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F....................F...........F........F..F                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_rgb_to_hls[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7feec127c040>
trace_args = (tensor([[[[0.8493, 0.8295, 0.7528, 0.6232, 0.7986],
          [0.7259, 0.1969, 0.2656, 0.2055, 0.3967],
          [0.... [0.5627, 0.1750, 0.0442, 0.3268, 0.0354],
          [0.2043, 0.6470, 0.1159, 0.2744, 0.5001]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.7361, 0.9638, 0.9503, 0.2020, 0.5746],
          [0.6328, 0.6993, 0.3311, 0.6977, 0.0157],
          [0.... [0.8454, 0.4145, 0.2051, 0.1054, 0.9467],
          [0.0732, 0.2929, 0.9351, 0.4051, 0.8245]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7feec127c040>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.8493, 0.8295, 0.7528, 0.6232, 0.7986],
          [0.7259, 0.1969, 0.2656, 0.2055, 0.3967],
          [0.... [0.5627, 0.1750, 0.0442, 0.3268, 0.0354],
          [0.2043, 0.6470, 0.1159, 0.2744, 0.5001]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.7361, 0.9638, 0.9503, 0.2020, 0.5746],
          [0.6328, 0.6993, 0.3311, 0.6977, 0.0157],
          [0.... [0.8454, 0.4145, 0.2051, 0.1054, 0.9467],
          [0.0732, 0.2929, 0.9351, 0.4051, 0.8245]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.1145, 4.7495, 5.8457, 1.4126, 0.1316],
          [0.6820, 2.4699, 3.9923, 3.6012, 2.7207],
          [3.5....5417, 0.8335, 0.5747, 0.9035],
          [0.8936, 0.2323, 0.4066, 0.8962, 0.4410]]]],
       grad_fn=<StackBackward0>)
transpiled_x = Array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.11451283, 4.7495136 , 5.845715  , 1.4125792 , 0.13164745],
         [0.68198776, 2.469882  , 3.9922745 , 3...0.57471234, 0.9034997 ],
         [0.8936062 , 0.23227207, 0.40661153, 0.8961927 , 0.44099268]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
__________________________________________________________________________________ test_rgb_to_yuv420[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7feec127dd80>
trace_args = (tensor([[[[0.7996, 0.4757, 0.2102, 0.2632, 0.7507, 0.1431],
          [0.5510, 0.6021, 0.1719, 0.6948, 0.3820, 0.5908...     [0.7990, 0.3099, 0.8602, 0.6039, 0.8414, 0.4405],
          [0.3195, 0.2110, 0.5688, 0.6136, 0.9255, 0.6999]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.2334, 0.8578, 0.2458, 0.8872, 0.4034, 0.7078],
          [0.6992, 0.5636, 0.9971, 0.3042, 0.2244, 0.7320...     [0.1648, 0.8555, 0.7901, 0.8989, 0.8666, 0.8922],
          [0.1384, 0.0813, 0.1079, 0.5464, 0.9366, 0.4062]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7feec127dd80>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.7996, 0.4757, 0.2102, 0.2632, 0.7507, 0.1431],
          [0.5510, 0.6021, 0.1719, 0.6948, 0.3820, 0.5908...     [0.7990, 0.3099, 0.8602, 0.6039, 0.8414, 0.4405],
          [0.3195, 0.2110, 0.5688, 0.6136, 0.9255, 0.6999]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.2334, 0.8578, 0.2458, 0.8872, 0.4034, 0.7078],
          [0.6992, 0.5636, 0.9971, 0.3042, 0.2244, 0.7320...     [0.1648, 0.8555, 0.7901, 0.8989, 0.8666, 0.8922],
          [0.1384, 0.0813, 0.1079, 0.5464, 0.9366, 0.4062]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.3998, 0.6909, 0.3347, 0.3145, 0.4469, 0.4255],
          [0.6207, 0.6819, 0.2358, 0.4976, 0.3521, 0.6010...       [-0.0122,  0.0127,  0.1076]],

         [[ 0.0077, -0.0093,  0.0090],
          [-0.0134,  0.1602,  0.1435]]]]))
transpiled_x = (Array([[[[0.3998209 , 0.6908557 , 0.33470356, 0.31447002, 0.44690296,
          0.42551002],
         [0.6207136 , 0....
        [[ 0.10090959,  0.01725892,  0.07135399],
         [-0.03244063,  0.08141884,  0.05919267]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.3998209 , 0.6908557 , 0.33470356, 0.31447002, 0.44690296,
          0.42551002],
         [0.6207136 , 0....
        [[ 0.00770017, -0.00930491,  0.0089984 ],
         [-0.01341336,  0.16021074,  0.14350234]]]], dtype=float32))
y = (array([[[[0.3998209 , 0.6908557 , 0.33470356, 0.31447002, 0.44690296,
          0.42551002],
         [0.6207136 , 0....
        [[ 0.10090959,  0.01725892,  0.07135399],
         [-0.03244063,  0.08141884,  0.05919267]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fee221b2f00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.0020344 ,  0.03979053,  0.01987968],
         [-0.01217067,  0.01267601,  0.1076145 ]],

        [[ 0.00770017, -0.00930491,  0.0089984 ],
         [-0.01341336,  0.16021074,  0.14350234]]]], dtype=float32)
y = array([[[[ 0.09435085, -0.06341284,  0.0740568 ],
         [-0.02025568,  0.12091069, -0.03989416]],

        [[ 0.10090959,  0.01725892,  0.07135399],
         [-0.03244063,  0.08141884,  0.05919267]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
_____________________________________________________________________________________ test_RgbToHls[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:908: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>
args = (tensor([[[[0.9075, 0.0828, 0.1653, 0.1684, 0.2959],
          [0.2720, 0.6921, 0.0316, 0.8920, 0.6668],
          [0...., 0.9551],
          [0.6751, 0.8404, 0.3824, 0.7332, 0.4084],
          [0.6324, 0.4523, 0.9696, 0.0257, 0.6794]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.461225  , 3.92106   , 2.9460151 , 3.5073647 , 4.366957  ],
         [4.1108546 , 4.7837443 , 2.6769888 , 5...0.858544  , 0.5960891 ],
         [0.74524975, 0.5175797 , 0.92262155, 0.9286813 , 0.7175099 ]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
___________________________________________________________________________________ test_RgbToYuv420[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1064: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>
args = (tensor([[[[0.6545, 0.9651, 0.9242, 0.5432, 0.5864, 0.5304],
          [0.1634, 0.7406, 0.9970, 0.5278, 0.7193, 0.1080...     [0.1269, 0.7158, 0.9037, 0.8197, 0.0586, 0.1456],
          [0.4807, 0.1667, 0.9340, 0.7710, 0.2522, 0.9506]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.7851937 , 0.47736126, 0.4192244 , 0.365865  , 0.2966674 ,
          0.36719772],
         [0.4787386 , 0....
        [[ 0.05927077, -0.1847139 ,  0.17519766],
         [ 0.01677487,  0.06942178, -0.05829566]]]], dtype=float32))
y = (array([[[[0.7851937 , 0.47736126, 0.4192244 , 0.365865  , 0.2966674 ,
          0.36719772],
         [0.4787386 , 0....
        [[-0.08838069,  0.143509  , -0.12946498],
         [ 0.12773985,  0.03159142, -0.00733909]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7fee21bf5cc0>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.02105265,  0.04243991, -0.0046603 ],
         [-0.0365293 , -0.08463822,  0.06861193]],

        [[ 0.051...

        [[ 0.05927077, -0.1847139 ,  0.17519766],
         [ 0.01677487,  0.06942178, -0.05829566]]]], dtype=float32)
y = array([[[[-0.13893522,  0.02844231,  0.04705425],
         [-0.00667404,  0.02696122,  0.04942816]],

        [[-0.038...

        [[-0.08838069,  0.143509  , -0.12946498],
         [ 0.12773985,  0.03159142, -0.00733909]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
______________________________________________________________________________________ test_Sepia[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Sepia(target_framework, mode, backend_compile):
        args = (
            torch.ones(3, 1, 1),
        )
>       _test_color_class(
            kornia.color.Sepia,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1198: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.sepia.Sepia'>, args = (tensor([[[1.]],

        [[1.]],

        [[1.]]]),), target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
>       transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)

kornia/test_color.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'

<string>:1: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.sepia.Sepia
__________________________________________________________________________________ test_apply_colormap[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_apply_colormap(target_framework, mode, backend_compile):
        print("kornia.color.ColorMap")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledColorMapType = ivy.transpile(kornia.color.ColorMapType, source="torch", target=target_framework)
        TranspiledColorMap = ivy.transpile(kornia.color.ColorMap, source="torch", target=target_framework)
        transpiled_apply_colormap = ivy.transpile(kornia.color.apply_colormap, source="torch", target=target_framework)
    
        torch_x = torch.tensor([[[0, 1, 2], [15, 25, 33], [128, 158, 188]]])
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        colormap = kornia.color.ColorMap(base=kornia.color.ColorMapType.autumn)
        torch_out = kornia.color.apply_colormap(torch_x, colormap)
    
>       colormap = TranspiledColorMap(base=TranspiledColorMapType.autumn)

kornia/test_color.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.color.colormap.jax_ColorMap object at 0x7fee1a189960>, base = <jax_ColorMapType.autumn: 1>, num_colors = 64, device = None, dtype = None

>   ???

ivy_transpiled_outputs/jax_outputs/kornia/color/colormap.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jax_ColorMapType.autumn: 1>

        f"`input_tensor` must be a Tensor. Got: {type(input_tensor)}",
    )
>   valid_types = [
        jnp.float16,
        jnp.float32,
        jnp.float64,
        jnp.uint8,
        jnp.int32,
        jnp.int64,
        jnp.int16,
    ]
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.color._colormap_data'

ivy_transpiled_outputs/jax_outputs/kornia/color/colormap.py:53: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.ColorMap
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToHls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_Sepia[jax-s2s-False] - AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'
FAILED kornia/test_color.py::test_apply_colormap[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.color._colormap_data'
============================================================================== 6 failed, 63 passed in 3965.14s (1:06:05) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ....F....F...FFFFF........sssssssssssss                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_adjust_gamma[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_adjust_gamma(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 2, 2),
            2.2,
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 1, 2, 2),
            0.4,
        )
        test_kwargs = {}
>       _test_function(
            kornia.enhance.adjust_gamma,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f62133bd120>, trace_args = (tensor([[[[0.1329, 0.6867],
          [0.5390, 0.4213]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.8655, 0.9341],
          [0.3926, 0.5704]]],


        [[[0.1702, 0.3235],
          [0.1015, 0.2150]]],...   [[[0.0516, 0.0595],
          [0.7966, 0.7115]]],


        [[[0.9339, 0.9285],
          [0.1794, 0.3860]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f62133bd120>, fn_name = 'kornia.enhance.adjust_gamma', trace_args = (tensor([[[[0.1329, 0.6867],
          [0.5390, 0.4213]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.8655, 0.9341],
          [0.3926, 0.5704]]],


        [[[0.1702, 0.3235],
          [0.1015, 0.2150]]],...   [[[0.0516, 0.0595],
          [0.7966, 0.7115]]],


        [[[0.9339, 0.9285],
          [0.1794, 0.3860]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.13286757, 0.6867021 ],
         [0.53900766, 0.42133266]]]], dtype=float32), gamma = 2.2, gain = 1.0

    def numpy_adjust_gamma(input, gamma, gain=1.0):
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_any_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_unsqueeze_frnt,
        )
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_pow_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_clamp_frnt
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(gamma, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gamma should be a positive float or Tensor. Got {type(gamma)}"
            )
        if not isinstance(gain, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gain should be a positive float or Tensor. Got {type(gain)}"
            )
        if isinstance(gamma, (float,)):
>           gamma = numpy.ndarray([gamma])
E           TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:52: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.adjust_gamma
_____________________________________________________________________________________ test_invert[numpy-s2s-False] _____________________________________________________________________________________

>   ???

VM.pyx:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Copyright (c) 2024 Transpile AI Ltd. All rights reserved.
    
    This file is automatically generated by Transpile AI Ltd.'s software.
    
    License: Non-Enterprise Use Only
    
    This software is licensed for personal, educational, or non-commercial use only.
    Non-commercial use includes personal projects, educational purposes, or other activities
    that do not generate revenue or are not used in any business, organization, or institution.
    Commercial, production, or enterprise use—including any use in a for-profit business environment, within an organization,
    or in a revenue-generating activity—is strictly prohibited without a valid enterprise contract with Transpile AI Ltd.
    Unauthorized enterprise use may result in legal action, including but not limited to injunctions, damages, and financial penalties.
    
    To obtain an enterprise license, please visit https://ivy.dev/ or contact enterprise@ivy.dev.
    
    Redistribution: You may not distribute, sublicense, or sell copies of the generated source code or
    any derivative works thereof without express written permission from Transpile AI Ltd.
    
    Termination: This license automatically terminates upon failure to comply with any of its terms and conditions.
    Upon termination, you must immediately cease all use of the software and destroy any copies in your possession.
    
    Disclaimer: This software is provided "AS IS", WITHOUT WARRANTY OF ANY KIND, either express or implied.
    Transpile AI Ltd. disclaims all liability for damages or liabilities arising from the use of this software, to the fullest extent permitted by law.
    """
    
    import numpy
    
    
>   def numpy_invert(image, max_val=numpy.ndarray([1.0])):
E   TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:30: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_invert(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 1, 2, 2),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 1, 2, 2),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.invert,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f62133bdc60>, trace_args = (tensor([[[[0.2452, 0.1481],
          [0.3088, 0.5695]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.8231, 0.6504],
          [0.3628, 0.9833]]],


        [[[0.1161, 0.1084],
          [0.9903, 0.0344]]],...       [[[0.6532, 0.3936],
          [0.2428, 0.3291]]],


        [[[0.7194, 0.0749],
          [0.7501, 0.5474]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f62133bdc60>, fn_name = 'kornia.enhance.invert', trace_args = (tensor([[[[0.2452, 0.1481],
          [0.3088, 0.5695]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.8231, 0.6504],
          [0.3628, 0.9833]]],


        [[[0.1161, 0.1084],
          [0.9903, 0.0344]]],...       [[[0.6532, 0.3936],
          [0.2428, 0.3291]]],


        [[[0.7194, 0.0749],
          [0.7501, 0.5474]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ImportError: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as an integer

VM.pyx:246: ImportError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.invert
____________________________________________________________________________________ test_equalize[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f62133bdab0>
trace_args = (tensor([[[[0.8077, 0.6651, 0.8761],
          [0.8896, 0.6361, 0.1334],
          [0.8774, 0.9065, 0.9515]],

         [[0.3136, 0.6011, 0.9691],
          [0.5115, 0.9961, 0.3586],
          [0.2486, 0.2166, 0.1198]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.3393, 0.6682, 0.9386],
          [0.1334, 0.3218, 0.4267],
          [0.1092, 0.5946, 0.0519]],

       ...99]],

         [[0.6415, 0.7467, 0.8899],
          [0.7082, 0.5459, 0.3306],
          [0.9005, 0.9192, 0.6193]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f62133bdab0>, fn_name = 'kornia.enhance.equalize'
trace_args = (tensor([[[[0.8077, 0.6651, 0.8761],
          [0.8896, 0.6361, 0.1334],
          [0.8774, 0.9065, 0.9515]],

         [[0.3136, 0.6011, 0.9691],
          [0.5115, 0.9961, 0.3586],
          [0.2486, 0.2166, 0.1198]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.3393, 0.6682, 0.9386],
          [0.1334, 0.3218, 0.4267],
          [0.1092, 0.5946, 0.0519]],

       ...99]],

         [[0.6415, 0.7467, 0.8899],
          [0.7082, 0.5459, 0.3306],
          [0.9005, 0.9192, 0.6193]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.8076565 , 0.66509205, 0.87614465],
         [0.88961834, 0.6361409 , 0.13344151],
         [0.8773933 , 0....09636],
         [0.5115094 , 0.99611473, 0.3586334 ],
         [0.24863851, 0.21655619, 0.1198383 ]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f61b9c0a200>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f61ba9c7640>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f61b9fdd360>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.8076565 , 0.66509205, 0.87614465],
         [0.88961834, 0.6361409 , 0.13344151],
         [0.8773933 , 0....09636],
         [0.5115094 , 0.99611473, 0.3586334 ],
         [0.24863851, 0.21655619, 0.1198383 ]]]], dtype=float32)

    @numpy_perform_keep_shape_image
    def numpy_equalize(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for image in input:
            scaled_image = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            image, (i, slice(None, None, None), slice(None, None, None))
                        )
                    )
                    for i in range(len(image))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f61ba0eed90>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    image, (i, slice(None, None, None), slice(None, None, None))
                )
            )
            for i in range(len(image))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[205.95241 , 169.59848 , 223.41689 ],
       [226.85268 , 162.21593 ,  34.027584],
       [223.73529 , 231.15894 , 242.6446  ]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 8.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(8., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize
_________________________________________________________________________________ test_equalize_clahe[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f62133bfa30>
trace_args = (tensor([[[0.0412, 0.5559, 0.8095, 0.6974, 0.3802, 0.4704, 0.6576, 0.8105,
          0.7834, 0.2521, 0.3815, 0.2686, 0...         0.2967, 0.7558, 0.7936, 0.5041, 0.1958, 0.4204, 0.0726, 0.6409,
          0.8094, 0.0080, 0.7479, 0.5099]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.6091, 0.5501, 0.3089,  ..., 0.2852, 0.3354, 0.9509],
          [0.2922, 0.1127, 0.7167,  ..., 0.4685, 0...., 0.3089, 0.5463,  ..., 0.0595, 0.4981, 0.7477],
          [0.0210, 0.1567, 0.1844,  ..., 0.1300, 0.2430, 0.0133]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f62133bfa30>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.0412, 0.5559, 0.8095, 0.6974, 0.3802, 0.4704, 0.6576, 0.8105,
          0.7834, 0.2521, 0.3815, 0.2686, 0...         0.2967, 0.7558, 0.7936, 0.5041, 0.1958, 0.4204, 0.0726, 0.6409,
          0.8094, 0.0080, 0.7479, 0.5099]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.6091, 0.5501, 0.3089,  ..., 0.2852, 0.3354, 0.9509],
          [0.2922, 0.1127, 0.7167,  ..., 0.4685, 0...., 0.3089, 0.5463,  ..., 0.0595, 0.4981, 0.7477],
          [0.0210, 0.1567, 0.1844,  ..., 0.1300, 0.2430, 0.0133]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.04121697, 0.55586743, 0.8094719 , 0.6974346 , 0.38017577,
          0.47044766, 0.6575876 , 0.8104668 , 0.... 0.42036134, 0.07261258,
          0.640898  , 0.8094297 , 0.00795597, 0.7478505 , 0.5098692 ]]]],
      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f61ba00c9d0>
numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f61ba00dab0>, numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f61ba00fbe0>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.04121697, 0.55586743, 0.8094719 , 0.6974346 , 0.38017577,
          0.47044766, 0.6575876 , 0.8104668 , 0.... 0.42036134, 0.07261258,
          0.640898  , 0.8094297 , 0.00795597, 0.7478505 , 0.5098692 ]]]],
      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @numpy_perform_keep_shape_image
    def numpy_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_permute_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = numpy__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:490: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = array([[[[0.04121697, 0.55586743, 0.8094719 , 0.6974346 , 0.38017577,
          0.47044766, 0.6575876 , 0.8104668 , 0.... 0.42036134, 0.07261258,
          0.640898  , 0.8094297 , 0.00795597, 0.7478505 , 0.5098692 ]]]],
      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def numpy__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            numpy_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = numpy_shape_frnt_(batch)[-2:][0], numpy_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > numpy_shape_frnt_(batch)[-2]
            or pad_horz > numpy_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = numpy_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = numpy_shape_frnt_(batch)[-3]
        tiles: typing.Any = numpy_contiguous_frnt_(
            numpy_squeeze_frnt_(
                numpy_unfold_frnt_(
>                   numpy_unfold_frnt_(
                        numpy_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[[[0.04121697, 0.44541305, 0.09751707, 0.45789933, 0.82795674,
           0.20147288, 0.75369555, 0.0479939 ,...       0.7276395 , 0.3343262 , 0.8625039 , 0.24059635, 0.716796  ,
           0.22599769]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f61b9ef9cf0>
array_like = array([[[[[0.04121697, 0.44541305, 0.09751707, 0.45789933, 0.82795674,
           0.20147288, 0.75369555, 0.0479939 , ...755 ,
           0.7276395 , 0.3343262 , 0.8625039 , 0.24059635, 0.716796  ,
           0.22599769]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[[[0.04121697, 0.44541305, 0.09751707, 0.45789933, 0.82795674,
           0.20147288, 0.75369555, 0.0479939 , ...755 ,
           0.7276395 , 0.3343262 , 0.8625039 , 0.24059635, 0.716796  ,
           0.22599769]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @numpy_handle_methods
    def numpy_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.general import numpy_set_item
        from .indexing_slicing_joining_mutating_ops import numpy_stack_frnt
    
        slices = []
        self_shape = tuple(numpy_shape_frnt_(tensor))
        for i in range(0, numpy_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(numpy_shape_frnt_(tensor))
            slicing = numpy_set_item(slicing, dimension, slice(i, i + size))
            slices.append(numpy_get_item(tensor, tuple(slicing)))
>       stacked = numpy_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def numpy_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.numpy.manipulation import numpy_stack
    
>       return numpy_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def numpy_stack(
        arrays: Union[Tuple[np.ndarray], List[np.ndarray]],
        /,
        *,
        axis: int = 0,
        out: Optional[np.ndarray] = None,
    ):
>       return np.stack(arrays, axis, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/backends/numpy/manipulation.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None

    @array_function_dispatch(_stack_dispatcher)
    def stack(arrays, axis=0, out=None, *, dtype=None, casting="same_kind"):
        """
        Join a sequence of arrays along a new axis.
    
        The ``axis`` parameter specifies the index of the new axis in the
        dimensions of the result. For example, if ``axis=0`` it will be the first
        dimension and if ``axis=-1`` it will be the last dimension.
    
        .. versionadded:: 1.10.0
    
        Parameters
        ----------
        arrays : sequence of array_like
            Each array must have the same shape.
    
        axis : int, optional
            The axis in the result array along which the input arrays are stacked.
    
        out : ndarray, optional
            If provided, the destination to place the result. The shape must be
            correct, matching that of what stack would have returned if no
            out argument were specified.
    
        dtype : str or dtype
            If provided, the destination array will have this dtype. Cannot be
            provided together with `out`.
    
            .. versionadded:: 1.24
    
        casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
            Controls what kind of data casting may occur. Defaults to 'same_kind'.
    
            .. versionadded:: 1.24
    
    
        Returns
        -------
        stacked : ndarray
            The stacked array has one more dimension than the input arrays.
    
        See Also
        --------
        concatenate : Join a sequence of arrays along an existing axis.
        block : Assemble an nd-array from nested lists of blocks.
        split : Split array into a list of multiple sub-arrays of equal size.
    
        Examples
        --------
        >>> arrays = [np.random.randn(3, 4) for _ in range(10)]
        >>> np.stack(arrays, axis=0).shape
        (10, 3, 4)
    
        >>> np.stack(arrays, axis=1).shape
        (3, 10, 4)
    
        >>> np.stack(arrays, axis=2).shape
        (3, 4, 10)
    
        >>> a = np.array([1, 2, 3])
        >>> b = np.array([4, 5, 6])
        >>> np.stack((a, b))
        array([[1, 2, 3],
               [4, 5, 6]])
    
        >>> np.stack((a, b), axis=-1)
        array([[1, 4],
               [2, 5],
               [3, 6]])
    
        """
        arrays = [asanyarray(arr) for arr in arrays]
        if not arrays:
>           raise ValueError('need at least one array to stack')
E           ValueError: need at least one array to stack

/opt/fw/mxnet/numpy/core/shape_base.py:445: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_equalize3d[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize3d(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:383: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f62133bdbd0>
trace_args = (tensor([[[[[0.1780, 0.6306, 0.3215],
           [0.8032, 0.0756, 0.6362],
           [0.2848, 0.9899, 0.3638]],

    ...,

          [[0.6477, 0.0497, 0.2843],
           [0.3249, 0.2915, 0.7787],
           [0.2871, 0.6595, 0.2727]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.7046, 0.0451, 0.8109],
           [0.4753, 0.5323, 0.1940],
           [0.2609, 0.3922, 0.3906]],

    ...,

          [[0.2411, 0.7741, 0.4256],
           [0.3726, 0.1322, 0.0148],
           [0.1604, 0.0811, 0.5721]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f62133bdbd0>, fn_name = 'kornia.enhance.equalize3d'
trace_args = (tensor([[[[[0.1780, 0.6306, 0.3215],
           [0.8032, 0.0756, 0.6362],
           [0.2848, 0.9899, 0.3638]],

    ...,

          [[0.6477, 0.0497, 0.2843],
           [0.3249, 0.2915, 0.7787],
           [0.2871, 0.6595, 0.2727]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.7046, 0.0451, 0.8109],
           [0.4753, 0.5323, 0.1940],
           [0.2609, 0.3922, 0.3906]],

    ...,

          [[0.2411, 0.7741, 0.4256],
           [0.3726, 0.1322, 0.0148],
           [0.1604, 0.0811, 0.5721]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.17798191, 0.63059485, 0.32151794],
          [0.8031885 , 0.07555884, 0.6361937 ],
          [0.28484583,...16],
          [0.3249088 , 0.2915467 , 0.77872497],
          [0.28705418, 0.6594866 , 0.27269626]]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f61bc2c27a0>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f61bc2c0700>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f61bc2c0790>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bcdhw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.17798191, 0.63059485, 0.32151794],
          [0.8031885 , 0.07555884, 0.6361937 ],
          [0.28484583,...16],
          [0.3249088 , 0.2915467 , 0.77872497],
          [0.28705418, 0.6594866 , 0.27269626]]]]], dtype=float32)

    @numpy_perform_keep_shape_video
    def numpy_equalize3d(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for volume in input:
            scaled_input = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            volume,
                            (
                                i,
                                slice(None, None, None),
                                slice(None, None, None),
                                slice(None, None, None),
                            ),
                        )
                    )
                    for i in range(len(volume))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f61ba98f900>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    volume,
                    (
                        i,
                        slice(None, None, None),
                        slice(None, None, None),
                        slice(None, None, None),
                    ),
                )
            )
            for i in range(len(volume))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[[ 45.385387, 160.80168 ,  81.987076],
        [204.81306 ,  19.267504, 162.22939 ],
        [ 72.63569 , 252.4...8.313437],
        [ 47.302307,  19.727295, 150.26389 ],
        [190.62868 ,  30.285637, 101.10771 ]]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 26.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(26., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize3d
___________________________________________________________________________________ test_histogram[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f62133bf490>
trace_args = (tensor([[0.6396, 0.9822, 0.6600, 0.6677, 0.3362, 0.8171, 0.7691, 0.6353, 0.6840,
         0.7672]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.1625, 0.4694, 0.0584, 0.1966, 0.6593, 0.9283, 0.8894, 0.6698, 0.6351,
         0.7619],
        [0.1127, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f62133bf490>, fn_name = 'kornia.enhance.histogram'
trace_args = (tensor([[0.6396, 0.9822, 0.6600, 0.6677, 0.3362, 0.8171, 0.7691, 0.6353, 0.6840,
         0.7672]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.1625, 0.4694, 0.0584, 0.1966, 0.6593, 0.9283, 0.8894, 0.6698, 0.6351,
         0.7619],
        [0.1127, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.63962036, 0.982203  , 0.65999913, 0.6676818 , 0.33616126,
        0.8170797 , 0.7690828 , 0.63531965, 0.6840096 , 0.76716954]],
      dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram(x, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       pdf, _ = numpy_marginal_pdf(numpy_unsqueeze_frnt_(x, 2), bins, bandwidth, epsilon)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.63962036],
        [0.982203  ],
        [0.65999913],
        [0.6676818 ],
        [0.33616126],
        [0.8170797 ],
        [0.7690828 ],
        [0.63531965],
        [0.6840096 ],
        [0.76716954]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[   0.7106893 ,   -1.5202819 ,   -3.7512531 , ...,
         -278.1607    , -280.3917    , -282.62265   ],
   ...524106 ,   -1.3785607 ,   -3.6095319 , ...,
         -278.01898   , -280.24997   , -282.48093   ]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f61b9aca680>
array_like = array([[[   0.7106893 ,   -1.5202819 ,   -3.7512531 , ...,
         -278.1607    , -280.3917    , -282.62265   ],
    ... 0.8524106 ,   -1.3785607 ,   -3.6095319 , ...,
         -278.01898   , -280.24997   , -282.48093   ]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[   0.7106893 ,   -1.5202819 ,   -3.7512531 , ...,
         -278.1607    , -280.3917    , -282.62265   ],
    ... 0.8524106 ,   -1.3785607 ,   -3.6095319 , ...,
         -278.01898   , -280.24997   , -282.48093   ]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[   0.7106893 ,   -1.5202819 ,   -3.7512531 , ...,
         -278.1607    , -280.3917    , -282.62265   ],
   ...524106 ,   -1.3785607 ,   -3.6095319 , ...,
         -278.01898   , -280.24997   , -282.48093   ]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f61b9aca680>
array_like = array([[[   0.7106893 ,   -1.5202819 ,   -3.7512531 , ...,
         -278.1607    , -280.3917    , -282.62265   ],
    ... 0.8524106 ,   -1.3785607 ,   -3.6095319 , ...,
         -278.01898   , -280.24997   , -282.48093   ]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[   0.7106893 ,   -1.5202819 ,   -3.7512531 , ...,
         -278.1607    , -280.3917    , -282.62265   ],
    ... 0.8524106 ,   -1.3785607 ,   -3.6095319 , ...,
         -278.01898   , -280.24997   , -282.48093   ]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[   0.7106893 ,   -1.5202819 ,   -3.7512531 , ...,
         -278.1607    , -280.3917    , -282.62265   ],
    ... 0.8524106 ,   -1.3785607 ,   -3.6095319 , ...,
         -278.01898   , -280.24997   , -282.48093   ]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram
__________________________________________________________________________________ test_histogram2d[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 32),
            torch.rand(2, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 32),
            torch.rand(5, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f62133bf5b0>
trace_args = (tensor([[0.9349, 0.6587, 0.2539, 0.1529, 0.3503, 0.1203, 0.5410, 0.2097, 0.0795,
         0.1826, 0.3377, 0.0665, 0.5...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.9399, 0.8684, 0.2678, 0.1787, 0.8283, 0.7051, 0.1243, 0.3986, 0.0570,
         0.0534, 0.6402, 0.1604, 0.7...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f62133bf5b0>, fn_name = 'kornia.enhance.histogram2d'
trace_args = (tensor([[0.9349, 0.6587, 0.2539, 0.1529, 0.3503, 0.1203, 0.5410, 0.2097, 0.0795,
         0.1826, 0.3377, 0.0665, 0.5...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.9399, 0.8684, 0.2678, 0.1787, 0.8283, 0.7051, 0.1243, 0.3986, 0.0570,
         0.0534, 0.6402, 0.1604, 0.7...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[0.93485785, 0.6587341 , 0.2539078 , 0.15287495, 0.35034198,
        0.12030536, 0.54102814, 0.20972002, 0.0794...7,
        0.05803108, 0.20840532, 0.67632455, 0.3488704 , 0.8329949 ,
        0.27472764, 0.01587689]], dtype=float32)
x2 = array([[0.84378904, 0.29980338, 0.01969659, 0.358164  , 0.24925464,
        0.4539861 , 0.2178244 , 0.8082847 , 0.9356...7,
        0.83986527, 0.11705452, 0.1887247 , 0.58286494, 0.2707281 ,
        0.01863641, 0.32898927]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram2d(x1, x2, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       _, kernel_values1 = numpy_marginal_pdf(
            numpy_unsqueeze_frnt_(x1, 2), bins, bandwidth, epsilon
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.93485785],
        [0.6587341 ],
        [0.2539078 ],
        [0.15287495],
        [0.35034198],
        ... [0.67632455],
        [0.3488704 ],
        [0.8329949 ],
        [0.27472764],
        [0.01587689]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 1.0387310e+00, -1.1922402e+00, -3.4232113e+00, ...,
         -2.7783267e+02, -2.8006363e+02, -2.8229462e+02...02, -2.2133303e+00, -4.4443016e+00, ...,
         -2.7885376e+02, -2.8108472e+02, -2.8331570e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f61badbd750>
array_like = array([[[ 1.0387310e+00, -1.1922402e+00, -3.4232113e+00, ...,
         -2.7783267e+02, -2.8006363e+02, -2.8229462e+02]...89e-02, -2.2133303e+00, -4.4443016e+00, ...,
         -2.7885376e+02, -2.8108472e+02, -2.8331570e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 1.0387310e+00, -1.1922402e+00, -3.4232113e+00, ...,
         -2.7783267e+02, -2.8006363e+02, -2.8229462e+02]...89e-02, -2.2133303e+00, -4.4443016e+00, ...,
         -2.7885376e+02, -2.8108472e+02, -2.8331570e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 1.0387310e+00, -1.1922402e+00, -3.4232113e+00, ...,
         -2.7783267e+02, -2.8006363e+02, -2.8229462e+02...02, -2.2133303e+00, -4.4443016e+00, ...,
         -2.7885376e+02, -2.8108472e+02, -2.8331570e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f61badbd750>
array_like = array([[[ 1.0387310e+00, -1.1922402e+00, -3.4232113e+00, ...,
         -2.7783267e+02, -2.8006363e+02, -2.8229462e+02]...89e-02, -2.2133303e+00, -4.4443016e+00, ...,
         -2.7885376e+02, -2.8108472e+02, -2.8331570e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 1.0387310e+00, -1.1922402e+00, -3.4232113e+00, ...,
         -2.7783267e+02, -2.8006363e+02, -2.8229462e+02]...89e-02, -2.2133303e+00, -4.4443016e+00, ...,
         -2.7885376e+02, -2.8108472e+02, -2.8331570e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 1.0387310e+00, -1.1922402e+00, -3.4232113e+00, ...,
         -2.7783267e+02, -2.8006363e+02, -2.8229462e+02]...89e-02, -2.2133303e+00, -4.4443016e+00, ...,
         -2.7885376e+02, -2.8108472e+02, -2.8331570e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram2d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_adjust_gamma[numpy-s2s-False] - TypeError: 'float' object cannot be interpreted as an integer
FAILED kornia/test_enhance.py::test_invert[numpy-s2s-False] - ImportError: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as a...
FAILED kornia/test_enhance.py::test_equalize[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_equalize_clahe[numpy-s2s-False] - ValueError: need at least one array to stack
FAILED kornia/test_enhance.py::test_equalize3d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram2d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
======================================================================== 7 failed, 19 passed, 13 skipped in 1795.76s (0:29:55) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.02s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....Fssssssssss                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_diamond_square[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f34ea34d2d0>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f35026c18c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f35026c18c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f34ea34d2d0>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f35026c18c0>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f35026c18c0>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = 0.5, random_scale = 1.0, random_fn = <built-in method ones of type object at 0x7f35026c18c0>, normalize_range = (0.0, 1.0), device = None, dtype = None

    def numpy_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=numpy_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import numpy_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_frnt_
        from ..core.check import numpy_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ..enhance.normalize import numpy_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
    
        numpy_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (numpy.ndarray, numpy.ndarray)):
            random_scale = numpy_to_frnt_(
>               numpy.ndarray([[[[random_scale]]]]), device, dtype
            )
E           TypeError: 'list' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/contrib/diamond_square.py:197: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[numpy-s2s-False] - TypeError: 'list' object cannot be interpreted as an integer
========================================================================= 1 failed, 4 passed, 10 skipped in 323.24s (0:05:23) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ssss                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 5.28s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ssssssssssssssss                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 16 skipped in 5.10s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_AutoAugment[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAutoAugment = ivy.transpile(
            kornia.augmentation.auto.AutoAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = TranspiledAutoAugment()

kornia/augmentation/test_auto.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fc4ec1ef580>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fc4ec1ef580>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fc4ec1ef580>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fc4ec1ef580>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fc4ec1ec5e0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7fc4ec1ef580>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        return tensorflow_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fc4ec1ed090>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:138: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
________________________________________________________________________________ test_RandAugment[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRandAugment = ivy.transpile(
            kornia.augmentation.auto.RandAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = TranspiledRandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fc4ed4f6860>, n = 2, m = 10, policy = None
transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fc4ed4f6860>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fc4ed4f6860>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fc4ed4f6860>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fc4ed4f6c80>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7fc4ed4f6860>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:83: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
______________________________________________________________________________ test_TrivialAugment[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTrivialAugment = ivy.transpile(
            kornia.augmentation.auto.TrivialAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = TranspiledTrivialAugment()

kornia/augmentation/test_auto.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fc4ed0d44c0>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_tensor_frnt,
        )
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fc4ed0d44c0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fc4ed0d44c0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fc4ed0d44c0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fc4ed0d4ca0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7fc4ed0d44c0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:71: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1379.30s (0:22:59) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py .......F                                                                                                                                                          [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_euclidean_distance[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_euclidean_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(3, 5),
            torch.rand(3, 5),
        )
        trace_kwargs = {'keepdim': False, 'eps': 1e-6}
        test_args = (
            torch.rand(5, 3, 5),
            torch.rand(5, 3, 5),
        )
        test_kwargs = {'keepdim': False, 'eps': 1e-6}
>       _test_function(
            kornia.geometry.linalg.euclidean_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_linalg.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f8546dbbe20>
trace_args = (tensor([[0.3076, 0.7109, 0.5626, 0.4430, 0.6435],
        [0.2143, 0.2123, 0.2737, 0.6559, 0.8731],
        [0.5263, ... 0.7770, 0.3662],
        [0.7208, 0.8386, 0.3547, 0.3547, 0.0205],
        [0.4491, 0.5590, 0.9310, 0.0458, 0.8433]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.6690, 0.8514, 0.2179, 0.8650, 0.3445],
         [0.1649, 0.4673, 0.1250, 0.9087, 0.8029],
         [0.298...4950, 0.7921],
         [0.8684, 0.4681, 0.2247, 0.9291, 0.9524],
         [0.6512, 0.4299, 0.2212, 0.0028, 0.4486]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f8546dbbe20>, fn_name = 'kornia.geometry.linalg.euclidean_distance'
trace_args = (tensor([[0.3076, 0.7109, 0.5626, 0.4430, 0.6435],
        [0.2143, 0.2123, 0.2737, 0.6559, 0.8731],
        [0.5263, ... 0.7770, 0.3662],
        [0.7208, 0.8386, 0.3547, 0.3547, 0.0205],
        [0.4491, 0.5590, 0.9310, 0.0458, 0.8433]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.6690, 0.8514, 0.2179, 0.8650, 0.3445],
         [0.1649, 0.4673, 0.1250, 0.9087, 0.8029],
         [0.298...4950, 0.7921],
         [0.8684, 0.4681, 0.2247, 0.9291, 0.9524],
         [0.6512, 0.4299, 0.2212, 0.0028, 0.4486]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.3075546 , 0.7109356 , 0.562589  , 0.44302487, 0.6434563 ],
       [0.21427631, 0.21229643, 0.2737283 , 0.6559028 , 0.87310266],
       [0.5263124 , 0.22846866, 0.8849978 , 0.37427568, 0.11615801]],
      dtype=float32)
y = array([[0.6704341 , 0.48407537, 0.62157726, 0.7769796 , 0.36622995],
       [0.7208361 , 0.83864206, 0.35471028, 0.3547414 , 0.02053058],
       [0.44909084, 0.5589833 , 0.93096286, 0.04577571, 0.8433276 ]],
      dtype=float32)
keepdim = False, eps = 1e-06

    def numpy_euclidean_distance(x, y, keepdim=False, eps=1e-06):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(x, ["*", "N"])
        numpy_KORNIA_CHECK_SHAPE(y, ["*", "N"])
        return numpy_sqrt_frnt_(
>           numpy_sum_frnt_(numpy_pow_frnt_(x - y + eps, 2), -1, keepdim)
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/linalg.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.3628785 ,  0.22686122, -0.05898727, -0.33395374,  0.27722734],
       [-0.5065588 , -0.6263446 , -0.080980...6242,  0.8525731 ],
       [ 0.07722257, -0.33051366, -0.04596408,  0.328501  , -0.72716856]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f84ee1571c0>
array_like = array([[-0.3628785 ,  0.22686122, -0.05898727, -0.33395374,  0.27722734],
       [-0.5065588 , -0.6263446 , -0.0809809...30116242,  0.8525731 ],
       [ 0.07722257, -0.33051366, -0.04596408,  0.328501  , -0.72716856]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[-0.3628785 ,  0.22686122, -0.05898727, -0.33395374,  0.27722734],
       [-0.5065588 , -0.6263446 , -0.0809809...30116242,  0.8525731 ],
       [ 0.07722257, -0.33051366, -0.04596408,  0.328501  , -0.72716856]],
      dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.3628785 ,  0.22686122, -0.05898727, -0.33395374,  0.27722734],
       [-0.5065588 , -0.6263446 , -0.080980...6242,  0.8525731 ],
       [ 0.07722257, -0.33051366, -0.04596408,  0.328501  , -0.72716856]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f84ee1571c0>
array_like = array([[-0.3628785 ,  0.22686122, -0.05898727, -0.33395374,  0.27722734],
       [-0.5065588 , -0.6263446 , -0.0809809...30116242,  0.8525731 ],
       [ 0.07722257, -0.33051366, -0.04596408,  0.328501  , -0.72716856]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[-0.3628785 ,  0.22686122, -0.05898727, -0.33395374,  0.27722734],
       [-0.5065588 , -0.6263446 , -0.0809809...30116242,  0.8525731 ],
       [ 0.07722257, -0.33051366, -0.04596408,  0.328501  , -0.72716856]],
      dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[-0.3628785 ,  0.22686122, -0.05898727, -0.33395374,  0.27722734],
       [-0.5065588 , -0.6263446 , -0.0809809...30116242,  0.8525731 ],
       [ 0.07722257, -0.33051366, -0.04596408,  0.328501  , -0.72716856]],
      dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.linalg.euclidean_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_linalg.py::test_euclidean_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 1 failed, 7 passed in 260.80s (0:04:20) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_get_laf_descriptors[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7efeb3bf1b40>
trace_args = (tensor([[[[0.3484, 0.4696, 0.3585,  ..., 0.1505, 0.9183, 0.2903],
          [0.8360, 0.3473, 0.1822,  ..., 0.5801, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.7383, 0.5605, 0.9812,  ..., 0.6779, 0.6613, 0.5589],
          [0.2585, 0.0662, 0.2961,  ..., 0.0415, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7efeb3bf1b40>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.3484, 0.4696, 0.3585,  ..., 0.1505, 0.9183, 0.2903],
          [0.8360, 0.3473, 0.1822,  ..., 0.5801, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.7383, 0.5605, 0.9812,  ..., 0.6779, 0.6613, 0.5589],
          [0.2585, 0.0662, 0.2961,  ..., 0.0415, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
>       [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7efe5cce2100>

>   [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

original_model = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
translated_model = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models(
        original_model: "nn.Module",
        translated_model: Union["keras.Model", "KerasModel", "nnx.Module", "FlaxModel"],
    ):
        """Synchronizes the weights and buffers between a native PyTorch model
        (`torch.nn.Module`) and it's translated version in TensorFlow or Flax.
    
        Args:
        ----
            original_model (torch.nn.Module): The PyTorch model to synchronize from.
            translated_model (tf.keras.Model or nnx.Module): The target model to synchronize to,
                                                      either a TensorFlow or Flax model.
        """
        if not _is_submodule(original_model, "torch"):
            raise ivy.utils.exceptions.IvyException(
                "sync_models expected an instance of `nn.Module` as the first argument. got {}".format(
                    original_model
                )
            )
        if _is_submodule(translated_model, "keras"):
>           sync_models_torch_and_tf(original_model, translated_model)

../ivy/ivy/stateful/utilities.py:796: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model_pt = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model_tf = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models_torch_and_tf(
        model_pt: "nn.Module", model_tf: Union["keras.Model", "KerasModel"]
    ):
        """Synchronizes the weights and buffers between a PyTorch model
        (`torch.nn.Module`) and a TensorFlow model (`keras.Model`).
    
        This function ensures that both models have identical parameters and buffers by
        iterating through their submodules and synchronizing them. The TensorFlow model
        must either be an instance of `KerasModel` or have submodules that inherit from the
        translated `KerasModel`/`KerasLayer`, and expose interfaces similar to `torch.nn.Module`,
        including `named_parameters()` and `named_buffers()`.
    
        Args:
        ----
            model_pt (torch.nn.Module): The PyTorch model to synchronize from.
            model_tf (keras.Model): The TensorFlow model to synchronize to, with submodules
                                    inheriting from the custom `KerasModel`/`KerasLayer` class.
    
        Returns:
        -------
            None
    
    
        Example:
        -------
            ```python
            import torch.nn as nn
            import keras
    
            #`CustomKerasLinear` is a subclass of `Layer` that exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class CustomKerasLinear(Layer):
                def __init__(self, in_features, out_features):
                    super(CustomKerasLinear, self).__init__()
                    self.weight = tf.Variable(tf.random.normal([out_features, in_features]))
                    self.bias = tf.Variable(tf.random.normal([out_features]))
    
                def call(self, x):
                    return tf.matmul(x, self.weight) + self.bias
    
                def named_parameters(self):
                            return [("weight", self.weight), ("bias", self.bias)]
    
                def named_buffers(self):
                            return []
    
                def eval(self):
                    return False
    
            #`NativeKerasModel` is a subclass of keras.Model and does NOT exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class NativeKerasModel(keras.Model):
                def __init__(self):
                    super(NativeKerasModel, self).__init__()
                    self.linear = CustomKerasLinear(10, 5)
    
                def call(self, x):
                    return self.linear(x)
    
            class PyTorchModel(nn.Module):
                def __init__(self):
                    super(PyTorchModel, self).__init__()
                    self.linear = nn.Linear(10, 5)
    
                def forward(self, x):
                    return self.linear(x)
    
            # Instantiate both models
            model_pt = PyTorchModel()  # PyTorch model
            model_tf = NativeKerasModel()  # Native Keras model inheriting from keras.Model
    
            # Sync all submodules between the PyTorch and Keras models
            sync_models_torch_and_tf(model_pt, model_tf)
            ```
        """
    
        def _compute_module_dict_tf(model, prefix=""):
            _module_dict = dict()
            for key, value in model.__dict__.items():
                if isinstance(value, (tf.keras.Model, tf.keras.layers.Layer)):
                    if not hasattr(value, "named_parameters"):
                        _module_dict.update(
                            _compute_module_dict_tf(value, prefix=f"{key}.")
                        )
                    else:
                        _module_dict[prefix + key] = value
            return _module_dict
    
        try:
            pass
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`torch` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        try:
            import tensorflow as tf
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`tensorflow` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        if hasattr(model_tf, "named_parameters"):
>           _sync_models_torch_and_tf(model_pt, model_tf)

../ivy/ivy/stateful/utilities.py:626: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model1 = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model2 = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def _sync_models_torch_and_tf(model1: "nn.Module", model2: "KerasModel"):
        """Synchronizes the parameters and buffers of the original and the
        translated model.
    
        Args:
        ----
            model1 (torch.nn.Module): The original PyTorch model.
            model2 (ivy.Module converted keras.Model)): The converted ivy.Module converted keras.Model.
    
        Returns:
        -------
            None
        """
        def _pt_name_to_keras_name(layer, weight_name):
            if layer.__class__.__name__ in ("KerasConv2D", "KerasDense"):
                param_and_buff_map = {
                    "weight": "_kernel",
                    "bias": "bias",
                }
            elif layer.__class__.__name__ == "KerasDepthwiseConv2D":
                if parse(keras.__version__).major > 2:
                    param_and_buff_map = {
                        "weight": "kernel",
                        "bias": "bias",
                    }
                else:
                    param_and_buff_map = {
                        "weight": "depthwise_kernel",
                        "bias": "bias",
                    }
            elif layer.__class__.__name__ == "KerasBatchNorm2D":
                param_and_buff_map = {
                    "weight": "gamma",
                    "bias": "beta",
                    "running_mean": "moving_mean",
                    "running_var": "moving_variance",
                    "num_batches_tracked": "num_batches_tracked",
                }
            else:
                raise ValueError(f"Layer '{layer}' is not supported.")
    
            return param_and_buff_map[weight_name]
    
        def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
            # Update the weight in the retrieved layer
            if hasattr(layer, weight_name):
                layer._is_built = True
                weight_var = getattr(layer, weight_name)
                if isinstance(weight_var, tf.Variable):
                    weight_var.assign(tf.Variable(new_weight, dtype=weight_var.dtype))
                elif isinstance(weight_var, KerasVariable):
                    weight_var.assign(
                        KerasVariable(
                            new_weight, dtype=weight_var.dtype, name=weight_var.name
                        )
                    )
                else:
                    setattr(
                        layer,
                        weight_name,
                        tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                    )
                # now also update the PT placeholder weights for this layer
                layer._is_built = False
                pt_weight_name = (
                    "pt_weight"
                    if weight_name == "weight"
                    else "pt_bias" if weight_name == "bias" else weight_name
                )
                setattr(
                    layer,
                    pt_weight_name,
                    None if original_weight is None else tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                )
            else:
                raise AttributeError(
                    f"Layer '{layer}' does not have a weight named '{weight_name}'"
                )
    
        import torch
        import tensorflow as tf
        import keras
    
        if parse(keras.__version__).major > 2:
            KerasVariable = keras.src.backend.Variable
        else:
            KerasVariable = tf.Variable
    
        has_keras_layers = os.environ.get("USE_NATIVE_FW_LAYERS", "true") == "true"
        transpose_weights = (
            has_keras_layers
            or os.environ.get("APPLY_TRANSPOSE_OPTIMIZATION", "true") == "true"
        )
    
        params1 = dict(model1.named_parameters())
        params2 = dict(model2.named_parameters())
        buffers1 = dict(model1.named_buffers())
        buffers2 = dict(model2.named_buffers())
        # TODO: remove this once the stateful attribute name-conflict has been resolved.
        key_mapping = {}
        for k in params2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        for k in buffers2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        params2 = {k.replace("pt_", ""): v for k, v in params2.items()}
        buffers2 = {k.replace("pt_", ""): v for k, v in buffers2.items()}
    
        # Check if both models have the same parameters and buffers
        assert params1.keys() == params2.keys()
        assert buffers1.keys() == buffers2.keys()
    
        # Set the parameters and buffers of the second model to be the same as the first model
        with torch.no_grad():
            for name in params1:
                layer, weight_name = _retrive_layer(model2, key_mapping[name])
    
                params1_np = params1[name].cpu().detach().numpy()
                # Transpose the parameters to match the TensorFlow format
                params1_np = transpose_weights_pt_to_tf_jax(layer, params1_np, transpose_weights, fw='tensorflow')
    
                # inplace update the native keras layer. This is done as the parameters in
                # self.v are a different copy than the parameters in self.weights. Hence, we
                # need to explicitly update self.weights, otherwise the changes won't reflect.
                if layer.__class__.__name__.startswith("Keras"):
                    keras_name = _pt_name_to_keras_name(layer, weight_name)
>                   _maybe_update_keras_layer_weights(
                        layer=layer, weight_name=weight_name, new_weight=params1_np, original_weight=params1[name].cpu().detach().numpy()
                    )

../ivy/ivy/stateful/utilities.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

layer = KerasConv2D(), weight_name = 'weight'
new_weight = array([[[[ 3.20830762e-01, -1.32047862e-01,  3.29629588e-03,
           3.40370345e-03,  1.19920298e-01,  1.13393784e-...0239735e-03,
           3.32196563e-01, -2.62892306e-01, -1.41379442e-02,
           2.63136119e-01]]]], dtype=float32)
original_weight = array([[[[ 3.20830762e-01, -4.66238260e-02,  2.09962539e-02],
         [ 2.90868163e-01, -1.10816836e-01,  3.31277728e...7.52119254e-03,  2.65368633e-02],
         [ 8.73179436e-02, -1.09725356e-01,  2.63136119e-01]]]],
      dtype=float32)

    def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
        # Update the weight in the retrieved layer
        if hasattr(layer, weight_name):
            layer._is_built = True
>           weight_var = getattr(layer, weight_name)

../ivy/ivy/stateful/utilities.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasConv2D(), name = 'weight'

    def __getattribute__(self, name):
        built = object.__getattribute__(self, "__dict__").get("_is_built", False)
        use_bias = object.__getattribute__(self, "__dict__").get("use_bias", True)
        if built:
            attr_map = {"weight": "_kernel", "bias": "bias"}
        else:
            attr_map = {"weight": "pt_weight", "bias": "pt_bias"}
        if not use_bias:
            attr_map["bias"] = "pt_bias"
        new_name = attr_map[name] if name in attr_map else name
>       return super().__getattribute__(new_name)
E       AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:626: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[tensorflow-s2s-False] - AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?
============================================================================== 1 failed, 18 passed in 1628.36s (0:27:08) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_AutoAugment[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAutoAugment = ivy.transpile(
            kornia.augmentation.auto.AutoAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = TranspiledAutoAugment()

kornia/augmentation/test_auto.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fca1d09a320>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fca1d09a320>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fca1d09a320>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fca1d09a320>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fca1d09a320>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fca1d09a320>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fca1d099e10>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fca1d09a320>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        return jax_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fca1d099720>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:136: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
___________________________________________________________________________________ test_RandAugment[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRandAugment = ivy.transpile(
            kornia.augmentation.auto.RandAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = TranspiledRandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fca1f51b070>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fca1f51b070>, args = (), kwargs = {'m': 10, 'n': 2}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fca1f51b070>, n = 2, m = 10, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fca1f51b070>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fca1f51b070>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fca1f51b070>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fca1f518fa0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fca1f51b070>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:81: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
__________________________________________________________________________________ test_TrivialAugment[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTrivialAugment = ivy.transpile(
            kornia.augmentation.auto.TrivialAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = TranspiledTrivialAugment()

kornia/augmentation/test_auto.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fca1e74cd30>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fca1e74cd30>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fca1e74cd30>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fca1e74cd30>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fca1e74cd30>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fca1e74cd30>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fca1e74e020>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fca1e74cd30>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:67: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1325.64s (0:22:05) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py F                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_Quaternion[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Quaternion(target_framework, mode, backend_compile):
        print("kornia.geometry.quaternion.Quaternion")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledQuaternion = ivy.transpile(Quaternion, source="torch", target=target_framework)
    
        # test Quaternion.identity
    
        torch_q = Quaternion.identity(batch_size=4)
        transpiled_q = TranspiledQuaternion.identity(batch_size=4)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__add__
    
        torch_q1 = Quaternion.identity()
        torch_q2 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q3 = torch_q1 + torch_q2
        transpiled_q1 = TranspiledQuaternion.identity()
        transpiled_q2 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
        transpiled_q3 = transpiled_q1 + transpiled_q2
    
        orig_np = _nest_array_to_numpy(torch_q3.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q3.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__init__()
    
        torch_q = Quaternion(torch.tensor([[1., 0., 0., 0.], [0., 1., 0., 0.]]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([[1., 0., 0., 0.], [0., 1., 0., 0.]]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__neg__()
    
        torch_q = -Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = -TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__pow__()
    
        torch_q = Quaternion(torch.tensor([1., .5, 0., 0.])) ** 2
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., .5, 0., 0.]), target_framework)) ** 2
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.__sub__()
    
        torch_q1 = Quaternion(torch.tensor([2., 0., 1., 1.]))
        torch_q2 = Quaternion.identity()
        torch_q3 = torch_q1 - torch_q2
        transpiled_q1 = TranspiledQuaternion(_array_to_new_backend(torch.tensor([2., 0., 1., 1.]), target_framework))
        transpiled_q2 = TranspiledQuaternion.identity()
        transpiled_q3 = transpiled_q1 - transpiled_q2
    
        orig_np = _nest_array_to_numpy(torch_q3.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q3.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.coeffs
    
        torch_q = Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        torch_coeffs = _nest_array_to_numpy(torch_q.coeffs)
        transpiled_coeffs = _nest_array_to_numpy(transpiled_q.coeffs)
        _check_allclose(torch_coeffs, transpiled_coeffs)
    
    
        # test Quaternion.data
    
        torch_q = Quaternion(torch.tensor([1., 0., 0., 0.]))
        transpiled_q = TranspiledQuaternion(_array_to_new_backend(torch.tensor([1., 0., 0., 0.]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_axis_angle()
    
        torch_q = Quaternion.from_axis_angle(torch.tensor([[1., 0., 0.]]))
        transpiled_q = TranspiledQuaternion.from_axis_angle(_array_to_new_backend(torch.tensor([[1., 0., 0.]]), target_framework))
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_coeffs()
    
        torch_q = Quaternion.from_coeffs(1., 0., 0., 0.)
        transpiled_q = TranspiledQuaternion.from_coeffs(1., 0., 0., 0.)
    
        orig_np = _nest_array_to_numpy(torch_q.data)
        transpiled_np = _nest_array_to_numpy(transpiled_q.data)
        _check_allclose(orig_np, transpiled_np)
    
    
        # test Quaternion.from_euler()
    
        roll, pitch, yaw = torch.tensor(0), torch.tensor(1), torch.tensor(0)
        torch_q = Quaternion.from_euler(roll, pitch, yaw)
>       transpiled_q = TranspiledQuaternion.from_euler(
            _array_to_new_backend(roll, target_framework), _array_to_new_backend(pitch, target_framework), _array_to_new_backend(yaw, target_framework)
        )

kornia/geometry/test_quaternion.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.quaternion.tensorflow_Quaternion'>, roll = <tf.Tensor: shape=(), dtype=int64, numpy=0>
pitch = <tf.Tensor: shape=(), dtype=int64, numpy=1>, yaw = <tf.Tensor: shape=(), dtype=int64, numpy=0>

    @classmethod
    def from_euler(cls, roll, pitch, yaw):
        from ..core._backend import stack
        from .conversions import tensorflow_quaternion_from_euler
    
        w, x, y, z = tensorflow_quaternion_from_euler(roll=roll, pitch=pitch, yaw=yaw)
        q = stack((w, x, y, z), -1)
>       return cls(q)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/quaternion.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_Quaternion' object has no attribute '_data'") raised in repr()] tensorflow_Quaternion object at 0x7f7057c6c220>
data = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

    def __init__(self, data):
        self.super___init__(
            data,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self._data = tensorflow.keras.Variable(data)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/quaternion.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_16>, initializer = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>
shape = None, dtype = 'float32', trainable = True, autocast = True, aggregation = 'mean', name = 'variable_16'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_16>, value = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>)
kwargs = {'dtype': 'float32', 'name': 'variable_16', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.87758256, 0.        , 0.47942554, 0.        ])>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.quaternion.Quaternion
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_quaternion.py::test_Quaternion[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: sh...
===================================================================================== 1 failed in 94.52s (0:01:34) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 2023.77s (0:33:43) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py FFFF.F                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_AugmentationSequential[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AugmentationSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.AugmentationSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.AugmentationSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.augmentation.RandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledAugmentationSequential(
            TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledRandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
            torch.tensor([[
                [1., 1.],
                [2., 1.],
                [2., 2.],
                [1., 2.],
            ]]).expand(2, 1, -1, -1),
            torch.tensor([[[1., 1.]]]).expand(2, -1, -1),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.9903386 , -0.20409884,  0.01873558, -0.86706495,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd0af1cd440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.9903386 , -0.20409884,  0.01873558, -0.86706495,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.9903386 , -0.20409884,  0.01873558, -0.86706495,
 ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (*args, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...e, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
),)
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.9903386 , -0.20409884,  0.01873558, -0.867...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.9903386 , -0.20409884,  0.01873558, -0.867...
         [ 0.3050095 ,  0.26077875,  0.39965382,  0.89809996,
          -1.0426364 ,  1.5524701 ]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.9903386 , -0.20409884,  0.01873558, -0.867...
         [ 0.3050095 ,  0.26077875,  0.39965382,  0.89809996,
          -1.0426364 ,  1.5524701 ]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'args'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.AugmentationSequential
______________________________________________________________________ test_ManyToManyAugmentationDispather[tensorflow-s2s-False] ______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToManyAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToManyAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledManyToManyAugmentationDispather = ivy.transpile(
            kornia.augmentation.container.ManyToManyAugmentationDispather,
            source="torch",
            target=target_framework,
        )
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ManyToManyAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = TranspiledManyToManyAugmentationDispather(
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather()
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.75010425, -1.2665589 , -0.24325052,  0.82732046,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd0aa0ffa40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.750...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.75010425, -1.2665589 , -0.24325052,  0.82732046,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.750...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.75010425, -1.2665589 , -0.24325052,  0.82732046,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.75010425, -1.2665589 , -0.24325052,  0.82732046,
  ...,
         [-2.026977  ,  1.1741894 ,  0.2434495 ,  0.26647028,
          -0.05687229, -0.6928482 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(),)
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.75010425, -1.2665589 , -0.24325052,  0.8...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.75010425, -1.2665589 , -0.24325052,  0.8...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-0.75010425, -1.2665589 , -0.24325052,  0.8...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToManyAugmentationDispather
______________________________________________________________________ test_ManyToOneAugmentationDispather[tensorflow-s2s-False] _______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToOneAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToOneAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledManyToOneAugmentationDispather = ivy.transpile(
            kornia.augmentation.container.ManyToOneAugmentationDispather,
            source="torch",
            target=target_framework,
        )
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ManyToOneAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = TranspiledManyToOneAugmentationDispather(
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather()
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502846, -1.5994174 , -1.5170339 ,  0.63549924,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd0aaf69640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502846, -1.5994174 , -1.5170339 ,  0.63549924,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502846, -1.5994174 , -1.5170339 ,  0.63549924,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502846, -1.5994174 , -1.5170339 ,  0.63549924,
  ...,
         [-1.0757672 ,  0.49348933,  0.08148906, -1.7992    ,
           0.03492323, -0.5484543 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502846, -1.5994174 , -1.5170339 ,  0.63...
         [-1.0757672 ,  0.49348933,  0.08148906, -1.7992    ,
           0.03492323, -0.5484543 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502846, -1.5994174 , -1.5170339 ,  0.63...
         [-1.0757672 ,  0.49348933,  0.08148906, -1.7992    ,
           0.03492323, -0.5484543 ]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.90502846, -1.5994174 , -1.5170339 ,  0.63...
         [-1.0757672 ,  0.49348933,  0.08148906, -1.7992    ,
           0.03492323, -0.5484543 ]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToOneAugmentationDispather
______________________________________________________________________________ test_ImageSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
        TranspiledMedianBlur = ivy.transpile(
            kornia.filters.MedianBlur,
            source="torch",
            target=target_framework,
        )
        TranspiledInvert = ivy.transpile(
            kornia.enhance.Invert,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomMixUpV2 = ivy.transpile(
            kornia.augmentation.RandomMixUpV2,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledImageSequential(
            TranspiledBgrToRgb(),
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledMedianBlur((3, 3)),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledInvert(),
            TranspiledRandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ColorJiggle' object has no attribute 'p'") raised in repr()] tensorflow_ColorJiggle object at 0x7fd0b05a1600>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ColorJiggle' object has no attribute 'p'") raised in repr()] tensorflow_ColorJiggle object at 0x7fd0b05a1600>, brightness = 0.1, contrast = 0.1, saturation = 0.1
hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.random_generator._2d.color_jiggle'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:46: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
______________________________________________________________________________ test_VideoSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledVideoSequential = ivy.transpile(
            kornia.augmentation.container.VideoSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
        transpiled_aug_list =  TranspiledVideoSequential(
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledBgrToRgb(),
            TranspiledRandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'") raised in repr()] tensorflow_ColorJiggle object at 0x7fd0b0a6e650>
args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'") raised in repr()] tensorflow_ColorJiggle object at 0x7fd0b0a6e650>, brightness = 0.1
contrast = 0.1, saturation = 0.1, hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:46: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_AugmentationSequential[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'args'
FAILED kornia/augmentation/test_container.py::test_ManyToManyAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ManyToOneAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ImageSequential[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.random...
FAILED kornia/augmentation/test_container.py::test_VideoSequential[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'
=============================================================================== 5 failed, 1 passed in 2379.00s (0:39:38) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py ssssssssss                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 10 skipped in 5.13s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_Boxes[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes = ivy.transpile(kornia.geometry.boxes.Boxes, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
        transpiled_boxes = TranspiledBoxes.from_tensor(*transpiled_args, mode="xyxy")
        _check_boxes_same(torch_boxes, transpiled_boxes)
    
        # test .compute_area
        torch_area = torch_boxes.compute_area()
        transpiled_area = transpiled_boxes.compute_area()
        _to_numpy_and_allclose(torch_area, transpiled_area)
    
        # test .get_boxes_shape
        torch_heights, torch_widths = torch_boxes.get_boxes_shape()
        transpiled_heights, transpiled_widths = transpiled_boxes.get_boxes_shape()
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .merge
        torch_x = torch.as_tensor([[6, 6, 10, 10], [6, 6, 10, 10]])
        transpiled_x = _nest_torch_tensor_to_new_framework(torch_x, target_framework)
        merge_boxes = kornia.geometry.boxes.Boxes.from_tensor(torch_x, mode="xyxy")
        transpiled_merge_boxes = TranspiledBoxes.from_tensor(transpiled_x, mode="xyxy")
        torch_merged_boxes = torch_boxes.merge(merge_boxes)
        transpiled_merged_boxes = transpiled_boxes.merge(transpiled_merge_boxes)
        _check_boxes_same(torch_merged_boxes, transpiled_merged_boxes)
    
        # test .to_mask
        height, width = 10, 10
        torch_mask = torch_boxes.to_mask(height, width)
        transpiled_mask = transpiled_boxes.to_mask(height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0....., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
_____________________________________________________________________________________ test_Boxes3D[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes3D = ivy.transpile(kornia.geometry.boxes.Boxes3D, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
        transpiled_boxes3d = TranspiledBoxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
        _check_boxes_same(torch_boxes3d, transpiled_boxes3d)
    
        # test .get_boxes_shape
        torch_depths, torch_heights, torch_widths = torch_boxes3d.get_boxes_shape()
        transpiled_depths, transpiled_heights, transpiled_widths = transpiled_boxes3d.get_boxes_shape()
        _to_numpy_and_allclose(torch_depths, transpiled_depths)
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .to_mask
        depth, height, width = 10, 10, 10
        torch_mask = torch_boxes3d.to_mask(depth, height, width)
        transpiled_mask = transpiled_boxes3d.to_mask(depth, height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0... [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
transpiled_x = Array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
y = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[jax-s2s-False] - AssertionError: numpy array values are not all close
==================================================================================== 2 failed in 199.92s (0:03:19) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF..F.............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_HausdorffERLoss[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss = ivy.transpile(kornia.losses.HausdorffERLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = TranspiledHausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.47123492e-01, -1.71099818e+00, ...        ...,
         [1, 1, 1, ..., 1, 1, 0],
         [0, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 1]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8978de5440, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.4...        ...,
         [1, 1, 1, ..., 1, 1, 0],
         [0, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 1]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.47123492e-01, -1.71099818e+00, ...        ...,
         [1, 1, 1, ..., 1, 1, 0],
         [0, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 1]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.4...        ...,
         [1, 1, 1, ..., 1, 1, 0],
         [0, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 1]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.47123492e-01, -1.71099818e+00, ...        ...,
         [1, 1, 1, ..., 1, 1, 0],
         [0, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 1]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.47123492e-01, -1.71099818e+00, ....37970e+00, -1.98059559e+00, ...,
           9.62395191e-01,  4.22768947e-03,  5.46956539e-01]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.47123492e-01, -1.710998...        ...,
         [1, 1, 1, ..., 1, 1, 0],
         [0, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 1]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.47123492e-01, -1.71099818e+00, ....37970e+00, -1.98059559e+00, ...,
           9.62395191e-01,  4.22768947e-03,  5.46956539e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 1, 1, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, ...         ...,
         [1, 1, 1, ..., 1, 1, 0],
         [0, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 1]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        if tensorflow_dim_frnt_(pred) != 4:
            raise ValueError(
                f"Only 2D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
        if not (
            tensorflow_max_frnt_(target) < tensorflow_size_frnt_(pred, 1)
            and tensorflow_min_frnt_(target) >= 0
            and target.dtype == tf.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {tensorflow_size_frnt_(pred, 1)}). ({tensorflow_min_frnt_(target)}, {tensorflow_max_frnt_(target)})"
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:289: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.47123492e-01, -1.71099818e+00, ....37970e+00, -1.98059559e+00, ...,
           9.62395191e-01,  4.22768947e-03,  5.46956539e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 1, 1, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, ...         ...,
         [1, 1, 1, ..., 1, 1, 0],
         [0, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 1]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f8956ed7690>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 1, 20, 20), dtype=float32, numpy=
array([[[[ 5.79436600e-01, -5.47123492e-01, -1.71099818e+00, ....31168e-01, -6.90669194e-02, ...,
           4.86464977e-01,  4.97238576e-01, -3.21133196e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[0, 0, 0, ..., 0, 0, 0],
         [0, 1, 0, ..., 1, 1, ...         ...,
         [0, 0, 0, ..., 0, 0, 1],
         [1, 1, 1, ..., 0, 0, 0],
         [0, 1, 0, ..., 1, 1, 0]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
E           
E           [1mtensorflow_conv2d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss.call():
E             • pred=tf.Tensor(shape=(5, 3, 20, 20), dtype=float32)
E             • target=tf.Tensor(shape=(5, 1, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
_____________________________________________________________________________ test_HausdorffERLoss3D[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss3D = ivy.transpile(kornia.losses.HausdorffERLoss3D, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = TranspiledHausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+00,  7.49992609e-01,  9.10374939e...    ...,
          [1, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 1, 0],
          [0, 0, 1, ..., 0, 1, 0]]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8978157870, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+0...    ...,
          [1, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 1, 0],
          [0, 0, 1, ..., 0, 1, 0]]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+00,  7.49992609e-01,  9.10374939e...    ...,
          [1, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 1, 0],
          [0, 0, 1, ..., 0, 1, 0]]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+0...    ...,
          [1, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 1, 0],
          [0, 0, 1, ..., 0, 1, 0]]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+00,  7.49992609e-01,  9.10374939e...    ...,
          [1, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 1, 0],
          [0, 0, 1, ..., 0, 1, 0]]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+00,  7.49992609e-01,  9.10374939e-...622e+00,  9.74933922e-01, ...,
           -6.46642029e-01,  4.53178108e-01,  7.25368440e-01]]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+00,  7.49992609e-01,  9.1...    ...,
          [1, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 1, 0],
          [0, 0, 1, ..., 0, 1, 0]]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+00,  7.49992609e-01,  9.10374939e-...622e+00,  9.74933922e-01, ...,
           -6.46642029e-01,  4.53178108e-01,  7.25368440e-01]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 1, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., ...     ...,
          [1, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 1, 0],
          [0, 0, 1, ..., 0, 1, 0]]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
    
        if tensorflow_dim_frnt_(pred) != 5:
            raise ValueError(
                f"Only 3D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:280: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+00,  7.49992609e-01,  9.10374939e-...622e+00,  9.74933922e-01, ...,
           -6.46642029e-01,  4.53178108e-01,  7.25368440e-01]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 1, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., ...     ...,
          [1, 0, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 1, 0],
          [0, 0, 1, ..., 0, 1, 0]]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f8978c24ab0>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=float32, numpy=
array([[[[[-1.12466526e+00,  7.49992609e-01,  9.10374939e-...373e-01, -3.67197663e-01, ...,
           -6.42104387e-01, -7.86969423e-01, -7.31777012e-01]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[1, 0, 0, ..., 1, 0, 0],
          [1, 0, 0, ..., ...     ...,
          [0, 1, 0, ..., 1, 0, 0],
          [1, 0, 0, ..., 0, 0, 1],
          [1, 1, 0, ..., 1, 0, 1]]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
E           
E           [1mtensorflow_conv3d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss3D.call():
E             • pred=tf.Tensor(shape=(5, 3, 20, 20, 20), dtype=float32)
E             • target=tf.Tensor(shape=(5, 1, 20, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
________________________________________________________________________________ test_MS_SSIMLoss[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MS_SSIMLoss(target_framework, mode, backend_compile):
        print("kornia.losses.MS_SSIMLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMS_SSIMLoss = ivy.transpile(kornia.losses.MS_SSIMLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.MS_SSIMLoss()
        transpiled_loss_fn = TranspiledMS_SSIMLoss()
    
        torch_args = (
            torch.rand(1, 3, 5, 5),
            torch.rand(1, 3, 5, 5),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:546: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.224...86080337, 0.45468313],
         [0.47830856, 0.8425762 , 0.09855449, 0.4876868 , 0.7764025 ]]]],
      dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55e031f0ddc0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.8...86080337, 0.45468313],
         [0.47830856, 0.8425762 , 0.09855449, 0.4876868 , 0.7764025 ]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.224...86080337, 0.45468313],
         [0.47830856, 0.8425762 , 0.09855449, 0.4876868 , 0.7764025 ]]]],
      dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.8...86080337, 0.45468313],
         [0.47830856, 0.8425762 , 0.09855449, 0.4876868 , 0.7764025 ]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.224...86080337, 0.45468313],
         [0.47830856, 0.8425762 , 0.09855449, 0.4876868 , 0.7764025 ]]]],
      dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.2247....8520765 , 0.7397452 ],
         [0.1697188 , 0.6529278 , 0.8588105 , 0.6872022 , 0.3964582 ]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img1, img2)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(),)
kwargs = {'img1': <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.2801902...86080337, 0.45468313],
         [0.47830856, 0.8425762 , 0.09855449, 0.4876868 , 0.7764025 ]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
img1 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.2247....8520765 , 0.7397452 ],
         [0.1697188 , 0.6529278 , 0.8588105 , 0.6872022 , 0.3964582 ]]]],
      dtype=float32)>
img2 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.42046952, 0.18361485, 0.26352352, 0.1963731 , 0.8749....86080337, 0.45468313],
         [0.47830856, 0.8425762 , 0.09855449, 0.4876868 , 0.7764025 ]]]],
      dtype=float32)>

    def call(self, img1, img2):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.jit._jit_internal import (
            tensorflow_annotate_frnt,
        )
        from ...ivy.functional.frontends.torch.nn.functional.convolution_functions import (
            tensorflow_conv2d_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_prod_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.loss_functions import (
            tensorflow_l1_loss_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
    
        if not isinstance(img1, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Input type is not a torch.Tensor. Got {type(img1)}")
        if not isinstance(img2, (tensorflow.Tensor, tensorflow.keras.Variable)):
            raise TypeError(f"Output type is not a torch.Tensor. Got {type(img2)}")
        if not len(tensorflow_shape_frnt_(img1)) == len(tensorflow_shape_frnt_(img2)):
            raise ValueError(
                f"Input shapes should be same. Got {type(img1)} and {type(img2)}."
            )
        g_masks: typing.Any = tensorflow_annotate_frnt(tensorflow.Tensor, self._g_masks)
        CH: typing.Any = tensorflow_shape_frnt_(img1)[-3]
>       mux = tensorflow_conv2d_frnt(img1, g_masks, groups=CH, padding=self.pad)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/ms_ssim.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.2247....8520765 , 0.7397452 ],
         [0.1697188 , 0.6529278 , 0.8588105 , 0.6872022 , 0.3964582 ]]]],
      dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = 16, dilation = 1, groups = 3

    def tensorflow_conv2d_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
>       return tensorflow__conv_frnt(
            input,
            weight,
            bias=bias,
            stride=stride,
            padding=padding,
            dilation=dilation,
            groups=groups,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.2247....8520765 , 0.7397452 ],
         [0.1697188 , 0.6529278 , 0.8588105 , 0.6872022 , 0.3964582 ]]]],
      dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = [(16, 16), (16, 16)], dilation = 1, groups = 3

    def tensorflow__conv_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
        from ...tensor import tensorflow_shape_frnt_
        from .....backends.tensorflow.layers import tensorflow_conv_general_dilated
    
        dims = len(tensorflow_shape_frnt_(input)) - 2
        if isinstance(padding, (str,)):
            padding = padding.upper()
        elif isinstance(padding, (int,)):
            padding = [*[(padding, padding) for _ in range(dims)]]
        else:
            padding = [*[(p, p) for p in padding]]
>       ret = tensorflow_conv_general_dilated(
            input,
            weight,
            stride,
            padding,
            dims=dims,
            data_format="channel_last",
            filter_format="channel_last",
            dilations=dilation,
            feature_group_count=groups,
            bias=bias,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.224....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'bias': None, 'data_format': 'channel_first', 'dilations': 1, 'dims': 2, ...}, tensorflow_set_item = <function tensorflow_set_item at 0x7f8956ceec20>
tensorflow_get_item = <function tensorflow_get_item at 0x7f8956ceea70>, DATA_FORMAT = 'channels_first', value_map = {'NHWC': 'NCHW', 'NSC': 'NCS', 'channel_last': 'channel_first'}

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.69628286, 0.5574405 , 0.81531245, 0.28019023, 0.224....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)]]
kwargs = {'bias': None, 'data_format': 'channel_first', 'dilations': 1, 'dims': 2, ...}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f8956cec820>
tensorflow_set_item = <function tensorflow_set_item at 0x7f8956ceec20>, tensorflow_asarray = <function tensorflow_asarray at 0x7f8956ced480>
tensorflow_get_item = <function tensorflow_get_item at 0x7f8956ceea70>, num_args = 4
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'filters', 'strides', 'padding', 'dims', 'data_format', ...]
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[tenso...le[int, int, int]], typing.Union[str, int, typing.Sequence[typing.Tuple[int, int]]], <class 'int'>, <class 'str'>, ...]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 3

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.69628286, 0.49588597, 0.0287534 ],
         [0.55744...105 ],
         [0.6699739 , 0.08177853, 0.6872022 ],
         [0.35159516, 0.08837783, 0.3964582 ]]]], dtype=float32)>
filters = <tf.Tensor: shape=(33, 33, 1, 15), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...0000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.9322472e-05, 4.9322472e-05, 4.9322472e-05]]]], dtype=float32)>
strides = 1, padding = [(16, 16), (16, 16)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    @tensorflow_handle_array_like_without_promotion
    def tensorflow_conv_general_dilated(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        dims: int = 2,
        data_format: str = "channel_last",
        filter_format: str = "channel_last",
        feature_group_count: int = 1,
        x_dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        bias: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
        from ...ivy.layers import tensorflow__get_x_data_format_bknd
    
        if filter_format == "channel_first":
            filters = tensorflow.transpose(filters, (*range(2, dims + 2), 1, 0))
        num_channels = x.shape[1] if data_format == "channel_first" else x.shape[-1]
        if filters.shape[-2] != num_channels // feature_group_count:
            raise Exception(
                f"given feature_group_count {feature_group_count} expected input channel of the filter to be {num_channels // feature_group_count} but got {filters.shape[-2]}"
            )
        if num_channels % feature_group_count != 0:
            raise Exception(
                f"input channel should be divisible by feature group count {feature_group_count} but got input channel {num_channels}"
            )
        permuted_x = False
        if data_format == "channel_first" and (
            tensorflow_dev(x) == "cpu" or feature_group_count != 1
        ):
            x = tensorflow.transpose(x, (0, *range(2, dims + 2), 1))
            data_format = "channel_last"
            permuted_x = True
        data_format = tensorflow__get_x_data_format_bknd(dims, data_format)
        x = tensorflow__x_dil_before_conv(x, dims, x_dilations, data_format)
        if dims == 2:
            padding = tensorflow__extend_2d_padding(padding, data_format)
            if feature_group_count == 1:
                res = tensorflow.nn.conv2d(
                    x,
                    filters,
                    strides,
                    padding,
                    data_format=data_format,
                    dilations=dilations,
                )
            else:
                if not isinstance(padding, str):
                    padding = padding[1:-1]
>               res = tensorflow_depthwise_conv2d(
                    x,
                    tensorflow.transpose(filters, (0, 1, 3, 2)),
                    strides,
                    padding,
                    data_format=data_format,
                    dilations=dilations,
                )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.69628286, 0.49588597, 0.0287534 ],
         [0.5574...      [4.9322472e-05],
         [4.9322472e-05],
         [4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'data_format': 'NHWC', 'dilations': 1}, tensorflow_set_item = <function tensorflow_set_item at 0x7f8956ceec20>, tensorflow_get_item = <function tensorflow_get_item at 0x7f8956ceea70>
DATA_FORMAT = 'channels_last'

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.69628286, 0.49588597, 0.0287534 ],
         [0.55744...105 ],
         [0.6699739 , 0.08177853, 0.6872022 ],
         [0.35159516, 0.08837783, 0.3964582 ]]]], dtype=float32)>
filters = <tf.Tensor: shape=(33, 33, 15, 1), dtype=float32, numpy=
array([[[[0.0000000e+00],
         [0.0000000e+00],
         ...00e+00],
         ...,
         [4.9322472e-05],
         [4.9322472e-05],
         [4.9322472e-05]]]], dtype=float32)>
strides = [1, 1, 1, 1], padding = [(0, 0), (16, 16), (16, 16), (0, 0)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    def tensorflow_depthwise_conv2d(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        data_format: str = "NHWC",
        dilations: Union[int, Tuple[int, int]] = 1,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
    
        strides = [strides] * 2 if isinstance(strides, int) else strides
        dilations = [dilations] * 2 if isinstance(dilations, int) else dilations
        permuted_x = False
        if data_format == "NCHW" and tensorflow_dev(x) == "cpu":
            x = tensorflow.transpose(x, (0, 2, 3, 1))
            data_format = "NHWC"
            permuted_x = True
        if tensorflow.rank(filters) == 3:
            filters = tensorflow.expand_dims(filters, -1)
        padding = tensorflow__extend_2d_padding(padding, data_format)
        strides = [1, strides[0], strides[1], 1]
>       res = tensorflow.nn.depthwise_conv2d(
            x, filters, strides, padding, data_format, dilations
        )
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
E       
E       [1m{{function_node __wrapped__DepthwiseConv2dNative_device_/job:localhost/replica:0/task:0/device:CPU:0}} input and filter must have the same depth: 3 vs 15 [Op:DepthwiseConv2dNative] name: [0m
E       
E       Arguments received by tensorflow_MS_SSIMLoss.call():
E         • img1=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)
E         • img2=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:137: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.MS_SSIMLoss
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
FAILED kornia/test_losses.py::test_MS_SSIMLoss[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
============================================================================== 3 failed, 32 passed in 2244.59s (0:37:24) ===============================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ........FF...FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomResizedCrop[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomResizedCrop(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomResizedCrop")
    
        init_args = ()
        init_kwargs = {"size": (3, 3), "scale": (3., 3.), "ratio": (2., 2.), "p": 1., "cropping_mode": "resample"}
        call_args = (torch.tensor([[[0., 1., 2.],
                                    [3., 4., 5.],
                                    [6., 7., 8.]]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomResizedCrop,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resized_crop.RandomResizedCrop'>, target = 'tensorflow', init_args = ()
init_kwargs = {'cropping_mode': 'resample', 'p': 1.0, 'ratio': (2.0, 2.0), 'scale': (3.0, 3.0), ...}, call_args = (tensor([[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f4b6ce9dc40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, replace_v = False, replace_buffers = False
call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
input = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, params = None, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f4b6ce3b910>, tensorflow_set_item = <function tensorflow_set_item at 0x7f4b72c1c670>
tensor = <function tensorflow_tensor_frnt at 0x7f4b672ed870>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3), dtype=float32, numpy=
array([[[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = (1, 1, 3, 3)

    def generate_parameters(self, batch_shape):
        if self._param_generator is not None:
>           return self._param_generator(batch_shape, self.same_on_batch)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), args = ((1, 1, 3, 3), False), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f4b6ce9c840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}, replace_v = False, replace_buffers = False
call_signature = <Signature (batch_shape, same_on_batch=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), batch_shape = (1, 1, 3, 3), same_on_batch = False

    def call(self, batch_shape, same_on_batch=False):
        from ....utils.helpers import tensorflow__extract_device_dtype
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...utils.helpers import tensorflow__adapted_rsampling
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_exp_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_floor_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_round_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_sqrt_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_cumsum_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_bool_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_arange_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_round_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_where_frnt_
        from .....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ....core._backend import tensor
        from ....core._backend import zeros
    
        batch_size = batch_shape[0]
        size = batch_shape[-2], batch_shape[-1]
        _device, _dtype = tensorflow__extract_device_dtype([self.scale, self.ratio])
        if batch_size == 0:
            return {
                "src": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "dst": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "size": zeros([0, 2], device=_device, dtype=_dtype),
            }
        rand = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.rand_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        area = (
            (rand * (self.scale[1] - self.scale[0]) + self.scale[0]) * size[0] * size[1]
        )
        log_ratio = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.log_ratio_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        aspect_ratio = tensorflow_exp_frnt(log_ratio)
        w = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area * aspect_ratio))
        )
        h = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area / aspect_ratio))
        )
>       cond = tensorflow_int_frnt_((0 < w) * (w < size[0]) * (0 < h) * (h < size[1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/random_generator/_2d/crop.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
rhs = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
x2 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ResizedCropGenerator.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ResizedCropGenerator.call():
E         • batch_shape=('1', '1', '3', '3')
E         • same_on_batch=False

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:353: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomResizedCrop
______________________________________________________________________________ test_RandomRotation[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRotation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation")
    
        init_args = ()
        init_kwargs = {"degrees": 45.0, "p": 1.}
        call_args = (torch.tensor([[1., 0., 0., 2.],
                                   [0., 0., 0., 0.],
                                   [0., 1., 2., 0.],
                                   [0., 0., 1., 2.]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:271: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.rotation.RandomRotation'>, target = 'tensorflow', init_args = (), init_kwargs = {'degrees': 45.0, 'p': 1.0}
call_args = (tensor([[1., 0., 0., 2.],
        [0., 0., 0., 0.],
        [0., 1., 2., 0.],
        [0., 0., 1., 2.]]),), call_kwargs = {}, deterministic_output = False, backend_compile = False
tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f4b6cb63c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=Tru...=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True), v = None, buffers = None
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=Tru...=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True), v = None, buffers = None
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>, replace_v = False
replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True),)
kwargs = {'input': <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-43.154007], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f4b72a50af0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f4b5c547880>
tensor = <function tensorflow_tensor_frnt at 0x7f4b5c4b8430>
in_tensor = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([4, 4]), batch_shape = ivy.frontends.torch.Size([1, 1, 4, 4]), flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
in_tensor = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-43.154007], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-43.154007], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_is_autocast_enabled
        from ....ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not tensorflow_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif tensorflow_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-43.154007], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ....geometry.transform.affwarp import tensorflow__compute_tensor_center
        from ....geometry.transform.affwarp import tensorflow__compute_rotation_matrix
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....utils.misc import tensorflow_eye_like
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        angles: typing.Any = tensorflow_to_frnt_(params["degrees"], input)
        center: typing.Any = tensorflow__compute_tensor_center(input)
        rotation_mat: typing.Any = tensorflow__compute_rotation_matrix(
>           angles, center.expand(tensorflow_shape_frnt_(angles)[0], -1)
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomRotation.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'expand'[0m
E       
E       Arguments received by tensorflow_RandomRotation.call():
E         • input=tf.Tensor(shape=(4, 4), dtype=float32)
E         • params=None
E         • kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/geometric/rotation.py:70: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation
______________________________________________________________________________ test_RandomCutMixV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:355: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.3981, 0.1825, 0.2567],
          [0.5054, 0.0926, 0.5873],
          [0.8063, 0.5218, 0.6598]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
>       transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)

kornia/augmentation/test_augmentation3.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66f77ee0>, node = <gast.gast.Module object at 0x7f4b66b65ab0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66f77ee0>, node = <gast.gast.Module object at 0x7f4b66b65ab0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66f77ee0>, node = <gast.gast.ClassDef object at 0x7f4b66b656c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66f77ee0>, node = <gast.gast.FunctionDef object at 0x7f4b66b64d30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66f77ee0>, node = <gast.gast.AnnAssign object at 0x7f4b678be770>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66f77ee0>, node = <gast.gast.Call object at 0x7f4b678bf4f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66f77ee0>, node = <gast.gast.Call object at 0x7f4b678bf4f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66f77ee0>, node = <gast.gast.Attribute object at 0x7f4b678bf310>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.Module object at 0x7f4b66f82b00>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.Module object at 0x7f4b66f82b00>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.ClassDef object at 0x7f4b66f83850>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.FunctionDef object at 0x7f4b6c5a0a90>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.Assign object at 0x7f4b6cc249d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.Assign object at 0x7f4b6cc249d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.Call object at 0x7f4b6cc24730>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.Call object at 0x7f4b6cc24730>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5c11ff40>, node = <gast.gast.Attribute object at 0x7f4b6d2ab700>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.Module object at 0x7f4b6d3f6380>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.Module object at 0x7f4b6d3f6380>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.ClassDef object at 0x7f4b6d3f4a00>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.FunctionDef object at 0x7f4b6d3f5d80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.Assign object at 0x7f4b5cfe9de0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.Assign object at 0x7f4b5cfe9de0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.Call object at 0x7f4b5cfe8280>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.Call object at 0x7f4b5cfe8280>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66d502e0>, node = <gast.gast.Attribute object at 0x7f4b6492e3b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Module object at 0x7f4b673c0310>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Module object at 0x7f4b673c0310>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.ClassDef object at 0x7f4b673c1bd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.FunctionDef object at 0x7f4b6d5d0190>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Return object at 0x7f4b6d5d16c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Return object at 0x7f4b6d5d16c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Call object at 0x7f4b66f81270>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Call object at 0x7f4b66f81270>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Attribute object at 0x7f4b66f80d90>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Attribute object at 0x7f4b66f80d90>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b5cde8e80>, node = <gast.gast.Name object at 0x7f4b66f81360>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b72b168c0>, node = <gast.gast.Module object at 0x7f4b6d1c1cc0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b72b168c0>, node = <gast.gast.Module object at 0x7f4b6d1c1cc0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b72b168c0>, node = <gast.gast.ClassDef object at 0x7f4b6d1c2bc0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66b52d70>, node = <gast.gast.Module object at 0x7f4b67dbf9a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66b52d70>, node = <gast.gast.Module object at 0x7f4b67dbf9a0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66b52d70>, node = <gast.gast.ClassDef object at 0x7f4b67dbd960>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66fd8910>, node = <gast.gast.Module object at 0x7f4b671765f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66fd8910>, node = <gast.gast.Module object at 0x7f4b671765f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7f4b66fd8910>, node = <gast.gast.ClassDef object at 0x7f4b67177850>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IM.pyx:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
_______________________________________________________________________________ test_RandomJigsaw[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'tensorflow', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[-0.0771, -0.1225, -0.5411,  ...,  0.2466,  0.2474,  0.3244],
          [-0.7435, -0.8002,  0.4948,  ...,  ...-0.0110,  ..., -0.5119,  0.6523, -0.9446],
          [ 1.0899, -1.3319, -1.3093,  ...,  0.1342, -0.2805,  0.7106]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4))
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-0.07708812, -0.12245295, -0.54111046, ...,  0.24...    [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f4b6d3fba40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...     [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-0.07708812, -0.12245295, -0.54111046, ...,  0.24...    [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...     [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-0.07708812, -0.12245295, -0.54111046, ...,  0.24...    [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-0.07708812, -0.12245295, -0.54111046, ...,  0.246...      [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-0.07708812, -0.12245295, -0.54111046, ....     [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-0.07708812, -0.12245295, -0.54111046, ....     [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-0.07708812, -0.12245295, -0.54111046, ....     [ 1.0899123 , -1.3318676 , -1.3092614 , ...,  0.13418108,
          -0.28050488,  0.7105672 ]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
_______________________________________________________________________________ test_RandomMixUpV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:395: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.4504, 0.1954, 0.5938],
          [0.1281, 0.8487, 0.7261],
          [0.8750, 0.8398, 0.1235]]],


        [[[0.9898, 0.1386, 0.9020],
          [0.4406, 0.6287, 0.8654],
          [0.3626, 0.7909, 0.7320]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.45038253, 0.19538862, 0.5938389 ],
         [0.1281...   [0.36262304, 0.79092056, 0.73196423]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5557c8c78150, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.36262304, 0.79092056, 0.73196423]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.45038253, 0.19538862, 0.5938389 ],
         [0.1281...   [0.36262304, 0.79092056, 0.73196423]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.36262304, 0.79092056, 0.73196423]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.45038253, 0.19538862, 0.5938389 ],
         [0.1281...   [0.36262304, 0.79092056, 0.73196423]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.45038253, 0.19538862, 0.5938389 ],
         [0.12810...682 ],
         [0.44058013, 0.62866884, 0.8654224 ],
         [0.36262304, 0.79092056, 0.73196423]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.45038253, 0.19538862, 0.5938389 ],
       ...2304, 0.79092056, 0.73196423]]]], dtype=float32)>, 'params': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.45038253, 0.19538862, 0.5938389 ],
       ...82 ],
         [0.44058013, 0.62866884, 0.8654224 ],
         [0.36262304, 0.79092056, 0.73196423]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.45038253, 0.19538862, 0.5938389 ],
       ...82 ],
         [0.44058013, 0.62866884, 0.8654224 ],
         [0.36262304, 0.79092056, 0.73196423]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomResizedCrop[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling ten...
FAILED kornia/augmentation/test_augmentation3.py::test_RandomRotation[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomRotation.call().
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[tensorflow-s2s-False] - OSError: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
============================================================================== 5 failed, 11 passed in 3576.82s (0:59:36) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py .........F...FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_RandomRotation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRotation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation")
    
        init_args = ()
        init_kwargs = {"degrees": 45.0, "p": 1.}
        call_args = (torch.tensor([[1., 0., 0., 2.],
                                   [0., 0., 0., 0.],
                                   [0., 1., 2., 0.],
                                   [0., 0., 1., 2.]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:271: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.rotation.RandomRotation'>, target = 'jax', init_args = (), init_kwargs = {'degrees': 45.0, 'p': 1.0}
call_args = (tensor([[1., 0., 0., 2.],
        [0., 0., 0., 0.],
        [0., 1., 2., 0.],
        [0., 0., 1., 2.]]),), call_kwargs = {}, deterministic_output = False, backend_compile = False
tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fba002a9cf0>, jax_set_item = <function jax_set_item at 0x7fba08e57910>, tensor = <function jax_tensor_frnt at 0x7fba002f32e0>
in_tensor = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32), input_shape = ivy.frontends.torch.Size([4, 4])
batch_shape = ivy.frontends.torch.Size([1, 1, 4, 4]), flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
in_tensor = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_is_autocast_enabled
        from ....ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not jax_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif jax_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....geometry.transform.affwarp import jax__compute_tensor_center
        from ....geometry.transform.affwarp import jax__compute_rotation_matrix
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....utils.misc import jax_eye_like
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        angles: typing.Any = jax_to_frnt_(params["degrees"], input)
        center: typing.Any = jax__compute_tensor_center(input)
        rotation_mat: typing.Any = jax__compute_rotation_matrix(
>           angles, center.expand(jax_shape_frnt_(angles)[0], -1)
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/geometric/rotation.py:66: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation
__________________________________________________________________________________ test_RandomCutMixV2[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:355: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.8484, 0.9120, 0.5273],
          [0.6635, 0.7349, 0.4014],
          [0.6810, 0.8587, 0.5770]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
>       transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)

kornia/augmentation/test_augmentation3.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20720e80>, node = <gast.gast.Module object at 0x7fba20f3ec50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20720e80>, node = <gast.gast.Module object at 0x7fba20f3ec50>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20720e80>, node = <gast.gast.ClassDef object at 0x7fba20f3ca60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20720e80>, node = <gast.gast.FunctionDef object at 0x7fba002fc6d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20720e80>, node = <gast.gast.AnnAssign object at 0x7fba325f17e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20720e80>, node = <gast.gast.Call object at 0x7fba325f1090>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20720e80>, node = <gast.gast.Call object at 0x7fba325f1090>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20720e80>, node = <gast.gast.Attribute object at 0x7fba325f2200>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.Module object at 0x7fba3d389540>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.Module object at 0x7fba3d389540>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.ClassDef object at 0x7fba3d389bd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.FunctionDef object at 0x7fba3363e500>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.Assign object at 0x7fba3363e230>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.Assign object at 0x7fba3363e230>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.Call object at 0x7fb9eca0cb20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.Call object at 0x7fb9eca0cb20>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3816a020>, node = <gast.gast.Attribute object at 0x7fba0059bc40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.Module object at 0x7fba002643d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.Module object at 0x7fba002643d0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.ClassDef object at 0x7fba00266050>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.FunctionDef object at 0x7fba002645e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.Assign object at 0x7fba00265ff0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.Assign object at 0x7fba00265ff0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.Call object at 0x7fba002651b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.Call object at 0x7fba002651b0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba00251ea0>, node = <gast.gast.Attribute object at 0x7fba08c9ee60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Module object at 0x7fba0872a170>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Module object at 0x7fba0872a170>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.ClassDef object at 0x7fba00905060>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.FunctionDef object at 0x7fba206c6650>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Return object at 0x7fba206c7af0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Return object at 0x7fba206c7af0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Call object at 0x7fba08564100>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Call object at 0x7fba08564100>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Attribute object at 0x7fba08564c40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Attribute object at 0x7fba08564c40>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba3d36ac80>, node = <gast.gast.Name object at 0x7fba085663e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba2063b940>, node = <gast.gast.Module object at 0x7fba005ba710>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba2063b940>, node = <gast.gast.Module object at 0x7fba005ba710>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba2063b940>, node = <gast.gast.ClassDef object at 0x7fba005b91b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba319d0040>, node = <gast.gast.Module object at 0x7fba005990c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba319d0040>, node = <gast.gast.Module object at 0x7fba005990c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba319d0040>, node = <gast.gast.ClassDef object at 0x7fba005989d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20c4b310>, node = <gast.gast.Module object at 0x7fba20694f40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20c4b310>, node = <gast.gast.Module object at 0x7fba20694f40>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fba20c4b310>, node = <gast.gast.ClassDef object at 0x7fba20696140>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IM.pyx:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
___________________________________________________________________________________ test_RandomJigsaw[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'jax', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[ 1.5383,  0.1251, -0.1025,  ...,  0.7306, -1.0776,  1.4399],
          [ 0.3938,  0.2503, -0.3712,  ..., -... 0.1515,  ..., -0.2001,  1.1289, -0.5796],
          [-0.4568,  1.9168, -0.5126,  ..., -0.5340,  0.4711, -2.0762]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), params = None, data_keys = None
input = (Array([[[[ 1.538308  ,  0.12505569, -0.10250685, ...,  0.73057777,
          -1.0775858 ,  1.4399323 ],
         [ 0....     [-0.45677054,  1.9167706 , -0.51263446, ..., -0.53395766,
           0.4710831 , -2.0762167 ]]]], dtype=float32),)
tensor = <function jax_tensor_frnt at 0x7fba001c80d0>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
__________________________________________________________________________________ test_RandomMixUpV2[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:395: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.6896, 0.9733, 0.1156],
          [0.7174, 0.9718, 0.6899],
          [0.6499, 0.5495, 0.7887]]],


        [[[0.0198, 0.3015, 0.2645],
          [0.3287, 0.7584, 0.2050],
          [0.6186, 0.3884, 0.4114]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), params = None, data_keys = None
input = (Array([[[[0.6896286 , 0.97331905, 0.11564934],
         [0.7173841 , 0.9718148 , 0.6899281 ],
         [0.6498961 , 0... 0.75844896, 0.2050395 ],
         [0.61855704, 0.388386  , 0.41137147]]]], dtype=float32), Array([0, 1], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7fba329a1ea0>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomRotation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[jax-s2s-False] - OSError: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[jax-s2s-False] - KeyError: '2'
============================================================================== 4 failed, 12 passed in 3101.16s (0:51:41) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F............                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_upscale_double[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f4e67b505e0>
trace_args = (tensor([[[[0.1003, 0.5908, 0.4665, 0.7725],
          [0.0590, 0.7112, 0.3539, 0.1397],
          [0.5021, 0.6896, 0...., 0.2700, 0.9862, 0.1921],
          [0.0808, 0.3847, 0.5261, 0.9818],
          [0.9870, 0.0812, 0.2484, 0.5300]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.7833, 0.7124, 0.5265, 0.9436, 0.1200, 0.6017, 0.8893, 0.0953],
          [0.3078, 0.3990, 0.1032, 0.4867...0956, 0.4692, 0.1875, 0.9247, 0.6897],
          [0.1322, 0.3684, 0.3571, 0.2419, 0.1045, 0.9081, 0.0296, 0.3829]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f4e67b505e0>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.1003, 0.5908, 0.4665, 0.7725],
          [0.0590, 0.7112, 0.3539, 0.1397],
          [0.5021, 0.6896, 0...., 0.2700, 0.9862, 0.1921],
          [0.0808, 0.3847, 0.5261, 0.9818],
          [0.9870, 0.0812, 0.2484, 0.5300]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.7833, 0.7124, 0.5265, 0.9436, 0.1200, 0.6017, 0.8893, 0.0953],
          [0.3078, 0.3990, 0.1032, 0.4867...0956, 0.4692, 0.1875, 0.9247, 0.6897],
          [0.1322, 0.3684, 0.3571, 0.2419, 0.1045, 0.9081, 0.0296, 0.3829]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.10029769, 0.59083265, 0.4664687 , 0.77249867],
         [0.05904841, 0.7111507 , 0.35390502, 0.13965434],
... 0.38472247, 0.5260748 , 0.98184836],
         [0.98700315, 0.08121651, 0.2483651 , 0.5299786 ]]]],      dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.10029769, 0.        , 0.59083265, 0.        , 0.4664687 ,
          0.        , 0.77249867, 0.        ],
 ...     , 0.        , 0.        , 0.        , 0.        ,
          0.        , 0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.34556517, 0.52865064, 0.6194837 , 0.        ],
         [0.38509956, 0.53252786, 0.24677968, 0.        ],
... 0.45539865, 0.75396156, 0.        ],
         [0.53410983, 0.16479081, 0.38917184, 0.        ]]]],      dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("'{}' object does not support item assignment. JAX arrays are "
             "immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` "
             "or another .at[] method: "
             "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:587: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
______________________________________________________________________________________ test_Shear[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledShear = ivy.transpile(kornia.geometry.transform.Shear, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = TranspiledShear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Shear()
input = Array([[[[0.4272248 , 0.12229681, 0.38439816, 0.3381861 ],
         [0.7281403 , 0.06104338, 0.06078386, 0.428083  ],
... 0.68256086, 0.7180881 , 0.13125461],
         [0.43907917, 0.66975385, 0.87448126, 0.59906536]]]],      dtype=float32)

    def __call__(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: name 'shear' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/affwarp.py:52: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[jax-s2s-False] - TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutabl...
FAILED kornia/geometry/test_transform.py::test_Shear[jax-s2s-False] - NameError: name 'shear' is not defined
============================================================================== 2 failed, 54 passed in 4787.67s (1:19:47) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ..                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 131.08s (0:02:11) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py FFFF.F.F                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_find_homography_dlt[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4), 'solver': 'svd'}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4), 'solver': 'svd'}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7f6ba51d7130>
trace_args = (tensor([[[0.1418, 0.0959],
         [0.2315, 0.3193],
         [0.7961, 0.6746],
         [0.4404, 0.6848]]]), tensor([[[0.8261, 0.4530],
         [0.6120, 0.3012],
         [0.8526, 0.8097],
         [0.3896, 0.0993]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.3230, 0.3497, 0.9296, 0.4323]])}
test_args = (tensor([[[0.8214, 0.1671],
         [0.7794, 0.0312],
         [0.4967, 0.5197],
         [0.6306, 0.7616]],

       ...6248]],

        [[0.5674, 0.0990],
         [0.6346, 0.5441],
         [0.8015, 0.2287],
         [0.0879, 0.4595]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[0.9481, 0.5432, 0.3184, 0.6298],
        [0.4933, 0.6163, 0.8047, 0.5914],
        [0.3510, 0.2494, 0.0930, 0.5451],
        [0.9444, 0.8237, 0.1387, 0.3878],
        [0.3207, 0.6842, 0.4479, 0.8815]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7f6ba51d7130>, fn_name = 'kornia.geometry.homography.find_homography_dlt'
trace_args = (tensor([[[0.1418, 0.0959],
         [0.2315, 0.3193],
         [0.7961, 0.6746],
         [0.4404, 0.6848]]]), tensor([[[0.8261, 0.4530],
         [0.6120, 0.3012],
         [0.8526, 0.8097],
         [0.3896, 0.0993]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.3230, 0.3497, 0.9296, 0.4323]])}
test_args = (tensor([[[0.8214, 0.1671],
         [0.7794, 0.0312],
         [0.4967, 0.5197],
         [0.6306, 0.7616]],

       ...6248]],

        [[0.5674, 0.0990],
         [0.6346, 0.5441],
         [0.8015, 0.2287],
         [0.0879, 0.4595]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[0.9481, 0.5432, 0.3184, 0.6298],
        [0.4933, 0.6163, 0.8047, 0.5914],
        [0.3510, 0.2494, 0.0930, 0.5451],
        [0.9444, 0.8237, 0.1387, 0.3878],
        [0.3207, 0.6842, 0.4479, 0.8815]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.1418491 , 0.09588546],
        [0.2315275 , 0.3192721 ],
        [0.7961495 , 0.6745798 ],
        [0.44043094, 0.6848263 ]]], dtype=float32)
points2 = array([[[0.8260566 , 0.45298326],
        [0.6119774 , 0.30120808],
        [0.8526367 , 0.8097382 ],
        [0.3896292 , 0.09931201]]], dtype=float32)
weights = array([[0.32301247, 0.34966195, 0.92958516, 0.43226725]], dtype=float32), solver = 'svd'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.32301247, 0.32301247, 0.34966195, 0.34966195, 0.92958516,
         0.92958516, 0.43226725, 0.43226725]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
__________________________________________________________________________ test_find_homography_dlt_iterated[numpy-s2s-False] __________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f6ba51d7250>
trace_args = (tensor([[[0.1204, 0.6394],
         [0.4887, 0.8591],
         [0.2607, 0.7979],
         [0.7705, 0.0165]]]), tensor... [0.5977, 0.1143],
         [0.5269, 0.3127],
         [0.0936, 0.5420]]]), tensor([[0.5469, 0.7921, 0.7542, 0.4565]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.5830, 0.4097],
         [0.6321, 0.2280],
         [0.1263, 0.6242],
         [0.3015, 0.4323]],

       ...[0.9667, 0.8858, 0.4399, 0.5868],
        [0.4694, 0.3643, 0.6943, 0.7234],
        [0.8831, 0.1636, 0.3241, 0.8939]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f6ba51d7250>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.1204, 0.6394],
         [0.4887, 0.8591],
         [0.2607, 0.7979],
         [0.7705, 0.0165]]]), tensor... [0.5977, 0.1143],
         [0.5269, 0.3127],
         [0.0936, 0.5420]]]), tensor([[0.5469, 0.7921, 0.7542, 0.4565]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.5830, 0.4097],
         [0.6321, 0.2280],
         [0.1263, 0.6242],
         [0.3015, 0.4323]],

       ...[0.9667, 0.8858, 0.4399, 0.5868],
        [0.4694, 0.3643, 0.6943, 0.7234],
        [0.8831, 0.1636, 0.3241, 0.8939]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.12042069, 0.6394109 ],
        [0.48869687, 0.85911226],
        [0.2607214 , 0.7978625 ],
        [0.77052146, 0.01650763]]], dtype=float32)
points2 = array([[[0.39499563, 0.9943696 ],
        [0.5976988 , 0.11429167],
        [0.52687246, 0.31273502],
        [0.09357274, 0.5419809 ]]], dtype=float32)
weights = array([[0.5468587 , 0.7920947 , 0.7542105 , 0.45653886]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def numpy_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:183: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.12042069, 0.6394109 ],
        [0.48869687, 0.85911226],
        [0.2607214 , 0.7978625 ],
        [0.77052146, 0.01650763]]], dtype=float32)
points2 = array([[[0.39499563, 0.9943696 ],
        [0.5976988 , 0.11429167],
        [0.52687246, 0.31273502],
        [0.09357274, 0.5419809 ]]], dtype=float32)
weights = array([[0.5468587 , 0.7920947 , 0.7542105 , 0.45653886]], dtype=float32), solver = 'lu'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.5468587 , 0.5468587 , 0.7920947 , 0.7920947 , 0.7542105 ,
         0.7542105 , 0.45653886, 0.45653886]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
___________________________________________________________________________ test_find_homography_lines_dlt[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4)}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4)}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7f6ba51d7370>
trace_args = (tensor([[[[0.8077, 0.7151],
          [0.6604, 0.3120]],

         [[0.6646, 0.5393],
          [0.1749, 0.7455]],

 ...

         [[0.3089, 0.8382],
          [0.1426, 0.4777]],

         [[0.1909, 0.2412],
          [0.1413, 0.4572]]]]))
trace_kwargs = {'weights': tensor([[0.7109, 0.7359, 0.3490, 0.8576]])}
test_args = (tensor([[[[0.1010, 0.9282],
          [0.1775, 0.7130]],

         [[0.4131, 0.5663],
          [0.4525, 0.8874]],

 ...

         [[0.7840, 0.8639],
          [0.6152, 0.4834]],

         [[0.5769, 0.8491],
          [0.1950, 0.3346]]]]))
test_kwargs = {'weights': tensor([[0.9132, 0.3267, 0.1323, 0.6612],
        [0.1650, 0.6873, 0.0670, 0.6495],
        [0.0463, 0.8273, 0.0677, 0.5024],
        [0.8393, 0.9729, 0.9400, 0.4313],
        [0.2159, 0.8463, 0.7422, 0.5767]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7f6ba51d7370>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt'
trace_args = (tensor([[[[0.8077, 0.7151],
          [0.6604, 0.3120]],

         [[0.6646, 0.5393],
          [0.1749, 0.7455]],

 ...

         [[0.3089, 0.8382],
          [0.1426, 0.4777]],

         [[0.1909, 0.2412],
          [0.1413, 0.4572]]]]))
trace_kwargs = {'weights': tensor([[0.7109, 0.7359, 0.3490, 0.8576]])}
test_args = (tensor([[[[0.1010, 0.9282],
          [0.1775, 0.7130]],

         [[0.4131, 0.5663],
          [0.4525, 0.8874]],

 ...

         [[0.7840, 0.8639],
          [0.6152, 0.4834]],

         [[0.5769, 0.8491],
          [0.1950, 0.3346]]]]))
test_kwargs = {'weights': tensor([[0.9132, 0.3267, 0.1323, 0.6612],
        [0.1650, 0.6873, 0.0670, 0.6495],
        [0.0463, 0.8273, 0.0677, 0.5024],
        [0.8393, 0.9729, 0.9400, 0.4313],
        [0.2159, 0.8463, 0.7422, 0.5767]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.80767494, 0.71511644],
         [0.6603647 , 0.31196994]],

        [[0.6646392 , 0.53926706],
         [0...    [0.07137799, 0.72039753]],

        [[0.21966374, 0.24188924],
         [0.51817805, 0.0882116 ]]]], dtype=float32)
ls2 = array([[[[0.6549655 , 0.36203557],
         [0.7301814 , 0.8502225 ]],

        [[0.9781119 , 0.21508658],
         [0...    [0.14263153, 0.47772425]],

        [[0.19090873, 0.24115813],
         [0.14133877, 0.45721018]]]], dtype=float32)
weights = array([[0.7109438 , 0.7359416 , 0.3490417 , 0.85761404]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.7109438 , 0.7109438 , 0.7359416 , 0.7359416 , 0.3490417 ,
         0.3490417 , 0.85761404, 0.85761404]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
_______________________________________________________________________ test_find_homography_lines_dlt_iterated[numpy-s2s-False] _______________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7f6ba51d7490>
trace_args = (tensor([[[[0.9141, 0.6951],
          [0.6233, 0.1170]],

         [[0.8102, 0.2112],
          [0.9176, 0.2487]],

 ...826, 0.3345]],

         [[0.9989, 0.5983],
          [0.1717, 0.6162]]]]), tensor([[0.2801, 0.1663, 0.8999, 0.8724]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.7838, 0.7640],
          [0.5216, 0.0570]],

         [[0.1992, 0.4884],
          [0.1877, 0.8125]],

 ...[0.5285, 0.2254, 0.6775, 0.8006],
        [0.7421, 0.4420, 0.8755, 0.6128],
        [0.3482, 0.1246, 0.3363, 0.8342]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7f6ba51d7490>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt_iterated'
trace_args = (tensor([[[[0.9141, 0.6951],
          [0.6233, 0.1170]],

         [[0.8102, 0.2112],
          [0.9176, 0.2487]],

 ...826, 0.3345]],

         [[0.9989, 0.5983],
          [0.1717, 0.6162]]]]), tensor([[0.2801, 0.1663, 0.8999, 0.8724]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.7838, 0.7640],
          [0.5216, 0.0570]],

         [[0.1992, 0.4884],
          [0.1877, 0.8125]],

 ...[0.5285, 0.2254, 0.6775, 0.8006],
        [0.7421, 0.4420, 0.8755, 0.6128],
        [0.3482, 0.1246, 0.3363, 0.8342]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.914134  , 0.695117  ],
         [0.62332326, 0.11700779]],

        [[0.8101653 , 0.21117383],
         [0...    [0.23392016, 0.61970764]],

        [[0.9884695 , 0.75391173],
         [0.87347525, 0.84109914]]]], dtype=float32)
ls2 = array([[[[0.6849183 , 0.3166268 ],
         [0.02422589, 0.27367985]],

        [[0.83083177, 0.26431698],
         [0...    [0.98257643, 0.33448827]],

        [[0.99885345, 0.5982903 ],
         [0.17165303, 0.61616135]]]], dtype=float32)
weights = array([[0.2800759 , 0.16632932, 0.8998926 , 0.8724403 ]], dtype=float32), soft_inl_th = 4.0, n_iter = 5

    def numpy_find_homography_lines_dlt_iterated(
        ls1, ls2, weights, soft_inl_th=4.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_lines_dlt(ls1, ls2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.914134  , 0.695117  ],
         [0.62332326, 0.11700779]],

        [[0.8101653 , 0.21117383],
         [0...    [0.23392016, 0.61970764]],

        [[0.9884695 , 0.75391173],
         [0.87347525, 0.84109914]]]], dtype=float32)
ls2 = array([[[[0.6849183 , 0.3166268 ],
         [0.02422589, 0.27367985]],

        [[0.83083177, 0.26431698],
         [0...    [0.98257643, 0.33448827]],

        [[0.99885345, 0.5982903 ],
         [0.17165303, 0.61616135]]]], dtype=float32)
weights = array([[0.2800759 , 0.16632932, 0.8998926 , 0.8724403 ]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.2800759 , 0.2800759 , 0.16632932, 0.16632932, 0.8998926 ,
         0.8998926 , 0.8724403 , 0.8724403 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
_____________________________________________________________________________ test_oneway_transfer_error[numpy-s2s-False] ______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_oneway_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': False, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': False, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.oneway_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7f6ba51d6ef0>
trace_args = (tensor([[[0.6907, 0.5230],
         [0.5594, 0.0288],
         [0.4816, 0.8378],
         [0.1186, 0.6494]]]), tensor...0.3295]]]), tensor([[[0.3157, 0.7926, 0.0917],
         [0.0852, 0.5813, 0.5193],
         [0.4814, 0.0587, 0.3892]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.1661, 0.4302],
         [0.1732, 0.8798],
         [0.4024, 0.7129],
         [0.7613, 0.5371]],

       ... 0.9500]],

        [[0.9639, 0.8108, 0.7695],
         [0.1712, 0.7155, 0.0920],
         [0.3736, 0.5078, 0.1981]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7f6ba51d6ef0>, fn_name = 'kornia.geometry.homography.oneway_transfer_error'
trace_args = (tensor([[[0.6907, 0.5230],
         [0.5594, 0.0288],
         [0.4816, 0.8378],
         [0.1186, 0.6494]]]), tensor...0.3295]]]), tensor([[[0.3157, 0.7926, 0.0917],
         [0.0852, 0.5813, 0.5193],
         [0.4814, 0.0587, 0.3892]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.1661, 0.4302],
         [0.1732, 0.8798],
         [0.4024, 0.7129],
         [0.7613, 0.5371]],

       ... 0.9500]],

        [[0.9639, 0.8108, 0.7695],
         [0.1712, 0.7155, 0.0920],
         [0.3736, 0.5078, 0.1981]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.6906868 , 0.52296066],
        [0.55938476, 0.02880532],
        [0.481551  , 0.8378051 ],
        [0.11864853, 0.64943254]]], dtype=float32)
pts2 = array([[[0.4918971 , 0.6095929 ],
        [0.13544524, 0.7347299 ],
        [0.74197257, 0.5612258 ],
        [0.00096387, 0.3294813 ]]], dtype=float32)
H = array([[[0.31570077, 0.79263675, 0.09166104],
        [0.08520627, 0.58128095, 0.51933706],
        [0.48140383, 0.05872577, 0.3891731 ]]], dtype=float32), squared = False, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[0.47068268, 0.562914  ],
        [0.30549896, 0.14952362],
        [0.6125035 , 1.0015572 ],
        [1.328193  , 1.5427203 ]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f6b4c6617e0>
array_like = array([[[0.47068268, 0.562914  ],
        [0.30549896, 0.14952362],
        [0.6125035 , 1.0015572 ],
        [1.328193  , 1.5427203 ]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[0.47068268, 0.562914  ],
        [0.30549896, 0.14952362],
        [0.6125035 , 1.0015572 ],
        [1.328193  , 1.5427203 ]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[0.47068268, 0.562914  ],
        [0.30549896, 0.14952362],
        [0.6125035 , 1.0015572 ],
        [1.328193  , 1.5427203 ]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f6b4c6617e0>
array_like = array([[[0.47068268, 0.562914  ],
        [0.30549896, 0.14952362],
        [0.6125035 , 1.0015572 ],
        [1.328193  , 1.5427203 ]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.47068268, 0.562914  ],
        [0.30549896, 0.14952362],
        [0.6125035 , 1.0015572 ],
        [1.328193  , 1.5427203 ]]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[0.47068268, 0.562914  ],
        [0.30549896, 0.14952362],
        [0.6125035 , 1.0015572 ],
        [1.328193  , 1.5427203 ]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.oneway_transfer_error
____________________________________________________________________________ test_symmetric_transfer_error[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetric_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.symmetric_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7f6ba51d7010>
trace_args = (tensor([[[0.2338, 0.9863],
         [0.5309, 0.5518],
         [0.5950, 0.5838],
         [0.2252, 0.2991]]]), tensor...0.3661]]]), tensor([[[0.8374, 0.6661, 0.0716],
         [0.1892, 0.5964, 0.5497],
         [0.2433, 0.1459, 0.0598]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.3419, 0.7894],
         [0.4725, 0.4445],
         [0.0248, 0.5624],
         [0.7574, 0.5195]],

       ... 0.3051]],

        [[0.9453, 0.4569, 0.8967],
         [0.9384, 0.1709, 0.1468],
         [0.2052, 0.6813, 0.5427]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7f6ba51d7010>, fn_name = 'kornia.geometry.homography.symmetric_transfer_error'
trace_args = (tensor([[[0.2338, 0.9863],
         [0.5309, 0.5518],
         [0.5950, 0.5838],
         [0.2252, 0.2991]]]), tensor...0.3661]]]), tensor([[[0.8374, 0.6661, 0.0716],
         [0.1892, 0.5964, 0.5497],
         [0.2433, 0.1459, 0.0598]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.3419, 0.7894],
         [0.4725, 0.4445],
         [0.0248, 0.5624],
         [0.7574, 0.5195]],

       ... 0.3051]],

        [[0.9453, 0.4569, 0.8967],
         [0.9384, 0.1709, 0.1468],
         [0.2052, 0.6813, 0.5427]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.23379505, 0.98634326],
        [0.53091973, 0.5518311 ],
        [0.59501886, 0.58380324],
        [0.22517699, 0.29907393]]], dtype=float32)
pts2 = array([[[0.9630579 , 0.7926863 ],
        [0.37823254, 0.38011813],
        [0.8053373 , 0.4925545 ],
        [0.03617495, 0.36606407]]], dtype=float32)
H = array([[[0.837425  , 0.66605747, 0.07164961],
        [0.18919891, 0.59639764, 0.5496728 ],
        [0.2433371 , 0.1458916 , 0.05979991]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetric_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from ...ivy.functional.frontends.torch.miscellaneous_ops import numpy_finfo_frnt
        from ..utils.helpers import numpy_safe_inverse_with_mask
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        max_num = numpy_finfo_frnt(pts1.dtype).max
        H_inv, good_H = numpy_safe_inverse_with_mask(H)
>       there: typing.Any = numpy_oneway_transfer_error(pts1, pts2, H, True, eps)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.23379505, 0.98634326],
        [0.53091973, 0.5518311 ],
        [0.59501886, 0.58380324],
        [0.22517699, 0.29907393]]], dtype=float32)
pts2 = array([[[0.9630579 , 0.7926863 ],
        [0.37823254, 0.38011813],
        [0.8053373 , 0.4925545 ],
        [0.03617495, 0.36606407]]], dtype=float32)
H = array([[[0.837425  , 0.66605747, 0.07164961],
        [0.18919891, 0.59639764, 0.5496728 ],
        [0.2433371 , 0.1458916 , 0.05979991]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[2.5842628, 3.7437842],
        [2.9011984, 3.253401 ],
        [2.5035143, 2.9945428],
        [2.8673825, 4.5044503]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f6b4c58c670>
array_like = array([[[2.5842628, 3.7437842],
        [2.9011984, 3.253401 ],
        [2.5035143, 2.9945428],
        [2.8673825, 4.5044503]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[2.5842628, 3.7437842],
        [2.9011984, 3.253401 ],
        [2.5035143, 2.9945428],
        [2.8673825, 4.5044503]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:272: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[2.5842628, 3.7437842],
        [2.9011984, 3.253401 ],
        [2.5035143, 2.9945428],
        [2.8673825, 4.5044503]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f6b4c58c670>
array_like = array([[[2.5842628, 3.7437842],
        [2.9011984, 3.253401 ],
        [2.5035143, 2.9945428],
        [2.8673825, 4.5044503]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[2.5842628, 3.7437842],
        [2.9011984, 3.253401 ],
        [2.5035143, 2.9945428],
        [2.8673825, 4.5044503]]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[2.5842628, 3.7437842],
        [2.9011984, 3.253401 ],
        [2.5035143, 2.9945428],
        [2.8673825, 4.5044503]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.symmetric_transfer_error
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_oneway_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_homography.py::test_symmetric_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 6 failed, 2 passed in 536.27s (0:08:56) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ..                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 134.14s (0:02:14) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.....ssss                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_mean_average_precision[numpy-s2s-False] _____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f299aab24d0>
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f299aab24d0>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [array([1.], dtype=float32)], pred_scores = [array([0.7], dtype=float32)]
gt_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[numpy-s2s-False] - TypeError: 'int' object is not callable
========================================================================== 1 failed, 8 passed, 4 skipped in 469.95s (0:07:49) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 307.07s (0:05:07) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F.......F..FF                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_upscale_double[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f1bfea605e0>
trace_args = (tensor([[[[0.6031, 0.6904, 0.3983, 0.5528],
          [0.0164, 0.2684, 0.3495, 0.8612],
          [0.2993, 0.0420, 0...., 0.7285, 0.8152, 0.5674],
          [0.6310, 0.7936, 0.3031, 0.9267],
          [0.0665, 0.1942, 0.8787, 0.5783]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.6103, 0.9050, 0.2312, 0.3472, 0.7863, 0.0850, 0.4923, 0.7456],
          [0.4105, 0.4641, 0.1573, 0.6262...4191, 0.4422, 0.6142, 0.7439, 0.2008],
          [0.3987, 0.6974, 0.6901, 0.0523, 0.9174, 0.3581, 0.6620, 0.1253]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f1bfea605e0>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.6031, 0.6904, 0.3983, 0.5528],
          [0.0164, 0.2684, 0.3495, 0.8612],
          [0.2993, 0.0420, 0...., 0.7285, 0.8152, 0.5674],
          [0.6310, 0.7936, 0.3031, 0.9267],
          [0.0665, 0.1942, 0.8787, 0.5783]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.6103, 0.9050, 0.2312, 0.3472, 0.7863, 0.0850, 0.4923, 0.7456],
          [0.4105, 0.4641, 0.1573, 0.6262...4191, 0.4422, 0.6142, 0.7439, 0.2008],
          [0.3987, 0.6974, 0.6901, 0.0523, 0.9174, 0.3581, 0.6620, 0.1253]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 4, 4), dtype=float32, numpy=
array([[[[0.6030716 , 0.69044167, 0.39825088, 0.5528009 ],
     ....79359293, 0.30314302, 0.926652  ],
         [0.06647974, 0.19417173, 0.87871885, 0.5783403 ]]]],
      dtype=float32)>

    def tensorflow_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK_IS_TENSOR(x)
        tensorflow_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = tensorflow_shape_frnt_(x)[:-2] + (
            tensorflow_shape_frnt_(x)[-2] * 2,
            tensorflow_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = tensorflow_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = tensorflow_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )
E       TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/pyramid.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
___________________________________________________________________________________ test_Shear[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledShear = ivy.transpile(kornia.geometry.transform.Shear, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = TranspiledShear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.4453966 , 0.84035414, 0.5700084 , 0.31768048],
    ...8206104, 0.8387817 , 0.24798054],
         [0.4769969 , 0.5068369 , 0.20830464, 0.63119894]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f1babb4cfc0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.4453966 , 0.84035414, 0.5700084...78206104, 0.8387817 , 0.24798054],
         [0.4769969 , 0.5068369 , 0.20830464, 0.63119894]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.4453966 , 0.84035414, 0.5700084 , 0.31768048],
    ...8206104, 0.8387817 , 0.24798054],
         [0.4769969 , 0.5068369 , 0.20830464, 0.63119894]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2017: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.4453966 , 0.84035414, 0.5700084...78206104, 0.8387817 , 0.24798054],
         [0.4769969 , 0.5068369 , 0.20830464, 0.63119894]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.4453966 , 0.84035414, 0.5700084 , 0.31768048],
    ...8206104, 0.8387817 , 0.24798054],
         [0.4769969 , 0.5068369 , 0.20830464, 0.63119894]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.4453966 , 0.84035414, 0.5700084 , 0.31768048],
     ....78206104, 0.8387817 , 0.24798054],
         [0.4769969 , 0.5068369 , 0.20830464, 0.63119894]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.4453966 , 0.84035414, 0.5700084 , 0.317680...78206104, 0.8387817 , 0.24798054],
         [0.4769969 , 0.5068369 , 0.20830464, 0.63119894]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
input = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.4453966 , 0.84035414, 0.5700084 , 0.31768048],
     ....78206104, 0.8387817 , 0.24798054],
         [0.4769969 , 0.5068369 , 0.20830464, 0.63119894]]]],
      dtype=float32)>

    def call(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: Exception encountered when calling tensorflow_Shear.call().
E       
E       [1mname 'shear' is not defined[0m
E       
E       Arguments received by tensorflow_Shear.call():
E         • input=tf.Tensor(shape=(2, 3, 4, 4), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/affwarp.py:55: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
__________________________________________________________________________________ test_Rescale[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Rescale(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Rescale")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRescale = ivy.transpile(kornia.geometry.transform.Rescale, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 4, 4)
        torch_out = kornia.geometry.transform.Rescale((2.0, 3.0))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_out = TranspiledRescale((2.0, 3.0))(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/geometry/test_transform.py:1294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.0270, 0.2767, 0.5264, 0.7761, 0.9276, 0.8830, 0.8383, 0.7936,
           0.6580, 0.4770, 0.2960, 0.1150],...        [0.2253, 0.2533, 0.2813, 0.3094, 0.3800, 0.5360, 0.6919, 0.8478,
           0.8875, 0.8691, 0.8506, 0.8322]]]])
transpiled_x = <tf.Tensor: shape=(1, 3, 8, 12), dtype=float32, numpy=
array([[[[0.026995  , 0.026995  , 0.33217216, 0.6373493 , 0.942...      0.5186275 , 0.7092061 , 0.8997846 , 0.8772575 , 0.8547305 ,
          0.8322034 , 0.8322034 ]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.026995  , 0.2766854 , 0.5263758 , 0.7760662 , 0.9276333 ,
          0.8829541 , 0.8382749 , 0.7935958 , 0....       0.5359528 , 0.69188076, 0.84780866, 0.8874971 , 0.8690659 ,
          0.85063463, 0.8322034 ]]]], dtype=float32)
y = array([[[[0.026995  , 0.026995  , 0.33217216, 0.6373493 , 0.94252634,
          0.8879185 , 0.8333106 , 0.77870274, 0....       0.5186275 , 0.7092061 , 0.8997846 , 0.8772575 , 0.8547305 ,
          0.8322034 , 0.8322034 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Rescale
________________________________________________________________________________ test_Homography[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Homography(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Homography")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomography = ivy.transpile(
            kornia.geometry.transform.image_registrator.Homography, source="torch", target=target_framework
        )
    
        torch_out = kornia.geometry.transform.image_registrator.Homography()()
>       transpiled_out = TranspiledHomography()()

kornia/geometry/test_transform.py:1354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>), args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f1b786ce8f0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>),), kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>), v = None, buffers = None, args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>),), kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>), v = None, buffers = None, args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False
call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<KerasVariable shape=(3, 3), dtype=float32, path=variable>),), kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7f1b88fdaf20>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Homography
________________________________________________________________________________ test_Similarity[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Similarity(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Similarity")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSimilarity = ivy.transpile(
            kornia.geometry.transform.image_registrator.Similarity, source="torch", target=target_framework
        )
    
        torch_out = kornia.geometry.transform.image_registrator.Similarity()()
>       transpiled_out = TranspiledSimilarity()()

kornia/geometry/test_transform.py:1392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>)
args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x562dc1fca040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>),)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>)
v = None, buffers = None, args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>),)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Keras...e shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>)
v = None, buffers = None, args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False, call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <KerasVariable shape=(1,), dtype=float32, path=variable_1>,               
 shift=<Kera...shape=(1, 2, 1), dtype=float32, path=variable_2>, 
 scale=<KerasVariable shape=(1,), dtype=float32, path=variable_3>),)
kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7f1b88805240>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Similarity
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/geometry/test_transform.py::test_Shear[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_Shear.call().
FAILED kornia/geometry/test_transform.py::test_Rescale[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_transform.py::test_Homography[tensorflow-s2s-False] - IndexError: list index out of range
FAILED kornia/geometry/test_transform.py::test_Similarity[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 5 failed, 51 passed in 5436.39s (1:30:36) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 278.59s (0:04:38) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.33s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py .F.......F.FF                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_SOSNet[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_SOSNet(target_framework, mode, backend_compile):
        print("kornia.feature.SOSNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSOSNet = ivy.transpile(kornia.feature.SOSNet, source="torch", target=target_framework)
    
        x = torch.rand(8, 1, 32, 32)
        torch_out = kornia.feature.SOSNet()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledSOSNet()(transpiled_x)

kornia/test_feature3.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.sosnet.jax_SOSNet'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.sosnet.jax_SOSNet'>, args = (), kwargs = {}, node = jax_SOSNet()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.sosnet.jax_SOSNet'>, self = jax_SOSNet(), args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SOSNet(), pretrained = False

    def __init__(self, pretrained=False):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.instancenorm import jax_InstanceNorm2d
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.normalization import jax_LocalResponseNorm
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.layers = jax_Sequential(
            jax_InstanceNorm2d(1, affine=False),
            FlaxConv(
                in_features=1,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=128,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.1),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/sosnet.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}
node = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 32, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SOSNet
________________________________________________________________________________ test_ScaleSpaceDetector[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledScaleSpaceDetector = ivy.transpile(kornia.feature.ScaleSpaceDetector, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = TranspiledScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature3.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[12.1533,  0.0000, 14.0336],
          [ 0.0000, 12.1533, 16.9999]],

         [[12.1984,  0.0000, 14.9589]...00, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]))
transpiled_x = (Array([[[[12.153326 ,  0.       , 14.033583 ],
         [ 0.       , 12.153326 , 16.999935 ]],

        [[12.198442 ,...   , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],      dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[12.153326 ,  0.       , 14.033583 ],
         [ 0.       , 12.153326 , 16.999935 ]],

        [[12.198443 ,...  , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32))
y = (array([[[[12.153326 ,  0.       , 14.033583 ],
         [ 0.       , 12.153326 , 16.999935 ]],

        [[12.198442 ,...  , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f3fbcc4e440>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[12.153326 ,  0.       , 14.033583 ],
         [ 0.       , 12.153326 , 16.999935 ]],

        [[12.198443 , ...383]],

        [[54.288017 ,  0.       , 27.998547 ],
         [ 0.       , 54.288017 , 28.998535 ]]]], dtype=float32)
y = array([[[[12.153326 ,  0.       , 14.033583 ],
         [ 0.       , 12.153326 , 16.999935 ]],

        [[12.198442 , ...79 ]],

        [[24.198254 ,  0.       , 23.020517 ],
         [ 0.       , 24.198254 ,  0.9929597]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
All parameters and buffers are now synced!
__________________________________________________________________________________ test_LAFDescriptor[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LAFDescriptor(target_framework, mode, backend_compile):
        print("kornia.feature.LAFDescriptor")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLAFDescriptor = ivy.transpile(kornia.feature.LAFDescriptor, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 64, 64)
        lafs = torch.rand(1, 2, 2, 3)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_lafs = _nest_torch_tensor_to_new_framework(lafs, target_framework)
    
        model = kornia.feature.LAFDescriptor()
        torch_out = model(x, lafs)
    
>       transpiled_model = TranspiledLAFDescriptor()

kornia/test_feature3.py:251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LAFDescriptor'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LAFDescriptor'>, args = (), kwargs = {}
node = <[AttributeError("'jax_LAFDescriptor' object has no attribute 'descriptor'") raised in repr()] jax_LAFDescriptor object at 0x7f3f5c29dab0>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LAFDescriptor'>
self = <[AttributeError("'jax_LAFDescriptor' object has no attribute 'descriptor'") raised in repr()] jax_LAFDescriptor object at 0x7f3f5c29dab0>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_LAFDescriptor' object has no attribute 'descriptor'") raised in repr()] jax_LAFDescriptor object at 0x7f3f5c29dab0>, patch_descriptor_module = None, patch_size = 32
grayscale_descriptor = True

    def __init__(
        self, patch_descriptor_module=None, patch_size=32, grayscale_descriptor=True
    ):
        from .hardnet import jax_HardNet
    
        self.super___init__(
            patch_descriptor_module=patch_descriptor_module,
            patch_size=patch_size,
            grayscale_descriptor=grayscale_descriptor,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if patch_descriptor_module is None:
>           patch_descriptor_module = jax_HardNet(True)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, args = (True,), kwargs = {}, node = jax_HardNet()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, self = jax_HardNet(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet(), pretrained = True

    @jax_store_config_info
    def __init__(self, pretrained=False):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=128,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.3),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/hardnet.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}
node = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 32, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LAFDescriptor
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 202MB/s]
___________________________________________________________________________________ test_LocalFeature[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LocalFeature(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeature")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledKeyNetDetector = ivy.transpile(
            kornia.feature.KeyNetDetector, source="torch", target=target_framework
        )
        TranspiledLAFDescriptor = ivy.transpile(
            kornia.feature.LAFDescriptor, source="torch", target=target_framework
        )
        TranspiledLocalFeature = ivy.transpile(
            kornia.feature.LocalFeature, source="torch", target=target_framework
        )
    
        torch_detector = kornia.feature.KeyNetDetector()
        torch_descriptor = kornia.feature.LAFDescriptor()
        transpiled_detector = TranspiledKeyNetDetector()
>       transpiled_descriptor = TranspiledLAFDescriptor()

kornia/test_feature3.py:298: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LAFDescriptor'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LAFDescriptor'>, args = (), kwargs = {}
node = <[AttributeError("'jax_LAFDescriptor' object has no attribute 'descriptor'") raised in repr()] jax_LAFDescriptor object at 0x7f3f643f9b40>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LAFDescriptor'>
self = <[AttributeError("'jax_LAFDescriptor' object has no attribute 'descriptor'") raised in repr()] jax_LAFDescriptor object at 0x7f3f643f9b40>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_LAFDescriptor' object has no attribute 'descriptor'") raised in repr()] jax_LAFDescriptor object at 0x7f3f643f9b40>, patch_descriptor_module = None, patch_size = 32
grayscale_descriptor = True

    def __init__(
        self, patch_descriptor_module=None, patch_size=32, grayscale_descriptor=True
    ):
        from .hardnet import jax_HardNet
    
        self.super___init__(
            patch_descriptor_module=patch_descriptor_module,
            patch_size=patch_size,
            grayscale_descriptor=grayscale_descriptor,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if patch_descriptor_module is None:
>           patch_descriptor_module = jax_HardNet(True)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, args = (True,), kwargs = {}, node = jax_HardNet()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.hardnet.jax_HardNet'>, self = jax_HardNet(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet(), pretrained = True

    @jax_store_config_info
    def __init__(self, pretrained=False):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=128,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.3),
            FlaxConv(
                in_features=128,
                out_features=128,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=128,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/hardnet.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}
node = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 32, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 32, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeature
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_SOSNet[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_feature3.py::test_LAFDescriptor[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature3.py::test_LocalFeature[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
=============================================================================== 4 failed, 9 passed in 1729.50s (0:28:49) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 124.01s (0:02:04) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 353.29s (0:05:53) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomClahe[jax-s2s-False] ____________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 3, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4094: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'jax', init_args = (), init_kwargs = {}
call_args = (tensor([[[[0.2272, 0.3328, 0.2818,  ..., 0.1568, 0.2997, 0.4733],
          [0.4886, 0.4266, 0.7372,  ..., 0.3628, 0...., 0.6785, 0.2720,  ..., 0.4253, 0.3630, 0.3362],
          [0.1065, 0.0630, 0.4636,  ..., 0.0509, 0.7434, 0.5819]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, target=target)
        transpiled_cls = eval("transpiled_" + f"{augmentation_cls.__module__}.{augmentation_cls.__name__}")
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[0.22722298, 0.3327695 , 0.28178674, ..., 0.1568414 ,
          0.2996999 , 0.47325033],
         [0.48864377...6],
         [0.10651368, 0.06297761, 0.46355575, ..., 0.05090904,
          0.7433826 , 0.58187455]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fa70467f760>, jax_set_item = <function jax_set_item at 0x7fa6f4216710>, tensor = <function jax_tensor_frnt at 0x7fa6d49d0a60>
in_tensor = Array([[[[0.22722298, 0.3327695 , 0.28178674, ..., 0.1568414 ,
          0.2996999 , 0.47325033],
         [0.48864377...6],
         [0.10651368, 0.06297761, 0.46355575, ..., 0.05090904,
          0.7433826 , 0.58187455]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = Array([[[[0.22722298, 0.3327695 , 0.28178674, ..., 0.1568414 ,
          0.2996999 , 0.47325033],
         [0.48864377...6],
         [0.10651368, 0.06297761, 0.46355575, ..., 0.05090904,
          0.7433826 , 0.58187455]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[0.22722298, 0.3327695 , 0.28178674, ..., 0.1568414 ,
          0.2996999 , 0.47325033],
         [0.48864377...6],
         [0.10651368, 0.06297761, 0.46355575, ..., 0.05090904,
          0.7433826 , 0.58187455]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fa70467f760>, jax_all_frnt_ = <function jax_all_frnt_ at 0x7fa70467f130>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7fa704aada20>
jax_get_item = <function jax_get_item at 0x7fa6f4216560>, jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7fa6d4cb0d30>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7fa704aad900>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7fa6fde180d0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not jax_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                jax_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else jax_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[6.43669844e-01, 4.93176103e-01, 2.20393121e-01,
          9.69384551e-01, 7.94252694e-01, 9.65139210e-01,
  ...
          3.49241197e-01, 4.20864642e-01, 5.09090424e-02,
          7.43382573e-01, 5.81874549e-01]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import jax_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return jax_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/clahe.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[6.43669844e-01, 4.93176103e-01, 2.20393121e-01,
          9.69384551e-01, 7.94252694e-01, 9.65139210e-01,
  ...
          3.49241197e-01, 4.20864642e-01, 5.09090424e-02,
          7.43382573e-01, 5.81874549e-01]]]], dtype=float32)
args = (40.0, (8, 8), False), kwargs = {}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7fa70467f5b0>, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fa70467f760>
jax_view_frnt_ = <function jax_view_frnt_ at 0x7fa6d45a4d30>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[6.43669844e-01, 4.93176103e-01, 2.20393121e-01,
          9.69384551e-01, 7.94252694e-01, 9.65139210e-01,
  ...
          3.49241197e-01, 4.20864642e-01, 5.09090424e-02,
          7.43382573e-01, 5.81874549e-01]]]], dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:487: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[6.43669844e-01, 4.93176103e-01, 2.20393121e-01,
          9.69384551e-01, 7.94252694e-01, 9.65139210e-01,
  ...
          3.49241197e-01, 4.20864642e-01, 5.09090424e-02,
          7.43382573e-01, 5.81874549e-01]]]], dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
>               jax_unfold_frnt_(
                    jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[[0.64366984, 0.4931761 , 0.22039312, ..., 0.7495635 ,
            0.64033175, 0.02514488],
           [0.9...0.9858883 , 0.43535936, 0.4459437 , ..., 0.558482  ,
            0.33079123, 0.92477757]]]]]], dtype=float32), 3, 4, 4)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fa6d4591ab0>
array_like = Array([[[[[[0.64366984, 0.4931761 , 0.22039312, ..., 0.7495635 ,
            0.64033175, 0.02514488],
           [0.93...         [0.9858883 , 0.43535936, 0.4459437 , ..., 0.558482  ,
            0.33079123, 0.92477757]]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[[0.64366984, 0.4931761 , 0.22039312, ..., 0.7495635 ,
            0.64033175, 0.02514488],
           [0.93...         [0.9858883 , 0.43535936, 0.4459437 , ..., 0.558482  ,
            0.33079123, 0.92477757]]]]]], dtype=float32)
dimension = 3, size = 4, step = 4

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:149: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[jax-s2s-False] - Exception: Need at least one array to stack.
============================================================================== 1 failed, 17 passed in 3444.88s (0:57:24) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...........ssssss                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 11 passed, 6 skipped in 597.76s (0:09:57) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py ..FF.F.FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_OriNet[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_OriNet(target_framework, mode, backend_compile):
        print("kornia.feature.OriNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledOriNet = ivy.transpile(kornia.feature.OriNet, source="torch", target=target_framework)
    
        patch = torch.rand(16, 1, 32, 32)
        transpiled_patch = _nest_torch_tensor_to_new_framework(patch, target_framework)
    
        model = kornia.feature.OriNet()
        torch_out = model(patch)
    
>       transpiled_model = TranspiledOriNet()

kornia/test_feature5.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, args = (), kwargs = {}, node = jax_OriNet()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.orientation.jax_OriNet'>, self = jax_OriNet(), args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_OriNet(), pretrained = False, eps = 1e-08

    def __init__(self, pretrained=False, eps=1e-08):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.activation import jax_Tanh
        from ...torch.nn.modules.pooling import jax_AdaptiveAvgPool2d
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=32,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.25),
            FlaxConv(
                in_features=64,
                out_features=2,
                kernel_size=8,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=True,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_Tanh(),
            jax_AdaptiveAvgPool2d(1),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/orientation.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}
node = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 16, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.OriNet
_____________________________________________________________________________ test_LAFAffNetShapeEstimator[jax-s2s-False] ______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LAFAffNetShapeEstimator(target_framework, mode, backend_compile):
        print("kornia.feature.LAFAffNetShapeEstimator")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLAFAffNetShapeEstimator = ivy.transpile(kornia.feature.LAFAffNetShapeEstimator, source="torch", target=target_framework)
    
        laf = torch.rand(10, 2, 2, 3)
        img = torch.rand(10, 1, 32, 32)
        torch_out = kornia.feature.LAFAffNetShapeEstimator()(laf, img)
    
        transpiled_laf = _nest_torch_tensor_to_new_framework(laf, target_framework)
        transpiled_img = _nest_torch_tensor_to_new_framework(img, target_framework)
>       transpiled_out = TranspiledLAFAffNetShapeEstimator()(transpiled_laf, transpiled_img)

kornia/test_feature5.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, args = (), kwargs = {}, node = jax_LAFAffNetShapeEstimator()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.affine_shape.jax_LAFAffNetShapeEstimator'>, self = jax_LAFAffNetShapeEstimator(), args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LAFAffNetShapeEstimator(), pretrained = False, preserve_orientation = True

    def __init__(self, pretrained=False, preserve_orientation=True):
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.activation import jax_ReLU
        from ...torch.nn.modules.dropout import jax_Dropout
        from ...torch.nn.modules.activation import jax_Tanh
        from ...torch.nn.modules.pooling import jax_AdaptiveAvgPool2d
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import jax_map_location_to_cpu
        from ...jax__stateful_layers import FlaxConv
        from ...jax__stateful_layers import FlaxBatchNorm
    
        self.super___init__(
            pretrained=pretrained,
            preserve_orientation=preserve_orientation,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.features = jax_Sequential(
            FlaxConv(
                in_features=1,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
>           FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=16,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=16,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=16,
                out_features=32,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=32,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=32,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=32,
                out_features=64,
                kernel_size=3,
                strides=2,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            FlaxConv(
                in_features=64,
                out_features=64,
                kernel_size=3,
                strides=1,
                padding=1,
                padding_mode="zeros",
                use_bias=False,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            FlaxBatchNorm(
                num_features=64,
                momentum=0.99,
                epsilon=1e-05,
                use_bias=False,
                use_scale=False,
                axis=-1,
                track_running_stats=True,
            ),
            jax_ReLU(),
            jax_Dropout(0.25),
            FlaxConv(
                in_features=64,
                out_features=3,
                kernel_size=8,
                strides=1,
                padding=0,
                padding_mode="zeros",
                use_bias=True,
                feature_group_count=1,
                input_dilation=1,
                kernel_dilation=1,
            ),
            jax_Tanh(),
            jax_AdaptiveAvgPool2d(1),
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/affine_shape.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (), kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}
node = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, 

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = ()
kwargs = {'axis': -1, 'epsilon': 1e-05, 'momentum': 0.99, 'num_features': 16, ...}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(16, eps=1e-05, momentum=0.99, affine=False, , args = (), kwargs = {'axis': -1}, num_features = 16, momentum = 0.99, epsilon = 1e-05, use_bias = False, use_scale = False

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
        num_features = kwargs.pop("num_features")
        momentum = kwargs.pop("momentum", 0.1)
        epsilon = kwargs.pop("epsilon", 1e-5)
        use_bias = kwargs.pop("use_bias", True)
        use_scale = kwargs.pop("use_scale", True)
    
        super().__init__(
            num_features=num_features,
            use_running_average=True,
            momentum=1 - momentum,  # Flax uses decay rate, while PyTorch uses momentum
            epsilon=epsilon,
            use_bias=use_bias,
            use_scale=use_scale,
            rngs=nnx.Rngs(0),
            *args,
            **kwargs,
        )
    
        # ivy.Module attributes
        self._v = dict()
        self._buffers = dict()
    
        # create PT style placeholder weights on initialization
>       if self.scale:

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=None
)

    def __len__(self) -> int:
>     return len(self.value)  # type: ignore
E     TypeError: object of type 'NoneType' has no len()

/opt/fw/jax/flax/nnx/variablelib.py:438: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LAFAffNetShapeEstimator
_______________________________________________________________________________________ test_TLU[jax-s2s-False] ________________________________________________________________________________________

x = Param(
  value=Array([[[[-1.]],
  
          [[-1.]],
  
          [[-1.]]]], dtype=float32)
)

    def force(x):
      if x is None:
        return None
      try:
>       return operator.index(x)

/opt/fw/jax/jax/_src/numpy/reductions.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([[[[-1.]],
  
          [[-1.]],
  
          [[-1.]]]], dtype=float32)
)

    def __index__(self) -> A:
>     return self.value.__index__()  # type: ignore

/opt/fw/jax/flax/nnx/variablelib.py:656: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[-1.]],

        [[-1.]],

        [[-1.]]]], dtype=float32)

    def __index__(self):
>     core.check_integer_conversion(self)

/opt/fw/jax/jax/_src/array.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = Array([[[[-1.]],

        [[-1.]],

        [[-1.]]]], dtype=float32)

    def check_integer_conversion(arr: Array):
      if not (arr.shape == () and dtypes.issubdtype(arr.dtype, np.integer)):
>       raise TypeError("Only integer scalar arrays can be converted to a scalar index.")
E       TypeError: Only integer scalar arrays can be converted to a scalar index.

/opt/fw/jax/jax/_src/core.py:668: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TLU(target_framework, mode, backend_compile):
        print("kornia.feature.TLU")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTLU = ivy.transpile(kornia.feature.TLU, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 8, 8)
        torch_out = kornia.feature.TLU(3)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledTLU(3)(transpiled_x)

kornia/test_feature5.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TLU()
x = Array([[[[7.28272259e-01, 6.96376443e-01, 5.09552956e-01,
          1.96111560e-01, 8.20148885e-01, 6.31433666e-01,
  ...
          4.64353740e-01, 3.19496572e-01, 1.65397465e-01,
          9.34690773e-01, 9.59410667e-02]]]], dtype=float32)

    def __call__(self, x):
        from ...ivy.functional.frontends.torch.reduction_ops import jax_max_frnt
    
>       return jax_max_frnt(x, self.tau)

ivy_transpiled_outputs/jax_outputs/kornia/feature/hynet.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dim = Param(
  value=Array([[[[-1.]],
  
          [[-1.]],
  
          [[-1.]]]], dtype=float32)
), keepdim = False, out = None
input = Array([[[[7.28272259e-01, 6.96376443e-01, 5.09552956e-01,
          1.96111560e-01, 8.20148885e-01, 6.31433666e-01,
  ...
          4.64353740e-01, 3.19496572e-01, 1.65397465e-01,
          9.34690773e-01, 9.59410667e-02]]]], dtype=float32)

    def jax_max_frnt(*input, dim=None, keepdim=False, out=None):
        from ...ivy.general import jax_is_array_bknd
        from .comparison_ops import jax_maximum_frnt
        from ...backends.jax.statistical import jax_max
        from ...backends.jax.searching import jax_argmax
    
        if len(input) == 1:
            input = input[0]
        elif len(input) == 2:
            input_0 = input[0]
            input_1 = input[1]
            if jax_is_array_bknd(input_1):
                return jax_maximum_frnt(*input)
            else:
                input = input_0
                dim = input_1
        else:
            input = input[0]
            dim = input[1]
            keepdim = input[2]
        if dim is None:
            return jax_max(input, axis=dim, keepdims=keepdim, out=out)
        elif out is not None:
            jax_max(input, axis=dim, keepdims=keepdim, out=out[0])
            jax_argmax(input, axis=dim, keepdims=keepdim, out=out[1])
            return out
        else:
            max_tuple = namedtuple("max", ["values", "indices"])
            return max_tuple(
>               jax_max(input, axis=dim, keepdims=keepdim),
                jax_argmax(input, axis=dim, keepdims=keepdim),
            )

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/reduction_ops.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([[[[7.28272259e-01, 6.96376443e-01, 5.09552956e-01,
          1.96111560e-01, 8.20148885e-01, 6.31433666e-01,
 ...          4.64353740e-01, 3.19496572e-01, 1.65397465e-01,
          9.34690773e-01, 9.59410667e-02]]]], dtype=float32)]
kwargs = {'axis': Param(
  value=Array([[[[-1.]],
  
          [[-1.]],
  
          [[-1.]]]], dtype=float32)
), 'keepdims': False}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fd1c874f910>
jax_set_item = <function jax_set_item at 0x7fd1f64e5bd0>, jax_asarray = <function jax_asarray at 0x7fd1f64e4160>, jax_get_item = <function jax_get_item at 0x7fd1f64e5a20>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('axis', <Parameter "axis: Union[int, Sequence[int], None... None">), ('keepdims', <Parameter "keepdims: bool = False">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'axis', 'keepdims', 'out'], annotations = [<class 'jax.Array'>, typing.Union[int, typing.Sequence[int], NoneType], <class 'bool'>, typing.Optional[jax.Array]]
device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[7.28272259e-01, 6.96376443e-01, 5.09552956e-01,
          1.96111560e-01, 8.20148885e-01, 6.31433666e-01,
  ...
          4.64353740e-01, 3.19496572e-01, 1.65397465e-01,
          9.34690773e-01, 9.59410667e-02]]]], dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_max(
        x: jax.Array,
        /,
        *,
        axis: Optional[Union[int, Sequence[int]]] = None,
        keepdims: bool = False,
        out: Optional[jax.Array] = None,
    ):
        axis = tuple(axis) if isinstance(axis, list) else axis
>       return jax.numpy.max(a=jax.numpy.asarray(x), axis=axis, keepdims=keepdims)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/statistical.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Array([[[[7.28272259e-01, 6.96376443e-01, 5.09552956e-01,
          1.96111560e-01, 8.20148885e-01, 6.31433666e-01,
  ...
          4.64353740e-01, 3.19496572e-01, 1.65397465e-01,
          9.34690773e-01, 9.59410667e-02]]]], dtype=float32)
axis = Param(
  value=Array([[[[-1.]],
  
          [[-1.]],
  
          [[-1.]]]], dtype=float32)
), out = None, keepdims = False, initial = None, where = None

    def max(a: ArrayLike, axis: Axis = None, out: None = None,
            keepdims: bool = False, initial: ArrayLike | None = None,
            where: ArrayLike | None = None) -> Array:
      r"""Return the maximum of the array elements along a given axis.
    
      JAX implementation of :func:`numpy.max`.
    
      Args:
        a: Input array.
        axis: int or array, default=None. Axis along which the maximum to be computed.
          If None, the maximum is computed along all the axes.
        keepdims: bool, default=False. If true, reduced axes are left in the result
          with size 1.
        initial: int or array, default=None. Initial value for the maximum.
        where: int or array of boolean dtype, default=None. The elements to be used
          in the maximum. Array should be broadcast compatible to the input.
          ``initial`` must be specified when ``where`` is used.
        out: Unused by JAX.
    
      Returns:
        An array of maximum values along the given axis.
    
      See also:
        - :func:`jax.numpy.min`: Compute the minimum of array elements along a given
          axis.
        - :func:`jax.numpy.sum`: Compute the sum of array elements along a given axis.
        - :func:`jax.numpy.prod`: Compute the product of array elements along a given
          axis.
    
      Examples:
    
        By default, ``jnp.max`` computes the maximum of elements along all the axes.
    
        >>> x = jnp.array([[9, 3, 4, 5],
        ...                [5, 2, 7, 4],
        ...                [8, 1, 3, 6]])
        >>> jnp.max(x)
        Array(9, dtype=int32)
    
        If ``axis=1``, the maximum will be computed along axis 1.
    
        >>> jnp.max(x, axis=1)
        Array([9, 7, 8], dtype=int32)
    
        If ``keepdims=True``, ``ndim`` of the output will be same of that of the input.
    
        >>> jnp.max(x, axis=1, keepdims=True)
        Array([[9],
               [7],
               [8]], dtype=int32)
    
        To include only specific elements in computing the maximum, you can use
        ``where``. It can either have same dimension as input
    
        >>> where=jnp.array([[0, 0, 1, 0],
        ...                  [0, 0, 1, 1],
        ...                  [1, 1, 1, 0]], dtype=bool)
        >>> jnp.max(x, axis=1, keepdims=True, initial=0, where=where)
        Array([[4],
               [7],
               [8]], dtype=int32)
    
        or must be broadcast compatible with input.
    
        >>> where = jnp.array([[False],
        ...                    [False],
        ...                    [False]])
        >>> jnp.max(x, axis=0, keepdims=True, initial=0, where=where)
        Array([[0, 0, 0, 0]], dtype=int32)
      """
>     return _reduce_max(a, axis=_ensure_optional_axes(axis), out=out,
                         keepdims=keepdims, initial=initial, where=where)

/opt/fw/jax/jax/_src/numpy/reductions.py:459: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Param(
  value=Array([[[[-1.]],
  
          [[-1.]],
  
          [[-1.]]]], dtype=float32)
)

    def _ensure_optional_axes(x: Axis) -> Axis:
      def force(x):
        if x is None:
          return None
        try:
          return operator.index(x)
        except TypeError:
          return tuple(i if isinstance(i, str) else operator.index(i) for i in x)
>     return core.concrete_or_error(
        force, x, "The axis argument must be known statically.")

/opt/fw/jax/jax/_src/numpy/reductions.py:204: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

force = <function _ensure_optional_axes.<locals>.force at 0x7fd1c859f760>, val = Param(
  value=Array([[[[-1.]],
  
          [[-1.]],
  
          [[-1.]]]], dtype=float32)
)
context = 'The axis argument must be known statically.'

    def concrete_or_error(force: Any, val: Any, context=""):
      """Like force(val), but gives the context in the error message."""
      if force is None:
        force = lambda x: x
      if isinstance(val, Tracer):
        if isinstance(val.aval, ConcreteArray):
          return force(val.aval.val)
        else:
          raise ConcretizationTypeError(val, context)
      else:
>       return force(val)

/opt/fw/jax/jax/_src/core.py:1566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Param(
  value=Array([[[[-1.]],
  
          [[-1.]],
  
          [[-1.]]]], dtype=float32)
)

    def force(x):
      if x is None:
        return None
      try:
        return operator.index(x)
      except TypeError:
>       return tuple(i if isinstance(i, str) else operator.index(i) for i in x)

/opt/fw/jax/jax/_src/numpy/reductions.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <generator object ArrayImpl.__iter__.<locals>.<genexpr> at 0x7fd1f7594c80>

>   return tuple(i if isinstance(i, str) else operator.index(i) for i in x)

/opt/fw/jax/jax/_src/numpy/reductions.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[-1.]],

       [[-1.]],

       [[-1.]]], dtype=float32)

    def __index__(self):
>     core.check_integer_conversion(self)

/opt/fw/jax/jax/_src/array.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = Array([[[-1.]],

       [[-1.]],

       [[-1.]]], dtype=float32)

    def check_integer_conversion(arr: Array):
      if not (arr.shape == () and dtypes.issubdtype(arr.dtype, np.integer)):
>       raise TypeError("Only integer scalar arrays can be converted to a scalar index.")
E       TypeError: Only integer scalar arrays can be converted to a scalar index.

/opt/fw/jax/jax/_src/core.py:668: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.TLU
______________________________________________________________________________________ test_DeDoDe[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDeDoDe = ivy.transpile(kornia.feature.DeDoDe, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
>       transpiled_model = TranspiledDeDoDe(amp_dtype=ivy.as_native_dtype("float32"))

kornia/test_feature5.py:182: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}, node = jax_DeDoDe()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, self = jax_DeDoDe(), args = (), kwargs = {'amp_dtype': dtype('float32')}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DeDoDe(), detector_model = 'L', descriptor_model = 'G', amp_dtype = dtype('float32')

    def __init__(self, detector_model="L", descriptor_model="G", amp_dtype=jnp.float16):
        from .dedode_models import jax_get_detector
        from .dedode_models import jax_get_descriptor
        from ...enhance.normalize import jax_Normalize
        from ....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
    
        self.super___init__(
            detector_model=detector_model,
            descriptor_model=descriptor_model,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.detector: typing.Any = jax_get_detector(detector_model, amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kind = 'L', amp_dtype = dtype('float32')

    def jax_get_detector(kind="L", amp_dtype=jnp.float16):
        if kind == "L":
>           return jax_dedode_detector_L(amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amp_dtype = dtype('float32')

    def jax_dedode_detector_L(amp_dtype=jnp.float16):
        from ....torch.nn.modules.container import jax_ModuleDict
        from .decoder import jax_ConvRefiner
        from .encoder import jax_VGG19
        from .decoder import jax_Decoder
        from .detector import jax_DeDoDeDetector
    
        NUM_PROTOTYPES = 1
        residual = True
        hidden_blocks = 8
        amp = True
        conv_refiner = jax_ModuleDict(
            {
>               "8": jax_ConvRefiner(
                    512,
                    512,
                    256 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "4": jax_ConvRefiner(
                    256 + 256,
                    256,
                    128 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "2": jax_ConvRefiner(
                    128 + 128,
                    128,
                    64 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "1": jax_ConvRefiner(
                    64 + 64,
                    64,
                    1 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
            }
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}, node = jax_ConvRefiner()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, self = jax_ConvRefiner(), args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), args = (512, 512, 257), kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, hidden_dim = 512, out_dim = 257, dw = True, kernel_size = 5, hidden_blocks = 8, amp = True, residual = True, amp_dtype = dtype('float32')

    @jax_store_config_info
    def __init__(
        self,
        in_dim=6,
        hidden_dim=16,
        out_dim=2,
        dw=True,
        kernel_size=5,
        hidden_blocks=5,
        amp=True,
        residual=False,
        amp_dtype=jnp.float16,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....jax__stateful_layers import FlaxConv
    
        self.super___init__(
            in_dim=in_dim,
            hidden_dim=hidden_dim,
            out_dim=out_dim,
            dw=dw,
            kernel_size=kernel_size,
            hidden_blocks=hidden_blocks,
            amp=amp,
            residual=residual,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.block1 = self.create_block(in_dim, hidden_dim, dw=False, kernel_size=1)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, out_dim = 512, dw = False, kernel_size = 1, bias = True, norm_type = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>

    def create_block(
        self,
        in_dim,
        out_dim,
        dw=True,
        kernel_size=5,
        bias=True,
        norm_type=FlaxBatchNorm,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....torch.nn.modules.activation import jax_ReLU
        from ....jax__stateful_layers import FlaxConv
        from ....jax__stateful_layers import FlaxBatchNorm
    
        num_groups = 1 if not dw else in_dim
        if dw:
            if out_dim % in_dim != 0:
                raise Exception("outdim must be divisible by indim for depthwise")
        conv1 = FlaxConv(
            in_features=in_dim,
            out_features=out_dim,
            kernel_size=kernel_size,
            strides=1,
            padding=kernel_size // 2,
            padding_mode="zeros",
            use_bias=bias,
            feature_group_count=num_groups,
            input_dilation=1,
            kernel_dilation=1,
        )
        norm = (
>           norm_type(out_dim)
            if norm_type is FlaxBatchNorm
            else norm_type(num_channels=out_dim)
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}
node = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fd1a7e51510>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>
self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fd1a7e51510>, args = (512,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7fd1a7e51510>, args = (512,), kwargs = {}

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
>       num_features = kwargs.pop("num_features")
E       KeyError: 'num_features'

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:428: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  0%|          | 1.00M/1.13G [00:00<01:58, 10.2MB/s]
  1%|          | 12.1M/1.13G [00:00<00:16, 72.2MB/s]
  3%|▎         | 29.2M/1.13G [00:00<00:09, 121MB/s] 
  4%|▍         | 49.2M/1.13G [00:00<00:07, 154MB/s]
  6%|▌         | 69.6M/1.13G [00:00<00:06, 175MB/s]
  8%|▊         | 89.9M/1.13G [00:00<00:06, 187MB/s]
  9%|▉         | 110M/1.13G [00:00<00:05, 196MB/s] 
 11%|█         | 130M/1.13G [00:00<00:05, 200MB/s]
 13%|█▎        | 150M/1.13G [00:00<00:05, 203MB/s]
 15%|█▍        | 171M/1.13G [00:01<00:05, 207MB/s]
 16%|█▋        | 192M/1.13G [00:01<00:04, 209MB/s]
 18%|█▊        | 212M/1.13G [00:01<00:04, 210MB/s]
 20%|█▉        | 232M/1.13G [00:01<00:04, 210MB/s]
 22%|██▏       | 252M/1.13G [00:01<00:04, 208MB/s]
 23%|██▎       | 273M/1.13G [00:01<00:04, 210MB/s]
 25%|██▌       | 293M/1.13G [00:01<00:04, 210MB/s]
 27%|██▋       | 313M/1.13G [00:01<00:04, 210MB/s]
 29%|██▊       | 333M/1.13G [00:01<00:04, 209MB/s]
 30%|███       | 353M/1.13G [00:01<00:04, 208MB/s]
 32%|███▏      | 374M/1.13G [00:02<00:03, 210MB/s]
 34%|███▍      | 394M/1.13G [00:02<00:03, 211MB/s]
 36%|███▌      | 414M/1.13G [00:02<00:03, 211MB/s]
 37%|███▋      | 434M/1.13G [00:02<00:03, 206MB/s]
 39%|███▉      | 455M/1.13G [00:02<00:03, 208MB/s]
 41%|████      | 475M/1.13G [00:02<00:03, 200MB/s]
 43%|████▎     | 494M/1.13G [00:02<00:03, 200MB/s]
 44%|████▍     | 514M/1.13G [00:02<00:03, 205MB/s]
 46%|████▌     | 535M/1.13G [00:02<00:03, 207MB/s]
 48%|████▊     | 555M/1.13G [00:02<00:03, 205MB/s]
 49%|████▉     | 574M/1.13G [00:03<00:02, 206MB/s]
 51%|█████▏    | 595M/1.13G [00:03<00:02, 209MB/s]
 53%|█████▎    | 615M/1.13G [00:03<00:02, 205MB/s]
 55%|█████▍    | 636M/1.13G [00:03<00:02, 207MB/s]
 57%|█████▋    | 656M/1.13G [00:03<00:02, 210MB/s]
 58%|█████▊    | 677M/1.13G [00:03<00:02, 211MB/s]
 60%|██████    | 697M/1.13G [00:03<00:02, 211MB/s]
 62%|██████▏   | 717M/1.13G [00:03<00:02, 209MB/s]
 63%|██████▎   | 737M/1.13G [00:03<00:02, 210MB/s]
 65%|██████▌   | 757M/1.13G [00:03<00:02, 210MB/s]
 67%|██████▋   | 778M/1.13G [00:04<00:01, 211MB/s]
 69%|██████▊   | 798M/1.13G [00:04<00:01, 209MB/s]
 70%|███████   | 818M/1.13G [00:04<00:01, 208MB/s]
 72%|███████▏  | 838M/1.13G [00:04<00:01, 203MB/s]
 74%|███████▍  | 857M/1.13G [00:04<00:02, 158MB/s]
 75%|███████▌  | 874M/1.13G [00:04<00:02, 131MB/s]
 77%|███████▋  | 893M/1.13G [00:04<00:01, 146MB/s]
 79%|███████▊  | 912M/1.13G [00:04<00:01, 159MB/s]
 80%|████████  | 932M/1.13G [00:05<00:01, 172MB/s]
 82%|████████▏ | 952M/1.13G [00:05<00:01, 181MB/s]
 84%|████████▎ | 972M/1.13G [00:05<00:01, 191MB/s]
 85%|████████▌ | 992M/1.13G [00:05<00:00, 195MB/s]
 87%|████████▋ | 0.99G/1.13G [00:05<00:00, 200MB/s]
 89%|████████▉ | 1.01G/1.13G [00:05<00:00, 204MB/s]
 91%|█████████ | 1.03G/1.13G [00:05<00:00, 206MB/s]
 92%|█████████▏| 1.05G/1.13G [00:05<00:00, 206MB/s]
 94%|█████████▍| 1.07G/1.13G [00:05<00:00, 205MB/s]
 96%|█████████▌| 1.09G/1.13G [00:05<00:00, 204MB/s]
 98%|█████████▊| 1.11G/1.13G [00:06<00:00, 207MB/s]
 99%|█████████▉| 1.13G/1.13G [00:06<00:00, 206MB/s]
100%|██████████| 1.13G/1.13G [00:06<00:00, 196MB/s]
_______________________________________________________________________________________ test_DISK[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDISK = ivy.transpile(kornia.feature.DISK, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DISK()
        torch_out = model(x)
    
        transpiled_model = TranspiledDISK()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_shape_allclose(torch_out.keypoints, transpiled_out.keypoints)
E       AttributeError: 'list' object has no attribute 'keypoints'

kornia/test_feature5.py:217: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_OriNet[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature5.py::test_LAFAffNetShapeEstimator[jax-s2s-False] - TypeError: object of type 'NoneType' has no len()
FAILED kornia/test_feature5.py::test_TLU[jax-s2s-False] - TypeError: Only integer scalar arrays can be converted to a scalar index.
FAILED kornia/test_feature5.py::test_DeDoDe[jax-s2s-False] - KeyError: 'num_features'
FAILED kornia/test_feature5.py::test_DISK[jax-s2s-False] - AttributeError: 'list' object has no attribute 'keypoints'
=============================================================================== 5 failed, 5 passed in 1856.53s (0:30:56) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 5.09s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ...........................sssssssssssssssss                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 27 passed, 17 skipped in 1744.34s (0:29:04) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_mean_average_precision[jax-s2s-False] ______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f37682f24d0>
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f37682f24d0>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [Array([1.], dtype=float32)], pred_scores = [Array([0.7], dtype=float32)]
gt_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [Array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 1 failed, 12 passed in 757.97s (0:12:37) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py .................ss                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 17 passed, 2 skipped in 860.54s (0:14:20) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_bbox_to_mask[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f22801940d0>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f22801940d0>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001
deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[jax-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 504.01s (0:08:24) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ........                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 373.23s (0:06:13) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.2.post1, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_HomographyTracker[tensorflow-s2s-False] _____________________________________________________________________________

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'Variable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomographyTracker = ivy.transpile(kornia.tracking.HomographyTracker, source="torch", target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = TranspiledHomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HomographyTracker(), initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import tensorflow_LocalFeatureMatcher
        from ..feature.integrated import tensorflow_GFTTAffNetHardNet
        from ..feature.matching import tensorflow_DescriptorMatcher
        from ..feature.loftr.loftr import tensorflow_LoFTR
        from ..geometry.ransac import tensorflow_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or tensorflow_LocalFeatureMatcher(
>           tensorflow_GFTTAffNetHardNet(3000),
            tensorflow_DescriptorMatcher("smnn", 0.95),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/tracking/planar_tracker.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f163387dab0>, args = (3000,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f163387dab0>, num_features = 3000, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    @tensorflow_store_config_info
    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f163387e890>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f163387e890>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, query = slice(None, None, None)
val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<KerasVariable shape=(5, 1, 1), dtype=float32, path=variable>, slice(None, None, None), <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.]],

       [[0.]],

       [[0.]],

       [[0.]],

       [[0.]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|██████████| 332k/332k [00:00<00:00, 43.9MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|██████████| 5.10M/5.10M [00:00<00:00, 256MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:52, 409kB/s]
  1%|          | 256k/44.2M [00:00<01:08, 674kB/s]
  1%|          | 512k/44.2M [00:00<00:37, 1.24MB/s]
  2%|▏         | 896k/44.2M [00:00<00:22, 2.00MB/s]
  4%|▍         | 1.75M/44.2M [00:00<00:11, 4.03MB/s]
  8%|▊         | 3.50M/44.2M [00:00<00:05, 8.04MB/s]
 15%|█▍        | 6.50M/44.2M [00:00<00:02, 14.5MB/s]
 21%|██▏       | 9.50M/44.2M [00:01<00:01, 19.0MB/s]
 28%|██▊       | 12.5M/44.2M [00:01<00:01, 22.2MB/s]
 35%|███▍      | 15.4M/44.2M [00:01<00:01, 24.1MB/s]
 42%|████▏     | 18.4M/44.2M [00:01<00:01, 25.6MB/s]
 48%|████▊     | 21.4M/44.2M [00:01<00:00, 26.8MB/s]
 55%|█████▌    | 24.4M/44.2M [00:01<00:00, 27.4MB/s]
 62%|██████▏   | 27.4M/44.2M [00:01<00:00, 28.0MB/s]
 69%|██████▊   | 30.4M/44.2M [00:01<00:00, 28.1MB/s]
 76%|███████▌  | 33.4M/44.2M [00:01<00:00, 28.5MB/s]
 82%|████████▏ | 36.2M/44.2M [00:02<00:00, 28.9MB/s]
 89%|████████▉ | 39.2M/44.2M [00:02<00:00, 28.7MB/s]
 95%|█████████▌| 42.1M/44.2M [00:02<00:00, 29.0MB/s]
100%|██████████| 44.2M/44.2M [00:02<00:00, 20.3MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
==================================================================================== 1 failed in 465.66s (0:07:45) =====================================================================================

