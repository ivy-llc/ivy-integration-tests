========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 1865.61s (0:31:05) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_Boxes[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes = ivy.transpile(kornia.geometry.boxes.Boxes, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
        transpiled_boxes = TranspiledBoxes.from_tensor(*transpiled_args, mode="xyxy")
        _check_boxes_same(torch_boxes, transpiled_boxes)
    
        # test .compute_area
        torch_area = torch_boxes.compute_area()
        transpiled_area = transpiled_boxes.compute_area()
        _to_numpy_and_allclose(torch_area, transpiled_area)
    
        # test .get_boxes_shape
        torch_heights, torch_widths = torch_boxes.get_boxes_shape()
        transpiled_heights, transpiled_widths = transpiled_boxes.get_boxes_shape()
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .merge
        torch_x = torch.as_tensor([[6, 6, 10, 10], [6, 6, 10, 10]])
        transpiled_x = _nest_torch_tensor_to_new_framework(torch_x, target_framework)
        merge_boxes = kornia.geometry.boxes.Boxes.from_tensor(torch_x, mode="xyxy")
        transpiled_merge_boxes = TranspiledBoxes.from_tensor(transpiled_x, mode="xyxy")
        torch_merged_boxes = torch_boxes.merge(merge_boxes)
        transpiled_merged_boxes = transpiled_boxes.merge(transpiled_merge_boxes)
        _check_boxes_same(torch_merged_boxes, transpiled_merged_boxes)
    
        # test .to_mask
        height, width = 10, 10
        torch_mask = torch_boxes.to_mask(height, width)
        transpiled_mask = transpiled_boxes.to_mask(height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0....., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(2, 10, 10), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0....,
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
__________________________________________________________________________________ test_Boxes3D[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes3D = ivy.transpile(kornia.geometry.boxes.Boxes3D, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
        transpiled_boxes3d = TranspiledBoxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
        _check_boxes_same(torch_boxes3d, transpiled_boxes3d)
    
        # test .get_boxes_shape
        torch_depths, torch_heights, torch_widths = torch_boxes3d.get_boxes_shape()
        transpiled_depths, transpiled_heights, transpiled_widths = transpiled_boxes3d.get_boxes_shape()
        _to_numpy_and_allclose(torch_depths, transpiled_depths)
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .to_mask
        depth, height, width = 10, 10, 10
        torch_mask = torch_boxes3d.to_mask(depth, height, width)
        transpiled_mask = transpiled_boxes3d.to_mask(depth, height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0... [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
transpiled_x = <tf.Tensor: shape=(2, 10, 10, 10), dtype=float32, numpy=
array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0.,...., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
y = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
==================================================================================== 2 failed in 235.54s (0:03:55) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py .                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 1 passed in 93.41s (0:01:33) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_solve_pnp_dlt[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f118246a950>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f118246a950>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = Array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]], dtype=float64)
img_points = Array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]], dtype=float64)
intrinsics = Array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]], dtype=float64), weights = None, svd_eps = 0.001

    def jax_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...utils.helpers import jax__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import jax_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_inverse_frnt
        from ..conversions import jax_convert_points_to_homogeneous
        from ..linalg import jax_transform_points
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            jax_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...utils.misc import jax_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import jax_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import jax_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import jax_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (jax.Array, nnx.Param)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = jnp.float32, jnp.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if len(jax_shape_frnt_(world_points)) != 3 or jax_shape_frnt_(world_points)[2] != 3:
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {jax_shape_frnt_(world_points)}."
            )
        if len(jax_shape_frnt_(img_points)) != 3 or jax_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {jax_shape_frnt_(img_points)}."
            )
        if len(jax_shape_frnt_(intrinsics)) != 3 or jax_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {jax_shape_frnt_(intrinsics)}."
            )
        if jax_shape_frnt_(world_points)[1] != jax_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(img_points)[0]
            or jax_shape_frnt_(world_points)[0] != jax_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if jax_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {jax_shape_frnt_(world_points)[1]} points."
            )
        B, N = jax_shape_frnt_(world_points)[:2][0], jax_shape_frnt_(world_points)[:2][1]
        world_points_norm, world_transform_norm = jax__mean_isotropic_scale_normalize(
            world_points
        )
        s = jax__torch_linalg_svdvals(world_points_norm)
        if jax_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = jax_inverse_frnt(intrinsics)
        world_points_norm_h = jax_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = jax_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = jax__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = jax_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = jax_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = jax_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = jax_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = jax_eye_like(4, solution)
        solution_4x4 = jax_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = jax_bmm_frnt(solution_4x4, world_transform_norm)
        solution = jax_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = jax_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = jax_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/calibration/pnp.py:217: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': Array([[0.0754885 , 0.02388222, 0.0574928 ]], dtype=float64), 'p': 2}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f10ede7d870>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[jax-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 317.78s (0:05:17) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py s                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.03s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 5 skipped in 5.14s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py ...................                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1472.35s (0:24:32) ====================================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ........                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 468.74s (0:07:48) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py .........F...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_ScaleSpaceDetector[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledScaleSpaceDetector = ivy.transpile(kornia.feature.ScaleSpaceDetector, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = TranspiledScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature3.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[3.614986  , 6.6398964 , 1.7282832 , ..., 2.4879694 ...
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fbd454f1600, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[3.614986  , 6.6398964 , 1.7282832 , ..., 2.4879694 ...
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...,
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[3.614986  , 6.6398964 , 1.7282832 , ..., 2.4879694 ...
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[3.614986  , 6.6398964 , 1.7282832 , ..., 2.4879694 ,...],
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img, mask=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma...es=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF()),)
kwargs = {'img': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[3.614986  , 6.6398964 , 1.7282832 , ..., 2.4...,
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[3.614986  , 6.6398964 , 1.7282832 , ..., 2.4879694 ,...],
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>
mask = None

    def call(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ScaleSpaceDetector(num_features=500, mr_size=6.0, scale_pyr=tensorflow_ScalePyramid(n_levels=3, init_sigma=...ates=False, eps=1e-08, strict_maxima_bonus=0.0, output_value=True), ori=tensorflow_PassLAF(), aff=tensorflow_PassLAF())
img = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[3.614986  , 6.6398964 , 1.7282832 , ..., 2.4879694 ,...],
         [5.3002954 , 9.559075  , 0.31253457, ..., 7.630822  ,
          1.6429746 , 2.022277  ]]]], dtype=float32)>
num_feats = 500, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import (
            tensorflow_topk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from .laf import tensorflow_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
        sp, sigmas, _ = self.scale_pyr(img)
        all_responses: typing.Any = []
        all_lafs: typing.Any = []
        px_size = 0.5 if self.scale_pyr.double_image else 1.0
        for oct_idx, octave in enumerate(sp):
            sigmas_oct = tensorflow_get_item(sigmas, oct_idx)
            B, CH, L, H, W = tensorflow_size_frnt_(octave)
            if self.scale_space_response:
                oct_resp = self.resp(octave, tensorflow_view_frnt_(sigmas_oct, -1))
            else:
                oct_resp = tensorflow_view_frnt_(
                    self.resp(
                        tensorflow_reshape_frnt_(
                            tensorflow_permute_frnt_(octave, 0, 2, 1, 3, 4),
                            B * L,
                            CH,
                            H,
                            W,
                        ),
                        tensorflow_view_frnt_(sigmas_oct, -1),
                    ),
                    B,
                    L,
                    CH,
                    H,
                    W,
                )
                oct_resp = tensorflow_permute_frnt_(oct_resp, 0, 2, 1, 3, 4)
                if (
                    isinstance(
                        self.scale_pyr.extra_levels,
                        (tensorflow.Tensor, tensorflow.Variable),
                    )
                    and self.scale_pyr.extra_levels % 2 != 0
                ):
                    oct_resp = oct_resp[:, :, :-1]
            if mask is not None:
                oct_mask: typing.Any = tensorflow__create_octave_mask(
                    mask, tensorflow_shape_frnt_(oct_resp)
                )
                oct_resp = oct_mask * oct_resp
            coord_max: typing.Any
            response_max: typing.Any
            coord_max, response_max = self.nms(oct_resp)
            if self.minima_are_also_good:
                coord_min, response_min = self.nms(-oct_resp)
                take_min_mask = tensorflow_to_frnt_(
                    response_min > response_max, response_max.dtype
                )
                response_max = (
                    response_min * take_min_mask + (1 - take_min_mask) * response_max
                )
                coord_max = (
                    coord_min * tensorflow_unsqueeze_frnt_(take_min_mask, 2)
                    + (1 - tensorflow_unsqueeze_frnt_(take_min_mask, 2)) * coord_max
                )
            responses_flatten = tensorflow_view_frnt_(
                response_max, tensorflow_size_frnt_(response_max, 0), -1
            )
            max_coords_flatten = tensorflow_permute_frnt_(
                tensorflow_view_frnt_(
                    coord_max, tensorflow_size_frnt_(response_max, 0), 3, -1
                ),
                0,
                2,
                1,
            )
            if tensorflow_size_frnt_(responses_flatten, 1) > num_feats:
                resp_flat_best, idxs = tensorflow_topk_frnt(
                    responses_flatten, k=num_feats, dim=1
                )
                max_coords_best = tensorflow_gather_frnt(
                    max_coords_flatten,
                    1,
                    tensorflow_repeat_frnt_(
                        tensorflow_unsqueeze_frnt_(idxs, -1), 1, 1, 3
                    ),
                )
            else:
                resp_flat_best = responses_flatten
                max_coords_best = max_coords_flatten
            B, N = tensorflow_size_frnt_(resp_flat_best)
            if isinstance(
                self.scale_pyr.n_levels, (tensorflow.Tensor, tensorflow.Variable)
            ):
                num_levels = int(tensorflow_item_frnt_(self.scale_pyr.n_levels))
            elif isinstance(self.scale_pyr.n_levels, (int,)):
                num_levels = self.scale_pyr.n_levels
            else:
                raise TypeError(
                    f"Expected the scale pyramid module to have `n_levels` as a Tensor or int.Gotcha {type(self.scale_pyr.n_levels)}"
                )
            max_coords_best = tensorflow__scale_index_to_scale(
                max_coords_best, sigmas_oct, num_levels
            )
            rotmat = tensorflow_view_frnt_(eye(2, dtype=dtype, device=dev), 1, 1, 2, 2)
            current_lafs = concatenate(
                [
                    self.mr_size
                    * tensorflow_view_frnt_(max_coords_best[:, :, 0], B, N, 1, 1)
                    * rotmat,
                    tensorflow_view_frnt_(max_coords_best[:, :, 1:3], B, N, 2, 1),
                ],
                3,
            )
>           good_mask = tensorflow_laf_is_inside_image(current_lafs, octave[:, 0])

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/scale_space_detector.py:252: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 500, 2, 3), dtype=float32, numpy=
array([[[[10.687447,  0.      , 18.00791 ],
         [ 0.     ...2.012562]],

        [[15.270524,  0.      , 13.986228],
         [ 0.      , 15.270524, 21.052794]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 6, 32, 32), dtype=float32, numpy=
array([[[[4.922898 , 5.0200386, 5.169877 , ..., 3.9882607, 3.5...150117],
         [5.407976 , 5.409615 , 5.413828 , ..., 5.600741 , 5.6141133,
          5.6185985]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False,  True,  True],
        [ True,  True,  True, ..., False,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False,  True,  True],
        [ True,  True,  True, ..., False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False,  True,  True],
        [ True,  True,  True, ..., False,  True,  True]]])>
other = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ..., False,  True,  True],
        [ True,  True,  True, ..., False,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 500, 12), dtype=bool, numpy=
array([[[ True,  True,  True, ...,  True,  True,  True],
        [ ...],
        [ True,  True,  True, ...,  True,  True,  True],
        [ True,  True,  True, ...,  True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpaceDetector.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ScaleSpaceDetector.call():
E          img=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)
E          mask=None

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:239: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ScaleSpac...
============================================================================== 1 failed, 12 passed in 1900.95s (0:31:40) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 768.03s (0:12:48) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .F...F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_NerfModelRenderer[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
_________________________________________________________________________________ test_RandomRaySampler[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7faeb1c4d150>
cameras = <ivy_transpiled_outputs.jax_outputs.kornia.geometry.camera.pinhole.jax_PinholeCamera object at 0x7faee47dcee0>, num_img_rays = Array([1], dtype=int64)

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != jax_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {jax_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:359: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.nerf.samplers.jax_RandomRaySampler object at 0x7faeb1c4d150>, heights = Array([256], dtype=int64), widths = Array([256], dtype=int64)
num_img_rays = Array([1], dtype=int32)

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import jax_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_trunc_frnt
        from ...ivy.functional.frontends.torch.random_sampling import jax_rand_frnt
    
        num_img_rays = jax_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                jax_tolist_frnt_(heights),
                jax_tolist_frnt_(widths),
                jax_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = jax_trunc_frnt(
>               jax_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/jax_outputs/kornia/nerf/samplers.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
jax_random_uniform = <function jax_random_uniform at 0x7faeb1ce1c60>, seed = None

    def jax_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.jax.random import jax_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return jax_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/random_sampling.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, jax_exists_bknd = <function jax_exists_bknd at 0x7faeb1c95ea0>
jax_default_dtype_bknd = <function jax_default_dtype_bknd at 0x7faeb1c952d0>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import jax_exists_bknd
        from .functional.ivy.data_type import jax_default_dtype_bknd
    
        arr = None if jax_exists_bknd(dtype) else jax__get_first_array(*args, **kwargs)
        dtype = jax_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @jax_infer_dtype
    def jax_random_uniform(
        *,
        low: Union[float, jax.Array] = 0.0,
        high: Union[float, jax.Array, None] = 1.0,
        shape: Optional[Union[tuple, Sequence[int]]] = None,
        device: jaxlib.xla_extension.Device = None,
        dtype: jax.numpy.dtype,
        seed: Optional[int] = None,
        out: Optional[jax.Array] = None,
    ):
        from ...ivy.random import jax__check_bounds_and_get_shape_bknd
    
        if high is None:
            high = float(
                jax.numpy.finfo(dtype).max
                if dtype is not None
                else jax.numpy.finfo(jax.numpy.float32).max
            )
        shape = jax__check_bounds_and_get_shape_bknd(low, high, shape)
        if seed:
            rng_input = jax.random.PRNGKey(seed)
        else:
            RNG_, rng_input = jax.random.split(jax__getRNG())
            jax__setRNG(RNG_)
>       return jax.numpy.astype(
            jax.random.uniform(
                rng_input, shape, minval=low, maxval=high, dtype=jax.numpy.float32
            ),
            dtype,
        )

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/random.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([0.10536897], dtype=float32), dtype = torch.float32

    def astype(x: ArrayLike, dtype: DTypeLike | None,
               /, *, copy: bool = False,
               device: xc.Device | Sharding | None = None) -> Array:
      """Convert an array to a specified dtype.
    
      JAX imlementation of :func:`numpy.astype`.
    
      This is implemented via :func:`jax.lax.convert_element_type`, which may
      have slightly different behavior than :func:`numpy.astype` in some cases.
      In particular, the details of float-to-int and int-to-float casts are
      implementation dependent.
    
      Args:
        x: input array to convert
        dtype: output dtype
        copy: if True, then always return a copy. If False (default) then only
          return a copy if necessary.
        device: optionally specify the device to which the output will be committed.
    
      Returns:
        An array with the same shape as ``x``, containing values of the specified
        dtype.
    
      See Also:
        - :func:`jax.lax.convert_element_type`: lower-level function for XLA-style
          dtype conversions.
    
      Examples:
        >>> x = jnp.array([0, 1, 2, 3])
        >>> x
        Array([0, 1, 2, 3], dtype=int32)
        >>> x.astype('float32')
        Array([0.0, 1.0, 2.0, 3.0], dtype=float32)
    
        >>> y = jnp.array([0.0, 0.5, 1.0])
        >>> y.astype(int)  # truncates fractional values
        Array([0, 0, 1], dtype=int32)
      """
      util.check_arraylike("astype", x)
      x_arr = asarray(x)
    
      if dtype is None:
        dtype = dtypes.canonicalize_dtype(float_)
>     dtypes.check_user_dtype_supported(dtype, "astype")

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:5091: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, fun_name = 'astype'

    def check_user_dtype_supported(dtype, fun_name=None):
      if isinstance(dtype, Array):
        # Deprecation warning added 2024 June 13.
        warnings.warn("Passing an array as a dtype argument is deprecated; "
                      "instead of dtype=arr use dtype=arr.dtype.",
                      category=DeprecationWarning, stacklevel=3)
        return  # no further check needed, as array dtypes have already been validated.
>     if issubdtype(dtype, extended):

/opt/fw/jax/jax/_src/dtypes.py:776: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = torch.float32, b = <class 'jax.dtypes.extended'>

    def issubdtype(a: DTypeLike | ExtendedDType | None,
                   b: DTypeLike | ExtendedDType | None) -> bool:
      """Returns True if first argument is a typecode lower/equal in type hierarchy.
    
      This is like :func:`numpy.issubdtype`, but can handle dtype extensions such as
      :obj:`jax.dtypes.bfloat16` and `jax.dtypes.prng_key`.
      """
      # Main departures from np.issubdtype are:
      # - "extended" dtypes (like prng key types) are not normal numpy dtypes, so we
      #   need to handle them specifically. However, their scalar types do conform to
      #   the numpy scalar type hierarchy.
      # - custom dtypes (like bfloat16, int4, etc.) are normal numpy dtypes, but they
      #   don't conform to the standard numpy type hierarchy (e.g. the bfloat16 scalar
      #   type is not a subclass of np.floating) so we must also handle these specially.
    
      # We cannot use the cached version directly for all inputs, because some may be
      # unhashable (e.g. custom objects with a dtype attribute). The following check is
      # fast and covers the majority of calls to this function within JAX library code.
      return _issubdtype_cached(
>       a if isinstance(a, (type, np.dtype, ExtendedDType)) else np.dtype(a),  # type: ignore[arg-type]
        b if isinstance(b, (type, np.dtype, ExtendedDType)) else np.dtype(b),  # type: ignore[arg-type]
      )
E     TypeError: Cannot interpret 'torch.float32' as a data type

/opt/fw/jax/jax/_src/dtypes.py:363: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[jax-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_RandomRaySampler[jax-s2s-False] - TypeError: Cannot interpret 'torch.float32' as a data type
=============================================================================== 2 failed, 4 passed in 316.69s (0:05:16) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 176.89s (0:02:56) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_conv_quad_interp3d[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7ff0f4878ca0>
trace_args = (tensor([[[[[0.0978, 0.5602, 0.6707, 0.8590, 0.9988],
           [0.2235, 0.9560, 0.2611, 0.3921, 0.0420],
           ....5916],
           [0.1425, 0.5987, 0.9665, 0.5377, 0.9135],
           [0.6896, 0.9675, 0.8847, 0.7277, 0.9245]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[9.4438e-02, 7.4504e-01, 9.5217e-01, 6.9530e-03, 1.6191e-01],
           [2.7143e-01, 1.8646e-01, 8.2056e-...01, 8.3552e-01, 6.5605e-01, 9.5148e-01],
           [9.1530e-01, 1.6141e-01, 9.2723e-02, 2.9647e-01, 1.8290e-01]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7ff0f4878ca0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.0978, 0.5602, 0.6707, 0.8590, 0.9988],
           [0.2235, 0.9560, 0.2611, 0.3921, 0.0420],
           ....5916],
           [0.1425, 0.5987, 0.9665, 0.5377, 0.9135],
           [0.6896, 0.9675, 0.8847, 0.7277, 0.9245]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[9.4438e-02, 7.4504e-01, 9.5217e-01, 6.9530e-03, 1.6191e-01],
           [2.7143e-01, 1.8646e-01, 8.2056e-...01, 8.3552e-01, 6.5605e-01, 9.5148e-01],
           [9.1530e-01, 1.6141e-01, 9.2723e-02, 2.9647e-01, 1.8290e-01]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=float32, numpy=
array([[[[[0.09778935, 0.5602158 , 0.6706619 , 0.85901725, 0....3766245, 0.9135263 ],
          [0.68959236, 0.96751887, 0.8846517 , 0.7276828 , 0.9245365 ]]]]],
      dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(2, 2, 2, 5, 5), dtype=bool, numpy=
array([[[[[False, False, False, False, False],
          [False,...alse, False, False],
          [False, False, False, False, False],
          [False, False, False, False, False]]]]])>
name = 'view'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________ test_ConvQuadInterp3d[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledConvQuadInterp3d = ivy.transpile(
            kornia.geometry.subpix.ConvQuadInterp3d, source="torch", target=target_framework
        )
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = TranspiledConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:371: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.445022  ,  1.9072737 , -1.676221  , -0.9577176...72081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x56030e9dc760, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...772081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.445022  ,  1.9072737 , -1.676221  , -0.9577176...72081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array...772081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.445022  ,  1.9072737 , -1.676221  , -0.9577176...72081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.445022  ,  1.9072737 , -1.676221  , -0.95771766....772081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.445022  ,  1.9072737 , -1.676221  , -0.95...772081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.445022  ,  1.9072737 , -1.676221  , -0.95771766....772081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>

    def call(self, x):
>       return tensorflow_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 3, 5, 5), dtype=float32, numpy=
array([[[[[-0.445022  ,  1.9072737 , -1.676221  , -0.95771766....772081  ],
          [ 0.4589235 , -0.5066569 ,  0.50184023,  0.28873587,
            0.7061873 ]]]]], dtype=float32)>
strict_maxima_bonus = 10.0, eps = 1e-07

    def tensorflow_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import (
            tensorflow_is_tensor_frnt_,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...utils.grid import tensorflow_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...filters.sobel import tensorflow_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...utils._compat import tensorflow_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import tensorflow_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from .nms import tensorflow_nms3d
        from ...utils.helpers import tensorflow_safe_solve_with_mask
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import (
            tensorflow_masked_scatter_frnt_,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
    
        if not tensorflow_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(tensorflow_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {tensorflow_shape_frnt_(input)}"
            )
        B, CH, D, H, W = tensorflow_shape_frnt_(input)
        grid_global: typing.Any = tensorflow_permute_frnt_(
            tensorflow_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = tensorflow_to_frnt_(grid_global, input.dtype)
        b: typing.Any = tensorflow_spatial_gradient3d(input, order=1, mode="diff")
        b = tensorflow_reshape_frnt_(
            tensorflow_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1
        )
        A: typing.Any = tensorflow_spatial_gradient3d(input, order=2, mode="diff")
        A = tensorflow_reshape_frnt_(tensorflow_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = tensorflow_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not tensorflow_torch_version_ge(1, 10):
            Hes = (
                Hes
                + tensorflow_abs_frnt_(
                    rand(tensorflow_size_frnt_(Hes[0]), device=Hes.device)
                )[None]
                * eps
            )
        nms_mask: typing.Any = tensorflow_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
        x_solved_masked, _, solved_correctly = tensorflow_safe_solve_with_mask(
            tensorflow_get_item(b, tensorflow_view_frnt_(nms_mask, -1)),
            tensorflow_get_item(Hes, tensorflow_view_frnt_(nms_mask, -1)),
        )
        new_nms_mask = tensorflow_masked_scatter_frnt_(nms_mask, nms_mask, solved_correctly)
        x_solved = tensorflow_set_item(
            x_solved,
>           where(new_nms_mask.view(-1, 1, 1))[0],
            tensorflow_get_item(x_solved_masked, solved_correctly),
        )
E       AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'[0m
E       
E       Arguments received by tensorflow_ConvQuadInterp3d.call():
E          x=tf.Tensor(shape=(1, 1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:114: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'view'
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_ConvQuadInterp3d.call().
============================================================================== 2 failed, 13 passed in 1246.12s (0:20:46) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py .F......                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________ test_find_homography_dlt_iterated[jax-s2s-False] ___________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f7d01059120>
trace_args = (tensor([[[0.0083, 0.0464],
         [0.1748, 0.6569],
         [0.4750, 0.0101],
         [0.0460, 0.3345]]]), tensor... [0.0674, 0.7004],
         [0.7852, 0.2116],
         [0.6906, 0.0353]]]), tensor([[0.3448, 0.8763, 0.9435, 0.0274]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.9246, 0.9878],
         [0.2833, 0.4854],
         [0.0448, 0.6250],
         [0.6343, 0.6627]],

       ...[0.1356, 0.5143, 0.5791, 0.1124],
        [0.9042, 0.7405, 0.0512, 0.5747],
        [0.0549, 0.6734, 0.6468, 0.6904]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f7d01059120>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.0083, 0.0464],
         [0.1748, 0.6569],
         [0.4750, 0.0101],
         [0.0460, 0.3345]]]), tensor... [0.0674, 0.7004],
         [0.7852, 0.2116],
         [0.6906, 0.0353]]]), tensor([[0.3448, 0.8763, 0.9435, 0.0274]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.9246, 0.9878],
         [0.2833, 0.4854],
         [0.0448, 0.6250],
         [0.6343, 0.6627]],

       ...[0.1356, 0.5143, 0.5791, 0.1124],
        [0.9042, 0.7405, 0.0512, 0.5747],
        [0.0549, 0.6734, 0.6468, 0.6904]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'jax', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.00830323, 0.04639494],
        [0.1747647 , 0.6568704 ],
        [0.47504687, 0.01011461],
        [0.04599351, 0.33451283]]], dtype=float32)
points2 = Array([[[0.5352136 , 0.73187125],
        [0.06735712, 0.7003944 ],
        [0.7852304 , 0.21162528],
        [0.6906042 , 0.03532368]]], dtype=float32)
weights = Array([[0.3448226 , 0.8763125 , 0.94350845, 0.02736926]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def jax_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import jax_exp_frnt
    
>       H: typing.Any = jax_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = Array([[[0.00830323, 0.04639494],
        [0.1747647 , 0.6568704 ],
        [0.47504687, 0.01011461],
        [0.04599351, 0.33451283]]], dtype=float32)
points2 = Array([[[0.5352136 , 0.73187125],
        [0.06735712, 0.7003944 ],
        [0.7852304 , 0.21162528],
        [0.6906042 , 0.03532368]]], dtype=float32)
weights = Array([[0.3448226 , 0.8763125 , 0.94350845, 0.02736926]], dtype=float32), solver = 'lu'

    def jax_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ..utils.helpers import jax__extract_device_dtype
        from .epipolar.fundamental import jax_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import jax_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import jax_diag_embed_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ..utils.helpers import jax__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import jax_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ..utils.helpers import jax_safe_solve_with_mask
        from ..utils.helpers import jax_safe_inverse_with_mask
    
        if jax_shape_frnt_(points1) != jax_shape_frnt_(points2):
            raise AssertionError(jax_shape_frnt_(points1))
        if jax_shape_frnt_(points1)[1] < 4:
            raise AssertionError(jax_shape_frnt_(points1))
        jax_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        jax_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = jax__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = jax_normalize_points(points1)
        points2_norm, transform2 = jax_normalize_points(points2)
        x1, y1 = jax_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = jax_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = jax_ones_like_v_0p4p0_and_above_frnt(x1), jax_zeros_like_frnt(x1)
        ax = jax_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = jax_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = jax_reshape_frnt_(
            jax_cat_frnt((ax, ay), dim=-1),
            jax_shape_frnt_(ax)[0],
            -1,
            jax_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = jax_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(jax_shape_frnt_(weights)) == 2
                and jax_shape_frnt_(weights) == jax_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(jax_shape_frnt_(weights))
            w_diag = jax_diag_embed_frnt(
                jax_reshape_frnt_(
                    jax_repeat_frnt_(jax_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    jax_shape_frnt_(weights)[0],
                    -1,
                )
            )
            A = jax_transpose_frnt_(A, -2, -1) @ w_diag @ A
        if solver == "svd":
            try:
                _, _, V = jax__torch_svd_cast(A)
            except RuntimeError:
                warnings.warn("SVD did not converge", RuntimeWarning)
                return jax_empty_frnt(
                    (jax_size_frnt_(points1_norm, 0), 3, 3), device=device, dtype=dtype
                )
            H = jax_view_frnt_(V[..., -1], -1, 3, 3)
        elif solver == "lu":
            B = jax_ones_frnt(
                jax_shape_frnt_(A)[0], jax_shape_frnt_(A)[1], device=device, dtype=dtype
            )
>           sol, _, _ = jax_safe_solve_with_mask(B, A)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/homography.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)
A = Array([[[ 2.0732238 , -1.3002486 ,  1.0285697 ,  0.        ,
          0.        ,  0.        , -1.7522757 ,  1.433975...0628,  1.2514987 ,
         -2.0263672 , -0.5171848 ,  1.4898263 ,  3.7357316 ,
          4.9092827 ]]], dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([[[ 2.0732238 , -1.3002486 ,  1.0285697 ,  0.        ,
          0.        ,  0.        , -1.7522757 ,  1.433975...0628,  1.2514987 ,
         -2.0263672 , -0.5171848 ,  1.4898263 ,  3.7357316 ,
          4.9092827 ]]], dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([[[ 2.0732238 , -1.3002486 ,  1.0285697 ,  0.        ,
          0.        ,  0.        , -1.7522757 ,  1.43397...628,  1.2514987 ,
         -2.0263672 , -0.5171848 ,  1.4898263 ,  3.7357316 ,
          4.9092827 ]]], dtype=float32)]
kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f7c7ca65cf0>, jax_set_item = <function jax_set_item at 0x7f7c75d212d0>
jax_asarray = <function jax_asarray at 0x7f7c7ca66710>, jax_get_item = <function jax_get_item at 0x7f7c75d21120>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[ 2.0732238 , -1.3002486 ,  1.0285697 ,  0.        ,
          0.        ,  0.        , -1.7522757 ,  1.433975...0628,  1.2514987 ,
         -2.0263672 , -0.5171848 ,  1.4898263 ,  3.7357316 ,
          4.9092827 ]]], dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,9,9])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
=============================================================================== 1 failed, 7 passed in 593.66s (0:09:53) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ssssssss                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 8 skipped in 4.97s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF......FF.                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_diamond_square[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f1136ab7130>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f11521e6900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f11521e6900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7f1136ab7130>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f11521e6900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7f11521e6900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'jax', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = Array([[[[0.5]]]], dtype=float64), random_scale = Array([[[[1.]]]], dtype=float64), random_fn = <built-in method ones of type object at 0x7f11521e6900>
normalize_range = (0.0, 1.0), device = None, dtype = None

    def jax_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=jax_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_expand_frnt_
        from ..core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..enhance.normalize import jax_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
    
        jax_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (jax.Array, nnx.Param)):
            random_scale = jax_to_frnt_(jnp.asarray([[[[random_scale]]]]), device, dtype)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            jax_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = jax_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = jax_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = jax_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (jax.Array, nnx.Param)):
            roughness = jax_to_frnt_(jnp.asarray([[[[roughness]]]]), device, dtype)
            roughness = jax_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = jax_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = jax_expand_frnt_(roughness, [output_size[0], output_size[1], 1, 1])
            roughness = jax_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * jax__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )
E       TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'

ivy_transpiled_outputs/jax_outputs/kornia/contrib/diamond_square.py:225: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
___________________________________________________________________________________ test_EdgeDetector[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledEdgeDetector = ivy.transpile(kornia.contrib.EdgeDetector, source="torch", target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
        transpiled_detector = TranspiledEdgeDetector()
    
        torch_args = (
            torch.rand(1, 3, 320, 320),
        )
        torch_out = torch_detector(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_detector(*transpiled_args)

kornia/test_contrib.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_EdgeDetector(
  (model): jax_DexiNed(
    (block_1): jax_DoubleConvBlock(
      (conv1): FlaxConv(in_features=3, o..., 1), padding=0, padding_mode=zeros)
      (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
    )
  )
)
image = Array([[[[0.409285  , 0.19544315, 0.10304499, ..., 0.2607171 ,
          0.02396578, 0.4260949 ],
         [0.05858606... ],
         [0.7828104 , 0.6107123 , 0.78536224, ..., 0.7367133 ,
          0.991537  , 0.49580604]]]], dtype=float32)

    def __call__(self, image):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
    
        jax_KORNIA_CHECK_SHAPE(image, ["B", "3", "H", "W"])
        img = self.preprocess(image)
>       out = self.model(img)

ivy_transpiled_outputs/jax_outputs/kornia/contrib/edge_detection.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DexiNed(
  (block_1): jax_DoubleConvBlock(
    (conv1): FlaxConv(in_features=3, out_features=32, kernel_size=(3, 3...rides=(1, 1), padding=0, padding_mode=zeros)
    (bn): FlaxBatchNorm2D(1, eps=1e-05, momentum=0.99, affine=True, 
  )
)
x = Array([[[[0.409285  , 0.19544315, 0.10304499, ..., 0.2607171 ,
          0.02396578, 0.4260949 ],
         [0.05858606... ],
         [0.7828104 , 0.6107123 , 0.78536224, ..., 0.7367133 ,
          0.991537  , 0.49580604]]]], dtype=float32)

    def __call__(self, x):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ..core._backend import concatenate
    
        block_1 = self.block_1(x)
>       block_1_side = self.side_1(block_1)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SingleConvBlock(
  (conv): FlaxConv(in_features=64, out_features=128, kernel_size=(1, 1), strides=(2, 2), padding=0, padding_mode=zeros)
  (bn): FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
)
x = Array([[[[-4.18887921e-02,  2.55743954e-02,  5.36097735e-02, ...,
           1.03408098e-01,  7.83405453e-03,  1.52270...8933321e-01,  7.02897087e-02, ...,
          -7.72156864e-02, -3.43130971e-03, -3.77743912e-04]]]],      dtype=float32)

    def __call__(self, x):
        x = self.conv(x)
        if self.use_bn:
>           x = self.bn(x)

ivy_transpiled_outputs/jax_outputs/kornia/filters/dexined.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-4.18887921e-02,  2.55743954e-02,  5.36097735e-02, ...,
           1.03408098e-01,  7.83405453e-03,  1.5227...33321e-01,  7.02897087e-02, ...,
          -7.72156864e-02, -3.43130971e-03, -3.77743912e-04]]]],      dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x561dd47727e0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...y', lineno=159, function='pytest_pyfunc_call', code_context=['    result = testfunction(**testargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
args = (Array([[[[-4.18887921e-02,  2.55743954e-02,  5.36097735e-02, ...,
           1.03408098e-01,  7.83405453e-03,  1.5227...33321e-01,  7.02897087e-02, ...,
          -7.72156864e-02, -3.43130971e-03, -3.77743912e-04]]]],      dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7f109cc74af0>, jax_set_item = <function jax_set_item at 0x7f109cc74ca0>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[-4.18887921e-02,  1.39357597e-01, -6.38693348e-02, ...,
           1.32800832e-01, -2.74362326e-0...501139e-01, -4.41785336e-01, ...,
           1.23868458e-01, -2.13707715e-01, -3.77743912e-04]]]],      dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f109effb2e0>, next_call_in_seq = None, conv_block_continued = None
arg_name = 'inputs'
input = Array([[[[-4.18887921e-02,  2.55743954e-02,  5.36097735e-02, ...,
           1.03408098e-01,  7.83405453e-03,  1.52270...8933321e-01,  7.02897087e-02, ...,
          -7.72156864e-02, -3.43130971e-03, -3.77743912e-04]]]],      dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
inputs = Array([[[[-4.18887921e-02,  1.39357597e-01, -6.38693348e-02, ...,
           1.32800832e-01, -2.74362326e-01,  1.77836...6501139e-01, -4.41785336e-01, ...,
           1.23868458e-01, -2.13707715e-01, -3.77743912e-04]]]],      dtype=float32)
use_running_average = None

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs, use_running_average=None, *, mask=None):
        self._built = True
>       logits = super().__call__(
            inputs, use_running_average=use_running_average, mask=mask
        )

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxBatchNorm2D(128, eps=1e-05, momentum=0.99, affine=True, 
x = Array([[[[-4.18887921e-02,  1.39357597e-01, -6.38693348e-02, ...,
           1.32800832e-01, -2.74362326e-01,  1.77836...6501139e-01, -4.41785336e-01, ...,
           1.23868458e-01, -2.13707715e-01, -3.77743912e-04]]]],      dtype=float32)
use_running_average = True

    def __call__(
      self,
      x,
      use_running_average: tp.Optional[bool] = None,
      *,
      mask: tp.Optional[jax.Array] = None,
    ):
      """Normalizes the input using batch statistics.
    
      Args:
        x: the input to be normalized.
        use_running_average: if true, the stored batch statistics will be
          used instead of computing the batch statistics on the input. The
          ``use_running_average`` flag passed into the call method will take
          precedence over the ``use_running_average`` flag passed into the
          constructor.
    
      Returns:
        Normalized inputs (the same shape as inputs).
      """
    
      use_running_average = first_from(
        use_running_average,
        self.use_running_average,
        error_msg="""No `use_running_average` argument was provided to BatchNorm
          as either a __call__ argument, class attribute, or nnx.flag.""",
      )
      feature_axes = _canonicalize_axes(x.ndim, self.axis)
      reduction_axes = tuple(i for i in range(x.ndim) if i not in feature_axes)
    
      if use_running_average:
        mean, var = self.mean.value, self.var.value
      else:
        mean, var = _compute_stats(
          x,
          reduction_axes,
          dtype=self.dtype,
          axis_name=self.axis_name,
          axis_index_groups=self.axis_index_groups,
          use_fast_variance=self.use_fast_variance,
          mask=mask,
        )
    
        self.mean.value = (
          self.momentum * self.mean.value + (1 - self.momentum) * mean
        )
        self.var.value = (
          self.momentum * self.var.value + (1 - self.momentum) * var
        )
    
>     return _normalize(
        x,
        mean,
        var,
        self.scale.value,
        self.bias.value,
        reduction_axes,
        feature_axes,
        self.dtype,
        self.epsilon,
      )

/opt/fw/jax/flax/nnx/nnx/nn/normalization.py:367: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[-4.18887921e-02,  1.39357597e-01, -6.38693348e-02, ...,
           1.32800832e-01, -2.74362326e-01,  1.77836...6501139e-01, -4.41785336e-01, ...,
           1.23868458e-01, -2.13707715e-01, -3.77743912e-04]]]],      dtype=float32)
mean = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
var = Param(
  value=Array([0.2625539 , 0.27113461, 0.21946596, 0.15521275, 0.25643   ,
         0.21336786, 0.39907008, 0.2...8342604, 0.5336697 , 0.19832538, 0.22804523, 0.6139669 ,
         0.32740036, 0.37694854, 0.2545803 ], dtype=float32)
)
scale = Array([0.9180028 , 0.85888755, 0.83077097, 0.8763835 , 0.96300054,
       0.8625907 , 0.8677793 , 0.9038065 , 0.968281... 0.9293163 , 0.97165966, 0.9689161 , 0.9450734 , 0.8873313 ,
       0.88254374, 0.99936277, 0.848198  ], dtype=float32)
bias = Array([-0.07675791, -0.03457952, -0.06084337,  0.0461219 , -0.04142413,
        0.07173445, -0.01962172,  0.00044565, ...8167, -0.02156175, -0.02820837,  0.02331718, -0.01897949,
        0.0239033 ,  0.00923689, -0.05559541], dtype=float32)
reduction_axes = (0, 1, 2), feature_axes = (3,), dtype = None, epsilon = 1e-05

    def _normalize(
      x: Array,
      mean: Array,
      var: Array,
      scale: tp.Optional[Array],
      bias: tp.Optional[Array],
      reduction_axes: Axes,
      feature_axes: Axes,
      dtype: tp.Optional[Dtype],
      epsilon: float,
    ):
      """ "Normalizes the input of a normalization layer and optionally applies a learned scale and bias.
    
      Arguments:
        x: The input.
        mean: Mean to use for normalization.
        var: Variance to use for normalization.
        reduction_axes: The axes in ``x`` to reduce.
        feature_axes: Axes containing features. A separate bias and scale is learned
          for each specified feature.
        dtype: The dtype of the result (default: infer from input and params).
        epsilon: Normalization epsilon.
    
      Returns:
        The normalized input.
      """
      reduction_axes = _canonicalize_axes(x.ndim, reduction_axes)
      feature_axes = _canonicalize_axes(x.ndim, feature_axes)
      stats_shape = list(x.shape)
      for axis in reduction_axes:
        stats_shape[axis] = 1
>     mean = mean.reshape(stats_shape)

/opt/fw/jax/flax/nnx/nnx/nn/normalization.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([-0.2449035 ,  0.32071695, -0.8167501 , -0.30144545, -0.18064821,
          0.00530162,  0.227697..., -0.6198849 , -0.3519681 ,  0.04875631, -0.61422706,
          0.27642408, -0.27212012, -0.04358729], dtype=float32)
)
name = 'reshape'

    def custom_getattr(self, name):
        if name in ("shape", "device", "dtype", "ndim", "size", "itemsize", "T"):
            value = getattr(self, "value")
            if value is not None:
                # Attempt to retrieve the attribute from the wrapped object (`value`)
                return getattr(value, name)
>       return object.__getattribute__(self, name)
E       AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?

ivy_transpiled_outputs/jax_outputs/__init__.py:91: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<05:14, 448kB/s]
  0%|          | 512k/135M [00:00<01:56, 1.21MB/s]
  1%|          | 1.62M/135M [00:00<00:34, 3.99MB/s]
  3%|         | 3.50M/135M [00:00<00:20, 6.60MB/s]
  5%|         | 6.88M/135M [00:00<00:09, 13.4MB/s]
  8%|         | 10.2M/135M [00:00<00:06, 19.0MB/s]
 10%|         | 13.9M/135M [00:01<00:05, 24.0MB/s]
 13%|        | 17.2M/135M [00:01<00:04, 27.1MB/s]
 15%|        | 20.6M/135M [00:01<00:04, 29.4MB/s]
 18%|        | 24.0M/135M [00:01<00:04, 25.2MB/s]
 20%|        | 27.1M/135M [00:01<00:04, 26.8MB/s]
 23%|       | 30.6M/135M [00:01<00:03, 29.3MB/s]
 25%|       | 34.0M/135M [00:01<00:03, 30.9MB/s]
 28%|       | 37.5M/135M [00:01<00:03, 32.5MB/s]
 30%|       | 40.9M/135M [00:01<00:02, 33.3MB/s]
 33%|      | 44.4M/135M [00:02<00:03, 27.5MB/s]
 36%|      | 47.9M/135M [00:02<00:03, 29.8MB/s]
 38%|      | 51.4M/135M [00:02<00:02, 31.5MB/s]
 41%|      | 54.9M/135M [00:02<00:02, 32.9MB/s]
 43%|     | 58.2M/135M [00:02<00:02, 33.4MB/s]
 46%|     | 61.6M/135M [00:02<00:02, 33.8MB/s]
 48%|     | 65.0M/135M [00:02<00:02, 27.9MB/s]
 51%|     | 68.2M/135M [00:02<00:02, 29.3MB/s]
 53%|    | 71.5M/135M [00:03<00:02, 30.6MB/s]
 56%|    | 75.0M/135M [00:03<00:01, 32.2MB/s]
 58%|    | 78.4M/135M [00:03<00:01, 33.0MB/s]
 61%|    | 81.9M/135M [00:03<00:01, 34.1MB/s]
 63%|   | 85.2M/135M [00:03<00:01, 34.3MB/s]
 66%|   | 88.6M/135M [00:03<00:01, 28.0MB/s]
 68%|   | 92.0M/135M [00:03<00:01, 29.9MB/s]
 71%|   | 95.2M/135M [00:03<00:01, 30.9MB/s]
 73%|  | 98.5M/135M [00:03<00:01, 31.7MB/s]
 76%|  | 102M/135M [00:04<00:01, 33.1MB/s] 
 78%|  | 105M/135M [00:04<00:00, 33.6MB/s]
 81%|  | 109M/135M [00:04<00:00, 27.6MB/s]
 83%| | 112M/135M [00:04<00:00, 29.9MB/s]
 86%| | 116M/135M [00:04<00:00, 31.2MB/s]
 88%| | 119M/135M [00:04<00:00, 31.9MB/s]
 91%| | 123M/135M [00:04<00:00, 33.9MB/s]
 94%|| 126M/135M [00:04<00:00, 28.7MB/s]
 96%|| 130M/135M [00:04<00:00, 30.3MB/s]
 99%|| 133M/135M [00:05<00:00, 31.0MB/s]
100%|| 135M/135M [00:05<00:00, 27.6MB/s]
__________________________________________________________________________________ test_ImageStitcher[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
        TranspiledImageStitcher = ivy.transpile(kornia.contrib.ImageStitcher, source="torch", target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = TranspiledLoFTR(pretrained='outdoor')

kornia/test_contrib.py:314: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = (), kwargs = {'pretrained': 'outdoor'}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = (), kwargs = {'pretrained': 'outdoor'}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:43, 447kB/s]
  1%|          | 512k/44.2M [00:00<00:37, 1.21MB/s]
  4%|         | 1.62M/44.2M [00:00<00:11, 3.98MB/s]
  8%|         | 3.50M/44.2M [00:00<00:06, 6.61MB/s]
 15%|        | 6.50M/44.2M [00:00<00:03, 12.5MB/s]
 23%|       | 10.1M/44.2M [00:00<00:01, 18.9MB/s]
 31%|       | 13.6M/44.2M [00:01<00:01, 23.6MB/s]
 37%|      | 16.4M/44.2M [00:01<00:01, 25.0MB/s]
 45%|     | 19.8M/44.2M [00:01<00:00, 27.9MB/s]
 52%|    | 22.9M/44.2M [00:01<00:00, 23.5MB/s]
 59%|    | 26.1M/44.2M [00:01<00:00, 26.0MB/s]
 66%|   | 29.2M/44.2M [00:01<00:00, 27.8MB/s]
 73%|  | 32.4M/44.2M [00:01<00:00, 29.1MB/s]
 81%|  | 35.9M/44.2M [00:01<00:00, 31.2MB/s]
 89%| | 39.4M/44.2M [00:01<00:00, 32.7MB/s]
 98%|| 43.1M/44.2M [00:02<00:00, 27.9MB/s]
100%|| 44.2M/44.2M [00:02<00:00, 21.4MB/s]
______________________________________________________________________________________ test_Lambda[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Lambda(target_framework, mode, backend_compile):
        print("kornia.contrib.Lambda")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_fn = ivy.transpile(kornia.color.rgb_to_grayscale, source="torch", target=target_framework)
        TranspiledLambda = ivy.transpile(kornia.contrib.Lambda, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 5, 5)
        torch_out = kornia.contrib.Lambda(lambda x: kornia.color.rgb_to_grayscale(x))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledLambda(lambda x: transpiled_fn(x))(transpiled_x)

kornia/test_contrib.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Lambda()
img = Array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474858 ],
         [0.6257968 , 0.8783659 , 0.41070157, 0... 0.75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],      dtype=float32)
args = (), kwargs = {}

    def __call__(self, img, *args, **kwargs):
>       return self.func(img, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/contrib/lambda_module.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474858 ],
         [0.6257968 , 0.8783659 , 0.41070157, 0... 0.75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],      dtype=float32)

>   transpiled_out = TranspiledLambda(lambda x: transpiled_fn(x))(transpiled_x)

kornia/test_contrib.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = Array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474858 ],
         [0.6257968 , 0.8783659 , 0.41070157, 0... 0.75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],      dtype=float32)
rgb_weights = None

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.core'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/color/gray.py:32: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.Lambda
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[jax-s2s-False] - TypeError: unsupported operand type(s) for *: 'jaxlib.xla_extension.ArrayImpl' and 'Tensor'
FAILED kornia/test_contrib.py::test_EdgeDetector[jax-s2s-False] - AttributeError: 'Param' object has no attribute 'reshape'. Did you mean: 'shape'?
FAILED kornia/test_contrib.py::test_ImageStitcher[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/test_contrib.py::test_Lambda[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.core'
============================================================================== 4 failed, 11 passed in 1522.75s (0:25:22) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py FF.....F...F..FFF                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_RandomMosaic[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'tensorflow', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[ 2.0599e+00, -1.2867e-01, -3.9933e-01,  ...,  3.4881e-01,
            3.5322e-01,  6.5157e-03],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 2.05991817e+00, -1.28673211e-01, -3.99327338e-01... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f9445678840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 2.05991817e+00, -1.28673211e-01, -3.99327338e-01... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, ..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 2.05991817e+00, -1.28673211e-01, -3.99327338e-01... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 2.05991817e+00, -1.28673211e-01, -3.99327338e-01,...95450e-01, -3.09378594e-01, ...,
           1.49194396e+00,  3.53567868e-01,  1.33465850e+00]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0,...ize=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 2.05991817e+00, -1.28673211e-01, -3.993... [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 2.05991817e+00, -1.28673211e-01, -3.993...5450e-01, -3.09378594e-01, ...,
           1.49194396e+00,  3.53567868e-01,  1.33465850e+00]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 224, 224), dtype=float32, numpy=
array([[[[ 2.05991817e+00, -1.28673211e-01, -3.993...5450e-01, -3.09378594e-01, ...,
           1.49194396e+00,  3.53567868e-01,  1.33465850e+00]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
___________________________________________________________________________ test_RandomTransplantation[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.transplantation.RandomTransplantation'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[ 1.6448,  0.4358, -0.7447, -1.9170,  1.5390],
          [-0.1628, -1.0508,  0.8877,  1.8901, -0.2198],
   ...0, 1, 1, 2],
         [1, 2, 2, 1, 0],
         [1, 0, 1, 0, 0],
         [2, 1, 0, 1, 0],
         [2, 2, 1, 0, 2]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.6448472 ,  0.43579528, -0.74471015, -1.91698   ,
 ...1, 0, 1, 1, 2],
        [1, 2, 2, 1, 0],
        [1, 0, 1, 0, 0],
        [2, 1, 0, 1, 0],
        [2, 2, 1, 0, 2]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f9445c13c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...1, 0, 1, 1, 2],
        [1, 2, 2, 1, 0],
        [1, 0, 1, 0, 0],
        [2, 1, 0, 1, 0],
        [2, 2, 1, 0, 2]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.6448472 ,  0.43579528, -0.74471015, -1.91698   ,
 ...1, 0, 1, 1, 2],
        [1, 2, 2, 1, 0],
        [1, 0, 1, 0, 0],
        [2, 1, 0, 1, 0],
        [2, 2, 1, 0, 2]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=floa...1, 0, 1, 1, 2],
        [1, 2, 2, 1, 0],
        [1, 0, 1, 0, 0],
        [2, 1, 0, 1, 0],
        [2, 2, 1, 0, 2]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.6448472 ,  0.43579528, -0.74471015, -1.91698   ,
 ...1, 0, 1, 1, 2],
        [1, 2, 2, 1, 0],
        [1, 0, 1, 0, 0],
        [2, 1, 0, 1, 0],
        [2, 2, 1, 0, 2]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.6448472 ,  0.43579528, -0.74471015, -1.91698   ,
  ...  0.64068574],
         [ 0.0493564 , -0.07177813,  1.7874848 , -1.3698677 ,
           0.54474276]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.6448472 ,  0.43579528, -0.74471015, -1.91...1, 0, 1, 1, 2],
        [1, 2, 2, 1, 0],
        [1, 0, 1, 0, 0],
        [2, 1, 0, 1, 0],
        [2, 2, 1, 0, 2]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[2, 1, 0, 0, 0],
        [0, 1, 2, 2, 0],
        [1, 0, 1, 0...[1, 0, 1, 1, 2],
        [1, 2, 2, 1, 0],
        [1, 0, 1, 0, 0],
        [2, 1, 0, 1, 0],
        [2, 2, 1, 0, 2]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 1.6448472 ,  0.43579528, -0.74471015, -1.91... 0.64068574],
         [ 0.0493564 , -0.07177813,  1.7874848 , -1.3698677 ,
           0.54474276]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f943eaf03a0>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f944561a440>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7f943f056b90>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7f943ea63370>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f943f0553f0>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7f943ea9abf0>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 1, 0, 0, 0],
       [0, 1, 2, 2, 0],
       [1, 0, 1, 0, 0],
       [1, 1, 2, 2, 1],
       [1, 2, 1, 1, 0]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 1, 0, 0, 0],
       [0, 1, 2, 2, 0],
       [1, 0, 1, 0, 0],
       [1, 1, 2, 2, 1],
       [1, 2, 1, 1, 0]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 1, 0, 0, 0],
       [0, 1, 2, 2, 0],
       [1, 0, 1, 0, 0],
       [1, 1, 2, 2, 1],
       [1, 2, 1, 1, 0]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[2, 1, 0, 0, 0],
       [0, 1, 2, 2, 0],
       [1, 0, 1, 0, 0],
       [1, 1, 2, 2, 1],
       [1, 2, 1, 1, 0]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation.call():
E                  input=<class 'inspect._empty'>
E                  params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                  data_keys=None
E                  kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation
_____________________________________________________________________________ test_RandomRotation3D[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRotation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation3D")
    
        init_args = ((15., 20., 20.),)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.geometric.rotation.RandomRotation3D'>, target = 'tensorflow', init_args = ((15.0, 20.0, 20.0),), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[[0.6385, 0.6788, 0.3108],
           [0.5367, 0.6667, 0.1679],
           [0.4263, 0.9054, 0.0758]],

    ...,

          [[0.7656, 0.8942, 0.1038],
           [0.0815, 0.7832, 0.4509],
           [0.5388, 0.0436, 0.7037]]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0...,
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f943eadb040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, a...],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0...,
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, a...],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0...,
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0....2],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
   ...],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0....2],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...276285], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.004593], dtype=float32)>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f944a9601f0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f944aa4f910>
tensor = <function tensorflow_tensor_frnt at 0x7f944aa66b00>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0....2],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0....2],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...276285], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.004593], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/base.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0....2],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...276285], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.004593], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not tensorflow_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif tensorflow_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/base.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = <tf.Tensor: shape=(1, 1, 3, 3, 3), dtype=float32, numpy=
array([[[[[0.63845545, 0.67876625, 0.3107729 ],
          [0....2],
          [0.08145159, 0.7832208 , 0.45094997],
          [0.53881997, 0.04362518, 0.7036997 ]]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...276285], dtype=float32)>, 'roll': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.004593], dtype=float32)>, ...}
flags = {'align_corners': False, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ....geometry.transform.affwarp import tensorflow__compute_tensor_center3d
        from ....geometry.transform.affwarp import tensorflow__compute_rotation_matrix3d
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....utils.misc import tensorflow_eye_like
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        yaw: typing.Any = tensorflow_to_frnt_(params["yaw"], input)
        pitch: typing.Any = tensorflow_to_frnt_(params["pitch"], input)
        roll: typing.Any = tensorflow_to_frnt_(params["roll"], input)
        center: typing.Any = tensorflow__compute_tensor_center3d(input)
        rotation_mat: typing.Any = tensorflow__compute_rotation_matrix3d(
>           yaw, pitch, roll, center.expand(tensorflow_shape_frnt_(yaw)[0], -1)
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomRotation3D.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'expand'[0m
E       
E       Arguments received by tensorflow_RandomRotation3D.call():
E          input=tf.Tensor(shape=(1, 1, 3, 3, 3), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_3d/geometric/rotation.py:68: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation3D
__________________________________________________________________________ test_RandomTransplantation3D[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomTransplantation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomTransplantation3D")
    
        init_args = ()
        init_kwargs = {"p": 1.}
        call_args = (torch.randn(2, 3, 5, 5), torch.randint(0, 3, (2, 5, 5)))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomTransplantation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.mix.transplantation.RandomTransplantation3D'>, target = 'tensorflow', init_args = (), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[ 2.5628e-01, -9.0449e-01,  3.4887e-02, -1.3103e+00,  1.6679e-01],
          [ 8.5907e-01,  8.3611e-01,  2....2, 0, 1, 2],
         [1, 2, 0, 2, 0],
         [1, 1, 0, 1, 1],
         [0, 2, 2, 2, 2],
         [0, 1, 0, 0, 1]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 2.5627965e-01, -9.0448993e-01,  3.4886938e-02,
     ...2, 2, 0, 1, 2],
        [1, 2, 0, 2, 0],
        [1, 1, 0, 1, 1],
        [0, 2, 2, 2, 2],
        [0, 1, 0, 0, 1]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f9438a0fa40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...2, 2, 0, 1, 2],
        [1, 2, 0, 2, 0],
        [1, 1, 0, 1, 1],
        [0, 2, 2, 2, 2],
        [0, 1, 0, 0, 1]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 2.5627965e-01, -9.0448993e-01,  3.4886938e-02,
     ...2, 2, 0, 1, 2],
        [1, 2, 0, 2, 0],
        [1, 1, 0, 1, 1],
        [0, 2, 2, 2, 2],
        [0, 1, 0, 0, 1]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 3, 5, 5), dtype=fl...2, 2, 0, 1, 2],
        [1, 2, 0, 2, 0],
        [1, 1, 0, 1, 1],
        [0, 2, 2, 2, 2],
        [0, 1, 0, 0, 1]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 2.5627965e-01, -9.0448993e-01,  3.4886938e-02,
     ...2, 2, 0, 1, 2],
        [1, 2, 0, 2, 0],
        [1, 1, 0, 1, 1],
        [0, 2, 2, 2, 2],
        [0, 1, 0, 0, 1]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 2.5627965e-01, -9.0448993e-01,  3.4886938e-02,
      ...         [ 5.5944663e-01,  1.6050833e-01,  1.5699270e+00,
          -3.5204425e-01, -6.7648196e-01]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 2.5627965e-01, -9.0448993e-01,  3.4886938e-...2, 2, 0, 1, 2],
        [1, 2, 0, 2, 0],
        [1, 1, 0, 1, 1],
        [0, 2, 2, 2, 2],
        [0, 1, 0, 0, 1]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomTransplantation3D(p=1.0, p_batch=1.0, same_on_batch=False)
params = <tf.Tensor: shape=(2, 5, 5), dtype=int64, numpy=
array([[[0, 0, 1, 1, 1],
        [0, 0, 2, 1, 0],
        [0, 1, 2, 1...[2, 2, 0, 1, 2],
        [1, 2, 0, 2, 0],
        [1, 1, 0, 1, 1],
        [0, 2, 2, 2, 2],
        [0, 1, 0, 0, 1]]])>
data_keys = None, input = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 5), dtype=float32, numpy=
array([[[[ 2.5627965e-01, -9.0448993e-01,  3.4886938e-...        [ 5.5944663e-01,  1.6050833e-01,  1.5699270e+00,
          -3.5204425e-01, -6.7648196e-01]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f943e5b8c10>, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f9438a09240>
tensorflow_clone_frnt_ = <function tensorflow_clone_frnt_ at 0x7f9438ab03a0>, tensorflow__validate_input_dtype = <function tensorflow__validate_input_dtype at 0x7f943e53d750>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f943f72e8c0>, keys = [<tensorflow_DataKey.IMAGE: 0>, <tensorflow_DataKey.MASK: 1>]

    def call(self, *input, params=None, data_keys=None, **kwargs):
        from ....constants import tensorflow_DataKey
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...utils.helpers import tensorflow__validate_input_dtype
        from .....ivy.functional.frontends.torch.tensor import (
            tensorflow_index_put_frnt_,
        )
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [tensorflow_DataKey.get(inp) for inp in data_keys]
        if params is None:
            mask: typing.Any = tensorflow_get_item(
                input, keys.index(tensorflow_DataKey.MASK)
            )
            self._params = self.forward_parameters(tensorflow_shape_frnt_(mask))
        else:
            self._params = params
>       if any(
            k not in self._params
            for k in ["acceptor_indices", "donor_indices", "selection"]
        ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x7f944a9b2440>

    if any(
>       k not in self._params
        for k in ["acceptor_indices", "donor_indices", "selection"]
    ):

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/mix/transplantation.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 0, 1, 1, 1],
       [0, 0, 2, 1, 0],
       [0, 1, 2, 1, 2],
       [1, 0, 2, 0, 0],
       [1, 0, 2, 2, 2]])>, rhs = 'acceptor_indices'

    def impl(self, rhs):
        try:
            res = original_method(self, rhs)
            if isinstance(rhs, (list, tuple)):
                return False if orig_method_name == "__eq__" else True
            return res
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 0, 1, 1, 1],
       [0, 0, 2, 1, 0],
       [0, 1, 2, 1, 2],
       [1, 0, 2, 0, 0],
       [1, 0, 2, 2, 2]])>
other = 'acceptor_indices'

    def tensorflow___eq___frnt_(tensor, other):
        from .comparison_ops import tensorflow_eq_frnt
    
        if isinstance(other, (list, tuple)):
            return False
>       return tensorflow_eq_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 0, 1, 1, 1],
       [0, 0, 2, 1, 0],
       [0, 1, 2, 1, 2],
       [1, 0, 2, 0, 0],
       [1, 0, 2, 2, 2]])>
other = 'acceptor_indices'

    def tensorflow_eq_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_equal
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/comparison_ops.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(5, 5), dtype=int64, numpy=
array([[0, 0, 1, 1, 1],
       [0, 0, 2, 1, 0],
       [0, 1, 2, 1, 2],
       [1, 0, 2, 0, 0],
       [1, 0, 2, 2, 2]])>, x2 = 'acceptor_indices'

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
>       ) and tensorflow_is_int_dtype_bknd(x2):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_is_int_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from .general import tensorflow_is_array_bknd
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .nest import tensorflow_nested_argwhere_bknd
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "int" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (int, np.integer)) and not isinstance(
                dtype_in, bool
            )
        elif isinstance(dtype_in, (list, tuple, dict)):
    
            def nested_fun(x):
                from .general import tensorflow_is_array_bknd
                from ..backends.tensorflow.data_type import tensorflow_dtype
    
                return (
                    isinstance(x, (int, np.integer))
                    or tensorflow_is_array_bknd(x)
                    and "int" in tensorflow_dtype(x)
                ) and x is not bool
    
            return bool(tensorflow_nested_argwhere_bknd(dtype_in, nested_fun))
>       return "int" in tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = 'acceptor_indices'

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
>               raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
E               Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
E               
E               [1mCannot convert to ivy dtype. acceptor_indices is not supported by TensorFlow backend.[0m
E               
E               Arguments received by tensorflow_RandomTransplantation3D.call():
E                  input=<class 'inspect._empty'>
E                  params=tf.Tensor(shape=(2, 5, 5), dtype=int64)
E                  data_keys=None
E                  kwargs={'input': 'tf.Tensor(shape=(2, 3, 5, 5), dtype=float32)'}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:204: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomTransplantation3D
______________________________________________________________________________ test_LongestMaxSize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LongestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.LongestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 200, 200),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.LongestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:359: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.LongestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[2.6411e-01, 9.5287e-01, 1.5562e-01,  ..., 4.2480e-01,
           2.9499e-02, 6.7565e-01],
          [7.933... 4.2652e-01],
          [2.7488e-01, 1.4622e-01, 5.5766e-01,  ..., 8.5063e-01,
           2.7979e-01, 3.5302e-01]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.26411277, 0.16251591, 0.21451703, ..., 0.81402755,
          0.4281056 , 0.6756469 ],
         [0.23510867...4],
         [0.2748803 , 0.55203986, 0.21068826, ..., 0.09458617,
          0.8488047 , 0.35301793]]]], dtype=float32)
y = array([[[[0.6261338 , 0.36462998, 0.46732372, ..., 0.42076164,
          0.55608183, 0.5432554 ],
         [0.37436092...4],
         [0.49897358, 0.4472186 , 0.23824818, ..., 0.26444364,
          0.68349206, 0.50603837]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.LongestMaxSize
__________________________________________________________________________________ test_Resize[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Resize(target_framework, mode, backend_compile):
        print("kornia.augmentation.Resize")
    
        init_args = ((100, 100),)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.Resize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.Resize'>, target = 'tensorflow', init_args = ((100, 100),), init_kwargs = {}
call_args = (tensor([[[[0.6418, 0.9485, 0.2366,  ..., 0.8312, 0.8009, 0.7830],
          [0.5641, 0.0299, 0.4835,  ..., 0.2741, 0...., 0.4941, 0.0397,  ..., 0.4364, 0.8754, 0.8750],
          [0.8786, 0.9885, 0.3206,  ..., 0.1717, 0.5107, 0.1208]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.641826  , 0.7936041 , 0.9453821 , ..., 0.8007432 ,
          0.79186356, 0.78298396],
         [0.60337657... ],
         [0.8786165 , 0.93300277, 0.987389  , ..., 0.50671804,
          0.31373438, 0.12075073]]]], dtype=float32)
y = array([[[[0.641826  , 0.7184894 , 0.8718162 , ..., 0.7964393 ,
          0.7874691 , 0.78298396],
         [0.6224051 ...2],
         [0.8786165 , 0.9060871 , 0.96102834, ..., 0.4131801 ,
          0.21822721, 0.12075073]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.Resize
______________________________________________________________________________ test_SmallestMaxSize[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SmallestMaxSize(target_framework, mode, backend_compile):
        print("kornia.augmentation.SmallestMaxSize")
    
        init_args = (100,)
        init_kwargs = {}
        call_args = (torch.rand(10, 3, 50, 50),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.SmallestMaxSize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=True,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:399: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resize.SmallestMaxSize'>, target = 'tensorflow', init_args = (100,), init_kwargs = {}
call_args = (tensor([[[[0.0186, 0.9396, 0.5771,  ..., 0.0087, 0.5884, 0.8303],
          [0.5491, 0.9843, 0.5864,  ..., 0.1949, 0...., 0.1833, 0.1188,  ..., 0.3045, 0.6264, 0.1323],
          [0.5813, 0.6467, 0.3973,  ..., 0.0093, 0.2848, 0.6012]]]]),)
call_kwargs = {}, deterministic_output = True, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
        transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)
    
        orig_np = _nest_array_to_numpy(torch_out)
        transpiled_np = _nest_array_to_numpy(transpiled_out)
    
        _check_shape_allclose(orig_np, transpiled_np)
    
        if deterministic_output:
            orig_np = _nest_array_to_numpy(torch_out)
            transpiled_np = _nest_array_to_numpy(transpiled_out)
>           _check_allclose(orig_np, transpiled_np, tolerance=tolerance)

kornia/augmentation/test_augmentation4.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.01858675, 0.47441894, 0.9302511 , ..., 0.5908637 ,
          0.7105961 , 0.8303285 ],
         [0.28116578...7],
         [0.58129627, 0.6136874 , 0.6460785 , ..., 0.28804338,
          0.44463894, 0.60123456]]]], dtype=float32)
y = array([[[[0.01858675, 0.24882852, 0.709312  , ..., 0.6488972 ,
          0.76985145, 0.8303285 ],
         [0.15121596...2],
         [0.58129627, 0.5976571 , 0.6303787 , ..., 0.36394423,
          0.52213776, 0.60123456]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.SmallestMaxSize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomRotation3D[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomRotation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_RandomTransplantation3D[tensorflow-s2s-False] - Exception: Exception encountered when calling tensorflow_RandomTransplantation3D.call().
FAILED kornia/augmentation/test_augmentation4.py::test_LongestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_Resize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/augmentation/test_augmentation4.py::test_SmallestMaxSize[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 7 failed, 10 passed in 3673.70s (1:01:13) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 425.59s (0:07:05) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py .F.....FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_SIFTFeatureScaleSpace[jax-s2s-False] _______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeatureScaleSpace = ivy.transpile(kornia.feature.SIFTFeatureScaleSpace, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
        transpiled_model = TranspiledSIFTFeatureScaleSpace(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
>       transpiled_out = transpiled_model(transpiled_x)

kornia/test_feature4.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SIFTFeatureScaleSpace(
  (detector): jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyram...ng_bins=8, num_spatial_bins=4, patch_size=41, rootsift=True, clipval=0.2), patch_size=41, grayscale_descriptor='True)
)
img = Array([[[[0.7249347 , 0.22058696, 0.48966056, ..., 0.7484179 ,
          0.5014568 , 0.20342433],
         [0.5031322 ... ],
         [0.5364803 , 0.73888874, 0.7277581 , ..., 0.89725226,
          0.9379686 , 0.2508461 ]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
        from .laf import jax_scale_laf
    
>       lafs, responses = self.detector(img, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.7249347 , 0.22058696, 0.48966056, ..., 0.7484179 ,
          0.5014568 , 0.20342433],
         [0.5031322 ... ],
         [0.5364803 , 0.73888874, 0.7277581 , ..., 0.89725226,
          0.9379686 , 0.2508461 ]]]], dtype=float32)
mask = None

    def __call__(self, img, mask=None):
>       responses, lafs = self.detect(img, self.num_features, mask)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScaleSpaceDetector(num_features=10, mr_size=6.0, scale_pyr=jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=3...19, angle_detector=jax_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08)), aff=jax_PassLAF())
img = Array([[[[0.7249347 , 0.22058696, 0.48966056, ..., 0.7484179 ,
          0.5014568 , 0.20342433],
         [0.5031322 ... ],
         [0.5364803 , 0.73888874, 0.7277581 , ..., 0.89725226,
          0.9379686 , 0.2508461 ]]]], dtype=float32)
num_feats = 10, mask = None

    def detect(self, img, num_feats, mask=None):
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import jax_topk_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            jax_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from .laf import jax_laf_is_inside_image
        from ..core._backend import eye
        from ..core._backend import concatenate
    
        dev: typing.Any = img.device
        dtype: typing.Any = img.dtype
        sigmas: typing.Any
>       sp, sigmas, _ = self.scale_pyr(img)

ivy_transpiled_outputs/jax_outputs/kornia/feature/scale_space_detector.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
x = Array([[[[0.7249347 , 0.22058696, 0.48966056, ..., 0.7484179 ,
          0.5014568 , 0.20342433],
         [0.5031322 ... ],
         [0.5364803 , 0.73888874, 0.7277581 , ..., 0.89725226,
          0.9379686 , 0.2508461 ]]]], dtype=float32)

    def __call__(self, x):
        from ...filters.gaussian import jax_gaussian_blur2d
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...core._backend import ones
        from ...core._backend import stack
    
        bs, _, _, _ = jax_size_frnt_(x)
>       cur_level, cur_sigma, pixel_distance = self.get_first_level(x)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ScalePyramid(n_levels=3, init_sigma=1.6, min_size=32, extra_levels=3, border=15, sigma_step=1.2599210498948732, double_image=True)
input = Array([[[[0.7249347 , 0.22058696, 0.48966056, ..., 0.7484179 ,
          0.5014568 , 0.20342433],
         [0.5031322 ... ],
         [0.5364803 , 0.73888874, 0.7277581 , ..., 0.89725226,
          0.9379686 , 0.2508461 ]]]], dtype=float32)

    def get_first_level(self, input):
        from ...filters.gaussian import jax_gaussian_blur2d
    
        pixel_distance = 1.0
        cur_sigma = 0.5
        if self.double_image:
>           x = jax_upscale_double(input)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.7249347 , 0.22058696, 0.48966056, ..., 0.7484179 ,
          0.5014568 , 0.20342433],
         [0.5031322 ... ],
         [0.5364803 , 0.73888874, 0.7277581 , ..., 0.89725226,
          0.9379686 , 0.2508461 ]]]], dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.7249347 , 0.        , 0.22058696, ..., 0.        ,
          0.20342433, 0.        ],
         [0.        ... ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.47276083, 0.35512376, 0.26231015, ..., 0.62493736,
          0.35244057, 0.        ],
         [0.3801897 ... ],
         [0.6376845 , 0.73332345, 0.46338254, ..., 0.9176104 ,
          0.5944073 , 0.        ]]]], dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("'{}' object does not support item assignment. JAX arrays are "
             "immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` "
             "or another .at[] method: "
             "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:587: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
All parameters and buffers are now synced!
_______________________________________________________________________________ test_LocalFeatureMatcher[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
        TranspiledDescriptorMatcher = ivy.transpile(kornia.feature.DescriptorMatcher, source="torch", target=target_framework)
        TranspiledLocalFeatureMatcher = ivy.transpile(kornia.feature.LocalFeatureMatcher, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
        ...
         [0.983146  , 0.6155569 , 0.9821086 , ..., 0.73596215,
          0.58765954, 0.6284834 ]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
        ...
         [0.983146  , 0.6155569 , 0.9821086 , ..., 0.73596215,
          0.58765954, 0.6284834 ]]]], dtype=float32)},)
kwargs = {}
forward_call = <bound method LocalFeatureMatcher.forward of LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector)...k_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         ...],
         [0.983146  , 0.6155569 , 0.9821086 , ..., 0.73596215,
          0.58765954, 0.6284834 ]]]], dtype=float32)}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.05271316... ],
         [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32)
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.0527131...      [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.0527131...      [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32), None)
kwargs = {}
forward_call = <bound method LocalFeature.forward of GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFT...s=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.05271316... ],
         [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.0527131...      [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32), None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.0527131...      [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32), None)
kwargs = {}
forward_call = <bound method MultiResolutionDetector.forward of MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (n...(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.05271316... ],
         [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32)
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.05271316... ],
         [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32)
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.8351691 , 0.08836424, 0.26690477, ..., 0.06028897,
          0.9621109 , 0.33325136],
         [0.05271316... ],
         [0.29405284, 0.56774294, 0.06326938, ..., 0.68900394,
          0.9359023 , 0.52190083]]]], dtype=float32)
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_________________________________________________________________________________ test_LightGlueMatcher[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlueMatcher = ivy.transpile(kornia.feature.LightGlueMatcher, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = TranspiledLightGlueMatcher('disk')

kornia/test_feature4.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, args = ('disk',), kwargs = {}, node = jax_LightGlueMatcher()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.integrated.jax_LightGlueMatcher'>, self = jax_LightGlueMatcher(), args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import jax_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = jax_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/jax_outputs/kornia/feature/integrated.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>, args = ('disk',), kwargs = {}
node = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_LightGlue'>
self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LightGlue(
  (input_proj): FlaxLinear(in_features=128, out_features=256, use_bias=True)
  (posenc): jax_LearnableFourierPositionalEncoding(
    (Wr): FlaxLinear(in_features=2, out_features=32, use_bias=False)
  )
)
features = 'disk', conf_ = {}, jax_KORNIA_CHECK = <function jax_KORNIA_CHECK at 0x7f2c4222a320>, jax_get_item = <function jax_get_item at 0x7f2c3a8b8c10>
jax_Identity = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.linear.jax_Identity'>, jax_load_state_dict_from_url_frnt = <function jax_load_state_dict_from_url_frnt at 0x7f2c58fa12d0>
jax_load_frnt = <function jax_load_frnt at 0x7f2c58fa0040>, ModuleList = <class 'ivy_transpiled_outputs.jax_outputs.torch.nn.modules.container.jax_ModuleList'>
FlaxLinear = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxLinear'>

    @jax_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import jax_KORNIA_CHECK
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...torch.nn.modules.linear import jax_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            jax_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            jax_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in jax_get_item(self.features, features).items():
                setattr(conf, k, v)
        jax_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = FlaxLinear(
                in_features=conf.input_dim,
                out_features=conf.descriptor_dim,
                use_bias=True,
            )
        else:
            self.input_proj = jax_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = jax_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = jax_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:1389: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, args = (256, 4, True), kwargs = {}, node = jax_TransformerLayer()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_TransformerLayer'>, self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @jax_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = jax_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:944: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, args = (256, 4, True), kwargs = {}
node = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_SelfBlock'>, self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
)
args = (256, 4, True), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_SelfBlock(
  (Wqkv): FlaxLinear(in_features=256, out_features=768, use_bias=True)
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @jax_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import jax_KORNIA_CHECK
        from ...torch.nn.modules.container import jax_Sequential
        from ...torch.nn.modules.normalization import jax_LayerNorm
        from ...torch.nn.modules.activation import jax_GELU
        from ...jax__stateful_layers import FlaxLinear
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        jax_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = FlaxLinear(
            in_features=embed_dim, out_features=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = jax_Attention(flash)

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, args = (True,), kwargs = {}, node = jax_Attention()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.lightglue.jax_Attention'>, self = jax_Attention(), args = (True,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Attention(), allow_flash = True

    @jax_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/lightglue.py:398: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 53%|    | 23.9M/45.4M [00:00<00:00, 250MB/s]
100%|| 45.4M/45.4M [00:00<00:00, 293MB/s]
____________________________________________________________________________________ test_LightGlue[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlue = ivy.transpile(kornia.feature.LightGlue, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.9788756 , 0.390688  , 0.3550321 , ..., 0.45211262,
         0.02576602, 0.31574...     [0.8740442 , 0.2486856 ],
        [0.4690097 , 0.80362767],
        [0.32112926, 0.88690794]]], dtype=float32)}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': Array([[[0.9788756 , 0.390688  , 0.3550321 , ..., 0.45211262,
         0.02576602, 0.31574...     [0.8740442 , 0.2486856 ],
        [0.4690097 , 0.80362767],
        [0.32112926, 0.88690794]]], dtype=float32)}},)
kwargs = {}
forward_call = <bound method LightGlue.forward of LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncodin...Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.9788756 , 0.390688  , 0.3550321 , ..., 0.45211262,
         0.02576602, 0.315748...       [0.8740442 , 0.2486856 ],
        [0.4690097 , 0.80362767],
        [0.32112926, 0.88690794]]], dtype=float32)}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': Array([[[0.9788756 , 0.390688  , 0.3550321 , ..., 0.45211262,
         0.02576602, 0.315748...       [0.8740442 , 0.2486856 ],
        [0.4690097 , 0.80362767],
        [0.32112926, 0.88690794]]], dtype=float32)}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[0.11835545, 0.71417177],
        [0.2000317 , 0.08563817],
        [0.40763843, 0.27553093],
        [0.1355...        [0.03510642, 0.20595932],
        [0.5974161 , 0.28869438]]], dtype=float32), Array([[640, 480]], dtype=int64))
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:466: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = Array([[[0.11835545, 0.71417177],
        [0.2000317 , 0.08563817],
        [0.40763843, 0.27553093],
        [0.13556...
        [0.8560366 , 0.65065336],
        [0.03510642, 0.20595932],
        [0.5974161 , 0.28869438]]], dtype=float32)
size = Array([[640, 480]], dtype=int64)

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 67%|   | 30.2M/45.3M [00:00<00:00, 308MB/s]
100%|| 45.3M/45.3M [00:00<00:00, 230MB/s]
______________________________________________________________________________________ test_LoFTR[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[0.15139431, 0.912334  , 0.19216287, ..., 0.49381524,
          0.5689218 , 0.40185678],
        ...
         [0.5258261 , 0.02630687, 0.7507178 , ..., 0.94061136,
          0.684852  , 0.5981016 ]]]], dtype=float32)},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': Array([[[[0.15139431, 0.912334  , 0.19216287, ..., 0.49381524,
          0.5689218 , 0.40185678],
        ...
         [0.5258261 , 0.02630687, 0.7507178 , ..., 0.94061136,
          0.684852  , 0.5981016 ]]]], dtype=float32)},)
kwargs = {}
forward_call = <bound method LoFTR.forward of LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), str...  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': Array([[[[0.15139431, 0.912334  , 0.19216287, ..., 0.49381524,
          0.5689218 , 0.40185678],
         ...],
         [0.5258261 , 0.02630687, 0.7507178 , ..., 0.94061136,
          0.684852  , 0.5981016 ]]]], dtype=float32)}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[jax-s2s-False] - TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. ...
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[jax-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'jaxlib.xla_extension.ArrayImpl'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[jax-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'float'. Did you mean: 'flat'?
FAILED kornia/test_feature4.py::test_LoFTR[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 5 failed, 9 passed in 2973.05s (0:49:33) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py FFFF...FFFF...                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_SIFTFeature[tensorflow-s2s-False] ________________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.5125294 ]],

       [[ 0.3107617 ]],

       [[-0.6912    ]],

       [[-0.5433967 ]],

       [[-0.14397192]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeature(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeature")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeature = ivy.transpile(kornia.feature.SIFTFeature, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeature(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledSIFTFeature(num_features=10)

kornia/test_feature4.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeature object at 0x7f6f7148db40>, num_features = 10, upright = False, rootsift = True
device = 'cpu', config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_BlobDoGSingle
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_BlobDoGSingle(1.0, 1.6),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_PassLAF(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:353: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f6f7148f8e0>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f6f7148f8e0>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.5125294 ]],

       [[ 0.3107617 ]],

       [[-0.6912    ]],

       [[-0.5433967 ]],

       [[-0.14397192]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[-0.5125294 ]],

       [[ 0.3107617 ]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[-0.5125294 ]],

       [[ 0.3107617 ]],

       [[-0.6912    ]],

       [[-0.5433967 ]],

       [[-0.14397192]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeature
___________________________________________________________________________ test_SIFTFeatureScaleSpace[tensorflow-s2s-False] ___________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.6104462 ]],

       [[ 0.875401  ]],

       [[-0.42645502]],

       [[-0.71758676]],

       [[-0.13961363]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_SIFTFeatureScaleSpace(target_framework, mode, backend_compile):
        print("kornia.feature.SIFTFeatureScaleSpace")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSIFTFeatureScaleSpace = ivy.transpile(kornia.feature.SIFTFeatureScaleSpace, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.SIFTFeatureScaleSpace(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledSIFTFeatureScaleSpace(num_features=10)

kornia/test_feature4.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_SIFTFeatureScaleSpace object at 0x7f6f7186f6a0>, num_features = 10, upright = False, rootsift = True
device = 'cpu'

    def __init__(
        self,
        num_features=8000,
        upright=False,
        rootsift=True,
        device=tensorflow_device_frnt("cpu"),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_ScaleSpaceDetector
        from .responses import tensorflow_BlobDoG
        from ..geometry.subpix.spatial_soft_argmax import tensorflow_ConvQuadInterp3d
        from ..geometry.transform.pyramid import tensorflow_ScalePyramid
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .siftdesc import tensorflow_SIFTDescriptor
    
        patch_size: typing.Any = 41
        detector = tensorflow_to_frnt_(
            tensorflow_ScaleSpaceDetector(
                num_features,
                resp_module=tensorflow_BlobDoG(),
                nms_module=tensorflow_ConvQuadInterp3d(10),
                scale_pyr_module=tensorflow_ScalePyramid(3, 1.6, 32, double_image=True),
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                scale_space_response=True,
                minima_are_also_good=True,
                mr_size=6.0,
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f6f7186c1f0>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f6f7186c1f0>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.6104462 ]],

       [[ 0.875401  ]],

       [[-0.42645502]],

       [[-0.71758676]],

       [[-0.13961363]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.6104462 ]],

       [[ 0.875401  ]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[ 0.6104462 ]],

       [[ 0.875401  ]],

       [[-0.42645502]],

       [[-0.71758676]],

       [[-0.13961363]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.SIFTFeatureScaleSpace
_____________________________________________________________________________ test_GFTTAffNetHardNet[tensorflow-s2s-False] _____________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[0.8532181 ]],

       [[0.58871627]],

       [[0.73565865]],

       [[0.45180893]],

       [[0.51370525]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_GFTTAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.GFTTAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.GFTTAffNetHardNet(num_features=10)
        torch_out = model(x)
    
>       transpiled_model = TranspiledGFTTAffNetHardNet(num_features=10)

kornia/test_feature4.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f6f71346440>, num_features = 10, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:351: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f6f713469b0>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f6f713469b0>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[0.8532181 ]],

       [[0.58871627]],

       [[0.73565865]],

       [[0.45180893]],

       [[0.51370525]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[0.8532181 ]],

       [[0.58871627]],

     ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0.8532181 ]],

       [[0.58871627]],

       [[0.73565865]],

       [[0.45180893]],

       [[0.51370525]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.GFTTAffNetHardNet
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|| 332k/332k [00:00<00:00, 72.0MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|| 5.10M/5.10M [00:00<00:00, 261MB/s]
____________________________________________________________________________ test_KeyNetAffNetHardNet[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KeyNetAffNetHardNet(target_framework, mode, backend_compile):
        print("kornia.feature.KeyNetAffNetHardNet")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledKeyNetAffNetHardNet = ivy.transpile(kornia.feature.KeyNetAffNetHardNet, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.KeyNetAffNetHardNet(num_features=10)
        torch_out = model(x)
    
        transpiled_model = TranspiledKeyNetAffNetHardNet(num_features=10)
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature4.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[  6.1578, -13.3079, 167.6022],
          [ 15.1353,   6.5987,  43.1381]],

         [[-11.0609, -10.8297, ...96,  0.0009],
         [ 0.1963,  0.0372, -0.1658,  ...,  0.0487,  0.1337,  0.0633]]],
       grad_fn=<ViewBackward0>))
transpiled_x = (<tf.Tensor: shape=(1, 10, 2, 3), dtype=float32, numpy=
array([[[[  6.1582203 , -13.307666  , 167.60222   ],
         ...       [ 0.19634211,  0.03726843, -0.16584612, ...,  0.0487927 ,
          0.13358282,  0.06333835]]], dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[  6.1578054, -13.30786  , 167.60222  ],
         [ 15.135287 ,   6.5986843,  43.138123 ]],

        [[-11.0...        [ 0.19634727,  0.03722786, -0.16583186, ...,  0.04874583,
          0.13365975,  0.06331357]]], dtype=float32))
y = (array([[[[  6.1582203 , -13.307666  , 167.60222   ],
         [ 15.13509   ,   6.599148  ,  43.138123  ]],

        [...        [ 0.19634211,  0.03726843, -0.16584612, ...,  0.0487927 ,
          0.13358282,  0.06333835]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f6f4ae52e00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[  6.1578054, -13.30786  , 167.60222  ],
         [ 15.135287 ,   6.5986843,  43.138123 ]],

        [[-11.06...

        [[ -8.6092415, -20.754663 , 168.       ],
         [ 19.498417 ,  -9.213002 ,  44.       ]]]], dtype=float32)
y = array([[[[  6.1582203 , -13.307666  , 167.60222   ],
         [ 15.13509   ,   6.599148  ,  43.138123  ]],

        [[...    [[ -8.609655  , -20.754494  , 168.        ],
         [ 19.498232  ,  -9.213388  ,  44.        ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.KeyNetAffNetHardNet
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/OriNet.pth" to /root/.cache/torch/hub/checkpoints/OriNet.pth

  0%|          | 0.00/316k [00:00<?, ?B/s]
100%|| 316k/316k [00:00<00:00, 51.1MB/s]
Downloading: "https://github.com/axelBarroso/Key.Net-Pytorch/raw/main/model/weights/keynet_pytorch.pth" to /root/.cache/torch/hub/checkpoints/keynet_pytorch.pth

  0%|          | 0.00/78.0k [00:00<?, ?B/s]
100%|| 78.0k/78.0k [00:00<00:00, 23.5MB/s]
____________________________________________________________________________ test_LocalFeatureMatcher[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LocalFeatureMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LocalFeatureMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledGFTTAffNetHardNet = ivy.transpile(kornia.feature.GFTTAffNetHardNet, source="torch", target=target_framework)
        TranspiledDescriptorMatcher = ivy.transpile(kornia.feature.DescriptorMatcher, source="torch", target=target_framework)
        TranspiledLocalFeatureMatcher = ivy.transpile(kornia.feature.LocalFeatureMatcher, source="torch", target=target_framework)
    
        data = {
            "image0": torch.rand(1, 1, 320, 200),
            "image1": torch.rand(1, 1, 128, 128),
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        torch_local_feature = kornia.feature.GFTTAffNetHardNet(10)
        torch_matcher = kornia.feature.DescriptorMatcher('snn', 0.8)
        model = kornia.feature.LocalFeatureMatcher(torch_local_feature, torch_matcher)
>       torch_out = model(data)

kornia/test_feature4.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, .....         [0.56553686, 0.7377694 , 0.30921853, ..., 0.9346892 ,
          0.6356983 , 0.09277087]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, .....         [0.56553686, 0.7377694 , 0.30921853, ..., 0.9346892 ,
          0.6356983 , 0.09277087]]]], dtype=float32)>},)
kwargs = {}
forward_call = <bound method LocalFeatureMatcher.forward of LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector)...k_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ......,
         [0.56553686, 0.7377694 , 0.30921853, ..., 0.9346892 ,
          0.6356983 , 0.09277087]]]], dtype=float32)>}

    def forward(self, data: Dict[str, Tensor]) -> Dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``lafs0``, matching LAFs from image0 :math:`(1, NC, 2, 3)`.
            - ``lafs1``, matching LAFs from image1 :math:`(1, NC, 2, 3)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        num_image_pairs: int = data["image0"].shape[0]
    
        if ("lafs0" not in data.keys()) or ("descriptors0" not in data.keys()):
            # One can supply pre-extracted local features
>           feats_dict0: Dict[str, Tensor] = self.extract_features(data["image0"])

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LocalFeatureMatcher(
  (local_feature): GFTTAffNetHardNet(
    (detector): MultiResolutionDetector(
      (model): Cor...ck_running_stats=True)
      )
    ), patch_size=32, grayscale_descriptor='True)
  )
  (matcher): DescriptorMatcher()
)
image = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.2509354...],
         [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>
mask = None

    def extract_features(self, image: Tensor, mask: Optional[Tensor] = None) -> Dict[str, Tensor]:
        """Function for feature extraction from simple image."""
>       lafs0, resps0, descs0 = self.local_feature(image, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.250935...     [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.250935...     [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>, None)
kwargs = {}
forward_call = <bound method LocalFeature.forward of GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFT...s=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = GFTTAffNetHardNet(
  (detector): MultiResolutionDetector(
    (model): CornerGFTT(grads_mode=sobel)
    (nms): NonMaxi...ps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
  ), patch_size=32, grayscale_descriptor='True)
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.2509354...],
         [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:
        """
        Args:
            img: image to extract features with shape :math:`(B,C,H,W)`.
            mask: a mask with weights where to apply the response function.
                The shape must be the same as the input image.
    
        Returns:
            - Detected local affine frames with shape :math:`(B,N,2,3)`.
            - Response function values for corresponding lafs with shape :math:`(B,N,1)`.
            - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.
        """
>       lafs, responses = self.detector(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/integrated.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.250935...     [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>, None)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
args = (<tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.250935...     [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>, None)
kwargs = {}
forward_call = <bound method MultiResolutionDetector.forward of MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (n...(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.2509354...],
         [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>
mask = None

    def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Three stage local feature detection. First the location and scale of interest points are determined by
        detect function. Then affine shape and orientation.
    
        Args:
            img: image to extract features with shape [1xCxHxW]. KeyNetDetector does not support batch processing,
        because the number of detections is different on each image.
            mask: a mask with weights where to apply the response function. The shape must be the same as
              the input image.
    
        Returns:
            lafs: shape [1xNx2x3]. Detected local affine frames.
            responses: shape [1xNx1]. Response function values for corresponding lafs
        """
        KORNIA_CHECK_SHAPE(img, ["1", "C", "H", "W"])
>       responses, lafs = self.detect(img, mask)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MultiResolutionDetector(
  (model): CornerGFTT(grads_mode=sobel)
  (nms): NonMaximaSuppression2d()
  (ori): LAFOriente...d(64, 3, kernel_size=(8, 8), stride=(1, 1))
      (20): Tanh()
      (21): AdaptiveAvgPool2d(output_size=1)
    )
  )
)
img = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.2509354...],
         [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>
mask = None

    def detect(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        # Compute points per level
        num_features_per_level: List[float] = []
        tmp = 0.0
        factor_points = self.scale_factor_levels**2
        levels = self.num_pyramid_levels + self.num_upscale_levels + 1
        for idx_level in range(levels):
            tmp += factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            nf = self.num_features * factor_points ** (-1 * (idx_level - self.num_upscale_levels))
            num_features_per_level.append(nf)
        num_features_per_level = [int(x / tmp) for x in num_features_per_level]
    
        _, _, h, w = img.shape
        img_up = img
        cur_img = img
        all_responses: List[Tensor] = []
        all_lafs: List[Tensor] = []
        # Extract features from the upper levels
        for idx_level in range(self.num_upscale_levels):
            nf = num_features_per_level[len(num_features_per_level) - self.num_pyramid_levels - 1 - (idx_level + 1)]
            num_points_level = int(nf)
    
            # Resize input image
            up_factor = self.scale_factor_levels ** (1 + idx_level)
            nh, nw = int(h * up_factor), int(w * up_factor)
            up_factor_kpts = (float(w) / float(nw), float(h) / float(nh))
>           img_up = resize(img_up, (nh, nw), interpolation="bilinear", align_corners=False)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/scale_space_detector.py:345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.07880384, 0.49583662, 0.13155222, ..., 0.2509354...],
         [0.0535304 , 0.60433865, 0.28331494, ..., 0.6831892 ,
          0.29998952, 0.41131222]]]], dtype=float32)>
args = ((452, 282),), kwargs = {'align_corners': False, 'interpolation': 'bilinear'}

    @wraps(f)
    def _wrapper(input: Tensor, *args: Any, **kwargs: Any) -> Tensor:
        if not isinstance(input, Tensor):
>           raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
E           TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/utils/image.py:224: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LocalFeatureMatcher
_____________________________________________________________________________ test_LightGlueMatcher[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlueMatcher(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlueMatcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlueMatcher = ivy.transpile(kornia.feature.LightGlueMatcher, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(2, 128),
            torch.rand(5, 128),
            torch.rand(1, 2, 2, 3),
            torch.rand(1, 5, 2, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        model = kornia.feature.LightGlueMatcher('disk')
        torch_out = model(*torch_args)
    
>       transpiled_model = TranspiledLightGlueMatcher('disk')

kornia/test_feature4.py:260: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlueMatcher(), feature_name = 'disk', params = {}

    def __init__(self, feature_name="disk", params={}):
        from .lightglue import tensorflow_LightGlue
    
        feature_name_: typing.Any = feature_name.lower()
        super().__init__(feature_name_)
        self.feature_name = feature_name_
        self.params = params
>       self.matcher = tensorflow_LightGlue(self.feature_name, **params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), args = ('disk',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LightGlue(
  (input_proj): KerasDense()
  (posenc): tensorflow_LearnableFourierPositionalEncoding(
    (Wr): KerasDense()
  )
), features = 'disk', conf_ = {}
tensorflow_KORNIA_CHECK = <function tensorflow_KORNIA_CHECK at 0x7f6f715cedd0>, tensorflow_get_item = <function tensorflow_get_item at 0x7f6f71540670>
tensorflow_Identity = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.linear.tensorflow_Identity'>
tensorflow_load_state_dict_from_url_frnt = <function tensorflow_load_state_dict_from_url_frnt at 0x7f6f7304b490>, tensorflow_load_frnt = <function tensorflow_load_frnt at 0x7f6f7304ab90>
ModuleList = <class 'ivy_transpiled_outputs.tensorflow_outputs.torch.nn.modules.container.tensorflow_ModuleList'>
KerasDense = <class 'ivy_transpiled_outputs.tensorflow_outputs.tensorflow__stateful_layers.KerasDense'>

    @tensorflow_store_config_info
    def __init__(self, features="superpoint", **conf_):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...torch.nn.modules.linear import tensorflow_Identity
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ...ivy.functional.frontends.torch.serialization.serialization import (
            tensorflow_load_frnt,
        )
        from ..core._backend import ModuleList
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            features=features,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.conf = conf = SimpleNamespace(**{**self.default_conf, **conf_})
        if features is not None:
            tensorflow_KORNIA_CHECK(
                features in list(self.features.keys()), "Features keys are wrong"
            )
            for k, v in tensorflow_get_item(self.features, features).items():
                setattr(conf, k, v)
        tensorflow_KORNIA_CHECK(not (self.conf.add_scale_ori and self.conf.add_laf))
        if conf.input_dim != conf.descriptor_dim:
            self.input_proj = KerasDense(
                in_features=conf.input_dim, units=conf.descriptor_dim, use_bias=True
            )
        else:
            self.input_proj = tensorflow_Identity()
        head_dim = conf.descriptor_dim // conf.num_heads
        self.posenc = tensorflow_LearnableFourierPositionalEncoding(
            2 + 2 * conf.add_scale_ori + 4 * conf.add_laf, head_dim, head_dim
        )
        h, n, d = conf.num_heads, conf.n_layers, conf.descriptor_dim
        ag__result_list_0 = []
        for _ in range(n):
>           res = tensorflow_TransformerLayer(d, h, conf.flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:1433: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_TransformerLayer(), args = (256, 4, True), kwargs = {}

    @tensorflow_store_config_info
    def __init__(self, *args, **kwargs):
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.self_attn = tensorflow_SelfBlock(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:976: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), args = (256, 4, True), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_SelfBlock(
  (Wqkv): KerasDense()
), embed_dim = 256, num_heads = 4, flash = True, bias = True

    @tensorflow_store_config_info
    def __init__(self, embed_dim, num_heads, flash=False, bias=True):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...torch.nn.modules.normalization import tensorflow_LayerNorm
        from ...torch.nn.modules.activation import tensorflow_GELU
        from ...tensorflow__stateful_layers import KerasDense
    
        self.super___init__(
            embed_dim,
            num_heads,
            flash=flash,
            bias=bias,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        tensorflow_KORNIA_CHECK(
            self.embed_dim % num_heads == 0,
            "Embed dimension should be dividable by num_heads",
        )
        self.head_dim = self.embed_dim // num_heads
        self.Wqkv = KerasDense(
            in_features=embed_dim, units=3 * embed_dim, use_bias=bias
        )
>       self.inner_attn = tensorflow_Attention(flash)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), args = (True,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Attention(), allow_flash = True

    @tensorflow_store_config_info
    def __init__(self, allow_flash):
        self.super___init__(
            allow_flash,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if allow_flash and not FLASH_AVAILABLE:
            warnings.warn(
                "FlashAttention is not available. For optimal speed, consider installing torch >= 2.0 or flash-attn.",
                stacklevel=2,
            )
        self.enable_flash = allow_flash and FLASH_AVAILABLE
>       self.has_sdp = hasattr(torch.nn.functional, "scaled_dot_product_attention")
E       NameError: name 'torch' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/lightglue.py:411: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlueMatcher
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth" to /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.4M [00:00<?, ?B/s]
 18%|        | 8.38M/45.4M [00:00<00:00, 74.2MB/s]
 34%|      | 15.5M/45.4M [00:00<00:00, 73.1MB/s]
 54%|    | 24.8M/45.4M [00:00<00:00, 83.4MB/s]
 77%|  | 35.1M/45.4M [00:00<00:00, 93.0MB/s]
100%|| 45.4M/45.4M [00:00<00:00, 98.1MB/s]
100%|| 45.4M/45.4M [00:00<00:00, 90.9MB/s]
_________________________________________________________________________________ test_LightGlue[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LightGlue(target_framework, mode, backend_compile):
        print("kornia.feature.LightGlue")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLightGlue = ivy.transpile(kornia.feature.LightGlue, source="torch", target=target_framework)
    
        data = {
            "image0": {
                "keypoints": torch.rand(1, 100, 2),
                "descriptors": torch.rand(1, 100, 256),
                "image_size": torch.tensor([[640, 480]]),
            },
            "image1": {
                "keypoints": torch.rand(1, 120, 2),
                "descriptors": torch.rand(1, 120, 256),
                "image_size": torch.tensor([[640, 480]]),
            }
        }
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LightGlue(features='superpoint')
>       torch_out = model(data)

kornia/test_feature4.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.94031596, 0.06994444, 0....    [0.30261278, 0.7373067 ],
        [0.8889572 , 0.16632855],
        [0.33966464, 0.16683477]]], dtype=float32)>}},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
args = ({'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.94031596, 0.06994444, 0....    [0.30261278, 0.7373067 ],
        [0.8889572 , 0.16632855],
        [0.33966464, 0.16683477]]], dtype=float32)>}},)
kwargs = {}
forward_call = <bound method LightGlue.forward of LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncodin...Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.94031596, 0.06994444, 0.3...      [0.30261278, 0.7373067 ],
        [0.8889572 , 0.16632855],
        [0.33966464, 0.16683477]]], dtype=float32)>}}

    def forward(self, data: dict) -> dict:  # type: ignore
        """Match keypoints and descriptors between two images.
    
        Input (dict):
            image0: dict
                keypoints: [B x M x 2]
                descriptors: [B x M x D]
                image: [B x C x H x W] or image_size: [B x 2]
            image1: dict
                keypoints: [B x N x 2]
                descriptors: [B x N x D]
                image: [B x C x H x W] or image_size: [B x 2]
        Output (dict):
            log_assignment: [B x M+1 x N+1]
            matches0: [B x M]
            matching_scores0: [B x M]
            matches1: [B x N]
            matching_scores1: [B x N]
            matches: List[[Si x 2]], scores: List[[Si]]
        """
        with torch.autocast(enabled=self.conf.mp, device_type="cuda"):
>           return self._forward(data)

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LightGlue(
  (input_proj): Identity()
  (posenc): LearnableFourierPositionalEncoding(
    (Wr): Linear(in_features=2, ... Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
    )
  )
)
data = {'image0': {'descriptors': <tf.Tensor: shape=(1, 100, 256), dtype=float32, numpy=
array([[[0.94031596, 0.06994444, 0.3...      [0.30261278, 0.7373067 ],
        [0.8889572 , 0.16632855],
        [0.33966464, 0.16683477]]], dtype=float32)>}}

    def _forward(self, data: dict) -> dict:  # type: ignore
        for key in self.required_data_keys:
            KORNIA_CHECK(key in data, f"Missing key {key} in data")
        data0, data1 = data["image0"], data["image1"]
        kpts0, kpts1 = data0["keypoints"], data1["keypoints"]
        b, m, _ = kpts0.shape
        b, n, _ = kpts1.shape
        device = kpts0.device
        size0, size1 = data0.get("image_size"), data1.get("image_size")
        size0 = size0 if size0 is not None else data0["image"].shape[-2:][::-1]
        size1 = size1 if size1 is not None else data1["image"].shape[-2:][::-1]
    
>       kpts0 = normalize_keypoints(kpts0, size0).clone()

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[9.7369492e-01, 2.0039856e-01],
        [2.1397424e-01, ...  [8.1418419e-01, 6.2082356e-01]]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>)
kwargs = {}, autocast_context = False

    @functools.wraps(fwd)
    def decorate_fwd(*args, **kwargs):
        args[0]._dtype = torch.get_autocast_dtype(device_type)
        if cast_inputs is None:
            args[0]._fwd_used_autocast = torch.is_autocast_enabled(device_type)
            return fwd(*args, **kwargs)
        else:
            autocast_context = torch.is_autocast_enabled(device_type)
            args[0]._fwd_used_autocast = False
            if autocast_context:
                with autocast(device_type=device_type, enabled=False):
                    return fwd(
                        *_cast(args, device_type, cast_inputs),
                        **_cast(kwargs, device_type, cast_inputs),
                    )
            else:
>               return fwd(*args, **kwargs)

/opt/fw/torch/torch/amp/autocast_mode.py:466: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kpts = <tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=
array([[[9.7369492e-01, 2.0039856e-01],
        [2.1397424e-01, 3...e-01, 6.4493155e-01],
        [9.4967049e-01, 3.7607503e-01],
        [8.1418419e-01, 6.2082356e-01]]], dtype=float32)>
size = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>

    @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
    def normalize_keypoints(kpts: Tensor, size: Tensor) -> Tensor:
        if isinstance(size, torch.Size):
            size = Tensor(size)[None]
>       shift = size.float().to(kpts) / 2

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/lightglue.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[640, 480]])>, name = 'float'

    def __getattr__(self, name):
      if name in {"T", "astype", "ravel", "transpose", "reshape", "clip", "size",
                  "tolist", "data"}:
        # TODO(wangpeng): Export the enable_numpy_behavior knob
        raise AttributeError(
            f"{type(self).__name__} object has no attribute '{name}'. " + """
          If you are looking for numpy-related methods, please run the following:
          tf.experimental.numpy.experimental_enable_numpy_behavior()
        """)
>     self.__getattribute__(name)
E     AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:260: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LightGlue
Loaded LightGlue model
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/superpoint_lightglue.pth" to /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth

  0%|          | 0.00/45.3M [00:00<?, ?B/s]
 22%|       | 10.1M/45.3M [00:00<00:00, 95.0MB/s]
 55%|    | 24.8M/45.3M [00:00<00:00, 128MB/s] 
 82%| | 37.1M/45.3M [00:00<00:00, 127MB/s]
100%|| 45.3M/45.3M [00:00<00:00, 112MB/s]
___________________________________________________________________________________ test_LoFTR[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LoFTR(target_framework, mode, backend_compile):
        print("kornia.feature.LoFTR")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
    
        data = {"image0": torch.rand(1, 1, 320, 200), "image1": torch.rand(1, 1, 128, 128)}
        transpiled_data = _nest_torch_tensor_to_new_framework(data, target_framework)
    
        model = kornia.feature.LoFTR(None)
>       torch_out = model(data)

kornia/test_feature4.py:322: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.929798  , 0.60926497, 0.20982099, .....         [0.8504387 , 0.27032614, 0.20775265, ..., 0.54360336,
          0.6115197 , 0.36040765]]]], dtype=float32)>},)
kwargs = {}

    def _wrapped_call_impl(self, *args, **kwargs):
        if self._compiled_call_impl is not None:
            return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
        else:
>           return self._call_impl(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1553: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
args = ({'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.929798  , 0.60926497, 0.20982099, .....         [0.8504387 , 0.27032614, 0.20775265, ..., 0.54360336,
          0.6115197 , 0.36040765]]]], dtype=float32)>},)
kwargs = {}
forward_call = <bound method LoFTR.forward of LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), str...  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)>

    def _call_impl(self, *args, **kwargs):
        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
        # If we don't have any hooks, we want to skip the rest of the logic in
        # this function, and just call forward.
        if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
                or _global_backward_pre_hooks or _global_backward_hooks
                or _global_forward_hooks or _global_forward_pre_hooks):
>           return forward_call(*args, **kwargs)

/opt/fw/torch/torch/nn/modules/module.py:1562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LoFTR(
  (backbone): ResNetFPN_8_2(
    (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bia...   (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fine_matching): FineMatching()
)
data = {'image0': <tf.Tensor: shape=(1, 1, 320, 200), dtype=float32, numpy=
array([[[[0.929798  , 0.60926497, 0.20982099, ......,
         [0.8504387 , 0.27032614, 0.20775265, ..., 0.54360336,
          0.6115197 , 0.36040765]]]], dtype=float32)>}

    def forward(self, data: dict[str, Tensor]) -> dict[str, Tensor]:
        """
        Args:
            data: dictionary containing the input data in the following format:
    
        Keyword Args:
            image0: left image with shape :math:`(N, 1, H1, W1)`.
            image1: right image with shape :math:`(N, 1, H2, W2)`.
            mask0 (optional): left image mask. '0' indicates a padded position :math:`(N, H1, W1)`.
            mask1 (optional): right image mask. '0' indicates a padded position :math:`(N, H2, W2)`.
    
        Returns:
            - ``keypoints0``, matching keypoints from image0 :math:`(NC, 2)`.
            - ``keypoints1``, matching keypoints from image1 :math:`(NC, 2)`.
            - ``confidence``, confidence score [0, 1] :math:`(NC)`.
            - ``batch_indexes``, batch indexes for the keypoints and lafs :math:`(NC)`.
        """
        # 1. Local Feature CNN
        _data: dict[str, Tensor | int | torch.Size] = {
>           "bs": data["image0"].size(0),
            "hw0_i": data["image0"].shape[2:],
            "hw1_i": data["image1"].shape[2:],
        }
E       TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/feature/loftr/loftr.py:123: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LoFTR
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature4.py::test_SIFTFeature[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_SIFTFeatureScaleSpace[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_GFTTAffNetHardNet[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature4.py::test_KeyNetAffNetHardNet[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_feature4.py::test_LocalFeatureMatcher[tensorflow-s2s-False] - TypeError: Input input type is not a Tensor. Got <class 'tensorflow.python.framework.ops.EagerTensor'>
FAILED kornia/test_feature4.py::test_LightGlueMatcher[tensorflow-s2s-False] - NameError: name 'torch' is not defined
FAILED kornia/test_feature4.py::test_LightGlue[tensorflow-s2s-False] - AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'float'
FAILED kornia/test_feature4.py::test_LoFTR[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 8 failed, 6 passed in 3134.54s (0:52:14) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F...                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_RandomMotionBlur[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'jax', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32), params = None
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe498481fc0>, jax_set_item = <function jax_set_item at 0x7fe4ab097a30>, tensor = <function jax_tensor_frnt at 0x7fe4ab01d360>
in_tensor = Array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:213: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple((int(jax_item_frnt_(jax_sum_frnt_(to_apply))), *batch_shape[1:]))
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.jax.general import jax_set_item
        from .....ivy.functional.frontends.torch.random_sampling import jax_randint_frnt
    
        params = super().generate_parameters(batch_shape)
        params = jax_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else jax_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:66: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_____________________________________________________________________________ test_RandomSaltAndPepperNoise[jax-s2s-False] _____________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'jax', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.2108, 0.0265, 0.5011],
          [0.8438, 0.9736, 0.3539],
          [0.0361, 0.0745, 0.9265]],

       ...80]],

         [[0.7660, 0.5913, 0.3072],
          [0.4861, 0.3187, 0.3837],
          [0.4980, 0.7917, 0.2464]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.21084744, 0.02646446, 0.5011212 ],
         [0.8438371 , 0.9735543 , 0.3539139 ],
         [0.03614002, 0....15227],
         [0.48610502, 0.31865448, 0.38372016],
         [0.49802345, 0.791735  , 0.24640584]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe498d99e10>, jax_set_item = <function jax_set_item at 0x7fe4b6455630>, tensor = <function jax_tensor_frnt at 0x7fe470c7f5b0>
in_tensor = Array([[[[0.21084744, 0.02646446, 0.5011212 ],
         [0.8438371 , 0.9735543 , 0.3539139 ],
         [0.03614002, 0....15227],
         [0.48610502, 0.31865448, 0.38372016],
         [0.49802345, 0.791735  , 0.24640584]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.21084744, 0.02646446, 0.5011212 ],
         [0.8438371 , 0.9735543 , 0.3539139 ],
         [0.03614002, 0....15227],
         [0.48610502, 0.31865448, 0.38372016],
         [0.49802345, 0.791735  , 0.24640584]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.21084744, 0.02646446, 0.5011212 ],
         [0.8438371 , 0.9735543 , 0.3539139 ],
         [0.03614002, 0....15227],
         [0.48610502, 0.31865448, 0.38372016],
         [0.49802345, 0.791735  , 0.24640584]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe498d99e10>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7fe470c55240>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7fe4aaed1630>, jax_get_item = <function jax_get_item at 0x7fe4b6455480>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7fe4b6416a70>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7fe4aaed2950>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7fe4aaed3d90>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.21084744, 0.02646446, 0.5011212 ],
         [0.8438371 , 0.9735543 , 0.3539139 ],
         [0.03614002, 0....15227],
         [0.48610502, 0.31865448, 0.38372016],
         [0.49802345, 0.791735  , 0.24640584]]]], dtype=float32)
params = {'amount_factor': Array([0.5], dtype=float32), 'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array(...,

        [[False, False,  True],
         [False, False, False],
         [False,  True, False]]]], dtype=bool), ...}
flags = {}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import jax_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import jax_clone_frnt_
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK(
            len(jax_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(jax_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        jax_KORNIA_CHECK(
            jax_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = jax_clone_frnt_(input)
        noisy_image = jax_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:92: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
_________________________________________________________________________________ test_RandomSharpness[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'jax', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.8009, 0.6694, 0.9024, 0.8620, 0.7720],
          [0.9824, 0.6089, 0.8397, 0.6558, 0.3070],
          [0...., 0.7177],
          [0.5107, 0.9497, 0.9665, 0.1437, 0.9009],
          [0.8583, 0.7290, 0.9592, 0.4401, 0.5278]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.80086344, 0.66937006, 0.9024235 , 0.8620085 , 0.77201426],
         [0.9824392 , 0.6089334 , 0.8397017 , 0... 0.14367223, 0.90092   ],
         [0.85832095, 0.7290128 , 0.95922   , 0.44007725, 0.527783  ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe4707d0ca0>, jax_set_item = <function jax_set_item at 0x7fe48487eb00>, tensor = <function jax_tensor_frnt at 0x7fe45eba8280>
in_tensor = Array([[[[0.80086344, 0.66937006, 0.9024235 , 0.8620085 , 0.77201426],
         [0.9824392 , 0.6089334 , 0.8397017 , 0... 0.14367223, 0.90092   ],
         [0.85832095, 0.7290128 , 0.95922   , 0.44007725, 0.527783  ]]]],      dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = Array([[[[0.80086344, 0.66937006, 0.9024235 , 0.8620085 , 0.77201426],
         [0.9824392 , 0.6089334 , 0.8397017 , 0... 0.14367223, 0.90092   ],
         [0.85832095, 0.7290128 , 0.95922   , 0.44007725, 0.527783  ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.80086344, 0.66937006, 0.9024235 , 0.8620085 , 0.77201426],
         [0.9824392 , 0.6089334 , 0.8397017 , 0... 0.14367223, 0.90092   ],
         [0.85832095, 0.7290128 , 0.95922   , 0.44007725, 0.527783  ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fe4707d0ca0>
jax_all_frnt_ = <function jax_all_frnt_ at 0x7fe4707d12d0>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7fe4707e8c10>, jax_get_item = <function jax_get_item at 0x7fe48487e950>
jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7fe4847dfbe0>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7fe4707e8d30>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7fe4707e9360>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = Array([[[[0.80086344, 0.66937006, 0.9024235 , 0.8620085 , 0.77201426],
         [0.9824392 , 0.6089334 , 0.8397017 , 0... 0.14367223, 0.90092   ],
         [0.85832095, 0.7290128 , 0.95922   , 0.44007725, 0.527783  ]]]],      dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 5, 5], dtype=int64), 'sharpness': Array([0.10536897], dtype=float32)}, flags = {}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: name 'sharpness' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/sharpness.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[jax-s2s-False] - TypeError: jax_randint_frnt() missing 1 required positional argument: 'size'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'to'
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[jax-s2s-False] - NameError: name 'sharpness' is not defined
============================================================================== 3 failed, 14 passed in 3396.30s (0:56:36) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py Fs                                                                                                                                                                  [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_fit_line[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_fit_line(target_framework, mode, backend_compile):
        print("kornia.geometry.line.fit_line")
    
        if backend_compile:
            pytest.skip()
    
>       transpiled_fit_line = ivy.transpile(kornia.geometry.line.fit_line, source="torch", target=target_framework)

kornia/geometry/test_line.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <function fit_line at 0x7fb33e1611b0>, source = 'torch', target = 'numpy', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb2e53fd3f0>, node = <gast.gast.Module object at 0x7fb2e532da50>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb2e53fd3f0>, node = <gast.gast.Module object at 0x7fb2e532da50>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb2e53fd3f0>, node = <gast.gast.FunctionDef object at 0x7fb2e532f6a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb2e53fd3f0>, node = <gast.gast.Return object at 0x7fb2e54bd180>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb2e53fd3f0>, node = <gast.gast.Return object at 0x7fb2e54bd180>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb2e53fd3f0>, node = <gast.gast.Call object at 0x7fb2e5626890>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb2e53fd3f0>, node = <gast.gast.Call object at 0x7fb2e5626890>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7fb2e53fd3f0>, node = <gast.gast.Name object at 0x7fb2e5627d30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_ParametrizedLine'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.line.fit_line
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_line.py::test_fit_line[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.line.ivy_Para...
=============================================================================== 1 failed, 1 skipped in 67.65s (0:01:07) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 296.28s (0:04:56) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF...F............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_HausdorffERLoss[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss = ivy.transpile(kornia.losses.HausdorffERLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = TranspiledHausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[-0.82063925,  0.69551575,  0.9131023 , ...,  0.5080387 ,
           2.3940618 ,  0.68362606],
         [ 0.3...       [-0.80845785, -1.432914  , -0.01442517, ..., -0.38955206,
           0.04282983,  1.2807773 ]]]], dtype=float32)
target = Array([[[[1, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 0],
         [0, 0, 0, ..., 1, 0, 0],
         ...,
  ...,
         [0, 0, 0, ..., 1, 1, 0],
         [1, 1, 1, ..., 0, 1, 0],
         [1, 0, 0, ..., 1, 0, 1]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_min_frnt_
    
        if jax_dim_frnt_(pred) != 4:
            raise ValueError(f"Only 2D images supported. Got {jax_dim_frnt_(pred)}.")
        if not (
            jax_max_frnt_(target) < jax_size_frnt_(pred, 1)
            and jax_min_frnt_(target) >= 0
            and target.dtype == jnp.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {jax_size_frnt_(pred, 1)}). ({jax_min_frnt_(target)}, {jax_max_frnt_(target)})"
            )
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[-0.82063925,  0.69551575,  0.9131023 , ...,  0.5080387 ,
           2.3940618 ,  0.68362606],
         [ 0.3...       [-0.80845785, -1.432914  , -0.01442517, ..., -0.38955206,
           0.04282983,  1.2807773 ]]]], dtype=float32)
target = Array([[[[1, 0, 0, ..., 1, 1, 1],
         [1, 0, 1, ..., 0, 0, 0],
         [0, 0, 0, ..., 1, 0, 0],
         ...,
  ...,
         [0, 0, 0, ..., 1, 1, 0],
         [1, 1, 1, ..., 0, 1, 0],
         [1, 0, 0, ..., 1, 0, 1]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7fb27d19ae80>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss()
pred = Array([[[[-0.82063925,  0.69551575,  0.9131023 , ...,  0.5080387 ,
           2.3940618 ,  0.68362606],
         [ 0.3...       [ 3.0094962 ,  1.6574634 , -1.0952018 , ...,  0.54390913,
           0.66639835, -1.0797929 ]]]], dtype=float32)
target = Array([[[[0, 1, 1, ..., 0, 0, 0],
         [0, 1, 0, ..., 1, 1, 1],
         [1, 1, 1, ..., 0, 1, 1],
         ...,
  ...,
         [1, 1, 1, ..., 0, 0, 1],
         [0, 0, 0, ..., 1, 0, 1],
         [0, 1, 1, ..., 0, 1, 0]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
________________________________________________________________________________ test_HausdorffERLoss3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss3D = ivy.transpile(kornia.losses.HausdorffERLoss3D, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = TranspiledHausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[-4.42801237e-01, -2.18361050e-01,  1.28578573e-01, ...,
            1.51562643e+00,  1.65703547e+00, -6.945...64042e-01,  1.25172031e+00, ...,
            5.44131756e-01, -2.77931005e-01, -9.79258120e-02]]]]],      dtype=float32)
target = Array([[[[[0, 1, 0, ..., 1, 1, 1],
          [1, 0, 0, ..., 1, 0, 0],
          [1, 0, 0, ..., 0, 1, 0],
          ......        [0, 0, 1, ..., 1, 0, 0],
          [1, 1, 1, ..., 0, 0, 0],
          [1, 1, 0, ..., 1, 1, 1]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
    
        if jax_dim_frnt_(pred) != 5:
            raise ValueError(f"Only 3D images supported. Got {jax_dim_frnt_(pred)}.")
>       return super().__call__(pred, target)

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[-4.42801237e-01, -2.18361050e-01,  1.28578573e-01, ...,
            1.51562643e+00,  1.65703547e+00, -6.945...64042e-01,  1.25172031e+00, ...,
            5.44131756e-01, -2.77931005e-01, -9.79258120e-02]]]]],      dtype=float32)
target = Array([[[[[0, 1, 0, ..., 1, 1, 1],
          [1, 0, 0, ..., 1, 0, 0],
          [1, 0, 0, ..., 0, 1, 0],
          ......        [0, 0, 1, ..., 1, 0, 0],
          [1, 1, 1, ..., 0, 0, 0],
          [1, 1, 0, ..., 1, 1, 1]]]]], dtype=int64)

    def __call__(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_sum_frnt_
    
        if not (
            jax_shape_frnt_(pred)[2:] == jax_shape_frnt_(target)[2:]
            and jax_size_frnt_(pred, 0) == jax_size_frnt_(target, 0)
            and jax_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {jax_shape_frnt_(pred)} and {jax_shape_frnt_(target)}."
            )
        if jax_size_frnt_(pred, 1) < jax_item_frnt_(jax_max_frnt_(target)):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    jax_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(jax_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7fb27d624b10>

        [
>           self.perform_erosion(
                jax_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(jax_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HausdorffERLoss3D()
pred = Array([[[[[-4.42801237e-01, -2.18361050e-01,  1.28578573e-01, ...,
            1.51562643e+00,  1.65703547e+00, -6.945...09245e+00,  1.48651421e+00, ...,
           -3.24223995e-01, -5.06166875e-01,  9.61348116e-01]]]]],      dtype=float32)
target = Array([[[[[1, 0, 1, ..., 0, 0, 0],
          [0, 1, 1, ..., 0, 1, 1],
          [0, 1, 1, ..., 1, 0, 1],
          ......        [1, 1, 0, ..., 0, 1, 1],
          [0, 0, 0, ..., 1, 1, 1],
          [0, 0, 1, ..., 0, 0, 0]]]]], dtype=int64)

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            jax_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = jax_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=jnp.bool
        )
        padding = (jax_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'

ivy_transpiled_outputs/jax_outputs/kornia/losses/hausdorff.py:81: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
__________________________________________________________________________________ test_TotalVariation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TotalVariation(target_framework, mode, backend_compile):
        print("kornia.losses.TotalVariation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTotalVariation = ivy.transpile(kornia.losses.TotalVariation, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.TotalVariation()
        transpiled_loss_fn = TranspiledTotalVariation()
    
        torch_args = (
            torch.ones((2, 3, 4, 4)),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args).data
>       transpiled_res = transpiled_loss_fn(*transpiled_args).data
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'

kornia/test_losses.py:570: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.TotalVariation
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[jax-s2s-False] - TypeError: jax_conv2d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[jax-s2s-False] - TypeError: jax_conv3d_frnt() got multiple values for argument 'weight'
FAILED kornia/test_losses.py::test_TotalVariation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'data'
============================================================================== 3 failed, 32 passed in 2275.73s (0:37:55) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py .FF..F                                                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_NerfModelRenderer[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_NerfModelRenderer(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.NerfModelRenderer")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledNerfModel = ivy.transpile(nerf_model.NerfModel, source="torch", target=target_framework)
        TranspiledNerfModelRenderer = ivy.transpile(nerf_model.NerfModelRenderer, source="torch", target=target_framework)
    
        torch_nerf_model = nerf_model.NerfModel(num_ray_points=32)
        transpiled_nerf_model = TranspiledNerfModel(num_ray_points=32)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
>       transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args)
E       TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'

kornia/test_nerf.py:63: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.NerfModelRenderer
____________________________________________________________________________________ test_MLP[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MLP(target_framework, mode, backend_compile):
        print("kornia.nerf.nerf_model.MLP")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMLP = ivy.transpile(nerf_model.MLP, source="torch", target=target_framework)
    
        torch_args = (
            torch.rand(5, 3),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_mlp = nerf_model.MLP(num_dims=3)
        transpiled_mlp = TranspiledMLP(num_dims=3)
    
        torch_out = torch_mlp(*torch_args)
>       transpiled_out = transpiled_mlp(*transpiled_args)

kornia/test_nerf.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
)
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.33...7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f60b2697870, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      ....7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.33...7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      ....7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.33...7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.330...0.7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
),)
kwargs = {'x': <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 ,....7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MLP(
  (_mlp): tensorflow_ModuleList(
    (0-7): 8 x tensorflow_Sequential(
      (0): KerasDense()
      (1): tensorflow_ReLU()
    )
  )
)
x = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.330...0.7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
)
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.33...7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x556c4408a2d0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.33...7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.33...7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[0.20464247, 0.6779522 , 0.77566475],
       [0.6597239 , 0.330...0.7105313 ],
       [0.88161564, 0.41142768, 0.8644787 ],
       [0.82003   , 0.08021659, 0.63928294]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasDense()
  (1): tensorflow_ReLU()
)
input = <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.08332850e-01, -9.57032219e-02,  1.72465295e-01,
        -...
         1.04832515e-01,  1.03132688e-02, -1.77569941e-01,
        -5.32304347e-02,  1.08141929e-01]], dtype=float32)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU()
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.08332850e-01, -9.57032219e-02,  1.72465295e-01,
        ...        1.04832515e-01,  1.03132688e-02, -1.77569941e-01,
        -5.32304347e-02,  1.08141929e-01]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f60b28b1780, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.08332850e-01, -9.57032219e-02,  1.72465295e-01,
        ...        1.04832515e-01,  1.03132688e-02, -1.77569941e-01,
        -5.32304347e-02,  1.08141929e-01]], dtype=float32)>,)
kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.08332850e-01, -9.57032219e-02,  1.72465295e-01,
        ...        1.04832515e-01,  1.03132688e-02, -1.77569941e-01,
        -5.32304347e-02,  1.08141929e-01]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.08332850e-01, -9.57032219e-02,  1.72465295e-01,
        -...
         1.04832515e-01,  1.03132688e-02, -1.77569941e-01,
        -5.32304347e-02,  1.08141929e-01]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ReLU(), args = ()
kwargs = {'input': <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.08332850e-01, -9.57032219e-02,  1.72465295e-01,...         1.04832515e-01,  1.03132688e-02, -1.77569941e-01,
        -5.32304347e-02,  1.08141929e-01]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7f60b27680d0>, tensorflow_set_item = <function tensorflow_set_item at 0x7f60b2768280>, DATA_FORMAT = 'channels_first'
fn_args_and_kwargs = {'input': <tf.Tensor: shape=(5, 128), dtype=float32, numpy=
array([[-1.08332850e-01, -9.57032219e-02,  1.72465295e-01,...         1.04832515e-01,  1.03132688e-02, -1.77569941e-01,
        -5.32304347e-02,  1.08141929e-01]], dtype=float32)>}
conv_block_start = <function tensorflow_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7f60b30d6320>

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = tensorflow_ReLU()

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <frame at 0x556c43f22850, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py', line 77, code call>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <frame at 0x556c43f22850, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/nerf_model.py', line 77, code call>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
                raise OSError('source code not available')
    
        module = getmodule(object, file)
        if module:
            lines = linecache.getlines(file, module.__dict__)
        else:
            lines = linecache.getlines(file)
        if not lines:
>           raise OSError('could not get source code')
E           OSError: Exception encountered when calling tensorflow_ReLU.call().
E           
E           [1mcould not get source code[0m
E           
E           Arguments received by tensorflow_ReLU.call():
E              input=tf.Tensor(shape=(5, 128), dtype=float32)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:958: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.nerf_model.MLP
_____________________________________________________________________________ test_RandomRaySampler[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRaySampler(target_framework, mode, backend_compile):
        print("kornia.nerf.samplers.RandomRaySampler")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPinholeCamera = ivy.transpile(kornia.geometry.camera.pinhole.PinholeCamera, source="torch", target=target_framework)
        TranspiledRandomRaySampler = ivy.transpile(samplers.RandomRaySampler, source="torch", target=target_framework)
    
        torch_camera_args = (
            torch.rand(1, 4, 4),
            torch.rand(1, 4, 4),
            torch.tensor([256]),
            torch.tensor([256]),
        )
        transpiled_camera_args = _nest_torch_tensor_to_new_framework(torch_camera_args, target_framework)
    
        torch_camera = kornia.geometry.camera.pinhole.PinholeCamera(*torch_camera_args)
        transpiled_camera = TranspiledPinholeCamera(*transpiled_camera_args)
    
        heights, widths = torch.tensor([256]), torch.tensor([256])
        transpiled_heights = _array_to_new_backend(heights, target_framework)
        transpiled_widths = _array_to_new_backend(widths, target_framework)
    
        torch_sampler = samplers.RandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
        transpiled_sampler = TranspiledRandomRaySampler(min_depth=0.1, max_depth=10.0, ndc=True, device="cpu", dtype=torch.float32)
    
        torch_sampler.calc_ray_params(torch_camera, torch.tensor([1]))
>       transpiled_sampler.calc_ray_params(transpiled_camera, _array_to_new_backend(torch.tensor([1]), target_framework))

kornia/test_nerf.py:250: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7f60b23c7a90>
cameras = <ivy_transpiled_outputs.tensorflow_outputs.kornia.geometry.camera.pinhole.tensorflow_PinholeCamera object at 0x7f60b23c5870>
num_img_rays = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>

    def calc_ray_params(self, cameras, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        num_cams = cameras.batch_size
        if num_cams != tensorflow_shape_frnt_(num_img_rays)[0]:
            raise ValueError(
                f"Number of cameras {num_cams} does not match size of tensor to define number of rays to march from each camera {tensorflow_shape_frnt_(num_img_rays)[0]}"
            )
>       points_2d_camera = self.sample_points_2d(
            cameras.height, cameras.width, num_img_rays
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.nerf.samplers.tensorflow_RandomRaySampler object at 0x7f60b23c7a90>, heights = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>
widths = <tf.Tensor: shape=(1,), dtype=int64, numpy=array([256])>, num_img_rays = <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>

    def sample_points_2d(self, heights, widths, num_img_rays):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_tolist_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_trunc_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_rand_frnt,
        )
    
        num_img_rays = tensorflow_int_frnt_(num_img_rays)
        points2d_as_flat_tensors: typing.Any = {}
        for camera_id, (height, width, n) in enumerate(
            zip(
                tensorflow_tolist_frnt_(heights),
                tensorflow_tolist_frnt_(widths),
                tensorflow_tolist_frnt_(num_img_rays),
            )
        ):
            y_rand = tensorflow_trunc_frnt(
>               tensorflow_rand_frnt(n, device=self._device, dtype=self._dtype) * height
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/nerf/samplers.py:364: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

generator = None, out = None, dtype = torch.float32, layout = None, device = 'cpu', requires_grad = False, pin_memory = False, size = (1,), kwargs = {}
tensorflow_random_uniform = <function tensorflow_random_uniform at 0x7f60b2444790>, seed = None

    def tensorflow_rand_frnt(
        *size,
        generator=None,
        out=None,
        dtype=None,
        layout=None,
        device=None,
        requires_grad=False,
        pin_memory=False,
        **kwargs,
    ):
        from ...backends.tensorflow.random import tensorflow_random_uniform
    
        if not size and "size" not in kwargs:
            raise ValueError("Missing 1 required positional/keyword argument: size")
        size = size if size else kwargs["size"]
        if (
            isinstance(size, (list, tuple))
            and len(size) == 1
            and isinstance(size[0], (list, tuple, tuple))
        ):
            size = size[0]
        seed = generator.initial_seed() if generator is not None else None
>       return tensorflow_random_uniform(
            shape=size, seed=seed, out=out, dtype=dtype, device=device
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/random_sampling.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = torch.float32, args = (), kwargs = {'device': 'cpu', 'out': None, 'seed': None, 'shape': (1,)}, tensorflow_exists_bknd = <function tensorflow_exists_bknd at 0x7f60b23d2c20>
tensorflow_default_dtype_bknd = <function tensorflow_default_dtype_bknd at 0x7f60b23d2290>, arr = None

    @functools.wraps(fn)
    def _infer_dtype(*args, dtype=None, **kwargs):
        from .functional.ivy.general import tensorflow_exists_bknd
        from .functional.ivy.data_type import tensorflow_default_dtype_bknd
    
        arr = (
            None
            if tensorflow_exists_bknd(dtype)
            else tensorflow__get_first_array(*args, **kwargs)
        )
        dtype = tensorflow_default_dtype_bknd(dtype=dtype, item=arr, as_native=True)
>       return fn(*args, dtype=dtype, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @tensorflow_infer_dtype
    def tensorflow_random_uniform(
        *,
        low: Union[float, tensorflow.Tensor, tensorflow.Variable] = 0.0,
        high: Union[float, tensorflow.Tensor, tensorflow.Variable, None] = 1.0,
        shape: Optional[Union[tf.TensorShape, Sequence[int], tensorflow.Tensor]] = None,
        dtype: tf.DType,
        device: Optional[str] = None,
        seed: Optional[int] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.random import tensorflow__check_bounds_and_get_shape_bknd
    
        shape = tensorflow__check_bounds_and_get_shape_bknd(
            low,
            float(
                tensorflow.experimental.numpy.finfo(tensorflow.float32).max
                if dtype is None
                else tensorflow.experimental.numpy.finfo(dtype).max
            )
            if high is None
            else high,
            shape,
        )
>       low = tensorflow.cast(low, dtype)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/random.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (0.0, torch.float32), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type_value = torch.float32

    @tf_export("dtypes.as_dtype", "as_dtype")
    def as_dtype(type_value):
      """Converts the given `type_value` to a `tf.DType`.
    
      Inputs can be existing `tf.DType` objects, a [`DataType`
      enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),
      a string type name, or a
      [`numpy.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html).
    
      Examples:
      >>> tf.as_dtype(2)  # Enum value for float64.
      tf.float64
    
      >>> tf.as_dtype('float')
      tf.float32
    
      >>> tf.as_dtype(np.int32)
      tf.int32
    
      Note: `DType` values are interned (i.e. a single instance of each dtype is
      stored in a map). When passed a new `DType` object, `as_dtype` always returns
      the interned value.
    
      Args:
        type_value: A value that can be converted to a `tf.DType` object.
    
      Returns:
        A `DType` corresponding to `type_value`.
    
      Raises:
        TypeError: If `type_value` cannot be converted to a `DType`.
      """
      if isinstance(type_value, DType):
        if type_value._handle_data is None:  # pylint:disable=protected-access
          return _INTERN_TABLE[type_value.as_datatype_enum]
        else:
          return type_value
    
      if isinstance(type_value, np.dtype):
        try:
          return _NP_TO_TF[type_value.type]
        except KeyError:
          pass
    
      try:
        return _ANY_TO_TF[type_value]
      except (KeyError, TypeError):
        # TypeError indicates that type_value is not hashable.
        pass
    
      if hasattr(type_value, "dtype"):
        try:
          return _NP_TO_TF[np.dtype(type_value.dtype).type]
        except (KeyError, TypeError):
          pass
    
      if isinstance(type_value, _dtypes.DType):
        return _INTERN_TABLE[type_value.as_datatype_enum]
    
>     raise TypeError(f"Cannot convert the argument `type_value`: {type_value!r} "
                      "to a TensorFlow DType.")
E     TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.

/opt/fw/tensorflow/tensorflow/python/framework/dtypes.py:852: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.nerf.samplers.RandomRaySampler
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_nerf.py::test_NerfModelRenderer[tensorflow-s2s-False] - TypeError: _nest_torch_tensor_to_new_framework() missing 1 required positional argument: 'target'
FAILED kornia/test_nerf.py::test_MLP[tensorflow-s2s-False] - OSError: Exception encountered when calling tensorflow_ReLU.call().
FAILED kornia/test_nerf.py::test_RandomRaySampler[tensorflow-s2s-False] - TypeError: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType.
=============================================================================== 3 failed, 3 passed in 361.92s (0:06:01) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py .......F.....F...                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_laf_is_inside_image[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_laf_is_inside_image(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 5, 2, 3),
            torch.rand(1, 1, 32, 32),
        )
        trace_kwargs = {'border': 0}
        test_args = (
            torch.rand(2, 10, 2, 3),
            torch.rand(2, 1, 64, 64),
        )
        test_kwargs = {'border': 1}
>       _test_function(
            kornia.feature.laf_is_inside_image,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_feature2.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7f0a17e5e5f0>
trace_args = (tensor([[[[0.9545, 0.5754, 0.7233],
          [0.3644, 0.3179, 0.0654]],

         [[0.3769, 0.5380, 0.1576],
       ...4, 0.2122, 0.0024,  ..., 0.5884, 0.9880, 0.8479],
          [0.9085, 0.5608, 0.7709,  ..., 0.2608, 0.1057, 0.3389]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.8424, 0.3586, 0.8900],
          [0.9951, 0.6464, 0.7139]],

         [[0.0609, 0.9192, 0.4338],
       ...9, 0.3836, 0.6125,  ..., 0.3495, 0.3725, 0.9937],
          [0.5558, 0.5228, 0.3973,  ..., 0.5997, 0.5212, 0.6671]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function laf_is_inside_image at 0x7f0a17e5e5f0>, fn_name = 'kornia.feature.laf_is_inside_image'
trace_args = (tensor([[[[0.9545, 0.5754, 0.7233],
          [0.3644, 0.3179, 0.0654]],

         [[0.3769, 0.5380, 0.1576],
       ...4, 0.2122, 0.0024,  ..., 0.5884, 0.9880, 0.8479],
          [0.9085, 0.5608, 0.7709,  ..., 0.2608, 0.1057, 0.3389]]]]))
trace_kwargs = {'border': 0}
test_args = (tensor([[[[0.8424, 0.3586, 0.8900],
          [0.9951, 0.6464, 0.7139]],

         [[0.0609, 0.9192, 0.4338],
       ...9, 0.3836, 0.6125,  ..., 0.3495, 0.3725, 0.9937],
          [0.5558, 0.5228, 0.3973,  ..., 0.5997, 0.5212, 0.6671]]]]))
test_kwargs = {'border': 1}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

laf = <tf.Tensor: shape=(1, 5, 2, 3), dtype=float32, numpy=
array([[[[0.95451313, 0.5754021 , 0.72325754],
         [0.36442...2 ]],

        [[0.45492476, 0.63837796, 0.33240384],
         [0.6292316 , 0.07070148, 0.95075405]]]], dtype=float32)>
images = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[0.29977387, 0.28618324, 0.89764893, ..., 0.02970016,...],
         [0.90851575, 0.56078273, 0.77089655, ..., 0.26078922,
          0.10574657, 0.33890182]]]], dtype=float32)>
border = 0

    def tensorflow_laf_is_inside_image(laf, images, border=0):
        from ..core.check import tensorflow_KORNIA_CHECK_LAF
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        tensorflow_KORNIA_CHECK_LAF(laf)
        _, _, h, w = tensorflow_size_frnt_(images)
        pts = tensorflow_laf_to_boundary_points(laf, 12)
        good_lafs_mask = (
>           (pts[..., 0] >= border)
            * (pts[..., 0] <= w - border)
            * (pts[..., 1] >= border)
            * (pts[..., 1] <= h - border)
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/laf.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True, False, False, False,
          True,  True,  True]]])>
rhs = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True, False, False, False,
          True,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True, False, False, False,
          True,  True,  True]]])>
other = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True, False, Fals...True,  True],
        [ True,  True,  True,  True,  True,  True, False, False, False,
          True,  True,  True]]])>
x2 = <tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True,  True,  Tru...True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:151: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True, False, Fal...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      if not ops.is_auto_dtype_conversion_enabled():
>       return op(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/ops/weak_tensor_ops.py:142: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 12), dtype=bool, numpy=
array([[[ True,  True,  True,  True,  True,  True,  True, False, Fal...rue,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True]]])>)
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

e = _NotOkStatusException(), name = None

    def raise_from_not_ok_status(e, name) -> NoReturn:
      e.message += (" name: " + str(name if name is not None else ""))
>     raise core._status_to_exception(e) from None  # pylint: disable=protected-access
E     tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E     	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name:

/opt/fw/tensorflow/tensorflow/python/framework/ops.py:5983: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.laf.laf_is_inside_image
_______________________________________________________________________________ test_MKDDescriptor[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MKDDescriptor(target_framework, mode, backend_compile):
        print("kornia.feature.MKDDescriptor")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMKDDescriptor = ivy.transpile(kornia.feature.MKDDescriptor, source="torch", target=target_framework)
    
        x = torch.rand(23, 1, 32, 32)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.MKDDescriptor()
        torch_out = model(x)
    
>       transpiled_model = TranspiledMKDDescriptor()

kornia/test_feature2.py:339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_MKDDescriptor' object has no attribute 'output_dims'") raised in repr()] tensorflow_MKDDescriptor object at 0x7f098f937b50>, patch_size = 32
kernel_type = 'concat', whitening = 'pcawt', training_set = 'liberty', output_dims = 128

    def __init__(
        self,
        patch_size=32,
        kernel_type="concat",
        whitening="pcawt",
        training_set="liberty",
        output_dims=128,
    ):
        from ..filters.gaussian import tensorflow_GaussianBlur2d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...torch.nn.modules.container import tensorflow_Sequential
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            patch_size=patch_size,
            kernel_type=kernel_type,
            whitening=whitening,
            training_set=training_set,
            output_dims=output_dims,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size: typing.Any = patch_size
        self.kernel_type: typing.Any = kernel_type
        self.whitening: typing.Any = whitening
        self.training_set: typing.Any = training_set
        self.sigma = 1.4 * (patch_size / 64)
        self.smoothing = tensorflow_GaussianBlur2d(
            (5, 5), (self.sigma, self.sigma), "replicate"
        )
        self.gradients = tensorflow_MKDGradients()
        polar_s: typing.Any = "polar"
        cart_s: typing.Any = "cart"
        self.parametrizations = (
            [polar_s, cart_s] if self.kernel_type == "concat" else [self.kernel_type]
        )
        self.odims: typing.Any = 0
        relative_orientations = {polar_s: True, cart_s: False}
        self.feats = {}
        for parametrization in self.parametrizations:
            gradient_embedding = tensorflow_EmbedGradients(
                patch_size=patch_size,
                relative=tensorflow_get_item(relative_orientations, parametrization),
            )
>           spatial_encoding = tensorflow_ExplicitSpacialEncoding(
                kernel_type=parametrization,
                fmap_size=patch_size,
                in_dims=gradient_embedding.kernel.d,
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7f098f936140>, args = ()
kwargs = {'fmap_size': 32, 'in_dims': 7, 'kernel_type': 'polar'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ExplicitSpacialEncoding' object has no attribute 'out_dims'") raised in repr()] tensorflow_ExplicitSpacialEncoding object at 0x7f098f936140>, kernel_type = 'polar'
fmap_size = 32, in_dims = 7, do_gmask = True, do_l2 = True

    @tensorflow_store_config_info
    def __init__(
        self, kernel_type="polar", fmap_size=32, in_dims=7, do_gmask=True, do_l2=True
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        self.super___init__(
            kernel_type=kernel_type,
            fmap_size=fmap_size,
            in_dims=in_dims,
            do_gmask=do_gmask,
            do_l2=do_l2,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        if kernel_type not in ["polar", "cart"]:
            raise NotImplementedError(
                f"{kernel_type} is not valid, use polar or cart)."
            )
        self.kernel_type = kernel_type
        self.fmap_size = fmap_size
        self.in_dims = in_dims
        self.do_gmask = do_gmask
        self.do_l2 = do_l2
        self.grid = tensorflow_get_grid_dict(fmap_size)
        self.gmask = None
>       emb = tensorflow_spatial_kernel_embedding(self.kernel_type, self.grid)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:575: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kernel_type = 'polar'
grids = {'x': <tf.Tensor: shape=(32, 32), dtype=float32, numpy=
array([[-1.        , -0.9354839 , -0.87096775, ...,  0.8709677...,
       [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
         0.81871915,  0.7853981 ]], dtype=float32)>}

    def tensorflow_spatial_kernel_embedding(kernel_type, grids):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_select_frnt_
        from ..constants import pi
    
        factors = {"phi": 1.0, "rho": pi / sqrt2, "x": pi / 2, "y": pi / 2}
        if kernel_type == "cart":
            coeffs_ = "xy"
            params_ = ["x", "y"]
        elif kernel_type == "polar":
            coeffs_ = "rhophi"
            params_ = ["phi", "rho"]
        keys = list(grids.keys())
        patch_size = tensorflow_shape_frnt_(tensorflow_get_item(grids, keys[0]))[-1]
        grids_normed = {k: (v * tensorflow_get_item(factors, k)) for k, v in grids.items()}
        grids_normed = {
            k: tensorflow_float_frnt_(
                tensorflow_unsqueeze_frnt_(tensorflow_unsqueeze_frnt_(v, 0), 0)
            )
            for k, v in grids_normed.items()
        }
        vm_a = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        vm_b = tensorflow_VonMisesKernel(
            patch_size=patch_size, coeffs=tensorflow_get_item(COEFFS, coeffs_)
        )
        emb_a = tensorflow_squeeze_frnt_(
>           vm_a(tensorflow_get_item(grids_normed, params_[0]))
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:534: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x559e03d73010, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...339, function='test_MKDDescriptor', code_context=['    transpiled_model = TranspiledMKDDescriptor()\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), <tf.Tensor: shape=(1, ...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.8542...    [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (x)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]),)
kwargs = {'x': <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0...     [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234])
x = <tf.Tensor: shape=(1, 1, 32, 32), dtype=float32, numpy=
array([[[[-2.3561945 , -2.3228736 , -2.287338  , ..., -0.85425...      [ 2.3561945 ,  2.3228736 ,  2.287338  , ...,  0.8542547 ,
           0.81871915,  0.7853981 ]]]], dtype=float32)>

    def call(self, x):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ..core._backend import cos
        from ..core._backend import sin
    
        if not isinstance(x, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(x)}")
        if not len(tensorflow_shape_frnt_(x)) == 4 or tensorflow_shape_frnt_(x)[1] != 1:
            raise ValueError(
                f"Invalid input shape, we expect Bx1xHxW. Got: {tensorflow_shape_frnt_(x)}"
            )
        if not isinstance(self.emb0, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Emb0 type is not a Tensor. Got {type(x)}")
        emb0 = tensorflow_repeat_frnt_(
            tensorflow_to_frnt_(self.emb0, x), tensorflow_size_frnt_(x, 0), 1, 1, 1
        )
        frange = tensorflow_to_frnt_(self.frange, x) * x
        emb1 = cos(frange)
        emb2 = sin(frange)
        embedding = tensorflow_cat_frnt([emb0, emb1, emb2], dim=1)
>       embedding = self.pt_weights * embedding

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/mkd.py:265: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_VonMisesKernel(patch_size=32, n=2, d=5, coeffs=[0.14343168 0.268285   0.21979234]), name = 'pt_weights'

    @tf.autograph.experimental.do_not_convert
    def __getattr__(self, name):
        if name == "v":
            if not super().__getattribute__("_v") and not getattr(  # noqa: E501
                self, "_built", False
            ):
                return self._build_and_return_v(
                    *self._args, dynamic_backend=self._dynamic_backend, **self._kwargs
                )
    
        _dict = super().__getattribute__("__dict__")
        if name in _dict:
            return _dict[name]
    
        elif "_v" in _dict and name in _dict["_v"]:
            return _dict["_v"][name]
    
>       return super().__getattribute__(name)
E       AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
E       
E       [1m'tensorflow_VonMisesKernel' object has no attribute 'pt_weights'[0m
E       
E       Arguments received by tensorflow_VonMisesKernel.call():
E          x=tf.Tensor(shape=(1, 1, 32, 32), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1343: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.MKDDescriptor
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/manyids2/mkd_pytorch/raw/master/mkd_pytorch/mkd-concat-64.pth" to /root/.cache/torch/hub/checkpoints/mkd-concat-64.pth

  0%|          | 0.00/1.31M [00:00<?, ?B/s]
100%|| 1.31M/1.31M [00:00<00:00, 120MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_laf_is_inside_image[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allow...
FAILED kornia/test_feature2.py::test_MKDDescriptor[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_VonMisesKernel.call().
============================================================================== 2 failed, 15 passed in 1351.51s (0:22:31) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ...F.F                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_ImageSequential[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
        TranspiledMedianBlur = ivy.transpile(
            kornia.filters.MedianBlur,
            source="torch",
            target=target_framework,
        )
        TranspiledInvert = ivy.transpile(
            kornia.enhance.Invert,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomMixUpV2 = ivy.transpile(
            kornia.augmentation.RandomMixUpV2,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledImageSequential(
            TranspiledBgrToRgb(),
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledMedianBlur((3, 3)),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledInvert(),
            TranspiledRandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}
node = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7eff2c8f2350>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>
self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7eff2c8f2350>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7eff2c8f2350>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'jax_ColorJiggle' object has no attribute 'p'") raised in repr()] jax_ColorJiggle object at 0x7eff2c8f2350>, brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.1
same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.random_generator._2d.color_jiggle'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:43: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
_________________________________________________________________________________ test_VideoSequential[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledVideoSequential = ivy.transpile(
            kornia.augmentation.container.VideoSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
        transpiled_aug_list =  TranspiledVideoSequential(
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledBgrToRgb(),
            TranspiledRandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}
node = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7eff5d835b10>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation._2d.intensity.color_jiggle.jax_ColorJiggle'>
self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7eff5d835b10>, args = (0.1, 0.1, 0.1, 0.1)
kwargs = {'p': 1.0}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7eff5d835b10>, args = (0.1, 0.1, 0.1, 0.1)
kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'") raised in repr()] jax_ColorJiggle object at 0x7eff5d835b10>, brightness = 0.1, contrast = 0.1
saturation = 0.1, hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:43: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_ImageSequential[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.random_generator._2d...
FAILED kornia/augmentation/test_container.py::test_VideoSequential[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation'
=============================================================================== 2 failed, 4 passed in 2285.30s (0:38:05) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...............F.                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________________ test_HardNet8[jax-s2s-False] _____________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HardNet8(target_framework, mode, backend_compile):
        print("kornia.feature.HardNet8")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHardNet8 = ivy.transpile(kornia.feature.HardNet8, source="torch", target=target_framework)
    
        x = torch.rand(16, 1, 32, 32)
        torch_out = kornia.feature.HardNet8()(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledHardNet8()(transpiled_x)

kornia/test_feature2.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HardNet8(
  (features): jax_Sequential(
    (0): FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), stri...es=(1, 1), padding=0, padding_mode=zeros)
    (23): FlaxBatchNorm2D(512, eps=1e-05, momentum=0.99, affine=False, 
  )
)
input = Array([[[[0.17142558, 0.22821605, 0.09329826, ..., 0.8955955 ,
          0.9846756 , 0.73002183],
         [0.24262792...8],
         [0.15638661, 0.61953837, 0.10392755, ..., 0.4084218 ,
          0.06402409, 0.39076436]]]], dtype=float32)

    def __call__(self, input):
        from ..core.check import jax_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch._jit_internal import jax_annotate_frnt
        from ...ivy.functional.frontends.torch.nn.functional.non_linear_activation_functions import (
            jax_normalize_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.blas_and_lapack_ops import jax_mm_frnt
    
        jax_KORNIA_CHECK_SHAPE(input, ["B", "1", "32", "32"])
        x_norm: typing.Any = self._normalize_input(input)
>       x_features: typing.Any = self.features(x_norm)

ivy_transpiled_outputs/jax_outputs/kornia/feature/hardnet.py:292: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Sequential(
  (0): FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding... strides=(1, 1), padding=0, padding_mode=zeros)
  (23): FlaxBatchNorm2D(512, eps=1e-05, momentum=0.99, affine=False, 
)
input = Array([[[[-1.141348  , -0.94882494, -1.4062043 , ...,  1.3136315 ,
           1.6156183 ,  0.75232685],
         [-0.8...       [-1.2334334 ,  0.41178918, -1.4197801 , ..., -0.33814585,
          -1.5615265 , -0.40086922]]]], dtype=float32)

    def __call__(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/jax_outputs/torch/nn/modules/container.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
args = (Array([[[[-1.141348  , -0.94882494, -1.4062043 , ...,  1.3136315 ,
           1.6156183 ,  0.75232685],
         [-0....     [-1.2334334 ,  0.41178918, -1.4197801 , ..., -0.33814585,
          -1.5615265 , -0.40086922]]]], dtype=float32),)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x560f21374cd0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/jax__st...neno=103, function='_multicall', code_context=['                    res = hook_impl.function(*args)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/jax__stateful.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
args = (Array([[[[-1.141348  , -0.94882494, -1.4062043 , ...,  1.3136315 ,
           1.6156183 ,  0.75232685],
         [-0....     [-1.2334334 ,  0.41178918, -1.4197801 , ..., -0.33814585,
          -1.5615265 , -0.40086922]]]], dtype=float32),)
kwargs = {}, jax_get_item = <function jax_get_item at 0x7fe66c123d90>, jax_set_item = <function jax_set_item at 0x7fe66c123f40>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'inputs': Array([[[[-1.141348  ],
         [-0.94882494],
         [-1.4062043 ],
         ...,
         [ 1.3136315 ...[-1.4197801 ],
         ...,
         [-0.33814585],
         [-1.5615265 ],
         [-0.40086922]]]], dtype=float32)}
conv_block_start = <function jax_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7fe66c90ea70>
next_call_in_seq = FlaxBatchNorm2D(32, eps=1e-05, momentum=0.99, affine=False, , conv_block_continued = True, arg_name = 'inputs'
input = Array([[[[-1.141348  , -0.94882494, -1.4062043 , ...,  1.3136315 ,
           1.6156183 ,  0.75232685],
         [-0.8...       [-1.2334334 ,  0.41178918, -1.4197801 , ..., -0.33814585,
          -1.5615265 , -0.40086922]]]], dtype=float32)
transpose = <jax_TransposeType.CONV2D: 'conv2d'>

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.jax.general import jax_get_item
        from ..functional.backends.jax.general import jax_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = jax_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = jax_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = jax_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = jax_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = jax_TransposeType.CONV1D
            else:
                transpose = jax_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = jax_set_item(
                fn_args_and_kwargs,
                arg_name,
                jax_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = jax_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:412: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
inputs = Array([[[[-1.141348  ],
         [-0.94882494],
         [-1.4062043 ],
         ...,
         [ 1.3136315 ],
        ... [-1.4197801 ],
         ...,
         [-0.33814585],
         [-1.5615265 ],
         [-0.40086922]]]], dtype=float32)

    @store_frame_info
    @jax_handle_transpose_in_input_and_output
    def __call__(self, inputs):
        self._built = True
        if self.padding_mode != "zeros":
            padding_mode = (
                "constant" if self.padding_mode == "zeros" else self.padding_mode
            )
            # handle Pytorch-style padding
            inputs = torch_pad(
                inputs, self._reversed_padding_repeated_twice, mode=padding_mode
            )
            old_pad = self.padding
            self.padding = 0
            logits = super().__call__(inputs)
            self.padding = old_pad
            self._built = False
            return logits
>       logits = super().__call__(inputs)

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = FlaxConv(in_features=1, out_features=32, kernel_size=(3, 3), strides=(1, 1), padding=1, padding_mode=zeros)
inputs = Array([[[[-1.141348  ],
         [-0.94882494],
         [-1.4062043 ],
         ...,
         [ 1.3136315 ],
        ... [-1.4197801 ],
         ...,
         [-0.33814585],
         [-1.5615265 ],
         [-0.40086922]]]], dtype=float32)

    def __call__(self, inputs: Array) -> Array:
      """Applies a (potentially unshared) convolution to the inputs.
    
      Args:
        inputs: input data with dimensions ``(*batch_dims, spatial_dims..., features)``.
          This is the channels-last convention, i.e. NHWC for a 2d convolution and
          NDHWC for a 3D convolution. Note: this is different from the input convention
          used by ``lax.conv_general_dilated``, which puts the spatial dimensions last.
          Note: If the input has more than 1 batch dimension, all batch dimensions
          are flattened into a single dimension for the convolution and restored
          before returning.  In some cases directly vmap'ing the layer may yield
          better performance than this default flattening approach.  If the input
          lacks a batch dimension it will be added for the convolution and removed
          n return, an allowance made to enable writing single-example code.
    
      Returns:
        The convolved data.
      """
    
      assert isinstance(self.kernel_size, tuple)
      kernel_size = self.kernel_size
    
      def maybe_broadcast(
        x: tp.Optional[tp.Union[int, tp.Sequence[int]]],
      ) -> tuple[int, ...]:
        if x is None:
          # backward compatibility with using None as sentinel for
          # broadcast 1
          x = 1
        if isinstance(x, int):
          return (x,) * len(kernel_size)
        return tuple(x)
    
      # Combine all input batch dimensions into a single leading batch axis.
      num_batch_dimensions = inputs.ndim - (len(kernel_size) + 1)
      if num_batch_dimensions != 1:
        input_batch_shape = inputs.shape[:num_batch_dimensions]
        total_batch_size = int(np.prod(input_batch_shape))
        flat_input_shape = (total_batch_size,) + inputs.shape[
          num_batch_dimensions:
        ]
        inputs = jnp.reshape(inputs, flat_input_shape)
    
      # self.strides or (1,) * (inputs.ndim - 2)
      strides = maybe_broadcast(self.strides)
      input_dilation = maybe_broadcast(self.input_dilation)
      kernel_dilation = maybe_broadcast(self.kernel_dilation)
    
      padding_lax = canonicalize_padding(self.padding, len(kernel_size))
      if padding_lax == 'CIRCULAR':
        kernel_size_dilated = [
          (k - 1) * d + 1 for k, d in zip(kernel_size, kernel_dilation)
        ]
        zero_pad: tp.List[tuple[int, int]] = [(0, 0)]
        pads = (
          zero_pad
          + [((k - 1) // 2, k // 2) for k in kernel_size_dilated]
          + [(0, 0)]
        )
        inputs = jnp.pad(inputs, pads, mode='wrap')
        padding_lax = 'VALID'
      elif padding_lax == 'CAUSAL':
        if len(kernel_size) != 1:
          raise ValueError(
            'Causal padding is only implemented for 1D convolutions.'
          )
        left_pad = kernel_dilation[0] * (kernel_size[0] - 1)
        pads = [(0, 0), (left_pad, 0), (0, 0)]
        inputs = jnp.pad(inputs, pads)
        padding_lax = 'VALID'
    
      dimension_numbers = _conv_dimension_numbers(inputs.shape)
    
      # One shared convolutional kernel for all pixels in the output.
      assert self.in_features % self.feature_group_count == 0
    
      if self.mask is not None and self.mask.shape != self.kernel_shape:
        raise ValueError(
          'Mask needs to have the same shape as weights. '
          f'Shapes are: {self.mask.shape}, {self.kernel_shape}'
        )
    
      kernel = self.kernel.value
    
      if self.mask is not None:
        kernel *= self.mask
    
      bias = self.bias.value
    
      inputs, kernel, bias = dtypes.promote_dtype(
        (inputs, kernel, bias), dtype=self.dtype
      )
    
>     y = self.conv_general_dilated(
        inputs,
        kernel,
        strides,
        padding_lax,
        lhs_dilation=input_dilation,
        rhs_dilation=kernel_dilation,
        dimension_numbers=dimension_numbers,
        feature_group_count=self.feature_group_count,
        precision=self.precision,
      )

/opt/fw/jax/flax/nnx/nnx/nn/linear.py:777: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

lhs = Array([[[[-1.141348  ],
         [-0.94882494],
         [-1.4062043 ],
         ...,
         [ 1.3136315 ],
        ... [-1.4197801 ],
         ...,
         [-0.33814585],
         [-1.5615265 ],
         [-0.40086922]]]], dtype=float32)
rhs = Array([[ 0.17321092,  0.14065616, -0.1845205 ,  0.04476047,  0.02703602,
         0.05671129,  0.05412335, -0.08114062...0.07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32)
window_strides = (1, 1), padding = ((1, 1), (1, 1)), lhs_dilation = (1, 1), rhs_dilation = (1, 1)
dimension_numbers = ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), feature_group_count = 1, batch_group_count = 1, precision = None
preferred_element_type = None

    def conv_general_dilated(
      lhs: Array, rhs: Array, window_strides: Sequence[int],
      padding: str | Sequence[tuple[int, int]],
      lhs_dilation: Sequence[int] | None = None,
      rhs_dilation: Sequence[int] | None = None,
      dimension_numbers: ConvGeneralDilatedDimensionNumbers  = None,
      feature_group_count: int = 1, batch_group_count: int = 1,
      precision: lax.PrecisionLike = None,
      preferred_element_type: DTypeLike | None = None) -> Array:
      """General n-dimensional convolution operator, with optional dilation.
    
      Wraps XLA's `Conv
      <https://www.tensorflow.org/xla/operation_semantics#conv_convolution>`_
      operator.
    
      Args:
        lhs: a rank `n+2` dimensional input array.
        rhs: a rank `n+2` dimensional array of kernel weights.
        window_strides: a sequence of `n` integers, representing the inter-window
          strides.
        padding: either the strings `'SAME'`, `'SAME_LOWER'`, or `'VALID'`, or a
          sequence of `n` `(low, high)` integer pairs that give the padding to apply
          before and after each spatial dimension. `'SAME'` and `'SAME_LOWER'` add
          padding to produce same output size as the input. The padding is split
          between the two sides equally or almost equally. In case the padding is an
          odd number, the extra padding is added at the end for `'SAME'` and at the
          beginning for `'SAME_LOWER'`.
        lhs_dilation: `None`, or a sequence of `n` integers, giving the dilation
          factor to apply in each spatial dimension of `lhs`. LHS dilation is also
          known as transposed convolution.
        rhs_dilation: `None`, or a sequence of `n` integers, giving the dilation
          factor to apply in each spatial dimension of `rhs`. RHS dilation is also
          known as atrous convolution.
        dimension_numbers: either `None`, a ``ConvDimensionNumbers`` object, or a
          3-tuple ``(lhs_spec, rhs_spec, out_spec)``, where each element is a string
          of length `n+2`.
        feature_group_count: integer, default 1. See XLA HLO docs.
        batch_group_count: integer, default 1. See XLA HLO docs.
        precision: Optional. Either ``None``, which means the default precision for
          the backend, a :class:`~jax.lax.Precision` enum value
          (``Precision.DEFAULT``, ``Precision.HIGH`` or ``Precision.HIGHEST``), a
          string (e.g. 'highest' or 'fastest', see the
          ``jax.default_matmul_precision`` context manager), or a tuple of two
          :class:`~jax.lax.Precision` enums or strings indicating precision of
          ``lhs`` and ``rhs``.
        preferred_element_type: Optional. Either ``None``, which means the default
          accumulation type for the input types, or a datatype, indicating to
          accumulate results to and return a result with that datatype.
    
      Returns:
        An array containing the convolution result.
    
      In the string case of ``dimension_numbers``, each character identifies by
      position:
    
      - the batch dimensions in ``lhs``, ``rhs``, and the output with the character
        'N',
      - the feature dimensions in `lhs` and the output with the character 'C',
      - the input and output feature dimensions in rhs with the characters 'I'
        and 'O' respectively, and
      - spatial dimension correspondences between lhs, rhs, and the output using
        any distinct characters. The examples below use 'W' and 'H'.
    
      For example, to indicate dimension numbers consistent with the ``conv``
      function with two spatial dimensions, one could use ``('NCHW', 'OIHW',
      'NCHW')``. As another example, to indicate dimension numbers consistent with
      the TensorFlow Conv2D operation, one could use ``('NHWC', 'HWIO', 'NHWC')``.
      When using the latter form of convolution dimension specification, window
      strides are associated with spatial dimension character labels according to
      the order in which the labels appear in the ``rhs_spec`` string, so that
      ``window_strides[0]`` is matched with the dimension corresponding to the first
      character appearing in rhs_spec that is not ``'I'`` or ``'O'``.
    
      If ``dimension_numbers`` is ``None``, the default is ``('NCHW', 'OIHW',
      'NCHW')`` (for a 2D convolution).
      """
      dnums = conv_dimension_numbers(lhs.shape, rhs.shape, dimension_numbers)
      if lhs_dilation is None:
        lhs_dilation = (1,) * (lhs.ndim - 2)
      elif isinstance(padding, str) and not len(lhs_dilation) == lhs_dilation.count(1):
        raise ValueError(
            "String padding is not implemented for transposed convolution "
            "using this op. Please either exactly specify the required padding or "
            "use conv_transpose.")
      if rhs_dilation is None:
        rhs_dilation = (1,) * (rhs.ndim - 2)
      if isinstance(padding, str):
        lhs_perm, rhs_perm, _ = dnums
        rhs_shape = np.take(rhs.shape, rhs_perm)[2:]
        effective_rhs_shape = [core.dilate_dim(k, r) for k, r in zip(rhs_shape, rhs_dilation)]
        padding = lax.padtype_to_pads(
            np.take(lhs.shape, lhs_perm)[2:], effective_rhs_shape,
            window_strides, padding)
      else:
        try:
          padding = tuple((operator.index(lo), operator.index(hi))
                          for lo, hi in padding)
        except (ValueError, TypeError) as e:
          raise ValueError(
            "padding argument to conv_general_dilated should be a string or a "
            f"sequence of (low, high) pairs, got {padding}") from e
    
      preferred_element_type = (
          None if preferred_element_type is None else
          dtypes.canonicalize_dtype(np.dtype(preferred_element_type)))
>     return conv_general_dilated_p.bind(
          lhs, rhs, window_strides=tuple(window_strides), padding=tuple(padding),
          lhs_dilation=tuple(lhs_dilation), rhs_dilation=tuple(rhs_dilation),
          dimension_numbers=dnums,
          feature_group_count=feature_group_count,
          batch_group_count=batch_group_count,
          precision=lax.canonicalize_precision(precision),
          preferred_element_type=preferred_element_type)

/opt/fw/jax/jax/_src/lax/convolution.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = conv_general_dilated
args = (Array([[[[-1.141348  ],
         [-0.94882494],
         [-1.4062043 ],
         ...,
         [ 1.3136315 ],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def bind(self, *args, **params):
      assert (not config.enable_checks.value or
              all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args
>     return self.bind_with_trace(find_top_trace(args), args, params)

/opt/fw/jax/jax/_src/core.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = conv_general_dilated, trace = EvalTrace(level=0/0)
args = (Array([[[[-1.141348  ],
         [-0.94882494],
         [-1.4062043 ],
         ...,
         [ 1.3136315 ],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def bind_with_trace(self, trace, args, params):
      with pop_level(trace.level):
>       out = trace.process_primitive(self, map(trace.full_raise, args), params)

/opt/fw/jax/jax/_src/core.py:442: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = EvalTrace(level=0/0), primitive = conv_general_dilated
tracers = [Array([[[[-1.141348  ],
         [-0.94882494],
         [-1.4062043 ],
         ...,
         [ 1.3136315 ],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32)]
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}

    def process_primitive(self, primitive, tracers, params):
      if config.debug_key_reuse.value:
        # Import here to avoid circular imports
        from jax.experimental.key_reuse._core import call_impl_with_key_reuse_checks  # pytype: disable=import-error
        return call_impl_with_key_reuse_checks(primitive, primitive.impl, *tracers, **params)
      else:
>       return primitive.impl(*tracers, **params)

/opt/fw/jax/jax/_src/core.py:948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

prim = conv_general_dilated
args = (Array([[[[-1.141348  ],
         [-0.94882494],
         [-1.4062043 ],
         ...,
         [ 1.3136315 ],
       ....07064222,  0.01723543,  0.00141026,
        -0.12867665, -0.09788989, -0.0136649 , -0.03683599]],      dtype=float32))
params = {'batch_group_count': 1, 'dimension_numbers': ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)), 'feature_group_count': 1, 'lhs_dilation': (1, 1), ...}
fun = <PjitFunction of <function conv_general_dilated at 0x7fe66fcd4f70>>, prev = None

    def apply_primitive(prim, *args, **params):
      """Impl rule that compiles and runs a single primitive 'prim' using XLA."""
      fun = xla_primitive_callable(prim, **params)
      # TODO(yashkatariya): Investigate adding is_primitive to jit and never
      # triggering the disable jit path instead of messing around with it here.
      prev = lib.jax_jit.swap_thread_local_state_disable_jit(False)
      try:
>       outs = fun(*args)
E       ValueError: conv_general_dilated lhs and rhs must have the same number of dimensions, but got (16, 32, 32, 1) and (32, 9).

/opt/fw/jax/jax/_src/dispatch.py:90: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.HardNet8
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature2.py::test_HardNet8[jax-s2s-False] - ValueError: conv_general_dilated lhs and rhs must have the same number of dimensions, but got (16, 32, 32, 1) and (32, 9).
============================================================================== 1 failed, 16 passed in 1295.23s (0:21:35) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 340.75s (0:05:40) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ........                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 357.34s (0:05:57) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py ss                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 4.95s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_bbox_to_mask[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f3dc7f55f30>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f3dc7f55f30>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'tensorflow', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = <tf.Tensor: shape=(1, 5, 5), dtype=float32, numpy=
array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 502.51s (0:08:22) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py sssssssssssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 13 skipped in 4.97s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 4 passed in 82.31s (0:01:22) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ss                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 2 skipped in 4.88s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ..F.                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_So2[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_So2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        real_part = torch.tensor([1.0], requires_grad=True)
        imaginary_part = torch.tensor([2.0], requires_grad=True)
        complex_number = torch.complex(real_part, imaginary_part)
        torch_so2 = kornia.geometry.liegroup.So2(complex_number)
    
        TranspiledSo2 = ivy.transpile(kornia.geometry.liegroup.So2, source="torch", target=target_framework)
        transpiled_complex_number = _nest_torch_tensor_to_new_framework(complex_number, target_framework)
        transpiled_so2 = TranspiledSo2(transpiled_complex_number)
    
        # Test .matrix()
        torch_matrix = torch_so2.matrix()
        transpiled_matrix = transpiled_so2.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_so2.inverse()
        transpiled_inverse = transpiled_so2.inverse()
        _to_numpy_and_allclose(torch_inverse.z, transpiled_inverse.z)
    
        # Test .log()
        torch_log = torch_so2.log()
        transpiled_log = transpiled_so2.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_real_part = torch.tensor([0.5], requires_grad=True)
        other_imaginary_part = torch.tensor([0.5], requires_grad=True)
        other_complex_number = torch.complex(other_real_part, other_imaginary_part)
        other_torch_so2 = kornia.geometry.liegroup.So2(other_complex_number)
    
        transpiled_other_complex_number = _nest_torch_tensor_to_new_framework(other_complex_number, target_framework)
        transpiled_other_so2 = TranspiledSo2(transpiled_other_complex_number)
    
        torch_composed_so2 = torch_so2 * other_torch_so2
        transpiled_composed_so2 = transpiled_so2 * transpiled_other_so2
        _to_numpy_and_allclose(torch_composed_so2.z, transpiled_composed_so2.z)
    
        # Test .adjoint()
        torch_adjoint = torch_so2.adjoint()
>       transpiled_adjoint = transpiled_so2.adjoint()

kornia/geometry/test_liegroup.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Variable 'Variable:0' shape=(1,) dtype=complex64, numpy=array([1.+2.j], dtype=complex64)>

    def adjoint(self):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_real_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
>       batch_size = len(self.z) if len(tensorflow_shape_frnt_(self.z)) > 0 else None
E       TypeError: object of type 'ResourceVariable' has no len()

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/liegroup/so2.py:196: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_liegroup.py::test_So2[tensorflow-s2s-False] - TypeError: object of type 'ResourceVariable' has no len()
=============================================================================== 1 failed, 3 passed in 443.81s (0:07:23) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1085.68s (0:18:05) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py ...F.......F.F.F.                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomMotionBlur[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMotionBlur(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMotionBlur")
    
        init_args = (3, 35., 0.5)
        init_kwargs = {"p": 1.}
        call_args = (torch.ones(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMotionBlur,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.motion_blur.RandomMotionBlur'>, target = 'tensorflow', init_args = (3, 35.0, 0.5), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.],
          [1., 1., 1., 1., 1.]]]]),), call_kwargs = {}
deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fe5173ac840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border..., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
params = None, kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fe516603d00>, tensorflow_set_item = <function tensorflow_set_item at 0x7fe5145fa8c0>
tensor = <function tensorflow_tensor_frnt at 0x7fe5145aecb0>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest)
batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMotionBlur(kernel_size=3, angle=35.0, direction=0.5, p=1.0, p_batch=1.0, same_on_batch=False, border_type=constant, resample=nearest), batch_shape = (1, 1, 5, 5)

    def generate_parameters(self, batch_shape):
        from ....core._backend import tensor
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .....ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
    
        params = super().generate_parameters(batch_shape)
        params = tensorflow_set_item(
            params,
            "idx",
            tensor([0])
            if batch_shape[0] == 0
>           else tensorflow_randint_frnt(batch_shape[0], (1,)),
        )
E       TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
E       
E       [1mtensorflow_randint_frnt() missing 1 required positional argument: 'size'[0m
E       
E       Arguments received by tensorflow_RandomMotionBlur.call():
E          input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/motion_blur.py:73: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMotionBlur
_________________________________________________________________________ test_RandomSaltAndPepperNoise[tensorflow-s2s-False] __________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSaltAndPepperNoise(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSaltAndPepperNoise")
    
        init_args = ()
        init_kwargs = {"amount": 0.5, "salt_vs_pepper": 0.5, "p": 1.}
        call_args = (torch.rand(1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSaltAndPepperNoise,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.salt_pepper_noise.RandomSaltAndPepperNoise'>, target = 'tensorflow', init_args = ()
init_kwargs = {'amount': 0.5, 'p': 1.0, 'salt_vs_pepper': 0.5}
call_args = (tensor([[[[0.1720, 0.9862, 0.4098],
          [0.6851, 0.0096, 0.3461],
          [0.8870, 0.5910, 0.7202]],

       ...93]],

         [[0.7023, 0.7471, 0.5234],
          [0.9946, 0.8066, 0.5379],
          [0.4850, 0.3848, 0.9434]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.6851...6 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fe515ab9040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...16 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.6851...6 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=...16 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.6851...6 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.68513...516 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
       ...16 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.68513...516 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[ True, False, False],
         [False, False,  True],
         [False, False, False]]]])>, ...}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fe51c7684c0>, tensorflow_set_item = <function tensorflow_set_item at 0x7fe514af3a30>
tensor = <function tensorflow_tensor_frnt at 0x7fe51c553520>
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.68513...516 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 3, 3, 3]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.68513...516 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[ True, False, False],
         [False, False,  True],
         [False, False, False]]]])>, ...}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.68513...516 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[ True, False, False],
         [False, False,  True],
         [False, False, False]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fe51c7684c0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7fe51c72b760>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7fe50ca2e200>, tensorflow_get_item = <function tensorflow_get_item at 0x7fe514af3880>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7fe514ae1120>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7fe50ca2dab0>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fe50ca2e4d0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSaltAndPepperNoise(amount=(0.5, 0.5), salt_and_pepper=(0.5, 0.5), p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 3, 3, 3), dtype=float32, numpy=
array([[[[0.17196047, 0.9862122 , 0.4098152 ],
         [0.68513...516 ],
         [0.99461484, 0.8065719 , 0.5379108 ],
         [0.48503911, 0.3847503 , 0.9433932 ]]]], dtype=float32)>
params = {'amount_factor': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'batch_prob': <tf.Tensor:...se, False]],

        [[ True, False, False],
         [False, False,  True],
         [False, False, False]]]])>, ...}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....core.check import tensorflow_KORNIA_CHECK
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK(
            len(tensorflow_shape_frnt_(input)) in (3, 4), "Wrong input dimension."
        )
        if len(tensorflow_shape_frnt_(input)) == 3:
            input = input[None, :, :, :]
        tensorflow_KORNIA_CHECK(
            tensorflow_shape_frnt_(input)[1] in {3, 1},
            "Number of color channels should be 1 or 3.",
        )
        noisy_image = tensorflow_clone_frnt_(input)
        noisy_image = tensorflow_set_item(
>           noisy_image, params["mask_salt"].to(input.device), 1.0
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'to'[0m
E       
E       Arguments received by tensorflow_RandomSaltAndPepperNoise.call():
E          input=tf.Tensor(shape=(1, 3, 3, 3), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/salt_pepper_noise.py:99: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSaltAndPepperNoise
______________________________________________________________________________ test_RandomSharpness[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSharpness(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSharpness")
    
        init_args = (1.,)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSharpness,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.sharpness.RandomSharpness'>, target = 'tensorflow', init_args = (1.0,), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.0706, 0.2836, 0.2223, 0.0124, 0.3685],
          [0.4351, 0.3329, 0.0420, 0.6771, 0.1722],
          [0...., 0.7819],
          [0.9530, 0.6910, 0.9996, 0.5913, 0.1241],
          [0.9351, 0.1687, 0.0225, 0.3534, 0.0847]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.368...912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fe517329640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.368...912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(1, 1, 5, 5), d...5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.368...912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.3685....5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.012440...5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.3685....5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...mpy=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4687475], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fe50c70ad40>, tensorflow_set_item = <function tensorflow_set_item at 0x7fe50c52ecb0>
tensor = <function tensorflow_tensor_frnt at 0x7fe50c3fc430>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.3685....5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.3685....5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...mpy=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4687475], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.3685....5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...mpy=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4687475], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fe50c70ad40>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7fe50c70beb0>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7fe50c4c5bd0>, tensorflow_get_item = <function tensorflow_get_item at 0x7fe50c52eb00>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7fe50c57c3a0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7fe50c3ffb50>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fe50c3ff9a0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSharpness(sharpness=1.0, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.07061148, 0.2835523 , 0.22228515, 0.01244074, 0.3685....5912585 , 0.12407815],
         [0.93512833, 0.16867864, 0.0224731 , 0.35340416, 0.08467698]]]],
      dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'forward_input_shape': <tf.Te...mpy=array([1, 1, 5, 5])>, 'sharpness': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.4687475], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        factor = params["sharpness"]
>       return sharpness(input, factor)
E       NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
E       
E       [1mname 'sharpness' is not defined[0m
E       
E       Arguments received by tensorflow_RandomSharpness.call():
E          input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/sharpness.py:46: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSharpness
______________________________________________________________________________ test_RandomSolarize[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomSolarize(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomSolarize")
    
        init_args = (0.1, 0.1)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 5, 5),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomSolarize,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation2.py:373: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.solarize.RandomSolarize'>, target = 'tensorflow', init_args = (0.1, 0.1), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[0.1032, 0.9871, 0.2977, 0.3182, 0.4681],
          [0.3115, 0.2979, 0.3960, 0.8915, 0.4289],
          [0...., 0.8569],
          [0.8630, 0.8466, 0.9867, 0.7143, 0.5601],
          [0.7696, 0.9406, 0.0871, 0.7714, 0.3556]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation2.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.468...1433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fe514684c40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.468...1433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=...71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.468...1433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.4680....71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.318160...71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.4680....71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06567126], dtype=float32)>, 'batch_prob': <tf.Tens...mpy=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.533456], dtype=float32)>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fe50c36ae60>, tensorflow_set_item = <function tensorflow_set_item at 0x7fe50c1df1c0>
tensor = <function tensorflow_tensor_frnt at 0x7fe50c0c1b40>
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.4680....71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), batch_shape = ivy.frontends.torch.Size([1, 1, 5, 5]), flags = {}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
in_tensor = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.4680....71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06567126], dtype=float32)>, 'batch_prob': <tf.Tens...mpy=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.533456], dtype=float32)>}
flags = {}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.4680....71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06567126], dtype=float32)>, 'batch_prob': <tf.Tens...mpy=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.533456], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7fe50c36ae60>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7fe50c887d00>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7fe50c118700>, tensorflow_get_item = <function tensorflow_get_item at 0x7fe50c1df010>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7fe51c4a0ca0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7fe50c118b80>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7fe50c118f70>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=1.0, p_batch=1.0, same_on_batch=False)
input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.4680....71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>
params = {'additions': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06567126], dtype=float32)>, 'batch_prob': <tf.Tens...mpy=array([1, 1, 5, 5])>, 'thresholds': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.533456], dtype=float32)>}
flags = {}, transform = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.adjust import tensorflow_solarize
    
        thresholds = params["thresholds"]
        additions: typing.Any
        if "additions" in params:
            additions = params["additions"]
        else:
            additions = None
>       return tensorflow_solarize(input, thresholds, additions)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/solarize.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=
array([[[[0.10319161, 0.98711675, 0.2977339 , 0.31816083, 0.4680....71433115, 0.56007653],
         [0.7696209 , 0.94057286, 0.08714736, 0.7714344 , 0.35556668]]]],
      dtype=float32)>
thresholds = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.533456], dtype=float32)>, additions = <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06567126], dtype=float32)>

    def tensorflow_solarize(input, thresholds=0.5, additions=None):
        from ...ivy.functional.frontends.torch.creation_ops import tensorflow_as_tensor_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_all_frnt
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clamp_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(thresholds, (float, tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(
                f"The factor should be either a float or Tensor. Got {type(thresholds)}"
            )
        if isinstance(thresholds, (float,)):
            thresholds = tensorflow_as_tensor_frnt(thresholds)
        if additions is not None:
            if not isinstance(additions, (float, tensorflow.Tensor, tensorflow.Variable)):
                raise TypeError(
                    f"The factor should be either a float or Tensor. Got {type(additions)}"
                )
            if isinstance(additions, (float,)):
                additions = tensorflow_as_tensor_frnt(additions)
>           if not tensorflow_all_frnt((additions < 0.5) * (additions > -0.5)):

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/adjust.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, rhs = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, other = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, x2 = <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_RandomSolarize.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_RandomSolarize.call():
E          input=tf.Tensor(shape=(1, 1, 5, 5), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:299: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomSolarize
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation2.py::test_RandomMotionBlur[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_RandomMotionBlur.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSaltAndPepperNoise[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomSaltAndPepperNoise.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSharpness[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_RandomSharpness.call().
FAILED kornia/augmentation/test_augmentation2.py::test_RandomSolarize[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensor...
============================================================================== 4 failed, 13 passed in 3543.82s (0:59:03) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 122.72s (0:02:02) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py ........                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 685.05s (0:11:25) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py FF.....FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_LAFOrienter[tensorflow-s2s-False] ________________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.4886744]],

       [[ 0.933825 ]],

       [[ 0.0284667]],

       [[-0.3754406]],

       [[-0.6661885]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_LAFOrienter(target_framework, mode, backend_compile):
        print("kornia.feature.LAFOrienter")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLAFOrienter = ivy.transpile(kornia.feature.LAFOrienter, source="torch", target=target_framework)
    
        laf = torch.rand(1, 2, 2, 3)
        img = torch.rand(1, 1, 32, 32)
        transpiled_laf = _nest_torch_tensor_to_new_framework(laf, target_framework)
        transpiled_img = _nest_torch_tensor_to_new_framework(img, target_framework)
    
        model = kornia.feature.LAFOrienter()
        torch_out = model(laf, img)
    
>       transpiled_model = TranspiledLAFOrienter()

kornia/test_feature5.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7fd75dbaae00>, patch_size = 32, num_angular_bins = 36
angle_detector = None

    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (32, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.4886744]],

       [[ 0.933825 ]],

       [[ 0.0284667]],

       [[-0.3754406]],

       [[-0.6661885]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.4886744]],

       [[ 0.933825 ]],

     ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[ 0.4886744]],

       [[ 0.933825 ]],

       [[ 0.0284667]],

       [[-0.3754406]],

       [[-0.6661885]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.LAFOrienter
_____________________________________________________________________ test_PatchDominantGradientOrientation[tensorflow-s2s-False] ______________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.80481863]],

       [[-0.4615307 ]],

       [[ 0.03638268]],

       [[ 0.09349871]],

       [[-0.51485276]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

>   ???
E   AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PatchDominantGradientOrientation(target_framework, mode, backend_compile):
        print("kornia.feature.PatchDominantGradientOrientation")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPatchDominantGradientOrientation = ivy.transpile(kornia.feature.PatchDominantGradientOrientation, source="torch", target=target_framework)
    
        patch = torch.rand(10, 1, 32, 32)
        transpiled_patch = _nest_torch_tensor_to_new_framework(patch, target_framework)
    
        model = kornia.feature.PatchDominantGradientOrientation()
        torch_out = model(patch)
    
>       transpiled_model = TranspiledPatchDominantGradientOrientation()

kornia/test_feature5.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), args = (), kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=32, num_ang_bins=36, eps=1e-08), patch_size = 32, num_angular_bins = 36, eps = 1e-08

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.80481863]],

       [[-0.4615307 ]],

       [[ 0.03638268]],

       [[ 0.09349871]],

       [[-0.51485276]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.80481863]],

       [[-0.4615307 ]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

>   ???

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[ 0.80481863]],

       [[-0.4615307 ]],

       [[ 0.03638268]],

       [[ 0.09349871]],

       [[-0.51485276]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

>   ???
E   ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.PatchDominantGradientOrientation
__________________________________________________________________________________ test_DeDoDe[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDeDoDe = ivy.transpile(kornia.feature.DeDoDe, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
        transpiled_model = TranspiledDeDoDe(amp_dtype=ivy.as_native_dtype("float32"))
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.04556477, 0.83330387, 0.00959134, ..., 0.436569...
         [0.83463913, 0.97677046, 0.17238688, ..., 0.93621516,
          0.741126  , 0.61683404]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5603185fc3b0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.83463913, 0.97677046, 0.17238688, ..., 0.93621516,
          0.741126  , 0.61683404]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.04556477, 0.83330387, 0.00959134, ..., 0.436569...
         [0.83463913, 0.97677046, 0.17238688, ..., 0.93621516,
          0.741126  , 0.61683404]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...,
         [0.83463913, 0.97677046, 0.17238688, ..., 0.93621516,
          0.741126  , 0.61683404]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.04556477, 0.83330387, 0.00959134, ..., 0.436569...
         [0.83463913, 0.97677046, 0.17238688, ..., 0.93621516,
          0.741126  , 0.61683404]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.04556477, 0.83330387, 0.00959134, ..., 0.4365695...],
         [0.83463913, 0.97677046, 0.17238688, ..., 0.93621516,
          0.741126  , 0.61683404]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=10000, apply_imagenet_normalization=True, pad_if_not_divisible=True)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tenso...        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.04556477, 0.83330387, 0.00959134, ......,
         [0.83463913, 0.97677046, 0.17238688, ..., 0.93621516,
          0.741126  , 0.61683404]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.9189311 ,  1.5209775 , -2.0760205 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = True, pad_if_not_divisible = True

    def call(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...geometry.conversions import tensorflow_denormalize_pixel_coordinates
    
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       keypoints, scores = self.detect(
            images, n=n, apply_imagenet_normalization=False, crop_h=h, crop_w=w
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDe(
  (detector): tensorflow_DeDoDeDetector(
    (encoder): tensorflow_VGG19(
      (pt_layers): tensor...)
        )
      )
    )
  )
  (normalizer): tensorflow_Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.9189311 ,  1.5209775 , -2.0760205 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>
n = 10000, apply_imagenet_normalization = False, pad_if_not_divisible = True, crop_h = 256, crop_w = 256

    def detect(
        self,
        images,
        n=10000,
        apply_imagenet_normalization=True,
        pad_if_not_divisible=True,
        crop_h=None,
        crop_w=None,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_softmax_frnt_
        from .utils import tensorflow_sample_keypoints
    
        tensorflow_KORNIA_CHECK_SHAPE(images, ["B", "3", "H", "W"])
        self.train(False)
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 14 - h % 14 if h % 14 > 0 else 0
            pd_w = 14 - w % 14 if w % 14 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
        if apply_imagenet_normalization:
            images = self.normalizer(images)
        B, C, H, W = tensorflow_shape_frnt_(images)
>       logits = self.detector.call(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/dedode.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DeDoDeDetector(
  (encoder): tensorflow_VGG19(
    (pt_layers): tensorflow_ModuleList(
      (0): KerasConv...rflow_ReLU()
            (3): KerasConv2D()
          )
        )
        (out_conv): KerasConv2D()
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 266, 266), dtype=float32, numpy=
array([[[[-1.9189311 ,  1.5209775 , -2.0760205 , ...,  0.   ...      [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32)>

    def call(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_float_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_interpolate_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
    
        dtype = images.dtype
        features, sizes = self.encoder(images)
        context = None
        logits = None
        scales = ["8", "4", "2", "1"]
        for idx, (feature_map, scale) in enumerate(zip(reversed(features), scales)):
>           delta_logits, context = self.decoder(
                feature_map, context=context, scale=scale
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/detector.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}
stack = [FrameInfo(frame=<frame at 0x7fd75fcc2840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {'context': None, 'scale': '8'}, replace_v = False, replace_buffers = False, call_signature = <Signature (features, context=None, scale=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Decoder(
  (pt_layers): tensorflow_ModuleDict(
    (8): tensorflow_ConvRefiner(
      (block1): tensorflow_...      (2): tensorflow_ReLU()
          (3): KerasConv2D()
        )
      )
      (out_conv): KerasConv2D()
    )
  )
)
features = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.0051860...],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>
context = None, scale = '8'

    def call(self, features, context=None, scale=None):
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
        if context is not None:
            features = tensorflow_cat_frnt((features, context), dim=1)
>       stuff = tensorflow_get_item(self.pt_layers, scale)(features)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5603732f0260, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (feats)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ConvRefiner(
  (block1): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2):...  (1): KerasBatchNorm2D()
      (2): tensorflow_ReLU()
      (3): KerasConv2D()
    )
  )
  (out_conv): KerasConv2D()
)
feats = <tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.0051860...],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>

    def call(self, feats):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        b, c, hs, ws = tensorflow_shape_frnt_(feats)
>       x0 = self.block1(feats)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/dedode/decoder.py:298: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x56037b260ce0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 512, 33, 33), dtype=float32, numpy=
array([[[[0.00162289, 0.00726255, 0.00717265, ..., 0.005186...
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Sequential(
  (0): KerasConv2D()
  (1): KerasBatchNorm2D()
  (2): tensorflow_ReLU()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-5.09001024e-04, -2.96815089e-03, -4.72790049e-03,...61789e-03, -2.61247903e-03, ...,
           5.31821046e-03,  5.29843941e-03, -3.74876661e-03]]]],
      dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-5.09001024e-04, -2.96815089e-03, -4.72790049e-03...789e-03, -2.61247903e-03, ...,
           5.31821046e-03,  5.29843941e-03, -3.74876661e-03]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x56032a89ec50, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D()
args = (<tf.Tensor: shape=(1, 33, 33, 512), dtype=float32, numpy=
array([[[[-5.09001024e-04, -2.96815089e-03, -4.72790049e-03...789e-03, -2.61247903e-03, ...,
           5.31821046e-03,  5.29843941e-03, -3.74876661e-03]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    def __call__(self, *args, **kwargs):
        if not self.built:
>           res = super().__call__(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1010: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasBatchNorm2D(), input_shape = (1, 33, 33, 512)

    def build(self, input_shape):
        _, ch, _, _ = input_shape
        if (
            not self.built
            and self.axis == -1
            and os.environ.get("DATA_FORMAT", "channels_first") == "channels_first"
        ):
            order = (0, 2, 3, 1)
            new_shape = tuple(input_shape[i] for i in order)
            input_shape = tf.TensorShape(new_shape)
    
>       super().build(input_shape)
E       IndexError: Exception encountered when calling tensorflow_Sequential.call().
E       
E       [1mtuple index out of range[0m
E       
E       Arguments received by tensorflow_Sequential.call():
E          input=tf.Tensor(shape=(1, 512, 33, 33), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:1030: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  1%|          | 7.88M/1.13G [00:00<00:14, 82.3MB/s]
  2%|         | 22.6M/1.13G [00:00<00:09, 124MB/s] 
  4%|         | 46.6M/1.13G [00:00<00:06, 182MB/s]
  7%|         | 80.0M/1.13G [00:00<00:04, 248MB/s]
 10%|         | 112M/1.13G [00:00<00:03, 281MB/s] 
 13%|        | 149M/1.13G [00:00<00:03, 314MB/s]
 16%|        | 185M/1.13G [00:00<00:03, 336MB/s]
 19%|        | 222M/1.13G [00:00<00:02, 352MB/s]
 22%|       | 259M/1.13G [00:00<00:02, 364MB/s]
 25%|       | 294M/1.13G [00:01<00:02, 364MB/s]
 29%|       | 331M/1.13G [00:01<00:02, 371MB/s]
 32%|      | 367M/1.13G [00:01<00:02, 372MB/s]
 35%|      | 402M/1.13G [00:01<00:02, 364MB/s]
 38%|      | 439M/1.13G [00:01<00:02, 371MB/s]
 41%|      | 477M/1.13G [00:01<00:01, 379MB/s]
 44%|     | 514M/1.13G [00:01<00:01, 371MB/s]
 47%|     | 549M/1.13G [00:01<00:01, 351MB/s]
 50%|     | 583M/1.13G [00:01<00:01, 336MB/s]
 53%|    | 615M/1.13G [00:01<00:01, 329MB/s]
 56%|    | 648M/1.13G [00:02<00:01, 333MB/s]
 59%|    | 684M/1.13G [00:02<00:01, 344MB/s]
 62%|   | 718M/1.13G [00:02<00:01, 350MB/s]
 65%|   | 756M/1.13G [00:02<00:01, 364MB/s]
 68%|   | 793M/1.13G [00:02<00:01, 371MB/s]
 71%|  | 829M/1.13G [00:02<00:00, 367MB/s]
 74%|  | 864M/1.13G [00:02<00:00, 361MB/s]
 78%|  | 902M/1.13G [00:02<00:00, 372MB/s]
 81%|  | 938M/1.13G [00:02<00:00, 353MB/s]
 84%| | 972M/1.13G [00:02<00:00, 351MB/s]
 87%| | 0.98G/1.13G [00:03<00:00, 343MB/s]
 90%| | 1.02G/1.13G [00:03<00:00, 351MB/s]
 93%|| 1.05G/1.13G [00:03<00:00, 357MB/s]
 96%|| 1.08G/1.13G [00:03<00:00, 323MB/s]
 98%|| 1.12G/1.13G [00:03<00:00, 311MB/s]
100%|| 1.13G/1.13G [00:03<00:00, 336MB/s]
2024-10-12 17:53:57.157802: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-12 17:53:57.530281: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-12 17:53:58.166707: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-12 17:53:58.269924: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
2024-10-12 17:53:58.419392: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.
___________________________________________________________________________________ test_DISK[tensorflow-s2s-False] ____________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDISK = ivy.transpile(kornia.feature.DISK, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DISK()
        torch_out = model(x)
    
        transpiled_model = TranspiledDISK()
        if target_framework == "tensorflow":
            # build the layers
>           transpiled_model(transpiled_x)

kornia/test_feature5.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.078377...
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd75e4e7c10, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow...,
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.078377...
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow...,
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.078377...
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.0783775...],
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (images, n=None, window_size=5, score_threshold=0.0, pad_if_not_divisible=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDow... tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
),)
kwargs = {'images': <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ......,
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.0783775...],
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>
n = None, window_size = 5, score_threshold = 0.0, pad_if_not_divisible = False

    def call(
        self,
        images,
        n=None,
        window_size=5,
        score_threshold=0.0,
        pad_if_not_divisible=False,
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ....ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from .detector import tensorflow_heatmap_to_keypoints
    
        B = tensorflow_shape_frnt_(images)[0]
        if pad_if_not_divisible:
            h, w = (
                tensorflow_shape_frnt_(images)[2:][0],
                tensorflow_shape_frnt_(images)[2:][1],
            )
            pd_h = 16 - h % 16 if h % 16 > 0 else 0
            pd_w = 16 - w % 16 if w % 16 > 0 else 0
            images = tensorflow_pad_frnt(images, (0, pd_w, 0, pd_h), value=0.0)
>       heatmaps, descriptors = self.heatmap_and_dense_descriptors(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DISK(
  (unet): tensorflow_Unet(
    (path_down): tensorflow_ModuleList(
      (0): tensorflow_ThinUnetDown...): tensorflow_PReLU()
          (2): tensorflow_Sequential()
          (3): KerasConv2D()
        )
      )
    )
  )
)
images = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.0783775...],
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>

    def heatmap_and_dense_descriptors(self, images):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
    
>       unet_output = self.unet(images)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/disk.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.078377...
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd75ec699a0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ls.py', lineno=117, function='error_handler', code_context=['            return fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.078377...
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.078377...
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (inp)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Unet(
  (path_down): tensorflow_ModuleList(
    (0): tensorflow_ThinUnetDownBlock(
      (0): tensorflow_Se...d()
        (1): tensorflow_PReLU()
        (2): tensorflow_Sequential()
        (3): KerasConv2D()
      )
    )
  )
)
inp = <tf.Tensor: shape=(1, 3, 256, 256), dtype=float32, numpy=
array([[[[0.30448347, 0.67495584, 0.28521204, ..., 0.0783775...],
         [0.8874412 , 0.4689622 , 0.8197621 , ..., 0.70407116,
          0.16402131, 0.7921958 ]]]], dtype=float32)>

    def call(self, inp):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
    
        if tensorflow_size_frnt_(inp, 1) != self.in_features:
            fmt = "Expected {} feature channels in input, got {}"
            msg = fmt.format(self.in_features, tensorflow_size_frnt_(inp, 1))
            raise ValueError(msg)
        input_size_divisor = 2 ** len(self.up)
        if (
            tensorflow_size_frnt_(inp, 2) % input_size_divisor != 0
            or tensorflow_size_frnt_(inp, 3) % input_size_divisor != 0
        ):
            raise ValueError(
                f"Input image shape must be divisible by {input_size_divisor} (got {tensorflow_size_frnt_(inp)}). This is not inherent to DISK, but to the U-Net architecture used in pretrained models. Please pad if necessary."
            )
        features = [inp]
        for layer in self.path_down:
>           features.append(layer(features[-1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/disk/_unets/unet.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 4.88679036e-02, -2.37155780e-02,  2.12502226e-0...593e-01, -1.88014641e-01, ...,
          -1.33736461e-01, -2.53050178e-01, -2.44096383e-01]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5602f9721f90, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 4.88679036e-02, -2.37155780e-02,  2.12502226e-0...593e-01, -1.88014641e-01, ...,
          -1.33736461e-01, -2.53050178e-01, -2.44096383e-01]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 256, 256), dtype=float32, numpy=
array([[[[ 4.88679036e-02, -2.37155780e-02,  2.12502226e-0...593e-01, -1.88014641e-01, ...,
          -1.33736461e-01, -2.53050178e-01, -2.44096383e-01]]]],
      dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ThinUnetDownBlock(
  (0): tensorflow_TrivialDownsample()
  (1): tensorflow_Conv(
    (0): tensorflow_InstanceNorm2d()
    (1): tensorflow_PReLU()
    (2): tensorflow_Sequential()
    (3): KerasConv2D()
  )
)
input = <tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.20095293,  0.39604324,  0.42789298, ...,  0.41...      [-0.08349498, -0.12730354, -0.1673786 , ..., -0.11413597,
          -0.01821272, -0.13529873]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
)
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.20095293,  0.39604324,  0.42789298, ...,  0.4...    [-0.08349498, -0.12730354, -0.1673786 , ..., -0.11413597,
          -0.01821272, -0.13529873]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7fd75d87c610, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.20095293,  0.39604324,  0.42789298, ...,  0.4...    [-0.08349498, -0.12730354, -0.1673786 , ..., -0.11413597,
          -0.01821272, -0.13529873]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 16, 128, 128), dtype=float32, numpy=
array([[[[ 0.20095293,  0.39604324,  0.42789298, ...,  0.4...    [-0.08349498, -0.12730354, -0.1673786 , ..., -0.11413597,
          -0.01821272, -0.13529873]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Conv(
  (0): tensorflow_InstanceNorm2d()
  (1): tensorflow_PReLU()
  (2): tensorflow_Sequential()
  (3): KerasConv2D()
)
input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-5.3235908 , -2.1202593 , -0.36328012, ..., -0.51...      [-5.255541  , -2.7790875 , -0.1984875 , ...,  2.836959  ,
          -0.8516636 , -1.0386064 ]]]], dtype=float32)>

    def call(self, input):
        for i, module in enumerate(self):
>           input = module(input)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/container.py:199: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU()
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-5.3235908 , -2.1202593 , -0.36328012, ..., -0.5...    [-5.255541  , -2.7790875 , -0.1984875 , ...,  2.836959  ,
          -0.8516636 , -1.0386064 ]]]], dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5603185f9fe0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...function='__call__', code_context=['                    outputs = super().__call__(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-5.3235908 , -2.1202593 , -0.36328012, ..., -0.5...    [-5.255541  , -2.7790875 , -0.1984875 , ...,  2.836959  ,
          -0.8516636 , -1.0386064 ]]]], dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-5.3235908 , -2.1202593 , -0.36328012, ..., -0.5...    [-5.255541  , -2.7790875 , -0.1984875 , ...,  2.836959  ,
          -0.8516636 , -1.0386064 ]]]], dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU(), args = ()
kwargs = {'input': <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-5.3235908 , -2.1202593 , -0.36328012, ...     [-5.255541  , -2.7790875 , -0.1984875 , ...,  2.836959  ,
          -0.8516636 , -1.0386064 ]]]], dtype=float32)>}
tensorflow_get_item = <function tensorflow_get_item at 0x7fd736280d30>, tensorflow_set_item = <function tensorflow_set_item at 0x7fd736280ee0>, DATA_FORMAT = 'channels_last'
fn_args_and_kwargs = {'input': <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-5.3235908 , -2.1202593 , -0.36328012, ...     [-5.255541  , -2.7790875 , -0.1984875 , ...,  2.836959  ,
          -0.8516636 , -1.0386064 ]]]], dtype=float32)>}
conv_block_start = <function tensorflow_handle_transpose_in_input_and_output.<locals>.transpose_wrapper.<locals>.<lambda> at 0x7fd75dda5120>, next_call_in_seq = tensorflow_Sequential()
conv_block_continued = tensorflow_Sequential(), arg_name = 'input'

    @functools.wraps(fn)
    def transpose_wrapper(self, *args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_get_item
        from ..functional.backends.tensorflow.general import tensorflow_set_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        kwargs_call = {
            key: val
            for key, val in kwargs.items()
            if key not in dict(original_signature.parameters)
        }
        fn_args_and_kwargs = {
            key: val for key, val in kwargs.items() if key not in kwargs_call
        }
        fn_args_and_kwargs.update(dict(zip(fn.__code__.co_varnames[1:], args)))
        conv_block_start = lambda f: any(
            substr in f.__qualname__
            for substr in CONV_FUNCS
            + NORM_FUNCS
            + POOL_FUNCS
            + KERAS_CONV_FUNCS
            + KERAS_NORM_FUNCS
            + KERAS_POOL_FUNCS
            + FLAX_CONV_FUNCS
            + FLAX_NORM_FUNCS
            + FLAX_POOL_FUNCS
        )
        next_call_in_seq = tensorflow_get_next_func(self)
        name_of_next_call = (
            next_call_in_seq.__class__.__name__
            if hasattr(next_call_in_seq, "__class__")
            else ""
        )
        conv_block_continued = next_call_in_seq and any(
            substr in name_of_next_call for substr in CONV_BLOCK_FNS
        )
        arg_name = "input" if "input" in fn_args_and_kwargs else "inputs"
        if DATA_FORMAT == "channels_first" and conv_block_start(self.__class__):
            input = tensorflow_get_item(fn_args_and_kwargs, arg_name)
            if len(input.shape) > 4:
                transpose = tensorflow_TransposeType.CONV3D
            elif len(input.shape) > 3:
                transpose = tensorflow_TransposeType.CONV2D
            elif len(input.shape) > 2:
                transpose = tensorflow_TransposeType.CONV1D
            else:
                transpose = tensorflow_TransposeType.NO_TRANSPOSE
            fn_args_and_kwargs = tensorflow_set_item(
                fn_args_and_kwargs,
                arg_name,
                tensorflow_apply_transpose(input, transpose=transpose, pt_to_tf=True),
            )
            DATA_FORMAT = "channels_last"
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", DATA_FORMAT)
>       res = fn(self, **fn_args_and_kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:414: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PReLU()
input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-5.3235908 , -2.1202593 , -0.36328012, ..., -0.51...      [-5.255541  , -2.7790875 , -0.1984875 , ...,  2.836959  ,
          -0.8516636 , -1.0386064 ]]]], dtype=float32)>

    @tensorflow_handle_transpose_in_input_and_output
    def call(self, input):
        from ....ivy.functional.frontends.torch.nn.functional.non_linear_activation_functions import (
            tensorflow_prelu_frnt,
        )
    
>       return tensorflow_prelu_frnt(input, self.weight)

ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/activation.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 128, 128, 16), dtype=float32, numpy=
array([[[[-5.3235908 , -2.1202593 , -0.36328012, ..., -0.51...      [-5.255541  , -2.7790875 , -0.1984875 , ...,  2.836959  ,
          -0.8516636 , -1.0386064 ]]]], dtype=float32)>
weight = <tf.Variable 'Variable:0' shape=(16,) dtype=float32, numpy=
array([0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,
       0.25, 0.25, 0.25, 0.25, 0.25], dtype=float32)>

    def tensorflow_prelu_frnt(input, weight):
        from ...tensor import tensorflow_ndim_frnt_
        from ...tensor import tensorflow_shape_frnt_
        from ......data_classes.array.manipulation import tensorflow_expand_dims_bknd_
        from .....backends.tensorflow.elementwise import tensorflow_add
        from .....backends.tensorflow.elementwise import tensorflow_maximum
        from .....backends.tensorflow.elementwise import tensorflow_multiply
        from .....backends.tensorflow.elementwise import tensorflow_minimum
    
        input_dim = tensorflow_ndim_frnt_(input)
        weight_dim = tensorflow_ndim_frnt_(weight)
        if weight_dim == 0:
            pass
        elif weight_dim == 1:
            if input_dim >= 2:
>               assert (
                    tensorflow_shape_frnt_(weight)[0] == tensorflow_shape_frnt_(input)[1]
                ), "Weight size must match input channels"
E               AssertionError: Exception encountered when calling tensorflow_PReLU.call().
E               
E               [1mWeight size must match input channels[0m
E               
E               Arguments received by tensorflow_PReLU.call():
E                  input=tf.Tensor(shape=(1, 128, 128, 16), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/non_linear_activation_functions.py:61: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/torch/nn/modules/instancenorm.py:134: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_LAFOrienter[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_PatchDominantGradientOrientation[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
FAILED kornia/test_feature5.py::test_DeDoDe[tensorflow-s2s-False] - IndexError: Exception encountered when calling tensorflow_Sequential.call().
FAILED kornia/test_feature5.py::test_DISK[tensorflow-s2s-False] - AssertionError: Exception encountered when calling tensorflow_PReLU.call().
=============================================================================== 4 failed, 6 passed in 1452.68s (0:24:12) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py F......F.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomMosaic[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMosaic(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMosaic")
    
        init_args = ((300, 300),)
        init_kwargs = {"data_keys": ["input", "bbox_xyxy"]}
        call_args = (
            torch.randn(8, 3, 224, 224),
            torch.tensor([[
                [70, 5, 150, 100],
                [60, 180, 175, 220],
            ]]).repeat(8, 1, 1),
        )
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMosaic,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mosaic.RandomMosaic'>, target = 'jax', init_args = ((300, 300),), init_kwargs = {'data_keys': ['input', 'bbox_xyxy']}
call_args = (tensor([[[[ 1.7148e+00,  1.3322e+00,  1.3969e+00,  ..., -2.4217e+00,
            1.1137e+00, -2.9445e-01],
          ...[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]],

        [[ 70,   5, 150, 100],
         [ 60, 180, 175, 220]]]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMosaic(output_size=(300, 300), mosaic_grid=(2, 2), start_ratio_range=(0.3, 0.7), p=0.7, p_batch=1.0, same_on..._size=(300, 300), min_bbox_size=0.0, padding_mode=constant, resample=bilinear, align_corners=True, cropping_mode=slice)
params = None, data_keys = None
input = (Array([[[[ 1.71480846e+00,  1.33217871e+00,  1.39691305e+00, ...,
          -2.42169833e+00,  1.11367500e+00, -2.9444... 150, 100],
        [ 60, 180, 175, 220]],

       [[ 70,   5, 150, 100],
        [ 60, 180, 175, 220]]], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7fd8a6cff5b0>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMosaic
_________________________________________________________________________________ test_RandomRotation3D[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRotation3D(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation3D")
    
        init_args = ((15., 20., 20.),)
        init_kwargs = {"p": 1.}
        call_args = (torch.rand(1, 1, 3, 3, 3),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation3D,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation4.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._3d.geometric.rotation.RandomRotation3D'>, target = 'jax', init_args = ((15.0, 20.0, 20.0),), init_kwargs = {'p': 1.0}
call_args = (tensor([[[[[0.7203, 0.1420, 0.9216],
           [0.0768, 0.4146, 0.8574],
           [0.2184, 0.3095, 0.7029]],

    ...,

          [[0.9587, 0.9937, 0.6155],
           [0.5399, 0.3134, 0.4188],
           [0.9901, 0.5606, 0.9801]]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation4.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.72028214, 0.14200944, 0.921588  ],
          [0.07678509, 0.41455352, 0.8573685 ],
          [0.21842337,...2 ],
          [0.53994805, 0.3134091 , 0.41882402],
          [0.99014586, 0.56061876, 0.98013973]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
kwargs = {}, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fd8a77649d0>, jax_set_item = <function jax_set_item at 0x7fd8a606dfc0>, tensor = <function jax_tensor_frnt at 0x7fd87ce71990>
in_tensor = Array([[[[[0.72028214, 0.14200944, 0.921588  ],
          [0.07678509, 0.41455352, 0.8573685 ],
          [0.21842337,...2 ],
          [0.53994805, 0.3134091 , 0.41882402],
          [0.99014586, 0.56061876, 0.98013973]]]]], dtype=float32)
input_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3, 3]), flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
in_tensor = Array([[[[[0.72028214, 0.14200944, 0.921588  ],
          [0.07678509, 0.41455352, 0.8573685 ],
          [0.21842337,...2 ],
          [0.53994805, 0.3134091 , 0.41882402],
          [0.99014586, 0.56061876, 0.98013973]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/base.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.72028214, 0.14200944, 0.921588  ],
          [0.07678509, 0.41455352, 0.8573685 ],
          [0.21842337,...2 ],
          [0.53994805, 0.3134091 , 0.41882402],
          [0.99014586, 0.56061876, 0.98013973]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from ....ivy.functional.backends.jax.general import jax_get_item
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not jax_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif jax_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/base.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation3D(degrees=(15.0, 20.0, 20.0), p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=False)
input = Array([[[[[0.72028214, 0.14200944, 0.921588  ],
          [0.07678509, 0.41455352, 0.8573685 ],
          [0.21842337,...2 ],
          [0.53994805, 0.3134091 , 0.41882402],
          [0.99014586, 0.56061876, 0.98013973]]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'forward_input_shape': Array([1, 1, 3, 3, 3], dtype=int64), 'pitch': Array([-8.851233], dtype=float32), 'roll': Array([7.4675026], dtype=float32), ...}
flags = {'align_corners': False, 'resample': <jax_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....geometry.transform.affwarp import jax__compute_tensor_center3d
        from ....geometry.transform.affwarp import jax__compute_rotation_matrix3d
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....utils.misc import jax_eye_like
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        yaw: typing.Any = jax_to_frnt_(params["yaw"], input)
        pitch: typing.Any = jax_to_frnt_(params["pitch"], input)
        roll: typing.Any = jax_to_frnt_(params["roll"], input)
        center: typing.Any = jax__compute_tensor_center3d(input)
        rotation_mat: typing.Any = jax__compute_rotation_matrix3d(
>           yaw, pitch, roll, center.expand(jax_shape_frnt_(yaw)[0], -1)
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_3d/geometric/rotation.py:66: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation4.py::test_RandomMosaic[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation4.py::test_RandomRotation3D[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'
============================================================================== 2 failed, 15 passed in 3360.60s (0:56:00) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F.............F..........                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_equalize_clahe[jax-s2s-False] __________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4094: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f35e0cfd480>
trace_args = (tensor([[[0.1690, 0.2184, 0.4825, 0.0973, 0.0169, 0.2129, 0.9721, 0.8753,
          0.6406, 0.7609, 0.2677, 0.8286, 0...         0.3482, 0.2980, 0.0443, 0.9849, 0.3226, 0.6020, 0.8551, 0.5363,
          0.0586, 0.5137, 0.6624, 0.3071]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.2705, 0.0699, 0.1708,  ..., 0.5926, 0.3105, 0.6203],
          [0.8898, 0.7225, 0.0438,  ..., 0.8076, 0...., 0.8763, 0.4528,  ..., 0.1252, 0.2420, 0.9286],
          [0.5139, 0.7284, 0.3908,  ..., 0.0221, 0.7124, 0.1314]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f35e0cfd480>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.1690, 0.2184, 0.4825, 0.0973, 0.0169, 0.2129, 0.9721, 0.8753,
          0.6406, 0.7609, 0.2677, 0.8286, 0...         0.3482, 0.2980, 0.0443, 0.9849, 0.3226, 0.6020, 0.8551, 0.5363,
          0.0586, 0.5137, 0.6624, 0.3071]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.2705, 0.0699, 0.1708,  ..., 0.5926, 0.3105, 0.6203],
          [0.8898, 0.7225, 0.0438,  ..., 0.8076, 0...., 0.8763, 0.4528,  ..., 0.1252, 0.2420, 0.9286],
          [0.5139, 0.7284, 0.3908,  ..., 0.0221, 0.7124, 0.1314]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.16898763, 0.21838194, 0.4825254 , 0.0972684 , 0.01690245,
          0.21294135, 0.9720932 , 0.8753158 , 0...., 0.60196507, 0.85508287,
          0.5362852 , 0.05862182, 0.5137021 , 0.66235036, 0.30712974]]]],      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7f3555fecd30>
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7f3589c52200>, jax_view_frnt_ = <function jax_view_frnt_ at 0x7f3560b58160>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[0.16898763, 0.21838194, 0.4825254 , 0.0972684 , 0.01690245,
          0.21294135, 0.9720932 , 0.8753158 , 0...., 0.60196507, 0.85508287,
          0.5362852 , 0.05862182, 0.5137021 , 0.66235036, 0.30712974]]]],      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[0.16898763, 0.21838194, 0.4825254 , 0.0972684 , 0.01690245,
          0.21294135, 0.9720932 , 0.8753158 , 0...., 0.60196507, 0.85508287,
          0.5362852 , 0.05862182, 0.5137021 , 0.66235036, 0.30712974]]]],      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
                jax_unfold_frnt_(
>                   jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[0.16898763, 0.21003973, 0.3251829 , 0.9283028 , 0.4208706 ,
           0.6963213 , 0.41293573, 0.16266209,...       0.70456517, 0.5039861 , 0.8273665 , 0.2773676 , 0.5728634 ,
           0.6051273 ]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f3542448e50>
array_like = Array([[[[[0.16898763, 0.21003973, 0.3251829 , 0.9283028 , 0.4208706 ,
           0.6963213 , 0.41293573, 0.16266209, ...9804,
           0.70456517, 0.5039861 , 0.8273665 , 0.2773676 , 0.5728634 ,
           0.6051273 ]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[0.16898763, 0.21003973, 0.3251829 , 0.9283028 , 0.4208706 ,
           0.6963213 , 0.41293573, 0.16266209, ...9804,
           0.70456517, 0.5039861 , 0.8273665 , 0.2773676 , 0.5728634 ,
           0.6051273 ]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:127: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_ZCAWhitening[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ZCAWhitening(target_framework, mode, backend_compile):
        print("kornia.enhance.ZCAWhitening")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledZCAWhitening = ivy.transpile(kornia.enhance.ZCAWhitening, source="torch", target=target_framework)
    
        x = torch.tensor([[0,1],[1,0],[-1,0],[0,-1]], dtype = torch.float32)
        zca = kornia.enhance.ZCAWhitening().fit(x)
        torch_out = zca(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_zca = TranspiledZCAWhitening().fit(transpiled_x)
>       transpiled_out = transpiled_zca(x)

kornia/test_enhance.py:697: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ZCAWhitening(), x = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), include_fit = False

    def __call__(self, x, include_fit=False):
        if include_fit:
            self.fit(x)
        if not self.fitted:
            raise RuntimeError(
                "Needs to be fitted first before running. Please call fit or set include_fit to True."
            )
>       x_whiten = jax_linear_transform(
            x, self.transform_matrix, self.mean_vector, self.dim
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = tensor([[ 0.,  1.],
        [ 1.,  0.],
        [-1.,  0.],
        [ 0., -1.]]), transform_matrix = Array([[1.224744, 0.      ],
       [0.      , 1.224744]], dtype=float32)
mean_vector = Array([[0., 0.]], dtype=float32), dim = 0

    def jax_linear_transform(inp, transform_matrix, mean_vector, dim=0):
        from ...ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_arange_frnt
        from ...ivy.functional.frontends.torch.comparison_ops import jax_argsort_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_tolist_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_item_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import jax_prod_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_mm_frnt_
        from ..core._backend import concatenate
        from ..core._backend import tensor
    
        inp_size = jax_size_frnt_(inp)
        if dim >= len(inp_size) or dim < -len(inp_size):
            raise IndexError(
                f"Dimension out of range (expected to be in range of [{-len(inp_size)},{len(inp_size) - 1}], but got {dim}"
            )
        if dim < 0:
            dim = len(inp_size) + dim
        feat_dims = concatenate(
            [jax_arange_frnt(0, dim), jax_arange_frnt(dim + 1, len(inp_size))]
        )
        perm = concatenate([tensor([dim]), feat_dims])
        perm_inv = jax_argsort_frnt(perm)
        new_order: typing.Any = jax_tolist_frnt_(perm)
        inv_order: typing.Any = jax_tolist_frnt_(perm_inv)
        feature_sizes = tensor(
            jax_get_item(inp_size, slice(0, dim, None))
            + jax_get_item(inp_size, slice(dim + 1, None, None))
        )
        num_features: typing.Any = int(jax_item_frnt_(jax_prod_frnt(feature_sizes)))
        inp_permute = jax_permute_frnt_(inp, new_order)
        inp_flat = jax_reshape_frnt_(inp_permute, (-1, num_features))
>       inp_center = inp_flat - mean_vector
E       TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'

ivy_transpiled_outputs/jax_outputs/kornia/enhance/zca.py:318: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.ZCAWhitening
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[jax-s2s-False] - Exception: Need at least one array to stack.
FAILED kornia/test_enhance.py::test_ZCAWhitening[jax-s2s-False] - TypeError: unsupported operand type(s) for -: 'Tensor' and 'jaxlib.xla_extension.ArrayImpl'
============================================================================== 2 failed, 37 passed in 2625.03s (0:43:45) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py F......F.......FF.........                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_find_essential[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_essential(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 8, 2),
            torch.rand(1, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 8)}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8)}
>       _test_function(
            kornia.geometry.epipolar.find_essential,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_epipolar.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7f8f743600d0>
trace_args = (tensor([[[2.0978e-01, 1.0505e-01],
         [8.2468e-01, 3.8590e-01],
         [1.8807e-01, 6.2367e-02],
         [7....0.1499],
         [0.6988, 0.2865],
         [0.3918, 0.0460],
         [0.9028, 0.0147],
         [0.9632, 0.7280]]]))
trace_kwargs = {'weights': tensor([[0.1124, 0.8117, 0.3460, 0.6873, 0.5661, 0.1300, 0.0797, 0.6085]])}
test_args = (tensor([[[0.4743, 0.3233],
         [0.0414, 0.9578],
         [0.8825, 0.5055],
         [0.8846, 0.9362],
         ....0204e-01],
         [2.5959e-01, 7.4082e-01],
         [8.5014e-01, 4.1853e-01],
         [7.8020e-01, 7.5801e-01]]]))
test_kwargs = {'weights': tensor([[0.3138, 0.9961, 0.7007, 0.4675, 0.8317, 0.1379, 0.7889, 0.0449],
        [0.9686, 0.8201, 0.6611,...5, 0.3907, 0.6898, 0.7567, 0.9608, 0.8932],
        [0.7402, 0.5908, 0.1454, 0.5097, 0.0956, 0.5795, 0.6950, 0.4037]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_essential at 0x7f8f743600d0>, fn_name = 'kornia.geometry.epipolar.find_essential'
trace_args = (tensor([[[2.0978e-01, 1.0505e-01],
         [8.2468e-01, 3.8590e-01],
         [1.8807e-01, 6.2367e-02],
         [7....0.1499],
         [0.6988, 0.2865],
         [0.3918, 0.0460],
         [0.9028, 0.0147],
         [0.9632, 0.7280]]]))
trace_kwargs = {'weights': tensor([[0.1124, 0.8117, 0.3460, 0.6873, 0.5661, 0.1300, 0.0797, 0.6085]])}
test_args = (tensor([[[0.4743, 0.3233],
         [0.0414, 0.9578],
         [0.8825, 0.5055],
         [0.8846, 0.9362],
         ....0204e-01],
         [2.5959e-01, 7.4082e-01],
         [8.5014e-01, 4.1853e-01],
         [7.8020e-01, 7.5801e-01]]]))
test_kwargs = {'weights': tensor([[0.3138, 0.9961, 0.7007, 0.4675, 0.8317, 0.1379, 0.7889, 0.0449],
        [0.9686, 0.8201, 0.6611,...5, 0.3907, 0.6898, 0.7567, 0.9608, 0.8932],
        [0.7402, 0.5908, 0.1454, 0.5097, 0.0956, 0.5795, 0.6950, 0.4037]])}
target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[2.09784567e-01, 1.05053306e-01],
        [8.24683785e-01, 3.85902941e-01],
        [1.88073754e-01, 6.2367260..., 7.34888911e-01],
        [9.39769685e-01, 9.31525290e-01],
        [9.52706873e-01, 5.26037276e-01]]], dtype=float32)
points2 = array([[[0.30121285, 0.5481485 ],
        [0.4004107 , 0.07518554],
        [0.74338037, 0.70290565],
        [0.85229...
        [0.39182347, 0.04597229],
        [0.9028129 , 0.0146842 ],
        [0.9631895 , 0.72796744]]], dtype=float32)
weights = array([[0.11236024, 0.811735  , 0.3459962 , 0.68731904, 0.5661142 ,
        0.13000321, 0.07966191, 0.6085225 ]], dtype=float32)

    def numpy_find_essential(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_to_frnt_
    
>       E = numpy_to_frnt_(numpy_run_5point(points1, points2, weights), points1.dtype)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:455: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[2.09784567e-01, 1.05053306e-01],
        [8.24683785e-01, 3.85902941e-01],
        [1.88073754e-01, 6.2367260..., 7.34888911e-01],
        [9.39769685e-01, 9.31525290e-01],
        [9.52706873e-01, 5.26037276e-01]]], dtype=float32)
points2 = array([[[0.30121285, 0.5481485 ],
        [0.4004107 , 0.07518554],
        [0.74338037, 0.70290565],
        [0.85229...
        [0.39182347, 0.04597229],
        [0.9028129 , 0.0146842 ],
        [0.9631895 , 0.72796744]]], dtype=float32)
weights = array([[0.11236024, 0.811735  , 0.3459962 , 0.68731904, 0.5661142 ,
        0.13000321, 0.07966191, 0.6085225 ]], dtype=float32)

    def numpy_run_5point(points1, points2, weights=None):
        from ...core.check import numpy_KORNIA_CHECK_SHAPE
        from ...core.check import numpy_KORNIA_CHECK_SAME_SHAPE
        from ...core.check import numpy_KORNIA_CHECK
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...core._backend import ones_like
    
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SAME_SHAPE(points1, points2)
        numpy_KORNIA_CHECK(
            numpy_shape_frnt_(points1)[1] >= 5, "Number of points should be >=5"
        )
        if weights is not None:
            numpy_KORNIA_CHECK_SAME_SHAPE(points1[:, :, 0], weights)
        batch_size, _, _ = numpy_shape_frnt_(points1)
        x1, y1 = numpy_chunk_frnt(points1, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x1 * x2, x1 * y2, x1, y1 * x2, y1 * y2, y1, x2, y2, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/essential.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.11236024, 0.811735  , 0.3459962 , 0.68731904, 0.5661142 ,
         0.13000321, 0.07966191, 0.6085225 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.essential.find_essential
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:80: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
________________________________________________________________________________ test_find_fundamental[numpy-s2s-False] ________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_fundamental(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 8, 2),
            torch.rand(2, 8, 2),
        )
        trace_kwargs = {'weights': torch.rand(2, 8), 'method': '8POINT'}
        test_args = (
            torch.rand(5, 8, 2),
            torch.rand(5, 8, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 8), 'method': '8POINT'}
>       _test_function(
            kornia.geometry.epipolar.find_fundamental,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=3e-2,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7f8f74360670>
trace_args = (tensor([[[0.3418, 0.1474],
         [0.0414, 0.0669],
         [0.9657, 0.4596],
         [0.9422, 0.5562],
         ...0.6797],
         [0.2590, 0.9221],
         [0.3031, 0.8065],
         [0.5763, 0.3562],
         [0.9594, 0.1912]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.2316, 0.6764, 0.1486, 0.4819, 0.6212, 0.8718, 0.0162, 0.8852],
        [0.5284, 0.5652, 0.5150, 0.2305, 0.5229, 0.8203, 0.8203, 0.6008]])}
test_args = (tensor([[[0.9672, 0.3222],
         [0.8725, 0.3098],
         [0.9810, 0.6164],
         [0.9244, 0.3151],
         ...0.7368],
         [0.4452, 0.2501],
         [0.0950, 0.0288],
         [0.2515, 0.0963],
         [0.1849, 0.1042]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.2398, 0.8312, 0.1577, 0.8024, 0.4099, 0.8229, 0.9069, 0.8729],
        [0.6...5, 0.5355, 0.6924, 0.2167, 0.6142, 0.8651],
        [0.8978, 0.2086, 0.4883, 0.5658, 0.2290, 0.7437, 0.1740, 0.1288]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_fundamental at 0x7f8f74360670>, fn_name = 'kornia.geometry.epipolar.find_fundamental'
trace_args = (tensor([[[0.3418, 0.1474],
         [0.0414, 0.0669],
         [0.9657, 0.4596],
         [0.9422, 0.5562],
         ...0.6797],
         [0.2590, 0.9221],
         [0.3031, 0.8065],
         [0.5763, 0.3562],
         [0.9594, 0.1912]]]))
trace_kwargs = {'method': '8POINT', 'weights': tensor([[0.2316, 0.6764, 0.1486, 0.4819, 0.6212, 0.8718, 0.0162, 0.8852],
        [0.5284, 0.5652, 0.5150, 0.2305, 0.5229, 0.8203, 0.8203, 0.6008]])}
test_args = (tensor([[[0.9672, 0.3222],
         [0.8725, 0.3098],
         [0.9810, 0.6164],
         [0.9244, 0.3151],
         ...0.7368],
         [0.4452, 0.2501],
         [0.0950, 0.0288],
         [0.2515, 0.0963],
         [0.1849, 0.1042]]]))
test_kwargs = {'method': '8POINT', 'weights': tensor([[0.2398, 0.8312, 0.1577, 0.8024, 0.4099, 0.8229, 0.9069, 0.8729],
        [0.6...5, 0.5355, 0.6924, 0.2167, 0.6142, 0.8651],
        [0.8978, 0.2086, 0.4883, 0.5658, 0.2290, 0.7437, 0.1740, 0.1288]])}
target = 'numpy', backend_compile = False, tolerance = 0.03, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.34183925, 0.14741409],
        [0.04143131, 0.06689489],
        [0.96573573, 0.45958686],
        [0.94222...
        [0.5299136 , 0.5495321 ],
        [0.12118793, 0.04198539],
        [0.6749633 , 0.16079903]]], dtype=float32)
points2 = array([[[0.40818703, 0.31251013],
        [0.41918916, 0.5544623 ],
        [0.3930052 , 0.5004052 ],
        [0.19381...
        [0.30309743, 0.80652773],
        [0.5762667 , 0.3562194 ],
        [0.9594017 , 0.19123644]]], dtype=float32)
weights = array([[0.23158127, 0.6764122 , 0.148592  , 0.48193377, 0.62119216,
        0.87182647, 0.01617289, 0.8851818 ],
     ....52841467, 0.56524813, 0.5150243 , 0.23048085, 0.52291256,
        0.82028526, 0.8203175 , 0.600764  ]], dtype=float32)
method = '8POINT'

    def numpy_find_fundamental(points1, points2, weights=None, method="8POINT"):
        if method.upper() == "7POINT":
            result = numpy_run_7point(points1, points2)
        elif method.upper() == "8POINT":
>           result = numpy_run_8point(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.34183925, 0.14741409],
        [0.04143131, 0.06689489],
        [0.96573573, 0.45958686],
        [0.94222...
        [0.5299136 , 0.5495321 ],
        [0.12118793, 0.04198539],
        [0.6749633 , 0.16079903]]], dtype=float32)
points2 = array([[[0.40818703, 0.31251013],
        [0.41918916, 0.5544623 ],
        [0.3930052 , 0.5004052 ],
        [0.19381...
        [0.30309743, 0.80652773],
        [0.5762667 , 0.3562194 ],
        [0.9594017 , 0.19123644]]], dtype=float32)
weights = array([[0.23158127, 0.6764122 , 0.148592  , 0.48193377, 0.62119216,
        0.87182647, 0.01617289, 0.8851818 ],
     ....52841467, 0.56524813, 0.5150243 , 0.23048085, 0.52291256,
        0.82028526, 0.8203175 , 0.600764  ]], dtype=float32)

    def numpy_run_8point(points1, points2, weights=None):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...utils.helpers import numpy__torch_svd_cast
        from ....ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ....ivy.functional.frontends.torch.creation_ops import numpy_tensor_frnt
        from ...core._backend import ones_like
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1), numpy_shape_frnt_(points2))
        if numpy_shape_frnt_(points1)[1] < 8:
            raise AssertionError(numpy_shape_frnt_(points1))
        if weights is not None:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights)[1] == numpy_shape_frnt_(points1)[1]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones = ones_like(x1)
        X = numpy_cat_frnt(
            [x2 * x1, x2 * y1, x2, y2 * x1, y2 * y1, y2, x1, y1, ones], dim=-1
        )
        if weights is None:
            X = numpy_transpose_frnt_(X, -2, -1) @ X
        else:
>           w_diag = numpy_diag_embed_frnt(weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/fundamental.py:242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.23158127, 0.6764122 , 0.148592  , 0.48193377, 0.62119216,
         0.87182647, 0.01617289, 0.8851818 ]],

 ...2841467, 0.56524813, 0.5150243 , 0.23048085, 0.52291256,
         0.82028526, 0.8203175 , 0.600764  ]]], dtype=float32)
offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar.fundamental.find_fundamental
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  cond = numpy_reshape_frnt_(cond, cond_shape)
___________________________________________________________________________ test_sampson_epipolar_distance[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_sampson_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.sampson_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:400: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7f8f74342440>
trace_args = (tensor([[[0.0628, 0.7126],
         [0.0340, 0.2385],
         [0.1742, 0.8298],
         [0.3078, 0.9902]]]), tensor...0.8136]]]), tensor([[[0.3347, 0.9969, 0.1345],
         [0.8670, 0.3302, 0.9702],
         [0.4257, 0.6714, 0.0944]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.2892, 0.4150],
         [0.0339, 0.7693],
         [0.9973, 0.2889],
         [0.2051, 0.3448]],

       ... 0.6312]],

        [[0.0872, 0.5727, 0.6162],
         [0.2542, 0.1673, 0.7373],
         [0.3552, 0.1766, 0.8108]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function sampson_epipolar_distance at 0x7f8f74342440>, fn_name = 'kornia.geometry.epipolar.sampson_epipolar_distance'
trace_args = (tensor([[[0.0628, 0.7126],
         [0.0340, 0.2385],
         [0.1742, 0.8298],
         [0.3078, 0.9902]]]), tensor...0.8136]]]), tensor([[[0.3347, 0.9969, 0.1345],
         [0.8670, 0.3302, 0.9702],
         [0.4257, 0.6714, 0.0944]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.2892, 0.4150],
         [0.0339, 0.7693],
         [0.9973, 0.2889],
         [0.2051, 0.3448]],

       ... 0.6312]],

        [[0.0872, 0.5727, 0.6162],
         [0.2542, 0.1673, 0.7373],
         [0.3552, 0.1766, 0.8108]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.06281704, 0.712571  , 1.        ],
        [0.03402454, 0.23847574, 1.        ],
        [0.17421675, 0.82983696, 1.        ],
        [0.30782676, 0.9901778 , 1.        ]]], dtype=float32)
pts2 = array([[[0.18421656, 0.5486523 , 1.        ],
        [0.592728  , 0.18432838, 1.        ],
        [0.5154281 , 0.15875888, 1.        ],
        [0.87363905, 0.8136186 , 1.        ]]], dtype=float32)
Fm = array([[[0.33467132, 0.9969493 , 0.13448942],
        [0.86697924, 0.33016866, 0.97015905],
        [0.42567486, 0.6714499 , 0.09441972]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_sampson_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[1.4503708, 0.6951915, 1.47306  , 3.2326963]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f8f153623b0>
array_like = array([[1.4503708, 0.6951915, 1.47306  , 3.2326963]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[1.4503708, 0.6951915, 1.47306  , 3.2326963]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[1.4503708, 0.6951915, 1.47306  , 3.2326963]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f8f153623b0>
array_like = array([[1.4503708, 0.6951915, 1.47306  , 3.2326963]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[1.4503708, 0.6951915, 1.47306  , 3.2326963]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[1.4503708, 0.6951915, 1.47306  , 3.2326963]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.sampson_epipolar_distance
_________________________________________________________________________ test_symmetrical_epipolar_distance[numpy-s2s-False] __________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetrical_epipolar_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-8}
>       _test_function(
            kornia.geometry.epipolar.symmetrical_epipolar_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_epipolar.py:426: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7f8f74342560>
trace_args = (tensor([[[0.9088, 0.6870],
         [0.6199, 0.8587],
         [0.9495, 0.9078],
         [0.0659, 0.8013]]]), tensor...0.0096]]]), tensor([[[0.4498, 0.0297, 0.8146],
         [0.3641, 0.4390, 0.8367],
         [0.5226, 0.1122, 0.8468]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[4.4981e-01, 6.4530e-01],
         [2.9518e-01, 8.3542e-01],
         [5.0625e-01, 5.7191e-01],
         [5.... 0.3742]],

        [[0.8487, 0.9942, 0.8304],
         [0.9449, 0.4566, 0.3135],
         [0.9605, 0.7582, 0.1217]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetrical_epipolar_distance at 0x7f8f74342560>, fn_name = 'kornia.geometry.epipolar.symmetrical_epipolar_distance'
trace_args = (tensor([[[0.9088, 0.6870],
         [0.6199, 0.8587],
         [0.9495, 0.9078],
         [0.0659, 0.8013]]]), tensor...0.0096]]]), tensor([[[0.4498, 0.0297, 0.8146],
         [0.3641, 0.4390, 0.8367],
         [0.5226, 0.1122, 0.8468]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[4.4981e-01, 6.4530e-01],
         [2.9518e-01, 8.3542e-01],
         [5.0625e-01, 5.7191e-01],
         [5.... 0.3742]],

        [[0.8487, 0.9942, 0.8304],
         [0.9449, 0.4566, 0.3135],
         [0.9605, 0.7582, 0.1217]]]))
test_kwargs = {'eps': 1e-08, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.9088451 , 0.68703663, 1.        ],
        [0.61994654, 0.8587143 , 1.        ],
        [0.949527  , 0.90780884, 1.        ],
        [0.06588471, 0.80130786, 1.        ]]], dtype=float32)
pts2 = array([[[0.03914195, 0.1554445 , 1.        ],
        [0.22339249, 0.38957834, 1.        ],
        [0.7940954 , 0.45939183, 1.        ],
        [0.34931612, 0.00957191, 1.        ]]], dtype=float32)
Fm = array([[[0.44981372, 0.02971363, 0.8145744 ],
        [0.36412358, 0.43896455, 0.83667254],
        [0.5225956 , 0.11221635, 0.8467502 ]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetrical_epipolar_distance(pts1, pts2, Fm, squared=True, eps=1e-08):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..conversions import numpy_convert_points_to_homogeneous
        from ....ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_norm_frnt_
        from ....ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        if not isinstance(Fm, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Fm type is not a torch.Tensor. Got {type(Fm)}")
        if len(numpy_shape_frnt_(Fm)) < 3 or not numpy_shape_frnt_(Fm)[-2:] == (3, 3):
            raise ValueError(f"Fm must be a (*, 3, 3) tensor. Got {numpy_shape_frnt_(Fm)}")
        if numpy_shape_frnt_(pts1)[-1] == 2:
            pts1 = numpy_convert_points_to_homogeneous(pts1)
        if numpy_shape_frnt_(pts2)[-1] == 2:
            pts2 = numpy_convert_points_to_homogeneous(pts2)
        F_t: typing.Any = numpy_transpose_frnt_(Fm, dim0=-2, dim1=-1)
        line1_in_2: typing.Any = pts1 @ F_t
        line2_in_1: typing.Any = pts2 @ Fm
>       numerator: typing.Any = numpy_pow_frnt_(
            numpy_sum_frnt_(pts2 * line1_in_2, dim=-1), 2
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/epipolar/_metrics.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[1.6758676, 2.0777998, 3.178535 , 1.2859195]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f8f15307ac0>
array_like = array([[1.6758676, 2.0777998, 3.178535 , 1.2859195]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[1.6758676, 2.0777998, 3.178535 , 1.2859195]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[1.6758676, 2.0777998, 3.178535 , 1.2859195]], dtype=float32), 2), kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f8f15307ac0>
array_like = array([[1.6758676, 2.0777998, 3.178535 , 1.2859195]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[1.6758676, 2.0777998, 3.178535 , 1.2859195]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[1.6758676, 2.0777998, 3.178535 , 1.2859195]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.epipolar._metrics.symmetrical_epipolar_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_epipolar.py::test_find_essential[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_find_fundamental[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_epipolar.py::test_sampson_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_epipolar.py::test_symmetrical_epipolar_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
============================================================================== 4 failed, 22 passed in 1426.62s (0:23:46) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py ..................                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 18 passed in 3660.94s (1:01:00) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py s                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 4.93s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py ..                                                                                                                                                                  [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 2 passed in 76.83s (0:01:16) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py ssssss                                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 4.91s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 463.28s (0:07:43) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py sss                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 3 skipped in 4.97s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_solve_pnp_dlt[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fc0a9a82950>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7fc0a9a82950>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])
img_points = array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
        [ 392.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])
intrinsics = array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]]), weights = None, svd_eps = 0.001

    def numpy_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...utils.helpers import numpy__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_inverse_frnt,
        )
        from ..conversions import numpy_convert_points_to_homogeneous
        from ..linalg import numpy_transform_points
        from ....ivy.functional.backends.numpy.general import numpy_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            numpy_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...utils.misc import numpy_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_bmm_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import numpy_det_frnt
        from ....ivy.functional.frontends.torch.reduction_ops import numpy_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import numpy_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import numpy_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(weights, (numpy.ndarray, numpy.ndarray)):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = np.float32, np.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(numpy_shape_frnt_(world_points)) != 3
            or numpy_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {numpy_shape_frnt_(world_points)}."
            )
        if len(numpy_shape_frnt_(img_points)) != 3 or numpy_shape_frnt_(img_points)[2] != 2:
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {numpy_shape_frnt_(img_points)}."
            )
        if len(numpy_shape_frnt_(intrinsics)) != 3 or numpy_shape_frnt_(intrinsics)[1:] != (
            3,
            3,
        ):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {numpy_shape_frnt_(intrinsics)}."
            )
        if numpy_shape_frnt_(world_points)[1] != numpy_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(img_points)[0]
            or numpy_shape_frnt_(world_points)[0] != numpy_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if numpy_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {numpy_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            numpy_shape_frnt_(world_points)[:2][0],
            numpy_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = numpy__mean_isotropic_scale_normalize(
            world_points
        )
        s = numpy__torch_linalg_svdvals(world_points_norm)
        if numpy_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = numpy_inverse_frnt(intrinsics)
        world_points_norm_h = numpy_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = numpy_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = numpy__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = numpy_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=None)
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = numpy_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = numpy_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = numpy_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = numpy_eye_like(4, solution)
        solution_4x4 = numpy_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = numpy_bmm_frnt(solution_4x4, world_transform_norm)
        solution = numpy_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = numpy_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = numpy_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/calibration/pnp.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': array([[0.0754885 , 0.02388223, 0.0574928 ]]), 'p': 2}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7fc050f22b00>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:193: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[numpy-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 326.91s (0:05:26) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3825.42s (1:03:45) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1667.54s (0:27:47) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 26 items

kornia/geometry/test_epipolar.py ..........................                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 26 passed in 1733.54s (0:28:53) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ..............F........................                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_equalize_clahe[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f3b4b155480>
trace_args = (tensor([[[0.6848, 0.7713, 0.2584, 0.9943, 0.3325, 0.4178, 0.2039, 0.5715,
          0.4306, 0.4697, 0.6028, 0.9802, 0...         0.3039, 0.9625, 0.4490, 0.6451, 0.4951, 0.4125, 0.0689, 0.0309,
          0.5460, 0.9540, 0.9174, 0.4047]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[1.3070e-01, 4.8280e-01, 8.9629e-01,  ..., 4.5905e-01,
           9.6532e-01, 5.7031e-01],
          [2.093... 3.2450e-01],
          [8.6520e-01, 9.0181e-01, 2.2646e-01,  ..., 8.1389e-01,
           2.8695e-01, 3.7285e-01]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True
deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f3b4b155480>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.6848, 0.7713, 0.2584, 0.9943, 0.3325, 0.4178, 0.2039, 0.5715,
          0.4306, 0.4697, 0.6028, 0.9802, 0...         0.3039, 0.9625, 0.4490, 0.6451, 0.4951, 0.4125, 0.0689, 0.0309,
          0.5460, 0.9540, 0.9174, 0.4047]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[1.3070e-01, 4.8280e-01, 8.9629e-01,  ..., 4.5905e-01,
           9.6532e-01, 5.7031e-01],
          [2.093... 3.2450e-01],
          [8.6520e-01, 9.0181e-01, 2.2646e-01,  ..., 8.1389e-01,
           2.8695e-01, 3.7285e-01]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.6848389 , 0.7712579 , 0.2584405 , 0.9942898 , 0.33...0.4125045 , 0.06894207,
          0.03092831, 0.54599196, 0.95399415, 0.91736835, 0.40466785]]]],
      dtype=float32)>
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, tensorflow_numel_frnt_ = <function tensorflow_numel_frnt_ at 0x7f3ae8e16170>
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f3ae8e16950>, tensorflow_view_frnt_ = <function tensorflow_view_frnt_ at 0x7f3ae8e175b0>
input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if tensorflow_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = tensorflow_shape_frnt_(input)
        input = tensorflow__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/utils/image.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.6848389 , 0.7712579 , 0.2584405 , 0.9942898 , 0.33...0.4125045 , 0.06894207,
          0.03092831, 0.54599196, 0.95399415, 0.91736835, 0.40466785]]]],
      dtype=float32)>
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @tensorflow_perform_keep_shape_image
    def tensorflow_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_permute_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = tensorflow__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:518: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = <tf.Tensor: shape=(1, 1, 10, 20), dtype=float32, numpy=
array([[[[0.6848389 , 0.7712579 , 0.2584405 , 0.9942898 , 0.33...0.4125045 , 0.06894207,
          0.03092831, 0.54599196, 0.95399415, 0.91736835, 0.40466785]]]],
      dtype=float32)>
grid_size = (8, 8), even_tile_size = True

    def tensorflow__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            tensorflow_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = tensorflow_shape_frnt_(batch)[-2:][0], tensorflow_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > tensorflow_shape_frnt_(batch)[-2]
            or pad_horz > tensorflow_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = tensorflow_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = tensorflow_shape_frnt_(batch)[-3]
        tiles: typing.Any = tensorflow_contiguous_frnt_(
            tensorflow_squeeze_frnt_(
                tensorflow_unfold_frnt_(
>                   tensorflow_unfold_frnt_(
                        tensorflow_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/equalization.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.6848389 , 0.17572838, 0.9298038 , 0.11930186,...      0.36099178, 0.95923615, 0.79733986, 0.06614918, 0.32034183,
           0.8213828 ]]]]], dtype=float32)>, 2, 2, 2)
kwargs = {}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f3ad4c372e0>
array_like = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.6848389 , 0.17572838, 0.9298038 , 0.11930186, ...896,
           0.36099178, 0.95923615, 0.79733986, 0.06614918, 0.32034183,
           0.8213828 ]]]]], dtype=float32)>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if tensorflow_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 32, 16), dtype=float32, numpy=
array([[[[[0.6848389 , 0.17572838, 0.9298038 , 0.11930186, ...896,
           0.36099178, 0.95923615, 0.79733986, 0.06614918, 0.32034183,
           0.8213828 ]]]]], dtype=float32)>
dimension = 2, size = 2, step = 2

    @tensorflow_handle_methods
    def tensorflow_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.tensorflow.general import tensorflow_get_item
        from ...backends.tensorflow.general import tensorflow_set_item
        from .indexing_slicing_joining_mutating_ops import tensorflow_stack_frnt
    
        slices = []
        self_shape = tuple(tensorflow_shape_frnt_(tensor))
        for i in range(0, tensorflow_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(tensorflow_shape_frnt_(tensor))
            slicing = tensorflow_set_item(slicing, dimension, slice(i, i + size))
            slices.append(tensorflow_get_item(tensor, tuple(slicing)))
>       stacked = tensorflow_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:263: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def tensorflow_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.tensorflow.manipulation import tensorflow_stack
    
>       return tensorflow_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def tensorflow_stack(
        arrays: Union[Tuple[tensorflow.Tensor], List[tensorflow.Tensor]],
        /,
        *,
        axis: int = 0,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        try:
>           return tensorflow.experimental.numpy.stack(arrays, axis)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/manipulation.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2

    @tf_export.tf_export('experimental.numpy.stack', v1=[])
    @np_utils.np_doc('stack')
    def stack(arrays, axis=0):  # pylint: disable=missing-function-docstring
      if isinstance(arrays, (np_arrays.ndarray, tensor_lib.Tensor)):
        arrays = asarray(arrays)
        if axis == 0:
          return arrays
        else:
          return swapaxes(arrays, 0, axis)
      arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access
      unwrapped_arrays = [
          a if isinstance(a, np_arrays.ndarray) else a for a in arrays
      ]
>     return asarray(array_ops_stack.stack(unwrapped_arrays, axis))

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_array_ops.py:1211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ([], 2), kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = [], axis = 2, name = 'stack'

    @tf_export("stack")
    @dispatch.add_dispatch_support
    def stack(values, axis=0, name="stack"):
      """Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.
    
      See also `tf.concat`, `tf.tile`, `tf.repeat`.
    
      Packs the list of tensors in `values` into a tensor with rank one higher than
      each tensor in `values`, by packing them along the `axis` dimension.
      Given a list of length `N` of tensors of shape `(A, B, C)`;
    
      if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
      if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
      Etc.
    
      For example:
    
      >>> x = tf.constant([1, 4])
      >>> y = tf.constant([2, 5])
      >>> z = tf.constant([3, 6])
      >>> tf.stack([x, y, z])
      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=
      array([[1, 4],
             [2, 5],
             [3, 6]], dtype=int32)>
      >>> tf.stack([x, y, z], axis=1)
      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=
      array([[1, 2, 3],
             [4, 5, 6]], dtype=int32)>
    
      This is the opposite of unstack.  The numpy equivalent is `np.stack`
    
      >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))
      True
    
      Args:
        values: A list of `Tensor` objects with the same shape and type.
        axis: An `int`. The axis to stack along. Defaults to the first dimension.
          Negative values wrap around, so the valid range is `[-(R+1), R+1)`.
        name: A name for this operation (optional).
    
      Returns:
        output: A stacked `Tensor` with the same type as `values`.
    
      Raises:
        ValueError: If `axis` is out of the range [-(R+1), R+1).
      """
      if axis == 0:
        try:
          # If the input is a constant list, it can be converted to a constant op
          return ops.convert_to_tensor(values, name=name)
        except (TypeError, ValueError, NotImplementedError):
          pass  # Input list contains non-constant tensors
    
>     value_shape = ops.convert_to_tensor(values[0], name=name)._shape_tuple()  # pylint: disable=protected-access
E     IndexError: list index out of range

/opt/fw/tensorflow/tensorflow/python/ops/array_ops_stack.py:78: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_equalize_clahe[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 1 failed, 38 passed in 2504.98s (0:41:44) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F.........sssssssssssssssssssssssssssssssss.ss                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_rgb_to_hls[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f77295e5ea0>
trace_args = (tensor([[[[0.7514, 0.4235, 0.2270, 0.7661, 0.5804],
          [0.9070, 0.0388, 0.3072, 0.8456, 0.0188],
          [0.... [0.4618, 0.9281, 0.4918, 0.8411, 0.7556],
          [0.7000, 0.2564, 0.4622, 0.1947, 0.4129]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.8758, 0.7798, 0.3011, 0.4221, 0.4631],
          [0.5767, 0.7250, 0.6959, 0.2723, 0.6975],
          [0.... [0.3869, 0.1668, 0.7072, 0.4174, 0.6744],
          [0.5857, 0.8582, 0.7041, 0.6525, 0.6072]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f77295e5ea0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.7514, 0.4235, 0.2270, 0.7661, 0.5804],
          [0.9070, 0.0388, 0.3072, 0.8456, 0.0188],
          [0.... [0.4618, 0.9281, 0.4918, 0.8411, 0.7556],
          [0.7000, 0.2564, 0.4622, 0.1947, 0.4129]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.8758, 0.7798, 0.3011, 0.4221, 0.4631],
          [0.5767, 0.7250, 0.6959, 0.2723, 0.6975],
          [0.... [0.3869, 0.1668, 0.7072, 0.4174, 0.6744],
          [0.5857, 0.8582, 0.7041, 0.6525, 0.6072]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = array([[[[0.75142086, 0.42348337, 0.22702873, 0.7661307 , 0.5804118 ],
         [0.9069635 , 0.0387761 , 0.3072099 , 0...0.84114164, 0.7555834 ],
         [0.6999712 , 0.25635839, 0.46224904, 0.194691  , 0.4128831 ]]]],
      dtype=float32)
eps = 1e-08

    def numpy_rgb_to_hls(image, eps=1e-08):
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.pointwise_ops import sub
        from ..core._backend import where
        from ..core._backend import stack
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_requires_grad_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_like_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_add_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_mul_frnt
    
        if not isinstance(image, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(image)}")
        if len(numpy_shape_frnt_(image)) < 3 or numpy_shape_frnt_(image)[-3] != 3:
            raise ValueError(
                f"Input size must have a shape of (*, 3, H, W). Got {numpy_shape_frnt_(image)}"
            )
        _RGB2HSL_IDX = tensor([[[0.0]], [[1.0]], [[2.0]]], device=None, dtype=image.dtype)
        _img_max: typing.Any = numpy_max_frnt_(image, -3)
        maxc = _img_max[0]
        imax = _img_max[1]
        minc: typing.Any = numpy_min_frnt_(image, -3)[0]
        if numpy_requires_grad_frnt_(image):
            l_ = maxc + minc
            s = maxc - minc
            h = l_
            image_hls = l_
        else:
            image_hls = numpy_empty_like_frnt(image)
            h, l_, s = (
                image_hls[..., 0, :, :],
                image_hls[..., 1, :, :],
                image_hls[..., 2, :, :],
            )
            numpy_add_frnt(maxc, minc, out=l_)
            sub(maxc, minc, out=s)
        im = image / numpy_unsqueeze_frnt_(s + eps, -3)
        s = s / (where(l_ < 1.0, l_, 2.0 - l_) + eps)
        l_ = l_ / 2
        r, g, b = im[..., 0, :, :], im[..., 1, :, :], im[..., 2, :, :]
        cond = imax[..., None, :, :] == _RGB2HSL_IDX
        if numpy_requires_grad_frnt_(image):
            h = (g - b) % 6 * cond[..., 0, :, :]
        else:
>           numpy_mul_frnt((g - b) % 6, cond[..., 0, :, :], out=h)

ivy_transpiled_outputs/numpy_outputs/kornia/color/hls.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.7340872 , 5.        , 5.3111067 , 1.        , 5.9768295 ],
        [5.5982385 , 0.92838615, 1.        , 0.4..., 0.02505994, 5.038392  ],
        [5.        , 0.99999994, 5.738415  , 5.9333835 , 5.567439  ]]],
      dtype=float32)
other = array([[[ True, False,  True, False, False],
        [ True, False, False,  True, False],
        [ True, False,  True, False, False],
        [False, False, False, False, False]]])

    def numpy_mul_frnt(input, other, *, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.elementwise import numpy_multiply
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[0.7340872 , 5.        , 5.3111067 , 1.        , 5.9768295 ],
        [5.5982385 , 0.92838615, 1.        , 0.4..., 0.02505994, 5.038392  ],
        [5.        , 0.99999994, 5.738415  , 5.9333835 , 5.567439  ]]],
      dtype=float32)
x2 = array([[[ True, False,  True, False, False],
        [ True, False, False,  True, False],
        [ True, False,  True, False, False],
        [False, False, False, False, False]]])

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('bool')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_________________________________________________________________________________ test_rgb_to_yuv420[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f77295e7be0>
trace_args = (tensor([[[[0.8701, 0.3721, 0.5861, 0.8087, 0.7313, 0.4309],
          [0.1701, 0.4689, 0.8075, 0.3351, 0.1197, 0.2978...     [0.6510, 0.5683, 0.4568, 0.2232, 0.0040, 0.6762],
          [0.9803, 0.1544, 0.6298, 0.5267, 0.8220, 0.1353]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.5873, 0.4792, 0.4207, 0.4969, 0.1591, 0.1119],
          [0.3903, 0.4047, 0.1600, 0.1769, 0.9181, 0.9599...     [0.5924, 0.8921, 0.0749, 0.6765, 0.5490, 0.4853],
          [0.7683, 0.3988, 0.8934, 0.7415, 0.2536, 0.2837]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f77295e7be0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.8701, 0.3721, 0.5861, 0.8087, 0.7313, 0.4309],
          [0.1701, 0.4689, 0.8075, 0.3351, 0.1197, 0.2978...     [0.6510, 0.5683, 0.4568, 0.2232, 0.0040, 0.6762],
          [0.9803, 0.1544, 0.6298, 0.5267, 0.8220, 0.1353]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.5873, 0.4792, 0.4207, 0.4969, 0.1591, 0.1119],
          [0.3903, 0.4047, 0.1600, 0.1769, 0.9181, 0.9599...     [0.5924, 0.8921, 0.0749, 0.6765, 0.5490, 0.4853],
          [0.7683, 0.3988, 0.8934, 0.7415, 0.2536, 0.2837]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.4044, 0.7271, 0.4927, 0.4003, 0.2948, 0.7479],
          [0.4357, 0.3322, 0.8406, 0.6187, 0.6119, 0.2532...       [ 0.0052, -0.0618, -0.0251]],

         [[-0.0040,  0.0406, -0.0720],
          [-0.1533, -0.0461,  0.1018]]]]))
transpiled_x = (array([[[[0.40443742, 0.7271374 , 0.49272493, 0.40031374, 0.2947769 ,
          0.7479034 ],
         [0.43573925, 0....
        [[ 0.10242422, -0.06118133,  0.06507713],
         [-0.11154149, -0.15300548,  0.02526342]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.40443742, 0.7271374 , 0.49272493, 0.40031374, 0.2947769 ,
          0.7479034 ],
         [0.43573925, 0....
        [[-0.00401948,  0.04058757, -0.07196048],
         [-0.15325722, -0.04611969,  0.10180578]]]], dtype=float32))
y = (array([[[[0.40443742, 0.7271374 , 0.49272493, 0.40031374, 0.2947769 ,
          0.7479034 ],
         [0.43573925, 0....
        [[ 0.10242422, -0.06118133,  0.06507713],
         [-0.11154149, -0.15300548,  0.02526342]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f76d34ee040>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.05188894, -0.09742007, -0.01817856],
         [ 0.00517581, -0.06184917, -0.02509166]],

        [[-0.00401948,  0.04058757, -0.07196048],
         [-0.15325722, -0.04611969,  0.10180578]]]], dtype=float32)
y = array([[[[-0.0586349 ,  0.0297734 , -0.10592545],
         [-0.00755259, -0.04193595,  0.03880076]],

        [[ 0.10242422, -0.06118133,  0.06507713],
         [-0.11154149, -0.15300548,  0.02526342]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_color.py::test_rgb_to_yuv420[numpy-s2s-False] - AssertionError: numpy array values are not all close
======================================================================== 2 failed, 32 passed, 35 skipped in 1618.93s (0:26:58) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py .                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 280.90s (0:04:40) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 14 items

kornia/test_feature4.py ssssssssssssss                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 14 skipped in 5.05s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/test_nerf.py ssssss                                                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 6 skipped in 5.18s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 268.37s (0:04:28) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 769.71s (0:12:49) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ....                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 4 passed in 86.23s (0:01:26) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_line.py ..                                                                                                                                                                  [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 2 passed in 75.69s (0:01:15) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ..F.                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________________ test_So2[jax-s2s-False] ________________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_So2(target_framework, mode, backend_compile):
        print("kornia.geometry.liegroup.So2")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        real_part = torch.tensor([1.0], requires_grad=True)
        imaginary_part = torch.tensor([2.0], requires_grad=True)
        complex_number = torch.complex(real_part, imaginary_part)
        torch_so2 = kornia.geometry.liegroup.So2(complex_number)
    
        TranspiledSo2 = ivy.transpile(kornia.geometry.liegroup.So2, source="torch", target=target_framework)
        transpiled_complex_number = _nest_torch_tensor_to_new_framework(complex_number, target_framework)
        transpiled_so2 = TranspiledSo2(transpiled_complex_number)
    
        # Test .matrix()
        torch_matrix = torch_so2.matrix()
        transpiled_matrix = transpiled_so2.matrix()
        _to_numpy_and_allclose(torch_matrix, transpiled_matrix)
    
        # Test .inverse()
        torch_inverse = torch_so2.inverse()
        transpiled_inverse = transpiled_so2.inverse()
        _to_numpy_and_allclose(torch_inverse.z, transpiled_inverse.z)
    
        # Test .log()
        torch_log = torch_so2.log()
        transpiled_log = transpiled_so2.log()
        _to_numpy_and_allclose(torch_log, transpiled_log)
    
        # Test .__mul__()
        other_real_part = torch.tensor([0.5], requires_grad=True)
        other_imaginary_part = torch.tensor([0.5], requires_grad=True)
        other_complex_number = torch.complex(other_real_part, other_imaginary_part)
        other_torch_so2 = kornia.geometry.liegroup.So2(other_complex_number)
    
        transpiled_other_complex_number = _nest_torch_tensor_to_new_framework(other_complex_number, target_framework)
        transpiled_other_so2 = TranspiledSo2(transpiled_other_complex_number)
    
        torch_composed_so2 = torch_so2 * other_torch_so2
        transpiled_composed_so2 = transpiled_so2 * transpiled_other_so2
        _to_numpy_and_allclose(torch_composed_so2.z, transpiled_composed_so2.z)
    
        # Test .adjoint()
        torch_adjoint = torch_so2.adjoint()
>       transpiled_adjoint = transpiled_so2.adjoint()

kornia/geometry/test_liegroup.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=Array([1.+2.j], dtype=complex64)
)

    def adjoint(self):
        from ....ivy.functional.frontends.torch.tensor import jax_real_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
    
>       batch_size = len(self.z) if len(jax_shape_frnt_(self.z)) > 0 else None
E       TypeError: object of type 'Param' has no len()

ivy_transpiled_outputs/jax_outputs/kornia/geometry/liegroup/so2.py:186: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.liegroup.So2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_liegroup.py::test_So2[jax-s2s-False] - TypeError: object of type 'Param' has no len()
=============================================================================== 1 failed, 3 passed in 414.67s (0:06:54) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 295.03s (0:04:55) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 266.89s (0:04:26) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

transformers/test_vision.py .                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 313.77s (0:05:13) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_solvers.py .....                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 passed in 281.56s (0:04:41) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py ssssssssssssssssss                                                                                                                                     [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 18 skipped in 5.43s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 125.16s (0:02:05) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py ..F.........F..                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_conv_quad_interp3d[jax-s2s-False] ________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f7553b84ca0>
trace_args = (tensor([[[[[0.2872, 0.2472, 0.0779, 0.2227, 0.3582],
           [0.6514, 0.9490, 0.5210, 0.9381, 0.7907],
           ....4501],
           [0.4509, 0.8221, 0.3858, 0.9011, 0.8711],
           [0.8987, 0.7845, 0.0638, 0.7832, 0.7872]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.5707, 0.0441, 0.5976, 0.3181, 0.7352],
           [0.6538, 0.7111, 0.9427, 0.8958, 0.5020],
           ....0222],
           [0.3128, 0.8783, 0.5276, 0.2238, 0.5391],
           [0.4117, 0.3036, 0.2396, 0.9307, 0.8648]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f7553b84ca0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[0.2872, 0.2472, 0.0779, 0.2227, 0.3582],
           [0.6514, 0.9490, 0.5210, 0.9381, 0.7907],
           ....4501],
           [0.4509, 0.8221, 0.3858, 0.9011, 0.8711],
           [0.8987, 0.7845, 0.0638, 0.7832, 0.7872]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.5707, 0.0441, 0.5976, 0.3181, 0.7352],
           [0.6538, 0.7111, 0.9427, 0.8958, 0.5020],
           ....0222],
           [0.3128, 0.8783, 0.5276, 0.2238, 0.5391],
           [0.4117, 0.3036, 0.2396, 0.9307, 0.8648]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[0.28719914, 0.24723566, 0.07794166, 0.22270477, 0.35818738],
          [0.6514048 , 0.9490464 , 0.5210154 ,....9011015 , 0.87108123],
          [0.8986632 , 0.78453094, 0.0638088 , 0.78319174, 0.7871852 ]]]]],      dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([], shape=(0, 3, 1), dtype=float32), A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([], shape=(0, 3, 3), dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([], shape=(0, 3, 3), dtype=float32)], kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f74bac64a60>
jax_set_item = <function jax_set_item at 0x7f74bac67e20>, jax_asarray = <function jax_asarray at 0x7f74bac65900>, jax_get_item = <function jax_get_item at 0x7f74bac67c70>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([], shape=(0, 3, 3), dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[0,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_________________________________________________________________________________ test_ConvQuadInterp3d[jax-s2s-False] _________________________________________________________________________________
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ConvQuadInterp3d(target_framework, mode, backend_compile):
        print("kornia.geometry.subpix.ConvQuadInterp3d")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledConvQuadInterp3d = ivy.transpile(
            kornia.geometry.subpix.ConvQuadInterp3d, source="torch", target=target_framework
        )
    
        conv_quad_interp3d = kornia.geometry.subpix.ConvQuadInterp3d()
        transpiled_conv_quad_interp3d = TranspiledConvQuadInterp3d()
    
        heatmap = torch.randn(1, 1, 3, 5, 5, requires_grad=True)
        transpiled_heatmap = _nest_torch_tensor_to_new_framework(heatmap, target_framework)
    
        torch_output = conv_quad_interp3d(heatmap)
>       transpiled_output = transpiled_conv_quad_interp3d(transpiled_heatmap)

kornia/geometry/test_subpix.py:371: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvQuadInterp3d(strict_maxima_bonus=10.0)
x = Array([[[[[ 0.5005156 ,  1.7330233 ,  0.05678923, -0.46742156,
           -1.0935519 ],
          [ 0.07581549,  1.856...0.962182  ],
          [-2.3185747 , -0.6794628 , -1.2264811 , -1.4572546 ,
            1.1447377 ]]]]], dtype=float32)

    def __call__(self, x):
>       return jax_conv_quad_interp3d(x, self.strict_maxima_bonus, self.eps)

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[[ 0.5005156 ,  1.7330233 ,  0.05678923, -0.46742156,
           -1.0935519 ],
          [ 0.07581549,  1.856...0.962182  ],
          [-2.3185747 , -0.6794628 , -1.2264811 , -1.4572546 ,
            1.1447377 ]]]]], dtype=float32)
strict_maxima_bonus = 10.0, eps = 1e-07

    def jax_conv_quad_interp3d(input, strict_maxima_bonus=10.0, eps=1e-07):
        from ...core._backend import stack
        from ...core._backend import rand
        from ...core._backend import zeros_like
        from ...core._backend import where
        from ....ivy.functional.frontends.torch.tensor_functions import jax_is_tensor_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...utils.grid import jax_create_meshgrid3d
        from ....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...filters.sobel import jax_spatial_gradient3d
        from ....ivy.functional.frontends.torch.tensor import jax_reshape_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_view_frnt_
        from ...utils._compat import jax_torch_version_ge
        from ....ivy.functional.frontends.torch.tensor import jax_abs_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_size_frnt_
        from .nms import jax_nms3d
        from ...utils.helpers import jax_safe_solve_with_mask
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ....ivy.functional.frontends.torch.tensor import jax_masked_scatter_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
        from ....ivy.functional.frontends.torch.tensor import jax_max_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_masked_fill__frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_expand_as_frnt_
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import jax_bmm_frnt
        from ....ivy.functional.frontends.torch.tensor import jax_flip_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_repeat_frnt_
    
        if not jax_is_tensor_frnt_(input):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not len(jax_shape_frnt_(input)) == 5:
            raise ValueError(
                f"Invalid input shape, we expect BxCxDxHxW. Got: {jax_shape_frnt_(input)}"
            )
        B, CH, D, H, W = jax_shape_frnt_(input)
        grid_global: typing.Any = jax_permute_frnt_(
            jax_create_meshgrid3d(D, H, W, False, device=input.device), 0, 4, 1, 2, 3
        )
        grid_global = jax_to_frnt_(grid_global, input.dtype)
        b: typing.Any = jax_spatial_gradient3d(input, order=1, mode="diff")
        b = jax_reshape_frnt_(jax_permute_frnt_(b, 0, 1, 3, 4, 5, 2), -1, 3, 1)
        A: typing.Any = jax_spatial_gradient3d(input, order=2, mode="diff")
        A = jax_reshape_frnt_(jax_permute_frnt_(A, 0, 1, 3, 4, 5, 2), -1, 6)
        dxx = A[..., 0]
        dyy = A[..., 1]
        dss = A[..., 2]
        dxy = 0.25 * A[..., 3]
        dys = 0.25 * A[..., 4]
        dxs = 0.25 * A[..., 5]
        Hes = jax_view_frnt_(
            stack([dxx, dxy, dxs, dxy, dyy, dys, dxs, dys, dss], -1), -1, 3, 3
        )
        if not jax_torch_version_ge(1, 10):
            Hes = (
                Hes
                + jax_abs_frnt_(rand(jax_size_frnt_(Hes[0]), device=Hes.device))[None] * eps
            )
        nms_mask: typing.Any = jax_nms3d(input, (3, 3, 3), True)
        x_solved: typing.Any = zeros_like(b)
>       x_solved_masked, _, solved_correctly = jax_safe_solve_with_mask(
            jax_get_item(b, jax_view_frnt_(nms_mask, -1)),
            jax_get_item(Hes, jax_view_frnt_(nms_mask, -1)),
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/subpix/spatial_soft_argmax.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

B = Array([[[0.72727  ],
        [0.3838268],
        [1.1545522]]], dtype=float32)
A = Array([[[-6.422401  , -0.08038354, -0.8825467 ],
        [-0.08038354, -3.9404984 , -0.01536058],
        [-0.8825467 , -0.01536058, -4.548442  ]]], dtype=float32)

    def jax_safe_solve_with_mask(B, A):
        from ._compat import jax_torch_version_ge
        from ...ivy.functional.frontends.torch.creation_ops import jax_ones_frnt
        from ...ivy.functional.frontends.torch.linalg import jax_lu_factor_ex_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.linalg import jax_lu_solve_frnt
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            jax_lu_solve_frnt_base_count_1_frnt,
        )
        from ...ivy.functional.frontends.torch.linalg import lu
    
        if not jax_torch_version_ge(1, 10):
            sol = jax__torch_solve_cast(A, B)
            warnings.warn(
                "PyTorch version < 1.10, solve validness mask maybe not correct",
                RuntimeWarning,
            )
            return sol, sol, jax_ones_frnt(len(A), dtype=jnp.bool, device=A.device)
        if not isinstance(B, (jax.Array, nnx.Param)):
            raise AssertionError(f"B must be Tensor. Got: {type(B)}.")
        dtype: typing.Any = B.dtype
        if dtype not in (jnp.float32, jnp.float64):
            dtype = jnp.float32
        if TYPE_CHECKING:
            A_LU: typing.Any
            pivots: typing.Any
            info: typing.Any
        elif jax_torch_version_ge(1, 13):
>           A_LU, pivots, info = jax_lu_factor_ex_frnt(jax_to_frnt_(A, dtype))

ivy_transpiled_outputs/jax_outputs/kornia/utils/helpers.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

A = Array([[[-6.422401  , -0.08038354, -0.8825467 ],
        [-0.08038354, -3.9404984 , -0.01536058],
        [-0.8825467 , -0.01536058, -4.548442  ]]], dtype=float32)

    def jax_lu_factor_ex_frnt(A, *, pivot=True, check_errors=False, out=None):
        from ...backends.jax.experimental.linear_algebra import jax_lu_factor
        from ...backends.jax.creation import jax_zeros
        from .tensor import jax_shape_frnt_
        from ...backends.jax.creation import jax_full_like
        from ...backends.jax.creation import jax_ones
    
        try:
>           LU, pivots = jax_lu_factor(A, pivot=pivot, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/linalg.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [Array([[[-6.422401  , -0.08038354, -0.8825467 ],
        [-0.08038354, -3.9404984 , -0.01536058],
        [-0.8825467 , -0.01536058, -4.548442  ]]], dtype=float32)]
kwargs = {'out': None, 'pivot': True}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f74b8829cf0>, jax_set_item = <function jax_set_item at 0x7f74b883d120>
jax_asarray = <function jax_asarray at 0x7f74b882ab90>, jax_get_item = <function jax_get_item at 0x7f74b883cf70>, num_args = 1
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: jax.Array">), ('pivot', <Parameter "pivot: Optional[bool] = True">), ('out', <Parameter "out: Optional[jax.Array] = None">)]))
parameters = ['x', 'pivot', 'out'], annotations = [<class 'jax.Array'>, typing.Optional[bool], typing.Optional[jax.Array]], device = CpuDevice(id=0), i = 0

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import jax_is_array_bknd
        from .functional.backends.jax.general import jax_set_item
        from .functional.backends.jax.creation import jax_asarray
        from .functional.backends.jax.general import jax_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = jax__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or jax__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not jax_is_array_bknd(arg):
                        args = jax_set_item(args, i, jax_asarray(arg, device=device))
                elif parameters in kwargs:
                    kwarg = jax_get_item(kwargs, parameter)
                    if not jax_is_array_bknd(kwarg):
                        kwargs = jax_set_item(
                            kwargs, parameter, jax_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[-6.422401  , -0.08038354, -0.8825467 ],
        [-0.08038354, -3.9404984 , -0.01536058],
        [-0.8825467 , -0.01536058, -4.548442  ]]], dtype=float32)

    @jax_handle_array_like_without_promotion
    def jax_lu_factor(
        x: jax.Array, /, *, pivot: Optional[bool] = True, out: Optional[jax.Array] = None
    ):
>       ret = jax.scipy.linalg.lu(x)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/experimental/linear_algebra.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,3,3])>with<DynamicJaxprTrace(level=1/0)>, permute_l = False

    @partial(jit, static_argnames=('permute_l', 'overwrite_a', 'check_finite'))
    def lu(a: ArrayLike, permute_l: bool = False, overwrite_a: bool = False,
           check_finite: bool = True) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      """Compute the LU decomposition
    
      JAX implementation of :func:`scipy.linalg.lu`.
    
      The LU decomposition of a matrix `A` is:
    
      .. math::
    
         A = P L U
    
      where `P` is a permutation matrix, `L` is lower-triangular and `U` is upper-triangular.
    
      Args:
        a: array of shape ``(..., M, N)`` to decompose.
        permute_l: if True, then permute ``L`` and return ``(P @ L, U)`` (default: False)
        overwrite_a: not used by JAX
        check_finite: not used by JAX
    
      Returns:
        A tuple of arrays ``(P @ L, U)`` if ``permute_l`` is True, else ``(P, L, U)``:
    
        - ``P`` is a permutation matrix of shape ``(..., M, M)``
        - ``L`` is a lower-triangular matrix of shape ``(... M, K)``
        - ``U`` is an upper-triangular matrix of shape ``(..., K, N)``
    
        with ``K = min(M, N)``
    
      See also:
        - :func:`jax.numpy.linalg.lu`: NumPy-style API for LU decomposition.
        - :func:`jax.lax.linalg.lu`: XLA-style API for LU decomposition.
        - :func:`jax.scipy.linalg.lu_solve`: LU-based linear solver.
    
      Examples:
        An LU decomposition of a 3x3 matrix:
    
        >>> a = jnp.array([[1., 2., 3.],
        ...                [5., 4., 2.],
        ...                [3., 2., 1.]])
        >>> P, L, U = jax.scipy.linalg.lu(a)
    
        ``P`` is a permutation matrix: i.e. each row and column has a single ``1``:
    
        >>> P
        Array([[0., 1., 0.],
               [1., 0., 0.],
               [0., 0., 1.]], dtype=float32)
    
        ``L`` and ``U`` are lower-triangular and upper-triangular matrices:
    
        >>> with jnp.printoptions(precision=3):
        ...   print(L)
        ...   print(U)
        [[ 1.     0.     0.   ]
         [ 0.2    1.     0.   ]
         [ 0.6   -0.333  1.   ]]
        [[5.    4.    2.   ]
         [0.    1.2   2.6  ]
         [0.    0.    0.667]]
    
        The original matrix can be reconstructed by multiplying the three together:
    
        >>> a_reconstructed = P @ L @ U
        >>> jnp.allclose(a, a_reconstructed)
        Array(True, dtype=bool)
      """
      del overwrite_a, check_finite  # unused
>     return _lu(a, permute_l)

/opt/fw/jax/jax/_src/scipy/linalg.py:821: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = Traced<ShapedArray(float32[1,3,3])>with<DynamicJaxprTrace(level=2/0)>, permute_l = False

    @partial(jit, static_argnums=(1,))
    def _lu(a: ArrayLike, permute_l: bool) -> tuple[Array, Array] | tuple[Array, Array, Array]:
      a, = promote_dtypes_inexact(jnp.asarray(a))
      lu, _, permutation = lax_linalg.lu(a)
      dtype = lax.dtype(a)
>     m, n = jnp.shape(a)
E     ValueError: too many values to unpack (expected 2)

/opt/fw/jax/jax/_src/scipy/linalg.py:729: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.ConvQuadInterp3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
FAILED kornia/geometry/test_subpix.py::test_ConvQuadInterp3d[jax-s2s-False] - ValueError: too many values to unpack (expected 2)
============================================================================== 2 failed, 13 passed in 1239.08s (0:20:39) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................................ssssssssssssssss                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 40 passed, 16 skipped in 3179.25s (0:52:59) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_get_laf_descriptors[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7fddb1cf39a0>
trace_args = (tensor([[[[0.8084, 0.0997, 0.1881,  ..., 0.9625, 0.2808, 0.7749],
          [0.1513, 0.5342, 0.3603,  ..., 0.3003, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[3.8296e-01, 9.8255e-01, 2.5100e-01,  ..., 2.0719e-01,
           6.7386e-01, 7.8309e-02],
          [9.951..., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7fddb1cf39a0>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.8084, 0.0997, 0.1881,  ..., 0.9625, 0.2808, 0.7749],
          [0.1513, 0.5342, 0.3603,  ..., 0.3003, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[3.8296e-01, 9.8255e-01, 2.5100e-01,  ..., 2.0719e-01,
           6.7386e-01, 7.8309e-02],
          [9.951..., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
>       transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]

helpers.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <enumerate object at 0x7fdd583ea080>

    transpiled_trace_args = [
>       transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
        for i, arg in enumerate(trace_args)
    ]

helpers.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arg = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
arg_class_info = {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}

    def transpile_and_instantiate(arg, arg_class_info=None):
        if arg_class_info:
            # If we have class info, transpile the class and instantiate it
>           transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)

helpers.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.feature.orientation.OriNet'>, source = 'torch', target = 'numpy', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientation.ivy_OriNet'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.feature.orientat...
============================================================================== 1 failed, 18 passed in 1281.67s (0:21:21) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F......F.............F...........F.....F..F..F                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_rgb_to_hls[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f73a76bdea0>
trace_args = (tensor([[[[0.2791, 0.8035, 0.1391, 0.3879, 0.4848],
          [0.5029, 0.7012, 0.9483, 0.3655, 0.9302],
          [0.... [0.3381, 0.1508, 0.0499, 0.0022, 0.3649],
          [0.5090, 0.2900, 0.9266, 0.4537, 0.9070]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[3.2261e-02, 8.5175e-01, 6.9574e-01, 3.0439e-01, 2.2596e-01],
          [9.8759e-01, 4.4278e-01, 2.3073e-01...1, 2.6066e-01],
          [8.1539e-01, 6.6618e-01, 3.2317e-01, 6.6944e-01, 7.8350e-01]]]],
       requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f73a76bdea0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.2791, 0.8035, 0.1391, 0.3879, 0.4848],
          [0.5029, 0.7012, 0.9483, 0.3655, 0.9302],
          [0.... [0.3381, 0.1508, 0.0499, 0.0022, 0.3649],
          [0.5090, 0.2900, 0.9266, 0.4537, 0.9070]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[3.2261e-02, 8.5175e-01, 6.9574e-01, 3.0439e-01, 2.2596e-01],
          [9.8759e-01, 4.4278e-01, 2.3073e-01...1, 2.6066e-01],
          [8.1539e-01, 6.6618e-01, 3.2317e-01, 6.6944e-01, 7.8350e-01]]]],
       requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[3.2427, 5.9867, 0.8904, 1.0258, 4.7223],
          [3.3317, 1.3423, 5.5410, 4.2308, 0.3393],
          [2.1....9745, 0.7416, 0.9728, 0.4471],
          [0.7647, 0.4481, 0.9490, 0.7027, 0.8809]]]],
       grad_fn=<StackBackward0>)
transpiled_x = <tf.Tensor: shape=(1, 3, 4, 5), dtype=float32, numpy=
array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
  ...., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[3.2426975 , 5.9867177 , 0.890447  , 1.0257664 , 4.7222543 ],
         [3.331704  , 1.3422672 , 5.540956  , 4...0.97279984, 0.4471199 ],
         [0.76468664, 0.4481023 , 0.9489832 , 0.70270276, 0.88088506]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
_______________________________________________________________________________ test_rgb_to_yuv420[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f73a76bfbe0>
trace_args = (tensor([[[[0.6206, 0.3147, 0.9766, 0.8421, 0.4072, 0.4874],
          [0.4906, 0.8105, 0.8951, 0.9420, 0.5556, 0.8934...     [0.9724, 0.6898, 0.3879, 0.3709, 0.4601, 0.1877],
          [0.2752, 0.3026, 0.1169, 0.4679, 0.0994, 0.8768]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.3698, 0.3917, 0.2297, 0.2445, 0.0121, 0.4158],
          [0.8012, 0.1062, 0.1972, 0.9865, 0.2287, 0.4810...     [0.9024, 0.9059, 0.7256, 0.5180, 0.3340, 0.2543],
          [0.7913, 0.2305, 0.9097, 0.6245, 0.4945, 0.4345]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f73a76bfbe0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.6206, 0.3147, 0.9766, 0.8421, 0.4072, 0.4874],
          [0.4906, 0.8105, 0.8951, 0.9420, 0.5556, 0.8934...     [0.9724, 0.6898, 0.3879, 0.3709, 0.4601, 0.1877],
          [0.2752, 0.3026, 0.1169, 0.4679, 0.0994, 0.8768]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.3698, 0.3917, 0.2297, 0.2445, 0.0121, 0.4158],
          [0.8012, 0.1062, 0.1972, 0.9865, 0.2287, 0.4810...     [0.9024, 0.9059, 0.7256, 0.5180, 0.3340, 0.2543],
          [0.7913, 0.2305, 0.9097, 0.6245, 0.4945, 0.4345]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.3573, 0.2057, 0.8467, 0.8121, 0.6191, 0.4254],
          [0.5979, 0.2885, 0.7642, 0.5619, 0.3076, 0.5849...       [ 0.0604, -0.0961, -0.0368]],

         [[ 0.1726,  0.1471,  0.0892],
          [-0.1008, -0.0184, -0.0713]]]]))
transpiled_x = (<tf.Tensor: shape=(1, 1, 4, 6), dtype=float32, numpy=
array([[[[0.3572529 , 0.2056647 , 0.8467384 , 0.8120759 , 0.619..., -1.0236658e-02,  3.8876317e-02],
         [-1.1723093e-01,  1.4124557e-01,  6.8518490e-02]]]],
      dtype=float32)>)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.3572529 , 0.2056647 , 0.8467384 , 0.8120759 , 0.6190939 ,
          0.42543325],
         [0.5979128 , 0....
        [[ 0.17261684,  0.14713475,  0.08919774],
         [-0.10084796, -0.01844837, -0.07127508]]]], dtype=float32))
y = (array([[[[0.3572529 , 0.2056647 , 0.8467384 , 0.8120759 , 0.6190939 ,
          0.42543325],
         [0.5979128 , 0....2, -1.0236658e-02,  3.8876317e-02],
         [-1.1723093e-01,  1.4124557e-01,  6.8518490e-02]]]],
      dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f73447652c0>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.01132749, -0.1721054 , -0.04755515],
         [ 0.06040736, -0.09607178, -0.03676225]],

        [[ 0.17261684,  0.14713475,  0.08919774],
         [-0.10084796, -0.01844837, -0.07127508]]]], dtype=float32)
y = array([[[[ 2.6680496e-02, -3.7985470e-02, -1.7807366e-01],
         [-5.9655141e-02, -3.1768467e-02,  4.2490661e-05]],...02, -1.0236658e-02,  3.8876317e-02],
         [-1.1723093e-01,  1.4124557e-01,  6.8518490e-02]]]],
      dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
________________________________________________________________________________ test_raw_to_rgb[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_raw_to_rgb(target_framework, mode, backend_compile):
        print("kornia.color.raw_to_rgb")
    
        transpiled_raw_to_rgb = ivy.transpile(kornia.color.raw_to_rgb, source="torch", target=target_framework)
        TranspiledCFA = ivy.transpile(kornia.color.CFA, source="torch", target=target_framework)
    
        torch_x = torch.rand(5, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.raw_to_rgb(torch_x, kornia.color.CFA.RG)
        transpiled_out = transpiled_raw_to_rgb(transpiled_x, TranspiledCFA.RG)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:713: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.4915, 0.4915, 0.3587, 0.2259, 0.3640, 0.5021],
          [0.4915, 0.4915, 0.3587, 0.2259, 0.3640, 0.5021]...       [0.2901, 0.1665, 0.0429, 0.3556, 0.6683, 0.6683],
          [0.2901, 0.1665, 0.0429, 0.3556, 0.6683, 0.6683]]]])
transpiled_x = <tf.Tensor: shape=(5, 3, 4, 6), dtype=float32, numpy=
array([[[[0.49154723, 0.49154723, 0.358741  , 0.24565774, 0.4034...3118 ],
         [0.29014438, 0.20184194, 0.06055807, 0.35560468, 0.6683118 ,
          0.6683118 ]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.49154723, 0.49154723, 0.358741  , 0.22593474, 0.36399537,
          0.502056  ],
         [0.49154723, 0.4...83118 ],
         [0.29014438, 0.16652098, 0.04289758, 0.35560468, 0.6683118 ,
          0.6683118 ]]]], dtype=float32)
y = array([[[[0.49154723, 0.49154723, 0.358741  , 0.24565774, 0.4034413 ,
          0.502056  ],
         [0.49154723, 0.4...83118 ],
         [0.29014438, 0.20184194, 0.06055807, 0.35560468, 0.6683118 ,
          0.6683118 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.raw_to_rgb
_________________________________________________________________________________ test_RgbToHls[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:908: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>
args = (tensor([[[[5.7313e-01, 3.4527e-01, 2.9151e-01, 2.2133e-01, 8.3378e-01],
          [5.3106e-01, 9.2180e-01, 1.9859e-01...e-01, 9.4781e-01, 9.5191e-01, 5.0718e-01],
          [8.8727e-01, 9.5601e-01, 7.3697e-01, 3.2172e-02, 2.4271e-01]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[4.776715  , 3.8376544 , 3.6819859 , 2.8329558 , 0.3275863 ],
         [0.43103722, 5.5568514 , 4.0555696 , 6...0.852929  , 0.34692362],
         [0.7673233 , 0.9052445 , 0.7860693 , 0.91587025, 0.80469704]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
________________________________________________________________________________ test_RgbToYuv420[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1064: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>
args = (tensor([[[[0.4062, 0.8998, 0.8161, 0.5213, 0.0792, 0.4762],
          [0.2594, 0.1100, 0.7059, 0.8553, 0.9343, 0.6442...     [0.5974, 0.3803, 0.5202, 0.6208, 0.2956, 0.1137],
          [0.9974, 0.4454, 0.9818, 0.0199, 0.3006, 0.4190]]]]),)
target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.32020167, 0.45037198, 0.740208  , 0.8311149 , 0.42147282,
          0.34877503],
         [0.6265246 , 0....
        [[-0.1317851 ,  0.04725627, -0.03036738],
         [-0.14087586,  0.10502526,  0.15926695]]]], dtype=float32))
y = (array([[[[0.32020167, 0.45037198, 0.740208  , 0.8311149 , 0.42147282,
          0.34877503],
         [0.6265246 , 0....
        [[ 0.05435318,  0.16139181, -0.13819093],
         [-0.12144426, -0.07336374,  0.12577409]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f73543e8900>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.0459438 , -0.03826872,  0.07872093],
         [-0.09310401, -0.05663098, -0.09341304]],

        [[-0.033...

        [[-0.1317851 ,  0.04725627, -0.03036738],
         [-0.14087586,  0.10502526,  0.15926695]]]], dtype=float32)
y = array([[[[ 0.11345775, -0.096715  ,  0.04145747],
         [-0.11593103, -0.10352565,  0.00450444]],

        [[ 0.093...

        [[ 0.05435318,  0.16139181, -0.13819093],
         [-0.12144426, -0.07336374,  0.12577409]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
_________________________________________________________________________________ test_RawToRgb[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RawToRgb(target_framework, mode, backend_compile):
        print("kornia.color.RawToRgb")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_RawToRgb = ivy.transpile(kornia.color.RawToRgb, source="torch", target=target_framework)
        TranspiledCFA = ivy.transpile(kornia.color.CFA, source="torch", target=target_framework)
    
        torch_x = torch.rand(2, 1, 4, 6)
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        torch_out = kornia.color.RawToRgb(kornia.color.CFA.RG)(torch_x)
        transpiled_out = transpiled_RawToRgb(TranspiledCFA.RG)(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_color.py:1155: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.5406, 0.5406, 0.4449, 0.3491, 0.6407, 0.9322],
          [0.5406, 0.5406, 0.4449, 0.3491, 0.6407, 0.9322]...       [0.9919, 0.6986, 0.4052, 0.6309, 0.8565, 0.8565],
          [0.9919, 0.6986, 0.4052, 0.6309, 0.8565, 0.8565]]]])
transpiled_x = <tf.Tensor: shape=(2, 3, 4, 6), dtype=float32, numpy=
array([[[[0.5405741 , 0.5405741 , 0.44485417, 0.39078352, 0.7239...52083],
         [0.99193954, 0.7824011 , 0.44713962, 0.6308764 , 0.85652083,
          0.85652083]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.5405741 , 0.5405741 , 0.44485414, 0.34913427, 0.6406783 ,
          0.93222225],
         [0.5405741 , 0.5...652083],
         [0.99193954, 0.69858575, 0.40523195, 0.6308764 , 0.85652083,
          0.85652083]]]], dtype=float32)
y = array([[[[0.5405741 , 0.5405741 , 0.44485417, 0.39078352, 0.7239766 ,
          0.93222225],
         [0.5405741 , 0.5...652083],
         [0.99193954, 0.7824011 , 0.44713962, 0.6308764 , 0.85652083,
          0.85652083]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.RawToRgb
___________________________________________________________________________________ test_Sepia[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Sepia(target_framework, mode, backend_compile):
        args = (
            torch.ones(3, 1, 1),
        )
>       _test_color_class(
            kornia.color.Sepia,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1198: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.sepia.Sepia'>, args = (tensor([[[1.]],

        [[1.]],

        [[1.]]]),), target = 'tensorflow', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
>       transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)

kornia/test_color.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'

<string>:1: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.sepia.Sepia
______________________________________________________________________________ test_apply_colormap[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_apply_colormap(target_framework, mode, backend_compile):
        print("kornia.color.ColorMap")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledColorMapType = ivy.transpile(kornia.color.ColorMapType, source="torch", target=target_framework)
        TranspiledColorMap = ivy.transpile(kornia.color.ColorMap, source="torch", target=target_framework)
        transpiled_apply_colormap = ivy.transpile(kornia.color.apply_colormap, source="torch", target=target_framework)
    
        torch_x = torch.tensor([[[0, 1, 2], [15, 25, 33], [128, 158, 188]]])
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        colormap = kornia.color.ColorMap(base=kornia.color.ColorMapType.autumn)
        torch_out = kornia.color.apply_colormap(torch_x, colormap)
    
>       colormap = TranspiledColorMap(base=TranspiledColorMapType.autumn)

kornia/test_color.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.color.colormap.tensorflow_ColorMap object at 0x7f7334b96530>, base = <tensorflow_ColorMapType.autumn: 1>, num_colors = 64, device = None
dtype = None

>   ???

ivy_transpiled_outputs/tensorflow_outputs/kornia/color/colormap.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tensorflow_ColorMapType.autumn: 1>

        f"`input_tensor` must be a Tensor. Got: {type(input_tensor)}",
    )
>   valid_types = [
        tf.float16,
        tf.float32,
        tf.float64,
        tf.uint8,
        tf.int32,
        tf.int64,
        tf.int16,
    ]
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.color._colormap_data'

ivy_transpiled_outputs/tensorflow_outputs/kornia/color/colormap.py:56: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.ColorMap
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_raw_to_rgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToHls[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RawToRgb[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_Sepia[tensorflow-s2s-False] - AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'
FAILED kornia/test_color.py::test_apply_colormap[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.color._colormap_data'
============================================================================== 8 failed, 61 passed in 3716.37s (1:01:56) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_ransac.py .                                                                                                                                                                 [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 1 passed in 170.58s (0:02:50) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py s                                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 1 skipped in 5.09s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_utils.py .............                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 13 passed in 815.22s (0:13:35) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 453.14s (0:07:33) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................ssssssssssssssssss                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 17 passed, 18 skipped in 1034.71s (0:17:14) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/geometry/test_subpix.py .FF....FFssssss                                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_conv_soft_argmax3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_soft_argmax3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(20, 16, 3, 50, 32),
        )
        trace_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(1.0),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
        test_args = (
            torch.rand(10, 16, 5, 50, 32),
        )
        test_kwargs = {
            'kernel_size': (3, 3, 3),
            'stride': (1, 1, 1),
            'padding': (1, 1, 1),
            'temperature': torch.tensor(0.5),
            'normalized_coordinates': False,
            'eps': 1e-8,
            'output_value': True,
            'strict_maxima_bonus': 0.0,
        }
>       _test_function(
            kornia.geometry.subpix.conv_soft_argmax3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7f5094f64b80>
trace_args = (tensor([[[[[3.7354e-01, 1.1260e-01, 3.1540e-01,  ..., 6.7422e-01,
            5.3259e-01, 8.7741e-01],
           [4....9201e-01],
           [6.8533e-01, 8.4505e-01, 6.4319e-01,  ..., 7.4760e-02,
            2.0937e-01, 8.5182e-01]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[1.8992e-01, 6.6126e-01, 8.1401e-01,  ..., 5.3481e-01,
            3.4963e-01, 7.6562e-02],
           [8....1550e-01],
           [1.7492e-01, 5.0655e-01, 2.6769e-01,  ..., 6.2979e-01,
            4.4625e-01, 6.1390e-01]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_soft_argmax3d at 0x7f5094f64b80>, fn_name = 'kornia.geometry.subpix.conv_soft_argmax3d'
trace_args = (tensor([[[[[3.7354e-01, 1.1260e-01, 3.1540e-01,  ..., 6.7422e-01,
            5.3259e-01, 8.7741e-01],
           [4....9201e-01],
           [6.8533e-01, 8.4505e-01, 6.4319e-01,  ..., 7.4760e-02,
            2.0937e-01, 8.5182e-01]]]]]),)
trace_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}
test_args = (tensor([[[[[1.8992e-01, 6.6126e-01, 8.1401e-01,  ..., 5.3481e-01,
            3.4963e-01, 7.6562e-02],
           [8....1550e-01],
           [1.7492e-01, 5.0655e-01, 2.6769e-01,  ..., 6.2979e-01,
            4.4625e-01, 6.1390e-01]]]]]),)
test_kwargs = {'eps': 1e-08, 'kernel_size': (3, 3, 3), 'normalized_coordinates': False, 'output_value': True, ...}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.Module object at 0x7f503c588ee0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.Module object at 0x7f503c588ee0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.FunctionDef object at 0x7f503c58b550>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.If object at 0x7f503c2ef910>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.If object at 0x7f503c2ef910>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.AnnAssign object at 0x7f503c571ed0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.Call object at 0x7f503c573dc0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.Call object at 0x7f503c573dc0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.Call object at 0x7f503c573040>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.Call object at 0x7f503c573040>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503ca7b580>, node = <gast.gast.Name object at 0x7f503c570040>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Module object at 0x7f5036993460>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Module object at 0x7f5036993460>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.FunctionDef object at 0x7f5036991bd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Return object at 0x7f5036993400>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Return object at 0x7f5036993400>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Call object at 0x7f50369901f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Call object at 0x7f50369901f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Call object at 0x7f503c2b5a80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Call object at 0x7f503c2b5a80>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c2b4af0>, node = <gast.gast.Name object at 0x7f503cb2e740>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_soft_argmax3d
_______________________________________________________________________________ test_conv_quad_interp3d[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_conv_quad_interp3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 2, 2, 5, 5),
        )
        trace_kwargs = {
            'strict_maxima_bonus': 10.0,
            'eps': 1e-7,
        }
        test_args = (
            torch.rand(1, 2, 2, 5, 5),
        )
        test_kwargs = {
            'strict_maxima_bonus': 5.0,
            'eps': 1e-7,
        }
>       _test_function(
            kornia.geometry.subpix.conv_quad_interp3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f5094f64ca0>
trace_args = (tensor([[[[[5.0958e-01, 1.3044e-01, 8.3107e-04, 6.7596e-01, 5.3729e-01],
           [6.2653e-01, 9.6829e-01, 2.2316e-...01, 2.8992e-01, 9.7706e-01, 5.2878e-01],
           [8.6403e-02, 3.3587e-02, 6.0327e-01, 6.0020e-01, 2.1626e-02]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.4682, 0.7502, 0.8907, 0.3927, 0.0334],
           [0.0629, 0.4474, 0.4811, 0.9672, 0.0027],
           ....4586],
           [0.9761, 0.9454, 0.5857, 0.4816, 0.6835],
           [0.5835, 0.7443, 0.8782, 0.8752, 0.7900]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function conv_quad_interp3d at 0x7f5094f64ca0>, fn_name = 'kornia.geometry.subpix.conv_quad_interp3d'
trace_args = (tensor([[[[[5.0958e-01, 1.3044e-01, 8.3107e-04, 6.7596e-01, 5.3729e-01],
           [6.2653e-01, 9.6829e-01, 2.2316e-...01, 2.8992e-01, 9.7706e-01, 5.2878e-01],
           [8.6403e-02, 3.3587e-02, 6.0327e-01, 6.0020e-01, 2.1626e-02]]]]]),)
trace_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 10.0}
test_args = (tensor([[[[[0.4682, 0.7502, 0.8907, 0.3927, 0.0334],
           [0.0629, 0.4474, 0.4811, 0.9672, 0.0027],
           ....4586],
           [0.9761, 0.9454, 0.5857, 0.4816, 0.6835],
           [0.5835, 0.7443, 0.8782, 0.8752, 0.7900]]]]]),)
test_kwargs = {'eps': 1e-07, 'strict_maxima_bonus': 5.0}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c20dc30>, node = <gast.gast.Module object at 0x7f503dec9000>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c20dc30>, node = <gast.gast.Module object at 0x7f503dec9000>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c20dc30>, node = <gast.gast.FunctionDef object at 0x7f5036c107c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c20dc30>, node = <gast.gast.AnnAssign object at 0x7f503c807730>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c20dc30>, node = <gast.gast.Call object at 0x7f503c804910>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c20dc30>, node = <gast.gast.Call object at 0x7f503c804910>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503c20dc30>, node = <gast.gast.Name object at 0x7f503cad8310>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Module object at 0x7f503658f100>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Module object at 0x7f503658f100>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.FunctionDef object at 0x7f503658c0a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Return object at 0x7f503658ffd0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Return object at 0x7f503658ffd0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Call object at 0x7f503658dff0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Call object at 0x7f503658dff0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Call object at 0x7f503658ebf0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Call object at 0x7f503658ebf0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036b316c0>, node = <gast.gast.Name object at 0x7f503658d9f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.spatial_soft_argmax.conv_quad_interp3d
_____________________________________________________________________________________ test_nms2d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5),
            (3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5),
            (3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7f509514be20>
trace_args = (tensor([[[[0.0159, 0.9504, 0.9070, 0.5707, 0.9006],
          [0.5431, 0.8983, 0.6362, 0.5146, 0.0195],
          [0....6],
          [0.2137, 0.8705, 0.5823, 0.5023, 0.7247],
          [0.9757, 0.9610, 0.4829, 0.1850, 0.1326]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.1237, 0.1507, 0.9866, 0.1241, 0.3377],
          [0.2085, 0.5649, 0.0717, 0.1914, 0.3556],
          [0....4],
          [0.2643, 0.0127, 0.0291, 0.4571, 0.7084],
          [0.4341, 0.8228, 0.8376, 0.0302, 0.7763]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms2d at 0x7f509514be20>, fn_name = 'kornia.geometry.subpix.nms2d'
trace_args = (tensor([[[[0.0159, 0.9504, 0.9070, 0.5707, 0.9006],
          [0.5431, 0.8983, 0.6362, 0.5146, 0.0195],
          [0....6],
          [0.2137, 0.8705, 0.5823, 0.5023, 0.7247],
          [0.9757, 0.9610, 0.4829, 0.1850, 0.1326]]]]), (3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[0.1237, 0.1507, 0.9866, 0.1241, 0.3377],
          [0.2085, 0.5649, 0.0717, 0.1914, 0.3556],
          [0....4],
          [0.2643, 0.0127, 0.0291, 0.4571, 0.7084],
          [0.4341, 0.8228, 0.8376, 0.0302, 0.7763]]]]), (3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Module object at 0x7f5036c11060>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Module object at 0x7f5036c11060>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.FunctionDef object at 0x7f50369b3400>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Return object at 0x7f50369b0d30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Return object at 0x7f50369b0d30>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Call object at 0x7f50369b2080>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Call object at 0x7f50369b2080>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Call object at 0x7f50369b29e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Call object at 0x7f50369b29e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f5036e47d30>, node = <gast.gast.Name object at 0x7f50369b32b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression2d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms2d
_____________________________________________________________________________________ test_nms3d[numpy-s2s-False] ______________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_nms3d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 5, 5, 5),
            (3, 3, 3),
        )
        trace_kwargs = {
            'mask_only': False,
        }
        test_args = (
            torch.rand(10, 1, 5, 5, 5),
            (3, 3, 3),
        )
        test_kwargs = {
            'mask_only': False,
        }
>       _test_function(
            kornia.geometry.subpix.nms3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_subpix.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7f5094f64280>
trace_args = (tensor([[[[[0.4881, 0.3663, 0.6494, 0.1564, 0.7856],
           [0.0581, 0.5369, 0.6672, 0.1885, 0.7636],
           ...         [0.7093, 0.5386, 0.9910, 0.4975, 0.9417],
           [0.0112, 0.2941, 0.3847, 0.4165, 0.3998]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[0.5560, 0.8151, 0.9687, 0.6278, 0.4679],
           [0.9259, 0.9986, 0.9949, 0.6342, 0.7876],
           ...         [0.8606, 0.2076, 0.6171, 0.8684, 0.6107],
           [0.1453, 0.1335, 0.1541, 0.6893, 0.1051]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function nms3d at 0x7f5094f64280>, fn_name = 'kornia.geometry.subpix.nms3d'
trace_args = (tensor([[[[[0.4881, 0.3663, 0.6494, 0.1564, 0.7856],
           [0.0581, 0.5369, 0.6672, 0.1885, 0.7636],
           ...         [0.7093, 0.5386, 0.9910, 0.4975, 0.9417],
           [0.0112, 0.2941, 0.3847, 0.4165, 0.3998]]]]]), (3, 3, 3))
trace_kwargs = {'mask_only': False}
test_args = (tensor([[[[[0.5560, 0.8151, 0.9687, 0.6278, 0.4679],
           [0.9259, 0.9986, 0.9949, 0.6342, 0.7876],
           ...         [0.8606, 0.2076, 0.6171, 0.8684, 0.6107],
           [0.1453, 0.1335, 0.1541, 0.6893, 0.1051]]]]]), (3, 3, 3))
test_kwargs = {'mask_only': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Module object at 0x7f503c77db70>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Module object at 0x7f503c77db70>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.FunctionDef object at 0x7f50367d3e80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Return object at 0x7f50367d0070>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Return object at 0x7f50367d0070>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Call object at 0x7f50367d2e00>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Call object at 0x7f50367d2e00>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Call object at 0x7f50367d0730>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Call object at 0x7f50367d0730>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MI.IvyRecurser object at 0x7f503cb095a0>, node = <gast.gast.Name object at 0x7f50367d3340>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy_NonMaximaSuppression3d'>' to `numpy` because it is an instance of a stateful class.

IL.pyx:247: InvalidObjectException
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.subpix.nms.nms3d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_subpix.py::test_conv_soft_argmax3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.s...
FAILED kornia/geometry/test_subpix.py::test_conv_quad_interp3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.s...
FAILED kornia/geometry/test_subpix.py::test_nms2d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy...
FAILED kornia/geometry/test_subpix.py::test_nms3d[numpy-s2s-False] - I.InvalidObjectException: Cannot transpile the object '<class 'ivy_transpiled_outputs.ivy_outputs.kornia.geometry.subpix.nms.ivy...
========================================================================== 4 failed, 5 passed, 6 skipped in 571.57s (0:09:31) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py ...................                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 19 passed in 1139.62s (0:18:59) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_HomographyTracker[jax-s2s-False] _________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomographyTracker = ivy.transpile(kornia.tracking.HomographyTracker, source="torch", target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = TranspiledHomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>, args = (), kwargs = {}
node = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.tracking.planar_tracker.jax_HomographyTracker'>
self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_HomographyTracker(
  (initial_matcher): jax_LocalFeatureMatcher(
    (local_feature): jax_GFTTAffNetHardNet(
     ...alse, 
        )
      ), patch_size=32, grayscale_descriptor='True)
    )
    (matcher): jax_DescriptorMatcher()
  )
)
initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import jax_LocalFeatureMatcher
        from ..feature.integrated import jax_GFTTAffNetHardNet
        from ..feature.matching import jax_DescriptorMatcher
        from ..feature.loftr.loftr import jax_LoFTR
        from ..geometry.ransac import jax_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or jax_LocalFeatureMatcher(
            jax_GFTTAffNetHardNet(3000), jax_DescriptorMatcher("smnn", 0.95)
        )
>       self.fast_matcher = fast_matcher or jax_LoFTR("outdoor")

ivy_transpiled_outputs/jax_outputs/kornia/tracking/planar_tracker.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, args = ('outdoor',), kwargs = {}, node = jax_LoFTR()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.loftr.loftr.jax_LoFTR'>, self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), args = ('outdoor',), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    @jax_store_config_info
    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.jax.general import jax_set_item
        from .backbone.__init__ import jax_build_backbone
        from .utils.position_encoding import jax_PositionEncodingSine
        from .loftr_module.transformer import jax_LocalFeatureTransformer
        from .utils.coarse_matching import jax_CoarseMatching
        from .loftr_module.fine_preprocess import jax_FinePreprocess
        from .utils.fine_matching import jax_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            jax_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = jax_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = jax_build_backbone(config)

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/loftr.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def jax_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/feature/loftr/backbone/__init__.py:42: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|| 332k/332k [00:00<00:00, 19.0MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|| 5.10M/5.10M [00:00<00:00, 119MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:44, 443kB/s]
  1%|          | 384k/44.2M [00:00<00:39, 1.15MB/s]
  2%|         | 896k/44.2M [00:00<00:24, 1.88MB/s]
  5%|         | 2.12M/44.2M [00:00<00:09, 4.78MB/s]
 10%|         | 4.25M/44.2M [00:00<00:04, 9.48MB/s]
 16%|        | 7.25M/44.2M [00:00<00:02, 15.6MB/s]
 24%|       | 10.5M/44.2M [00:00<00:01, 20.8MB/s]
 31%|       | 13.8M/44.2M [00:01<00:01, 24.6MB/s]
 39%|      | 17.1M/44.2M [00:01<00:01, 27.7MB/s]
 46%|     | 20.1M/44.2M [00:01<00:00, 28.8MB/s]
 52%|    | 23.0M/44.2M [00:01<00:00, 29.2MB/s]
 59%|    | 26.1M/44.2M [00:01<00:00, 30.2MB/s]
 67%|   | 29.5M/44.2M [00:01<00:00, 25.4MB/s]
 74%|  | 32.6M/44.2M [00:01<00:00, 27.3MB/s]
 81%|  | 35.8M/44.2M [00:01<00:00, 28.7MB/s]
 88%| | 38.9M/44.2M [00:01<00:00, 29.8MB/s]
 95%|| 42.0M/44.2M [00:02<00:00, 30.6MB/s]
100%|| 44.2M/44.2M [00:02<00:00, 22.2MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 1 failed in 453.45s (0:07:33) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_mean_average_precision[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f4410fa4a60>
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f4410fa4a60>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shap....,  50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 2)
trace_kwargs = {}
test_args = ([<tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], d...50., 150., 100.]], dtype=float32)>], [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 3)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>]
pred_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], pred_scores = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.7], dtype=float32)>]
gt_boxes = [<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[100.,  50., 150., 100.]], dtype=float32)>], gt_labels = [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]
n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'numpy.int64' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[tensorflow-s2s-False] - TypeError: 'numpy.int64' object is not callable
=============================================================================== 1 failed, 12 passed in 807.73s (0:13:27) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/geometry/test_calibration.py ....F                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_solve_pnp_dlt[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_solve_pnp_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[
                [5.0, -5.0, 0.0], [0.0, 0.0, 1.5],
                [2.5, 3.0, 6.0], [9.0, -2.0, 3.0],
                [-4.0, 5.0, 2.0], [-5.0, 5.0, 1.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1409.1504, -800.936], [407.0207, -182.1229],
                [392.7021, 177.9428], [1016.838, -2.9416],
                [-63.1116, 142.9204], [-219.3874, 99.666]
            ]], dtype=torch.float64),
            torch.tensor([[
                [500.0, 0.0, 250.0],
                [0.0, 500.0, 250.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        trace_kwargs = {'svd_eps': 1e-3}
        test_args = (
            torch.tensor([[
                [10.0, -10.0, 0.0], [0.0, 0.0, 3.0],
                [5.0, 6.0, 12.0], [18.0, -4.0, 6.0],
                [-8.0, 10.0, 4.0], [-10.0, 10.0, 2.0]
            ]], dtype=torch.float64),
            torch.tensor([[
                [2818.3008, -1601.872], [814.0414, -364.2458],
                [785.4042, 355.8856], [2033.676, -5.8832],
                [-126.2232, 285.8408], [-438.7748, 199.332]
            ]], dtype=torch.float64),
            torch.tensor([[
                [1000.0, 0.0, 500.0],
                [0.0, 1000.0, 500.0],
                [0.0, 0.0, 1.0]
            ]], dtype=torch.float64),
        )
        test_kwargs = {'svd_eps': 1e-3}
>       _test_function(
            kornia.geometry.calibration.solve_pnp_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_calibration.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f891df56950>
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function solve_pnp_dlt at 0x7f891df56950>, fn_name = 'kornia.geometry.calibration.solve_pnp_dlt'
trace_args = (tensor([[[ 5.0000, -5.0000,  0.0000],
         [ 0.0000,  0.0000,  1.5000],
         [ 2.5000,  3.0000,  6.0000],
   ...loat64), tensor([[[500.,   0., 250.],
         [  0., 500., 250.],
         [  0.,   0.,   1.]]], dtype=torch.float64))
trace_kwargs = {'svd_eps': 0.001}
test_args = (tensor([[[ 10., -10.,   0.],
         [  0.,   0.,   3.],
         [  5.,   6.,  12.],
         [ 18.,  -4.,   6.],
 ...tensor([[[1000.,    0.,  500.],
         [   0., 1000.,  500.],
         [   0.,    0.,    1.]]], dtype=torch.float64))
test_kwargs = {'svd_eps': 0.001}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

world_points = <tf.Tensor: shape=(1, 6, 3), dtype=float64, numpy=
array([[[ 5. , -5. ,  0. ],
        [ 0. ,  0. ,  1.5],
        [ 2.5,  3. ,  6. ],
        [ 9. , -2. ,  3. ],
        [-4. ,  5. ,  2. ],
        [-5. ,  5. ,  1. ]]])>
img_points = <tf.Tensor: shape=(1, 6, 2), dtype=float64, numpy=
array([[[1409.1504, -800.936 ],
        [ 407.0207, -182.1229],
   ...92.7021,  177.9428],
        [1016.838 ,   -2.9416],
        [ -63.1116,  142.9204],
        [-219.3874,   99.666 ]]])>
intrinsics = <tf.Tensor: shape=(1, 3, 3), dtype=float64, numpy=
array([[[500.,   0., 250.],
        [  0., 500., 250.],
        [  0.,   0.,   1.]]])>, weights = None, svd_eps = 0.001

    def tensorflow_solve_pnp_dlt(
        world_points, img_points, intrinsics, weights=None, svd_eps=0.0001
    ):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...utils.helpers import tensorflow__torch_linalg_svdvals
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_any_frnt
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_inverse_frnt,
        )
        from ..conversions import tensorflow_convert_points_to_homogeneous
        from ..linalg import tensorflow_transform_points
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_svd_frnt_base_count_1_frnt,
        )
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...utils.misc import tensorflow_eye_like
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_bmm_frnt,
        )
        from ....ivy.functional.frontends.torch.blas_and_lapack_ops import (
            tensorflow_det_frnt,
        )
        from ....ivy.functional.frontends.torch.reduction_ops import tensorflow_norm_frnt
        from ....ivy.functional.frontends.torch.linalg import tensorflow_qr_frnt
        from ....ivy.functional.frontends.torch.pointwise_ops import tensorflow_sign_frnt
        from ....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_cat_frnt,
        )
        from ...core._backend import zeros
        from ...core._backend import ones_like
        from ...core._backend import where
    
        if not isinstance(world_points, (tensorflow.Tensor, tensorflow.Variable)):
            raise AssertionError(
                f"world_points is not an instance of torch.Tensor. Type of world_points is {type(world_points)}"
            )
        if not isinstance(img_points, (tensorflow.Tensor, tensorflow.Variable)):
            raise AssertionError(
                f"img_points is not an instance of torch.Tensor. Type of img_points is {type(img_points)}"
            )
        if not isinstance(intrinsics, (tensorflow.Tensor, tensorflow.Variable)):
            raise AssertionError(
                f"intrinsics is not an instance of torch.Tensor. Type of intrinsics is {type(intrinsics)}"
            )
        if weights is not None and not isinstance(
            weights, (tensorflow.Tensor, tensorflow.Variable)
        ):
            raise AssertionError(
                f"If weights is not None, then weights should be an instance of torch.Tensor. Type of weights is {type(weights)}"
            )
        if not isinstance(svd_eps, (float,)):
            raise AssertionError(f"Type of svd_eps is not float. Got {type(svd_eps)}")
        accepted_dtypes = tf.float32, tf.float64
        if world_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"world_points must have one of the following dtypes {accepted_dtypes}. Currently it has {world_points.dtype}."
            )
        if img_points.dtype not in accepted_dtypes:
            raise AssertionError(
                f"img_points must have one of the following dtypes {accepted_dtypes}. Currently it has {img_points.dtype}."
            )
        if intrinsics.dtype not in accepted_dtypes:
            raise AssertionError(
                f"intrinsics must have one of the following dtypes {accepted_dtypes}. Currently it has {intrinsics.dtype}."
            )
        if (
            len(tensorflow_shape_frnt_(world_points)) != 3
            or tensorflow_shape_frnt_(world_points)[2] != 3
        ):
            raise AssertionError(
                f"world_points must be of shape (B, N, 3). Got shape {tensorflow_shape_frnt_(world_points)}."
            )
        if (
            len(tensorflow_shape_frnt_(img_points)) != 3
            or tensorflow_shape_frnt_(img_points)[2] != 2
        ):
            raise AssertionError(
                f"img_points must be of shape (B, N, 2). Got shape {tensorflow_shape_frnt_(img_points)}."
            )
        if len(tensorflow_shape_frnt_(intrinsics)) != 3 or tensorflow_shape_frnt_(
            intrinsics
        )[1:] != (3, 3):
            raise AssertionError(
                f"intrinsics must be of shape (B, 3, 3). Got shape {tensorflow_shape_frnt_(intrinsics)}."
            )
        if tensorflow_shape_frnt_(world_points)[1] != tensorflow_shape_frnt_(img_points)[1]:
            raise AssertionError(
                "world_points and img_points must have equal number of points."
            )
        if (
            tensorflow_shape_frnt_(world_points)[0] != tensorflow_shape_frnt_(img_points)[0]
            or tensorflow_shape_frnt_(world_points)[0]
            != tensorflow_shape_frnt_(intrinsics)[0]
        ):
            raise AssertionError(
                "world_points, img_points and intrinsics must have the same batch size."
            )
        if tensorflow_shape_frnt_(world_points)[1] < 6:
            raise AssertionError(
                f"At least 6 points are required to use this function. Got {tensorflow_shape_frnt_(world_points)[1]} points."
            )
        B, N = (
            tensorflow_shape_frnt_(world_points)[:2][0],
            tensorflow_shape_frnt_(world_points)[:2][1],
        )
        world_points_norm, world_transform_norm = (
            tensorflow__mean_isotropic_scale_normalize(world_points)
        )
        s = tensorflow__torch_linalg_svdvals(world_points_norm)
        if tensorflow_any_frnt(s[:, -1] < svd_eps):
            raise AssertionError(
                f"The last singular value of one/more of the elements of the batch is smaller than {svd_eps}. This function cannot be used if all world_points (of any element of the batch) lie on a line or if all world_points (of any element of the batch) lie on a plane."
            )
        intrinsics_inv = tensorflow_inverse_frnt(intrinsics)
        world_points_norm_h = tensorflow_convert_points_to_homogeneous(world_points_norm)
        img_points_inv = tensorflow_transform_points(intrinsics_inv, img_points)
        img_points_norm, img_transform_norm = tensorflow__mean_isotropic_scale_normalize(
            img_points_inv
        )
        inv_img_transform_norm = tensorflow_inverse_frnt(img_transform_norm)
        system = zeros((B, 2 * N, 12), dtype=world_points.dtype, device=world_points.device)
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(0, 4, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(4, 8, None)),
            world_points_norm_h,
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(0, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 0:1],
        )
        system = tensorflow_set_item(
            system,
            (slice(None, None, None), slice(1, None, 2), slice(8, 12, None)),
            world_points_norm_h * -1 * img_points_norm[..., 1:2],
        )
        _, _, v = tensorflow_svd_frnt_base_count_1_frnt(system)
        solution = v[..., -1]
        solution = tensorflow_reshape_frnt_(solution, B, 3, 4)
        solution_4x4 = tensorflow_eye_like(4, solution)
        solution_4x4 = tensorflow_set_item(
            solution_4x4,
            (slice(None, None, None), slice(None, 3, None), slice(None, None, None)),
            solution,
        )
        intermediate = tensorflow_bmm_frnt(solution_4x4, world_transform_norm)
        solution = tensorflow_bmm_frnt(inv_img_transform_norm, intermediate[:, :3, :])
        det = tensorflow_det_frnt(solution[:, :3, :3])
        ones = ones_like(det)
        sign_fix = where(det < 0, ones * -1, ones)
        solution = solution * sign_fix[:, None, None]
>       norm_col = tensorflow_norm_frnt(input=solution[:, :3, 0], p=2, dim=1)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/calibration/pnp.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {'dim': 1, 'input': <tf.Tensor: shape=(1, 3), dtype=float64, numpy=array([[-0.02017229,  0.02388222,  0.0574928 ]])>, 'p': 2}
tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7f88acd013f0>

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import tensorflow_is_array_bknd
    
>       array_like = args[0]
E       IndexError: tuple index out of range

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:195: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.calibration.pnp.solve_pnp_dlt
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_calibration.py::test_solve_pnp_dlt[tensorflow-s2s-False] - IndexError: tuple index out of range
=============================================================================== 1 failed, 4 passed in 401.84s (0:06:41) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 1940.92s (0:32:20) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....FF..F...FF.                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_diamond_square[tensorflow-s2s-False] _______________________________________________________________________________

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}, arg = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def rep_method(*args, **kwargs):
        for arg in args:
            if ivy.is_ivy_array(arg):
                return NotImplemented
>       return func(*args, **kwargs)

../ivy/ivy/functional/backends/tensorflow/__init__.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]]))
kwargs = {}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays_and_dtypes = [<class 'numpy.float32'>, tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])]

    def _result_type(*arrays_and_dtypes):
      """Returns the resulting type given a set of arrays."""
    
      def preprocess_float(x):
        if is_prefer_float32():
          if isinstance(x, float):
            return np.float32(x)
          elif isinstance(x, complex):
            return np.complex64(x)
        return x
    
      arrays_and_dtypes = [preprocess_float(x) for x in arrays_and_dtypes]
>     dtype = np.result_type(*arrays_and_dtypes)
E     TypeError: Cannot interpret 'tensor([[[[0.3333, 1.0000, 0.3333],
E               [1.0000, 0.3333, 1.0000],
E               [0.3333, 1.0000, 0.3333]]]])' as a data type

/opt/fw/tensorflow/tensorflow/python/ops/numpy_ops/np_dtypes.py:190: TypeError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

>   ???

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
>           return original_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7ff07b27f130>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7ff096b69900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7ff096b69900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7ff07b27f130>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7ff096b69900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7ff096b69900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'tensorflow'
backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[0.5]]]], dtype=float32)>
random_scale = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>, random_fn = <built-in method ones of type object at 0x7ff096b69900>, normalize_range = (0.0, 1.0)
device = None, dtype = None

    def tensorflow_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=tensorflow_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ..core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import tensorflow_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..enhance.normalize import tensorflow_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import tensorflow_contiguous_frnt_
    
        tensorflow_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (tensorflow.Tensor, tensorflow.Variable)):
            random_scale = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[random_scale]]]]), device, dtype
            )
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            tensorflow_KORNIA_CHECK_IS_TENSOR(random_scale)
            random_scale = tensorflow_view_frnt_(random_scale, -1, 1, 1, 1)
            random_scale = tensorflow_expand_frnt_(
                random_scale, [output_size[0], output_size[1], 1, 1]
            )
            random_scale = tensorflow_reshape_frnt_(random_scale, [-1, 1, 1, 1])
        if not isinstance(roughness, (tensorflow.Tensor, tensorflow.Variable)):
            roughness = tensorflow_to_frnt_(
                tensorflow.convert_to_tensor([[[[roughness]]]]), device, dtype
            )
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0] * output_size[1], 1, 1, 1]
            )
        else:
            roughness = tensorflow_view_frnt_(roughness, -1, 1, 1, 1)
            roughness = tensorflow_expand_frnt_(
                roughness, [output_size[0], output_size[1], 1, 1]
            )
            roughness = tensorflow_reshape_frnt_(roughness, [-1, 1, 1, 1])
        width, height = output_size[-2:][0], output_size[-2:][1]
        num_samples: typing.Any = 1
        for x in output_size[:-2]:
            num_samples = num_samples * x
        p2_width: typing.Any = 2 ** math.ceil(math.log2(width - 1)) + 1
        p2_height: typing.Any = 2 ** math.ceil(math.log2(height - 1)) + 1
        recursion_depth: typing.Any = int(
            min(math.log2(p2_width - 1) - 1, math.log2(p2_height - 1) - 1)
        )
        seed_width: typing.Any = (p2_width - 1) // 2**recursion_depth + 1
        seed_height: typing.Any = (p2_height - 1) // 2**recursion_depth + 1
>       img: typing.Any = random_scale * tensorflow__diamond_square_seed(
            num_samples, seed_width, seed_height, random_fn, device, dtype
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/diamond_square.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
rhs = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
other = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
>       input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[1.]]]], dtype=float32)>
x2 = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import tensorflow_isscalar_bknd
        from ...ivy.data_type import tensorflow_is_int_dtype_bknd
        from ...backends.tensorflow.creation import tensorflow_asarray
        from ...ivy.data_type import tensorflow_default_dtype_bknd
        from .tensor import tensorflow_shape_frnt_
        from ...ivy.device import tensorflow_default_device_bknd
        from ....data_classes.array.data_type import tensorflow_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x1):
            x1 = tensorflow_asarray(x1, dtype="int64")
        elif tensorflow_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = tensorflow_asarray(x1)
        if (
            tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and tensorflow_is_int_dtype_bknd(x2):
            x2 = tensorflow_asarray(x2, dtype="int64")
        elif tensorflow_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = tensorflow_asarray(x2)
        type1 = tensorflow_default_dtype_bknd(item=x1).strip("u123456789")
>       type2 = tensorflow_default_dtype_bknd(item=x2).strip("u123456789")

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/__init__.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def tensorflow_default_dtype_bknd(
        *,
        dtype: Optional[Union[str, str]] = None,
        item: Optional[Union[tensorflow.Tensor, tf.Tensor]] = None,
        as_native: bool = False,
    ):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
        from ..backends.tensorflow.data_type import tensorflow_as_native_dtype
        from .general import tensorflow_exists_bknd
        from .general import tensorflow_default_bknd
    
        if tensorflow_exists_bknd(dtype):
            if as_native is True:
                return tensorflow_as_native_dtype(dtype)
            return tensorflow_as_ivy_dtype(dtype)
        as_native = tensorflow_default_bknd(as_native, False)
        if tensorflow_exists_bknd(item):
            if hasattr(item, "override_dtype_check"):
                return item.override_dtype_check()
            elif isinstance(item, (list, tuple, dict)) and len(item) == 0:
                pass
>           elif tensorflow_is_complex_dtype_bknd(item):

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_is_complex_dtype_bknd(
        dtype_in: Union[str, str, tensorflow.Tensor, tf.Tensor, Number], /
    ):
        from ..backends.tensorflow.data_type import tensorflow_dtype
        from .general import tensorflow_is_array_bknd
        from .nest import tensorflow_nested_argwhere_bknd
    
        if tensorflow_is_array_bknd(dtype_in):
            dtype_in = tensorflow_dtype(dtype_in)
        elif isinstance(dtype_in, tuple):
            dtype_in = tensorflow_default_int_dtype_bknd()
        elif isinstance(dtype_in, np.ndarray):
            return "complex" in dtype_in.dtype.name
        elif isinstance(dtype_in, Number):
            return isinstance(dtype_in, (complex, np.complexfloating))
        elif isinstance(dtype_in, (list, tuple, dict)):
            return tensorflow_nested_argwhere_bknd(
                dtype_in,
                lambda x: isinstance(x, (complex, np.complexfloating))
                or tensorflow_is_array_bknd(x)
                and "complex" in tensorflow_dtype(x),
            )
>       return "complex" in tensorflow_as_ivy_dtype_bknd(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:562: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype_bknd(dtype_in: Union[str, str], /):
        from ..backends.tensorflow.data_type import tensorflow_as_ivy_dtype
    
>       return tensorflow_as_ivy_dtype(dtype_in)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/ivy/data_type.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype_in = tensor([[[[0.3333, 1.0000, 0.3333],
          [1.0000, 0.3333, 1.0000],
          [0.3333, 1.0000, 0.3333]]]])

    def tensorflow_as_ivy_dtype(
        dtype_in: Union[tensorflow.DType, str, int, float, complex, bool, np.dtype], /
    ):
        from ...ivy.data_type import tensorflow_default_int_dtype_bknd
        from ...ivy.data_type import tensorflow_default_float_dtype_bknd
        from ...ivy.data_type import tensorflow_default_complex_dtype_bknd
    
        if dtype_in is int:
            return tensorflow_default_int_dtype_bknd()
        if dtype_in is float:
            return tensorflow_default_float_dtype_bknd()
        if dtype_in is complex:
            return tensorflow_default_complex_dtype_bknd()
        if dtype_in is bool:
            return str("bool")
        if isinstance(dtype_in, np.dtype):
            dtype_in = dtype_in.name
        if isinstance(dtype_in, str):
            if dtype_in in native_dtype_dict:
                dtype_str = dtype_in
            else:
                raise Exception(
                    f"Cannot convert to ivy dtype. {dtype_in} is not supported by TensorFlow backend."
                )
        else:
>           dtype_str = ivy_dtype_dict[dtype_in]
E           KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
E                     [1.0000, 0.3333, 1.0000],
E                     [0.3333, 1.0000, 0.3333]]]])

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/data_type.py:184: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
_______________________________________________________________________________ test_EdgeDetector[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_EdgeDetector(target_framework, mode, backend_compile):
        print("kornia.contrib.EdgeDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledEdgeDetector = ivy.transpile(kornia.contrib.EdgeDetector, source="torch", target=target_framework)
    
        torch_detector = kornia.contrib.EdgeDetector()
>       transpiled_detector = TranspiledEdgeDetector()

kornia/test_contrib.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_EdgeDetector()

    def __init__(self):
        from ..filters.dexined import tensorflow_DexiNed
    
        self.super___init__(
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.model = tensorflow_DexiNed(pretrained=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/edge_detection.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
args = (), kwargs = {'pretrained': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
pretrained = True

    @tensorflow_store_config_info
    def __init__(self, pretrained):
        from ...torch.nn.modules.pooling import tensorflow_MaxPool2d
    
        self.super___init__(
            pretrained,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.block_1 = tensorflow_DoubleConvBlock(3, 32, 64, stride=2)
        self.block_2 = tensorflow_DoubleConvBlock(64, 128, use_act=False)
        self.dblock_3 = tensorflow__DenseBlock(2, 128, 256)
        self.dblock_4 = tensorflow__DenseBlock(3, 256, 512)
        self.dblock_5 = tensorflow__DenseBlock(3, 512, 512)
        self.dblock_6 = tensorflow__DenseBlock(3, 512, 256)
        self.maxpool = tensorflow_MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.side_1 = tensorflow_SingleConvBlock(64, 128, 2)
        self.side_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.side_3 = tensorflow_SingleConvBlock(256, 512, 2)
        self.side_4 = tensorflow_SingleConvBlock(512, 512, 1)
        self.side_5 = tensorflow_SingleConvBlock(512, 256, 1)
        self.pre_dense_2 = tensorflow_SingleConvBlock(128, 256, 2)
        self.pre_dense_3 = tensorflow_SingleConvBlock(128, 256, 1)
        self.pre_dense_4 = tensorflow_SingleConvBlock(256, 512, 1)
        self.pre_dense_5 = tensorflow_SingleConvBlock(512, 512, 1)
        self.pre_dense_6 = tensorflow_SingleConvBlock(512, 256, 1)
        self.up_block_1 = tensorflow_UpConvBlock(64, 1)
        self.up_block_2 = tensorflow_UpConvBlock(128, 1)
        self.up_block_3 = tensorflow_UpConvBlock(256, 2)
        self.up_block_4 = tensorflow_UpConvBlock(512, 3)
        self.up_block_5 = tensorflow_UpConvBlock(512, 4)
        self.up_block_6 = tensorflow_UpConvBlock(256, 4)
        self.block_cat = tensorflow_SingleConvBlock(6, 1, stride=1, use_bs=False)
        if pretrained:
>           self.load_from_file(url)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
path_file = 'http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth'

    def load_from_file(self, path_file):
        from ...ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ..utils.helpers import tensorflow_map_location_to_cpu
    
        pretrained_dict = tensorflow_load_state_dict_from_url_frnt(
            path_file, map_location=tensorflow_map_location_to_cpu
        )
>       self.load_state_dict(pretrained_dict, strict=True)

ivy_transpiled_outputs/tensorflow_outputs/kornia/filters/dexined.py:613: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
strict = True, assign = False

    def load_state_dict(
        self,
        state_dict: typing.Mapping[str, Any],
        strict: bool = True,
        assign: bool = False,
    ):
        r"""Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.
    
        If :attr:`strict` is ``True``, then
        the keys of :attr:`state_dict` must exactly match the keys returned
        by this module's :meth:`~Module.state_dict` function.
    
        Args:
            state_dict (dict): a dict containing parameters and
                persistent buffers.
            strict (bool, optional): whether to strictly enforce that the keys
                in :attr:`state_dict` match the keys returned by this module's
                :meth:`~Module.state_dict` function. Default: ``True``
    
        Returns:
            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:
                * **missing_keys** is a list of str containing any keys that are expected
                    by this module but missing from the provided ``state_dict``.
                * **unexpected_keys** is a list of str containing the keys that are not
                    expected by this module but present in the provided ``state_dict``.
        """
        if not isinstance(state_dict, typing.Mapping):
            raise TypeError(
                f"Expected state_dict to be dict-like, got {type(state_dict)}."
            )
    
        missing_keys: List[str] = []
        unexpected_keys: List[str] = []
        error_msgs: List[str] = []
    
        state_dict = tf.nest.map_structure(
            lambda x: tf.convert_to_tensor(x.numpy()),
            state_dict,
        )
        state_dict = OrderedDict(state_dict)
    
        def load(module, local_state_dict, prefix=""):
            module._load_from_state_dict(
                local_state_dict,
                prefix,
                strict,
                missing_keys,
                unexpected_keys,
                error_msgs,
            )
            # TODO: maybe we should implement this similar to PT
            # and make this recursive.
    
>       load(self, state_dict)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:600: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
local_state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = ''

    def load(module, local_state_dict, prefix=""):
>       module._load_from_state_dict(
            local_state_dict,
            prefix,
            strict,
            missing_keys,
            unexpected_keys,
            error_msgs,
        )

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:589: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_DexiNed(
  (block_1): tensorflow_DoubleConvBlock(
    (conv1): KerasConv2D()
    (bn1): KerasBatchNorm2D()
...e2d()
    )
  )
  (block_cat): tensorflow_SingleConvBlock(
    (conv): KerasConv2D()
    (bn): KerasBatchNorm2D()
  )
)
state_dict = OrderedDict([('block_1.conv1.weight', <tf.Tensor: shape=(32, 3, 3, 3), dtype=float32, numpy=
array([[[[ 2.31264587e-02...numpy=array([1.], dtype=float32)>), ('block_cat.bn.num_batches_tracked', <tf.Tensor: shape=(), dtype=int64, numpy=0>)])
prefix = '', strict = True, missing_keys = [], unexpected_keys = [], error_msgs = []

    def _load_from_state_dict(
        self, state_dict, prefix, strict, missing_keys, unexpected_keys, error_msgs
    ):
        def _retrive_layer(model, key):
            if len(key.split(".")) == 1:
                return model, key
    
            module_path, weight_name = key.rsplit(".", 1)
    
            # Retrieve the layer using the module path
            layer = model
            for attr in module_path.split("."):
                layer = getattr(layer, attr)
    
            return layer, weight_name
    
        persistent_buffers = {k: v for k, v in self._buffers.items()}
        local_name_params = itertools.chain(
            self._parameters.items(), persistent_buffers.items()
        )
        local_state = {k: v for k, v in local_name_params if v is not None}
    
        for name, param in local_state.items():
            key = prefix + name
            if key in state_dict:
                input_param = state_dict[key]
                if not isinstance(input_param, tf.Tensor):
                    error_msgs.append(
                        f'While copying the parameter named "{key}", '
                        "expected ArrayLike object from checkpoint but "
                        f"received {type(input_param)}"
                    )
                    continue
    
                if not isinstance(input_param, KerasVariable):
>                   input_param = KerasVariable(input_param)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:522: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_57>, initializer = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, shape = None, dtype = 'float32', trainable = True
autocast = True, aggregation = 'mean', name = 'variable_57'

    def __init__(
        self,
        initializer,
        shape=None,
        dtype=None,
        trainable=True,
        autocast=True,
        aggregation="mean",
        name=None,
    ):
        name = name or auto_name(self.__class__.__name__)
        if not isinstance(name, str) or "/" in name:
            raise ValueError(
                "Argument `name` must be a string and "
                "cannot contain character `/`. "
                f"Received: name={name}"
            )
        if aggregation not in ("mean", "sum", "only_first_replica"):
            raise ValueError(
                "Invalid valid for argument `aggregation`. Expected "
                "one of {'mean', 'sum', 'only_first_replica'}. "
                f"Received: aggregation={aggregation}"
            )
        self.name = name
        parent_path = current_path()
        if parent_path:
            self.path = current_path() + "/" + self.name
        else:
            self.path = self.name
        dtype = standardize_dtype(dtype)
        self._dtype = dtype
        self._shape = None
        self._initializer = None
        self._regularizer = None
        self._constraint = None
        self._trainable = trainable
        self._autocast = autocast
        self._aggregation = aggregation
        # `self._overwrite_with_gradient` is an internal property to determine
        # whether this variable should be overwritten by the computed gradient.
        # Ref: https://github.com/google/flax/blob/main/flax/linen/fp8_ops.py
        self._overwrite_with_gradient = False
        if isinstance(initializer, str):
            from keras.src import initializers
    
            initializer = initializers.get(initializer)
        if callable(initializer):
            if shape is None:
                raise ValueError(
                    "When creating a Variable from an initializer, "
                    "the `shape` argument should be specified. "
                    f"Received: initializer={initializer} "
                    f"and shape={shape}"
                )
    
        if in_stateless_scope():
            if callable(initializer):
                self._value = None
                self._initializer = initializer
                self._shape = self._validate_shape(shape)
                register_uninitialized_variable(self)
            else:
                raise ValueError(
                    "You are attempting to create a variable "
                    "while in a stateless scope. This is disallowed. "
                    "Make sure that all variables are created "
                    "before you start using your layer/model objects.\n\n"
                    "In some cases, you might be seeing this error "
                    "because you need to "
                    "implement a `def build(self, input_shape)` method "
                    "on your layer/model, which will "
                    "create its variables.\n\n"
                    "In some other cases, you might be seeing this error "
                    "because you are instantiating a `Variable` and "
                    "assigning it to a layer without going through "
                    "self.add_variable()/self.add_weight(). Always prefer "
                    "using these methods "
                    "(with a `shape` and `initializer` argument)."
                )
        else:
            if callable(initializer):
                self._shape = self._validate_shape(shape)
                self._initialize_with_initializer(initializer)
            else:
>               self._initialize(initializer)

/opt/fw/tensorflow/keras/src/backend/common/variables.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <KerasVariable shape=<unknown>, dtype=float32, path=variable_57>, value = <tf.Tensor: shape=(), dtype=int64, numpy=79200>

    def _initialize(self, value):
>       self._value = tf.Variable(
            value, dtype=self._dtype, trainable=self.trainable, name=self.name
        )

/opt/fw/tensorflow/keras/src/backend/tensorflow/core.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<class 'tensorflow.python.ops.variables.Variable'>, <tf.Tensor: shape=(), dtype=int64, numpy=79200>), kwargs = {'dtype': 'float32', 'name': 'variable_57', 'trainable': True}

    def error_handler(*args, **kwargs):
      try:
        if not is_traceback_filtering_enabled():
          return fn(*args, **kwargs)
      except NameError:
        # In some very rare cases,
        # `is_traceback_filtering_enabled` (from the outer scope) may not be
        # accessible from inside this function
        return fn(*args, **kwargs)
    
      filtered_tb = None
      try:
        return fn(*args, **kwargs)
      except Exception as e:
        filtered_tb = _process_traceback_frames(e.__traceback__)
>       raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/tensorflow/python/util/traceback_utils.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(), dtype=int64, numpy=79200>, dtype = tf.float32, name = 'initial_value'

    def __tf_tensor__(
        self, dtype: Optional[dtypes.DType] = None, name: Optional[str] = None
        ) -> "Tensor":
      if dtype is not None and not dtype.is_compatible_with(self.dtype):
>       raise ValueError(
            _add_error_prefix(
                f"Tensor conversion requested dtype {dtype.name} "
                f"for Tensor with dtype {self.dtype.name}: {self!r}",
                name=name))
E       ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtype=int64, numpy=79200>

/opt/fw/tensorflow/tensorflow/python/framework/tensor.py:761: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.EdgeDetector
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/DexiNed_BIPED_10.pth" to /root/.cache/torch/hub/checkpoints/DexiNed_BIPED_10.pth

  0%|          | 0.00/135M [00:00<?, ?B/s]
  0%|          | 128k/135M [00:00<08:20, 281kB/s]
  0%|          | 256k/135M [00:00<05:04, 463kB/s]
  0%|          | 512k/135M [00:00<02:45, 849kB/s]
  1%|          | 896k/135M [00:00<01:41, 1.38MB/s]
  1%|         | 1.75M/135M [00:01<00:50, 2.77MB/s]
  3%|         | 3.50M/135M [00:01<00:24, 5.54MB/s]
  5%|         | 6.50M/135M [00:01<00:13, 10.0MB/s]
  7%|         | 9.50M/135M [00:01<00:10, 12.8MB/s]
  9%|         | 11.9M/135M [00:01<00:09, 13.5MB/s]
 11%|         | 14.8M/135M [00:01<00:08, 15.2MB/s]
 13%|        | 17.1M/135M [00:02<00:07, 15.5MB/s]
 15%|        | 20.1M/135M [00:02<00:07, 16.9MB/s]
 17%|        | 23.0M/135M [00:02<00:06, 17.7MB/s]
 19%|        | 26.0M/135M [00:02<00:06, 18.4MB/s]
 22%|       | 29.0M/135M [00:02<00:05, 19.0MB/s]
 24%|       | 32.0M/135M [00:02<00:05, 19.3MB/s]
 26%|       | 34.9M/135M [00:02<00:05, 19.4MB/s]
 28%|       | 37.5M/135M [00:03<00:05, 18.9MB/s]
 30%|       | 40.5M/135M [00:03<00:05, 19.3MB/s]
 32%|      | 43.5M/135M [00:03<00:04, 19.6MB/s]
 35%|      | 46.5M/135M [00:03<00:04, 19.8MB/s]
 37%|      | 49.5M/135M [00:03<00:04, 19.9MB/s]
 39%|      | 52.5M/135M [00:03<00:04, 20.0MB/s]
 41%|     | 55.5M/135M [00:04<00:04, 20.1MB/s]
 43%|     | 58.1M/135M [00:04<00:04, 19.1MB/s]
 45%|     | 60.0M/135M [00:04<00:04, 16.2MB/s]
 46%|     | 61.6M/135M [00:04<00:04, 15.5MB/s]
 47%|     | 63.2M/135M [00:04<00:05, 14.2MB/s]
 49%|     | 66.1M/135M [00:04<00:04, 15.8MB/s]
 51%|     | 68.6M/135M [00:04<00:04, 16.1MB/s]
 53%|    | 71.6M/135M [00:05<00:03, 17.4MB/s]
 55%|    | 74.6M/135M [00:05<00:03, 18.2MB/s]
 58%|    | 77.6M/135M [00:05<00:03, 18.8MB/s]
 60%|    | 80.6M/135M [00:05<00:02, 19.2MB/s]
 62%|   | 83.1M/135M [00:05<00:02, 18.6MB/s]
 64%|   | 86.1M/135M [00:05<00:02, 19.1MB/s]
 66%|   | 89.1M/135M [00:06<00:02, 19.4MB/s]
 68%|   | 92.1M/135M [00:06<00:02, 19.7MB/s]
 71%|   | 95.1M/135M [00:06<00:02, 19.8MB/s]
 73%|  | 98.0M/135M [00:06<00:01, 19.7MB/s]
 75%|  | 101M/135M [00:06<00:01, 19.9MB/s] 
 77%|  | 104M/135M [00:06<00:01, 20.0MB/s]
 79%|  | 107M/135M [00:07<00:01, 19.3MB/s]
 81%| | 110M/135M [00:07<00:01, 19.6MB/s]
 84%| | 113M/135M [00:07<00:01, 19.7MB/s]
 86%| | 116M/135M [00:07<00:01, 19.6MB/s]
 88%| | 118M/135M [00:07<00:00, 19.8MB/s]
 90%| | 122M/135M [00:07<00:00, 19.9MB/s]
 92%|| 124M/135M [00:07<00:00, 19.8MB/s]
 94%|| 127M/135M [00:08<00:00, 19.2MB/s]
 97%|| 130M/135M [00:08<00:00, 19.5MB/s]
 99%|| 133M/135M [00:08<00:00, 19.7MB/s]
100%|| 135M/135M [00:08<00:00, 16.7MB/s]
__________________________________________________________________________________ test_KMeans[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_KMeans(target_framework, mode, backend_compile):
        print("kornia.contrib.KMeans")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledKMeans = ivy.transpile(kornia.contrib.KMeans, source="torch", target=target_framework)
    
        torch_kmeans = kornia.contrib.KMeans(3, None, 10e-4, 100, 0)
        transpiled_kmeans = TranspiledKMeans(3, None, 10e-4, 100, 0)
    
        torch_x1 = torch.rand((1000, 5))
        torch_x2 = torch.rand((10, 5))
        transpiled_x1 = _array_to_new_backend(torch_x1, target_framework)
        transpiled_x2 = _array_to_new_backend(torch_x2, target_framework)
    
        torch_kmeans.fit(torch_x1)
        torch_predictions = torch_kmeans.predict(torch_x2)
    
>       transpiled_kmeans.fit(transpiled_x1)

kornia/test_contrib.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.tensorflow_outputs.kornia.contrib.kmeans.tensorflow_KMeans object at 0x7ff021f00100>
X = <tf.Tensor: shape=(1000, 5), dtype=float32, numpy=
array([[0.4962566 , 0.7682218 , 0.08847743, 0.13203049, 0.30742282]...5, 0.49248123, 0.4287302 ],
       [0.3786084 , 0.04217941, 0.28761953, 0.5166052 , 0.11317676]],
      dtype=float32)>

    def fit(self, X):
        from ..core.check import tensorflow_KORNIA_CHECK
        from ..core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_argmin_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clone_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_nonzero_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_index_select_frnt,
        )
        from ...ivy.functional.frontends.torch.random_sampling import (
            tensorflow_randint_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import tensorflow_sqrt_frnt
    
        tensorflow_KORNIA_CHECK_SHAPE(X, ["N", "D"])
        if self._cluster_centers is None:
            self._cluster_centers = self._initialise_cluster_centers(
                X, self.num_clusters
            )
        else:
            tensorflow_KORNIA_CHECK(
                tensorflow_shape_frnt_(X)[1]
                == tensorflow_shape_frnt_(self._cluster_centers)[1],
                f"Dimensions at position 1 of X and cluster_centers do not match.                 {tensorflow_shape_frnt_(X)[1]} != {tensorflow_shape_frnt_(self._cluster_centers)[1]}",
            )
        current_centers = self._cluster_centers
        previous_centers: typing.Any = None
        iteration: typing.Any = 0
        while True:
            distance: typing.Any = self._pairwise_euclidean_distance(X, current_centers)
            cluster_assignment = tensorflow_argmin_frnt_(distance, -1)
            previous_centers = tensorflow_clone_frnt_(current_centers)
            for index in range(self.num_clusters):
                selected = tensorflow_squeeze_frnt_(
                    tensorflow_nonzero_frnt(cluster_assignment == index)
                )
                selected = tensorflow_index_select_frnt(X, 0, selected)
                if tensorflow_shape_frnt_(selected)[0] == 0:
                    selected = X[tensorflow_randint_frnt(len(X), (1,), device=X.device)]
>               current_centers[index] = tensorflow_mean_frnt_(selected, dim=0)
E               TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/kmeans.py:146: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.KMeans
_______________________________________________________________________________ test_ImageStitcher[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageStitcher(target_framework, mode, backend_compile):
        print("kornia.contrib.ImageStitcher")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledLoFTR = ivy.transpile(kornia.feature.LoFTR, source="torch", target=target_framework)
        TranspiledImageStitcher = ivy.transpile(kornia.contrib.ImageStitcher, source="torch", target=target_framework)
    
        torch_matcher = kornia.feature.LoFTR(pretrained='outdoor')
>       transpiled_matcher = TranspiledLoFTR(pretrained='outdoor')

kornia/test_contrib.py:314: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_LoFTR(), pretrained = 'outdoor'
config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def __init__(self, pretrained="outdoor", config=default_cfg):
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from .backbone.__init__ import tensorflow_build_backbone
        from .utils.position_encoding import tensorflow_PositionEncodingSine
        from .loftr_module.transformer import tensorflow_LocalFeatureTransformer
        from .utils.coarse_matching import tensorflow_CoarseMatching
        from .loftr_module.fine_preprocess import tensorflow_FinePreprocess
        from .utils.fine_matching import tensorflow_FineMatching
        from ....ivy.functional.frontends.torch.hub.hub import (
            tensorflow_load_state_dict_from_url_frnt,
        )
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_map_location_to_cpu
    
        self.super___init__(
            pretrained=pretrained,
            config=config,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.config = config
        if pretrained == "indoor_new":
            self.config["coarse"] = tensorflow_set_item(
                self.config["coarse"], "temp_bug_fix", True
            )
>       self.backbone = tensorflow_build_backbone(config)

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/loftr.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

config = {'backbone_type': 'ResNetFPN', 'coarse': {'attention': 'linear', 'd_ffn': 256, 'd_model': 256, 'layer_names': ['self',...: 'linear', 'd_ffn': 128, 'd_model': 128, 'layer_names': ['self', 'cross'], ...}, 'fine_concat_coarse_feat': True, ...}

    def tensorflow_build_backbone(config):
        if config["backbone_type"] == "ResNetFPN":
            if config["resolution"] == (8, 2):
>               return kornia.feature.loftr.resnet_fpn.ResNetFPN_8_2(config["resnetfpn"])
E               NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/loftr/backbone/__init__.py:41: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.ImageStitcher
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<02:53, 266kB/s]
  1%|          | 256k/44.2M [00:00<01:45, 438kB/s]
  1%|          | 512k/44.2M [00:00<00:57, 802kB/s]
  2%|         | 896k/44.2M [00:00<00:34, 1.30MB/s]
  4%|         | 1.75M/44.2M [00:01<00:17, 2.62MB/s]
  8%|         | 3.50M/44.2M [00:01<00:08, 5.22MB/s]
 15%|        | 6.50M/44.2M [00:01<00:04, 9.39MB/s]
 21%|       | 9.50M/44.2M [00:01<00:02, 12.3MB/s]
 28%|       | 12.5M/44.2M [00:01<00:02, 14.4MB/s]
 35%|      | 15.5M/44.2M [00:01<00:01, 15.8MB/s]
 42%|     | 18.5M/44.2M [00:02<00:01, 16.8MB/s]
 48%|     | 21.4M/44.2M [00:02<00:01, 17.2MB/s]
 55%|    | 24.2M/44.2M [00:02<00:01, 17.6MB/s]
 62%|   | 27.2M/44.2M [00:02<00:00, 18.0MB/s]
 68%|   | 30.2M/44.2M [00:02<00:00, 18.4MB/s]
 75%|  | 33.2M/44.2M [00:02<00:00, 18.6MB/s]
 82%| | 36.2M/44.2M [00:03<00:00, 18.7MB/s]
 88%| | 38.9M/44.2M [00:03<00:00, 18.1MB/s]
 95%|| 41.9M/44.2M [00:03<00:00, 18.4MB/s]
100%|| 44.2M/44.2M [00:03<00:00, 13.3MB/s]
__________________________________________________________________________________ test_Lambda[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Lambda(target_framework, mode, backend_compile):
        print("kornia.contrib.Lambda")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        transpiled_fn = ivy.transpile(kornia.color.rgb_to_grayscale, source="torch", target=target_framework)
        TranspiledLambda = ivy.transpile(kornia.contrib.Lambda, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 5, 5)
        torch_out = kornia.contrib.Lambda(lambda x: kornia.color.rgb_to_grayscale(x))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
>       transpiled_out = TranspiledLambda(lambda x: transpiled_fn(x))(transpiled_x)

kornia/test_contrib.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Lambda()
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.647...5066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5577d98e0f80, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Lambda(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.952068...75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Lambda(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.647...5066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Lambda(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.952068...75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Lambda(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.647...5066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474....75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img, *args, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Lambda(),)
kwargs = {'img': <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495...75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Lambda()
img = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474....75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>
args = (), kwargs = {}

    def call(self, img, *args, **kwargs):
>       return self.func(img, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/kornia/contrib/lambda_module.py:50: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474....75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>

>   transpiled_out = TranspiledLambda(lambda x: transpiled_fn(x))(transpiled_x)

kornia/test_contrib.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.24838495, 0.16381115, 0.9520681 , 0.86008495, 0.6474....75066984, 0.3293057 ],
         [0.561671  , 0.05817503, 0.5122101 , 0.06966799, 0.7259842 ]]]],
      dtype=float32)>
rgb_weights = None

>   ???
E   ModuleNotFoundError: Exception encountered when calling tensorflow_Lambda.call().
E   
E   [1mNo module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.core'[0m
E   
E   Arguments received by tensorflow_Lambda.call():
E      img=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)
E      args=<class 'inspect._empty'>
E      kwargs=<class 'inspect._empty'>

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/color/gray.py:34: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.Lambda
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[tensorflow-s2s-False] - KeyError: tensor([[[[0.3333, 1.0000, 0.3333],
FAILED kornia/test_contrib.py::test_EdgeDetector[tensorflow-s2s-False] - ValueError: initial_value: Tensor conversion requested dtype float32 for Tensor with dtype int64: <tf.Tensor: shape=(), dtyp...
FAILED kornia/test_contrib.py::test_KMeans[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/test_contrib.py::test_ImageStitcher[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/test_contrib.py::test_Lambda[tensorflow-s2s-False] - ModuleNotFoundError: Exception encountered when calling tensorflow_Lambda.call().
============================================================================== 5 failed, 10 passed in 1768.74s (0:29:28) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ............................................                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 44 passed in 3325.00s (0:55:24) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 7 items

kornia/test_morphology.py .......                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 7 passed in 581.19s (0:09:41) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 69 items

kornia/test_color.py ...........F...........F..........F.........F...........F........F..F                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________________ test_rgb_to_hls[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_hls(target_framework, mode, backend_compile):
        # Note: We test this function with requires_grad=True,
        # because otherwise we simply get an empty_like tensor
        # with garbage values on each run leading to test failures
        trace_args = (
            torch.rand(1, 3, 4, 5).requires_grad_(True),
        )
        trace_kwargs = {'eps': 1e-8}
        test_args = (
            torch.rand(5, 3, 4, 5).requires_grad_(True),
        )
        test_kwargs = {'eps': 1e-8}
>       _test_function(
            kornia.color.rgb_to_hls,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f44b8fadea0>
trace_args = (tensor([[[[0.5146, 0.4596, 0.4096, 0.4084, 0.5543],
          [0.9840, 0.4225, 0.4872, 0.8236, 0.5302],
          [0.... [0.8897, 0.2784, 0.0462, 0.2084, 0.7924],
          [0.4994, 0.2137, 0.8898, 0.1000, 0.3012]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.2777, 0.4053, 0.9826, 0.3437, 0.8500],
          [0.1239, 0.9196, 0.5271, 0.5058, 0.8662],
          [0.... [0.0129, 0.0359, 0.9941, 0.9780, 0.3049],
          [0.8813, 0.5782, 0.2893, 0.2212, 0.4575]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_hls at 0x7f44b8fadea0>, fn_name = 'kornia.color.rgb_to_hls'
trace_args = (tensor([[[[0.5146, 0.4596, 0.4096, 0.4084, 0.5543],
          [0.9840, 0.4225, 0.4872, 0.8236, 0.5302],
          [0.... [0.8897, 0.2784, 0.0462, 0.2084, 0.7924],
          [0.4994, 0.2137, 0.8898, 0.1000, 0.3012]]]], requires_grad=True),)
trace_kwargs = {'eps': 1e-08}
test_args = (tensor([[[[0.2777, 0.4053, 0.9826, 0.3437, 0.8500],
          [0.1239, 0.9196, 0.5271, 0.5058, 0.8662],
          [0.... [0.0129, 0.0359, 0.9941, 0.9780, 0.3049],
          [0.8813, 0.5782, 0.2893, 0.2212, 0.4575]]]], requires_grad=True),)
test_kwargs = {'eps': 1e-08}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[1.5443, 3.5199, 6.0106, 5.6493, 5.0462],
          [6.1092, 4.3226, 1.3408, 0.5024, 1.3555],
          [5.3....8958, 0.9009, 0.7348, 0.4859],
          [0.6338, 0.1800, 0.5864, 0.8774, 0.4687]]]],
       grad_fn=<StackBackward0>)
transpiled_x = Array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[1.5442675 , 3.5198598 , 6.0105724 , 5.649317  , 5.046181  ],
         [6.109161  , 4.3226357 , 1.3407772 , 0...0.7347592 , 0.48585373],
         [0.63379693, 0.17998146, 0.58644694, 0.87736374, 0.46874464]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.rgb_to_hls
__________________________________________________________________________________ test_rgb_to_yuv420[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_rgb_to_yuv420(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 6),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 4, 6),
        )
        test_kwargs = {}
>       _test_function(
            kornia.color.rgb_to_yuv420,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_color.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f44b8fafbe0>
trace_args = (tensor([[[[0.5300, 0.0830, 0.7387, 0.4745, 0.6328, 0.3489],
          [0.2843, 0.2246, 0.3388, 0.7635, 0.4720, 0.4720...     [0.8179, 0.5281, 0.1919, 0.3723, 0.2248, 0.7384],
          [0.7221, 0.5411, 0.9833, 0.4681, 0.6393, 0.5305]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[3.4482e-01, 4.4221e-01, 7.3333e-01, 3.3076e-01, 8.6712e-01,
           5.6498e-01],
          [4.9245e-01,...       8.8879e-02],
          [8.6381e-01, 6.1161e-01, 6.7198e-01, 4.9014e-01, 6.3203e-01,
           6.9196e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function rgb_to_yuv420 at 0x7f44b8fafbe0>, fn_name = 'kornia.color.rgb_to_yuv420'
trace_args = (tensor([[[[0.5300, 0.0830, 0.7387, 0.4745, 0.6328, 0.3489],
          [0.2843, 0.2246, 0.3388, 0.7635, 0.4720, 0.4720...     [0.8179, 0.5281, 0.1919, 0.3723, 0.2248, 0.7384],
          [0.7221, 0.5411, 0.9833, 0.4681, 0.6393, 0.5305]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[3.4482e-01, 4.4221e-01, 7.3333e-01, 3.3076e-01, 8.6712e-01,
           5.6498e-01],
          [4.9245e-01,...       8.8879e-02],
          [8.6381e-01, 6.1161e-01, 6.7198e-01, 4.9014e-01, 6.3203e-01,
           6.9196e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[0.3940, 0.6298, 0.2775, 0.3981, 0.3792, 0.5228],
          [0.6388, 0.5107, 0.3907, 0.5902, 0.6003, 0.7035...       [ 0.0606, -0.0236,  0.0136]],

         [[-0.2306,  0.1446, -0.0614],
          [ 0.1312,  0.2433,  0.0517]]]]))
transpiled_x = (Array([[[[0.39404163, 0.6297935 , 0.27747917, 0.3980586 , 0.37919495,
          0.5227795 ],
         [0.6387988 , 0....
        [[ 0.27292672, -0.06530358,  0.04715233],
         [-0.02642285, -0.07243004,  0.12270943]]]], dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.39404163, 0.6297935 , 0.27747917, 0.3980586 , 0.37919495,
          0.5227795 ],
         [0.6387988 , 0....
        [[-0.23063275,  0.14455895, -0.06141367],
         [ 0.13119726,  0.24325863,  0.0516636 ]]]], dtype=float32))
y = (array([[[[0.39404163, 0.6297935 , 0.27747917, 0.3980586 , 0.37919495,
          0.5227795 ],
         [0.6387988 , 0....
        [[ 0.27292672, -0.06530358,  0.04715233],
         [-0.02642285, -0.07243004,  0.12270943]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f4461fd8200>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[ 0.02372566,  0.01988545, -0.19912623],
         [ 0.06064944, -0.02362251,  0.01364248]],

        [[-0.23063275,  0.14455895, -0.06141367],
         [ 0.13119726,  0.24325863,  0.0516636 ]]]], dtype=float32)
y = array([[[[ 0.0330028 , -0.14329411, -0.02515207],
         [ 0.07111371, -0.02219323, -0.01832281]],

        [[ 0.27292672, -0.06530358,  0.04715233],
         [-0.02642285, -0.07243004,  0.12270943]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.rgb_to_yuv420
__________________________________________________________________________________ test_RgbToGrayscale[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToGrayscale(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToGrayscale,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:776: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.gray.RgbToGrayscale'>
args = (tensor([[[[0.7322, 0.1675, 0.1051, 0.6219, 0.1426],
          [0.3666, 0.5546, 0.4065, 0.7975, 0.2823],
          [0...., 0.3151],
          [0.3704, 0.2841, 0.0604, 0.6435, 0.9632],
          [0.4883, 0.8245, 0.6422, 0.6305, 0.8039]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
>       transpiled_out = transpiled_obj(*transpile_args)

kornia/test_color.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RgbToGrayscale()
image = Array([[[[0.73217803, 0.16745251, 0.10513687, 0.6219176 , 0.14262253],
         [0.3666392 , 0.55463225, 0.4064871 , 0... 0.6435224 , 0.96316034],
         [0.48830163, 0.82454085, 0.6422057 , 0.6305456 , 0.80385596]]]],      dtype=float32)

    def __call__(self, image):
>       return jax_rgb_to_grayscale(image, rgb_weights=self.rgb_weights)

ivy_transpiled_outputs/jax_outputs/kornia/color/gray.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

image = Array([[[[0.73217803, 0.16745251, 0.10513687, 0.6219176 , 0.14262253],
         [0.3666392 , 0.55463225, 0.4064871 , 0... 0.6435224 , 0.96316034],
         [0.48830163, 0.82454085, 0.6422057 , 0.6305456 , 0.80385596]]]],      dtype=float32)
rgb_weights = Param(
  value=[0.299, 0.587, 0.114]
)

    def jax_rgb_to_grayscale(image, rgb_weights=None):
        from ..core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unbind_frnt_
    
        jax_KORNIA_CHECK_IS_TENSOR(image)
        if len(jax_shape_frnt_(image)) < 3 or jax_shape_frnt_(image)[-3] != 3:
            raise ValueError(
                f"Input size must have a shape of (*, 3, H, W). Got {jax_shape_frnt_(image)}"
            )
        if rgb_weights is None:
            if image.dtype == jnp.uint8:
                rgb_weights = jax_tensor_frnt(
                    [76, 150, 29], device=image.device, dtype=jnp.uint8
                )
            elif image.dtype in (jnp.float16, jnp.float32, jnp.float64):
                rgb_weights = jax_tensor_frnt(
                    [0.299, 0.587, 0.114], device=image.device, dtype=image.dtype
                )
            else:
                raise TypeError(f"Unknown data type: {image.dtype}")
        else:
>           rgb_weights = jax_to_frnt_(rgb_weights, image)

ivy_transpiled_outputs/jax_outputs/kornia/color/gray.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Param(
  value=[0.299, 0.587, 0.114]
), Array([[[[0.73217803, 0.16745251, 0.10513687, 0.6219176 , 0.14262253],
      ...0.6435224 , 0.96316034],
         [0.48830163, 0.82454085, 0.6422057 , 0.6305456 , 0.80385596]]]],      dtype=float32))
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f4465ef4a60>, array_like = Param(
  value=[0.299, 0.587, 0.114]
)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Param(
  value=[0.299, 0.587, 0.114]
)
args = (Array([[[[0.73217803, 0.16745251, 0.10513687, 0.6219176 , 0.14262253],
         [0.3666392 , 0.55463225, 0.4064871 , ....6435224 , 0.96316034],
         [0.48830163, 0.82454085, 0.6422057 , 0.6305456 , 0.80385596]]]],      dtype=float32),)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7f4465ef4a60>, jax_dev = <function jax_dev at 0x7f4465ef5900>, jax_dtype = <function jax_dtype at 0x7f4465ef5750>
jax_check_elem_in_list = <function jax_check_elem_in_list at 0x7f4465ef7520>, jax_as_ivy_dev = <function jax_as_ivy_dev at 0x7f4465ef5a20>, jax_asarray = <function jax_asarray at 0x7f4465ef5240>
_all_ivy_dtypes_str = ('int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', ...), device = 'cpu', dtype = 'float32'
arg = Array([[[[0.73217803, 0.16745251, 0.10513687, 0.6219176 , 0.14262253],
         [0.3666392 , 0.55463225, 0.4064871 , 0... 0.6435224 , 0.96316034],
         [0.48830163, 0.82454085, 0.6422057 , 0.6305456 , 0.80385596]]]],      dtype=float32)

    @jax_handle_methods
    def jax_to_frnt_(tensor, *args, **kwargs):
        from ...ivy.general import jax_is_array_bknd
        from ...backends.jax.device import jax_dev
        from ...backends.jax.data_type import jax_dtype
        from ....utils.assertions import jax_check_elem_in_list
        from ...backends.jax.device import jax_as_ivy_dev
        from ...backends.jax.creation import jax_asarray
        from ....__init__ import _all_ivy_dtypes_str
    
        device = None
        dtype = None
        for arg in args:
            if hasattr(arg, "ivy_array") or jax_is_array_bknd(arg):
                device = jax_dev(arg)
                dtype = jax_dtype(arg)
            elif (
                isinstance(arg, (np.dtype,))
                or isinstance(arg, (str,))
                and hasattr(arg, "as_native_dtype")
                or arg in _all_ivy_dtypes_str
            ):
                dtype = arg
            elif isinstance(arg, (str, jax.Device, str)):
                if isinstance(arg, (str,)) and not isinstance(arg, (str, jax.Device)):
                    jax_check_elem_in_list(
                        arg,
                        [
                            "cpu",
                            "cuda",
                            "mps",
                            "xpu",
                            "mkldnn",
                            "opengl",
                            "opencl",
                            "ideep",
                            "hip",
                            "ve",
                            "ort",
                            "mlc",
                            "xla",
                            "lazy",
                            "vulkan",
                            "meta",
                            "hpu",
                        ],
                    )
                device = arg
        if "device" in kwargs:
            device = kwargs["device"]
        if "dtype" in kwargs:
            dtype = kwargs["dtype"]
>       if (dtype is None or tensor.dtype == dtype) and (
            device is None or tensor.device == jax_as_ivy_dev(device)
        ):

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Param(
  value=[0.299, 0.587, 0.114]
), name = 'dtype'

    def custom_getattr(self, name):
        if name in ("shape", "device", "dtype", "ndim", "size", "itemsize", "T"):
            value = getattr(self, "value")
            if value is not None:
                # Attempt to retrieve the attribute from the wrapped object (`value`)
>               return getattr(value, name)
E               AttributeError: 'list' object has no attribute 'dtype'

ivy_transpiled_outputs/jax_outputs/__init__.py:90: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.gray.RgbToGrayscale
_____________________________________________________________________________________ test_RgbToHls[jax-s2s-False] _____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToHls(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 5),
        )
>       _test_color_class(
            kornia.color.RgbToHls,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:908: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.hls.RgbToHls'>
args = (tensor([[[[0.0420, 0.8991, 0.1010, 0.7759, 0.3210],
          [0.9270, 0.1485, 0.8939, 0.3771, 0.9738],
          [0...., 0.2331],
          [0.5721, 0.3705, 0.3937, 0.0674, 0.0409],
          [0.4160, 0.3498, 0.0782, 0.9107, 0.2942]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[2.9189212 , 0.04070779, 2.944206  , 0.12714943, 3.4109573 ],
         [6.0567713 , 2.7431233 , 1.1851693 , 1...0.8035683 , 0.89451325],
         [0.87190574, 0.6697154 , 0.8269468 , 0.78772926, 0.45493308]]]],
      dtype=float32)
y = array([[[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0.,...0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.hls.RgbToHls
___________________________________________________________________________________ test_RgbToYuv420[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RgbToYuv420(target_framework, mode, backend_compile):
        args = (
            torch.rand(2, 3, 4, 6),
        )
>       _test_color_class(
            kornia.color.RgbToYuv420,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1064: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.yuv.RgbToYuv420'>
args = (tensor([[[[0.8855, 0.3863, 0.7864, 0.5771, 0.8343, 0.5426],
          [0.1789, 0.2730, 0.7736, 0.7378, 0.9279, 0.9903...     [0.2704, 0.1735, 0.1795, 0.5784, 0.3303, 0.6690],
          [0.5802, 0.5271, 0.2266, 0.9269, 0.3239, 0.3866]]]]),)
target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
        transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)
    
        torch_out = torch_obj(*args)
        transpile_args = _nest_torch_tensor_to_new_framework(args, target)
        transpiled_out = transpiled_obj(*transpile_args)
    
        orig_np = _nest_array_to_numpy(torch_out)
        graph_np = _nest_array_to_numpy(transpiled_out)
    
>       _check_allclose(orig_np, graph_np, tolerance=tolerance)

kornia/test_color.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[0.37925407, 0.68392986, 0.31813976, 0.54283524, 0.55916107,
          0.55855906],
         [0.58808994, 0....
        [[-0.19041601, -0.00548077,  0.14811906],
         [ 0.20003308,  0.02162537,  0.09146954]]]], dtype=float32))
y = (array([[[[0.37925407, 0.68392986, 0.31813976, 0.54283524, 0.55916107,
          0.55855906],
         [0.58808994, 0....
        [[ 0.08030862,  0.0489165 , -0.07012054],
         [ 0.02005644,  0.26646924, -0.08027999]]]], dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f442cb56c00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[-0.04938417,  0.00658382, -0.13986753],
         [ 0.01857491,  0.08318904, -0.06280804]],

        [[-0.094...

        [[-0.19041601, -0.00548077,  0.14811906],
         [ 0.20003308,  0.02162537,  0.09146954]]]], dtype=float32)
y = array([[[[ 0.03417655, -0.05453772, -0.13222799],
         [ 0.1079215 , -0.08626992, -0.01277439]],

        [[ 0.232...

        [[ 0.08030862,  0.0489165 , -0.07012054],
         [ 0.02005644,  0.26646924, -0.08027999]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.yuv.RgbToYuv420
______________________________________________________________________________________ test_Sepia[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Sepia(target_framework, mode, backend_compile):
        args = (
            torch.ones(3, 1, 1),
        )
>       _test_color_class(
            kornia.color.Sepia,
            args,
            target_framework,
            backend_compile,
            tolerance=1e-3,
        )

kornia/test_color.py:1198: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'kornia.color.sepia.Sepia'>, args = (tensor([[[1.]],

        [[1.]],

        [[1.]]]),), target = 'jax', backend_compile = False, tolerance = 0.001, init_args = ()

    def _test_color_class(
        cls,
        args,
        target,
        backend_compile=False,
        tolerance=1e-3,
        init_args=(),
    ):
        print(f"{cls.__module__}.{cls.__name__}")
    
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
    
        torch_obj = cls(*init_args)
>       transpiled_obj = eval("transpiled_" + f"{cls.__module__}.{cls.__name__}")(*init_args)

kornia/test_color.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'

<string>:1: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.sepia.Sepia
__________________________________________________________________________________ test_apply_colormap[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_apply_colormap(target_framework, mode, backend_compile):
        print("kornia.color.ColorMap")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledColorMapType = ivy.transpile(kornia.color.ColorMapType, source="torch", target=target_framework)
        TranspiledColorMap = ivy.transpile(kornia.color.ColorMap, source="torch", target=target_framework)
        transpiled_apply_colormap = ivy.transpile(kornia.color.apply_colormap, source="torch", target=target_framework)
    
        torch_x = torch.tensor([[[0, 1, 2], [15, 25, 33], [128, 158, 188]]])
        transpiled_x = _array_to_new_backend(torch_x, target_framework)
    
        colormap = kornia.color.ColorMap(base=kornia.color.ColorMapType.autumn)
        torch_out = kornia.color.apply_colormap(torch_x, colormap)
    
>       colormap = TranspiledColorMap(base=TranspiledColorMapType.autumn)

kornia/test_color.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ivy_transpiled_outputs.jax_outputs.kornia.color.colormap.jax_ColorMap object at 0x7f4418564820>, base = <jax_ColorMapType.autumn: 1>, num_colors = 64, device = None, dtype = None

>   ???

ivy_transpiled_outputs/jax_outputs/kornia/color/colormap.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jax_ColorMapType.autumn: 1>

        f"`input_tensor` must be a Tensor. Got: {type(input_tensor)}",
    )
>   valid_types = [
        jnp.float16,
        jnp.float32,
        jnp.float64,
        jnp.uint8,
        jnp.int32,
        jnp.int64,
        jnp.int16,
    ]
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.color._colormap_data'

ivy_transpiled_outputs/jax_outputs/kornia/color/colormap.py:53: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.color.ColorMap
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_color.py::test_rgb_to_hls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_rgb_to_yuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToGrayscale[jax-s2s-False] - AttributeError: 'list' object has no attribute 'dtype'
FAILED kornia/test_color.py::test_RgbToHls[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_RgbToYuv420[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/test_color.py::test_Sepia[jax-s2s-False] - AttributeError: '_cython_3_0_11.cython_function_or_method' object has no attribute 'Sepia'
FAILED kornia/test_color.py::test_apply_colormap[jax-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.jax_outputs.kornia.color._colormap_data'
============================================================================== 7 failed, 62 passed in 3805.92s (1:03:25) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 39 items

kornia/test_enhance.py ....F....F...FFFFF........sssssssssssss                                                                                                                                   [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_adjust_gamma[numpy-s2s-False] __________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_adjust_gamma(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 2, 2),
            2.2,
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 1, 2, 2),
            0.4,
        )
        test_kwargs = {}
>       _test_function(
            kornia.enhance.adjust_gamma,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f9253aa6b00>, trace_args = (tensor([[[[0.4047, 0.1547],
          [0.6467, 0.9761]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.5842, 0.5248],
          [0.5628, 0.2298]]],


        [[[0.5917, 0.4881],
          [0.8595, 0.0407]]],...   [[[0.7050, 0.1726],
          [0.9128, 0.9668]]],


        [[[0.1065, 0.3372],
          [0.1469, 0.8215]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function adjust_gamma at 0x7f9253aa6b00>, fn_name = 'kornia.enhance.adjust_gamma', trace_args = (tensor([[[[0.4047, 0.1547],
          [0.6467, 0.9761]]]]), 2.2), trace_kwargs = {}
test_args = (tensor([[[[0.5842, 0.5248],
          [0.5628, 0.2298]]],


        [[[0.5917, 0.4881],
          [0.8595, 0.0407]]],...   [[[0.7050, 0.1726],
          [0.9128, 0.9668]]],


        [[[0.1065, 0.3372],
          [0.1469, 0.8215]]]]), 0.4)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.40467757, 0.1546548 ],
         [0.6466936 , 0.976053  ]]]], dtype=float32), gamma = 2.2, gain = 1.0

    def numpy_adjust_gamma(input, gamma, gain=1.0):
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_any_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_unsqueeze_frnt,
        )
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_pow_frnt
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_clamp_frnt
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(gamma, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gamma should be a positive float or Tensor. Got {type(gamma)}"
            )
        if not isinstance(gain, (float, numpy.ndarray, numpy.ndarray)):
            raise TypeError(
                f"The gain should be a positive float or Tensor. Got {type(gain)}"
            )
        if isinstance(gamma, (float,)):
>           gamma = numpy.ndarray([gamma])
E           TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:52: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.adjust_gamma
_____________________________________________________________________________________ test_invert[numpy-s2s-False] _____________________________________________________________________________________

>   ???

VM.pyx:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """
    Copyright (c) 2024 Transpile AI Ltd. All rights reserved.
    
    This file is automatically generated by Transpile AI Ltd.'s software.
    
    License: Non-Enterprise Use Only
    
    This software is licensed for personal, educational, or non-commercial use only.
    Non-commercial use includes personal projects, educational purposes, or other activities
    that do not generate revenue or are not used in any business, organization, or institution.
    Commercial, production, or enterprise useincluding any use in a for-profit business environment, within an organization,
    or in a revenue-generating activityis strictly prohibited without a valid enterprise contract with Transpile AI Ltd.
    Unauthorized enterprise use may result in legal action, including but not limited to injunctions, damages, and financial penalties.
    
    To obtain an enterprise license, please visit https://ivy.dev/ or contact enterprise@ivy.dev.
    
    Redistribution: You may not distribute, sublicense, or sell copies of the generated source code or
    any derivative works thereof without express written permission from Transpile AI Ltd.
    
    Termination: This license automatically terminates upon failure to comply with any of its terms and conditions.
    Upon termination, you must immediately cease all use of the software and destroy any copies in your possession.
    
    Disclaimer: This software is provided "AS IS", WITHOUT WARRANTY OF ANY KIND, either express or implied.
    Transpile AI Ltd. disclaims all liability for damages or liabilities arising from the use of this software, to the fullest extent permitted by law.
    """
    
    import numpy
    
    
>   def numpy_invert(image, max_val=numpy.ndarray([1.0])):
E   TypeError: 'float' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:30: TypeError

During handling of the above exception, another exception occurred:

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_invert(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 1, 2, 2),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 1, 2, 2),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.invert,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f9253aa7640>, trace_args = (tensor([[[[0.0949, 0.5717],
          [0.1772, 0.2374]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.4054, 0.9728],
          [0.8148, 0.4139]]],


        [[[0.9144, 0.1731],
          [0.1080, 0.9396]]],...       [[[0.1547, 0.9068],
          [0.3576, 0.6836]]],


        [[[0.5877, 0.5453],
          [0.2302, 0.0702]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function invert at 0x7f9253aa7640>, fn_name = 'kornia.enhance.invert', trace_args = (tensor([[[[0.0949, 0.5717],
          [0.1772, 0.2374]]]]),), trace_kwargs = {}
test_args = (tensor([[[[0.4054, 0.9728],
          [0.8148, 0.4139]]],


        [[[0.9144, 0.1731],
          [0.1080, 0.9396]]],...       [[[0.1547, 0.9068],
          [0.3576, 0.6836]]],


        [[[0.5877, 0.5453],
          [0.2302, 0.0702]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   ImportError: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as an integer

VM.pyx:246: ImportError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.invert
____________________________________________________________________________________ test_equalize[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f9253aa7490>
trace_args = (tensor([[[[0.3160, 0.1735, 0.5805],
          [0.7564, 0.0593, 0.3624],
          [0.8562, 0.9038, 0.6064]],

         [[0.8452, 0.5458, 0.9481],
          [0.3191, 0.9200, 0.9011],
          [0.9086, 0.6124, 0.4464]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.8292, 0.8639, 0.4940],
          [0.8730, 0.4501, 0.2637],
          [0.2373, 0.7800, 0.4996]],

       ...09]],

         [[0.8143, 0.3451, 0.5840],
          [0.5927, 0.5524, 0.7303],
          [0.4606, 0.0157, 0.9517]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize at 0x7f9253aa7490>, fn_name = 'kornia.enhance.equalize'
trace_args = (tensor([[[[0.3160, 0.1735, 0.5805],
          [0.7564, 0.0593, 0.3624],
          [0.8562, 0.9038, 0.6064]],

         [[0.8452, 0.5458, 0.9481],
          [0.3191, 0.9200, 0.9011],
          [0.9086, 0.6124, 0.4464]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[0.8292, 0.8639, 0.4940],
          [0.8730, 0.4501, 0.2637],
          [0.2373, 0.7800, 0.4996]],

       ...09]],

         [[0.8143, 0.3451, 0.5840],
          [0.5927, 0.5524, 0.7303],
          [0.4606, 0.0157, 0.9517]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.31601483, 0.17351967, 0.58049595],
         [0.75639313, 0.05926371, 0.3624283 ],
         [0.8561921 , 0....1156 ],
         [0.319117  , 0.91997665, 0.90111125],
         [0.90855044, 0.61238116, 0.44638246]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f91faaa68c0>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f91faaa6050>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f91faaa6c20>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.31601483, 0.17351967, 0.58049595],
         [0.75639313, 0.05926371, 0.3624283 ],
         [0.8561921 , 0....1156 ],
         [0.319117  , 0.91997665, 0.90111125],
         [0.90855044, 0.61238116, 0.44638246]]]], dtype=float32)

    @numpy_perform_keep_shape_image
    def numpy_equalize(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for image in input:
            scaled_image = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            image, (i, slice(None, None, None), slice(None, None, None))
                        )
                    )
                    for i in range(len(image))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f91faa38ed0>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    image, (i, slice(None, None, None), slice(None, None, None))
                )
            )
            for i in range(len(image))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[ 80.58378 ,  44.247517, 148.02647 ],
       [192.88025 ,  15.112246,  92.41922 ],
       [218.329   , 230.46223 , 154.62204 ]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 8.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(8., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize
_________________________________________________________________________________ test_equalize_clahe[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize_clahe(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 10, 20),)
        trace_kwargs = {
            "clip_limit": 40.0,
            "grid_size": (8, 8),
            "slow_and_differentiable": False,
        }
        test_args = (torch.rand(2, 3, 10, 20),)
        test_kwargs = {
            "clip_limit": 20.0,
            "grid_size": (4, 4),
            "slow_and_differentiable": False,
        }
>       _test_function(
            kornia.enhance.equalize_clahe,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f9253ac9480>
trace_args = (tensor([[[0.4459, 0.6664, 0.2071, 0.8921, 0.2872, 0.0298, 0.8437, 0.7840,
          0.0468, 0.0541, 0.1129, 0.9268, 0...         0.6133, 0.1767, 0.4875, 0.8030, 0.4764, 0.8022, 0.8002, 0.8992,
          0.3205, 0.2496, 0.0428, 0.5149]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.3721, 0.1692, 0.0017,  ..., 0.9666, 0.7629, 0.1068],
          [0.1287, 0.8120, 0.7619,  ..., 0.7948, 0...., 0.7041, 0.0919,  ..., 0.4545, 0.4217, 0.3424],
          [0.5689, 0.4250, 0.8299,  ..., 0.5455, 0.4312, 0.4719]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True
class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize_clahe at 0x7f9253ac9480>, fn_name = 'kornia.enhance.equalize_clahe'
trace_args = (tensor([[[0.4459, 0.6664, 0.2071, 0.8921, 0.2872, 0.0298, 0.8437, 0.7840,
          0.0468, 0.0541, 0.1129, 0.9268, 0...         0.6133, 0.1767, 0.4875, 0.8030, 0.4764, 0.8022, 0.8002, 0.8992,
          0.3205, 0.2496, 0.0428, 0.5149]]]),)
trace_kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}
test_args = (tensor([[[[0.3721, 0.1692, 0.0017,  ..., 0.9666, 0.7629, 0.1068],
          [0.1287, 0.8120, 0.7619,  ..., 0.7948, 0...., 0.7041, 0.0919,  ..., 0.4545, 0.4217, 0.3424],
          [0.5689, 0.4250, 0.8299,  ..., 0.5455, 0.4312, 0.4719]]]]),)
test_kwargs = {'clip_limit': 20.0, 'grid_size': (4, 4), 'slow_and_differentiable': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.44593078, 0.6664488 , 0.20707095, 0.892052  , 0.28724897,
          0.02979028, 0.8436684 , 0.7839549 , 0.... 0.8022365 , 0.80022144,
          0.8991518 , 0.3204866 , 0.24963778, 0.04277217, 0.5149362 ]]]],
      dtype=float32)
args = (), kwargs = {'clip_limit': 40.0, 'grid_size': (8, 8), 'slow_and_differentiable': False}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f91fb009360>
numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f91fb347eb0>, numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f91fb00b7f0>, input_shape = ivy.frontends.torch.Size([1, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[0.44593078, 0.6664488 , 0.20707095, 0.892052  , 0.28724897,
          0.02979028, 0.8436684 , 0.7839549 , 0.... 0.8022365 , 0.80022144,
          0.8991518 , 0.3204866 , 0.24963778, 0.04277217, 0.5149362 ]]]],
      dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @numpy_perform_keep_shape_image
    def numpy_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_permute_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = numpy__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:488: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = array([[[[0.44593078, 0.6664488 , 0.20707095, 0.892052  , 0.28724897,
          0.02979028, 0.8436684 , 0.7839549 , 0.... 0.8022365 , 0.80022144,
          0.8991518 , 0.3204866 , 0.24963778, 0.04277217, 0.5149362 ]]]],
      dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def numpy__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            numpy_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = numpy_shape_frnt_(batch)[-2:][0], numpy_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if (
            pad_vert > numpy_shape_frnt_(batch)[-2]
            or pad_horz > numpy_shape_frnt_(batch)[-1]
        ):
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = numpy_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = numpy_shape_frnt_(batch)[-3]
        tiles: typing.Any = numpy_contiguous_frnt_(
            numpy_squeeze_frnt_(
                numpy_unfold_frnt_(
>                   numpy_unfold_frnt_(
                        numpy_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/equalization.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[[[0.44593078, 0.9638461 , 0.17194837, 0.02206802, 0.71027315,
           0.14611763, 0.9158501 , 0.1860494 ,...       0.41229445, 0.96070397, 0.7571163 , 0.56888807, 0.88849366,
           0.73881114]]]]], dtype=float32), 2, 2, 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f91fa598940>
array_like = array([[[[[0.44593078, 0.9638461 , 0.17194837, 0.02206802, 0.71027315,
           0.14611763, 0.9158501 , 0.1860494 , ...9853,
           0.41229445, 0.96070397, 0.7571163 , 0.56888807, 0.88849366,
           0.73881114]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[[[0.44593078, 0.9638461 , 0.17194837, 0.02206802, 0.71027315,
           0.14611763, 0.9158501 , 0.1860494 , ...9853,
           0.41229445, 0.96070397, 0.7571163 , 0.56888807, 0.88849366,
           0.73881114]]]]], dtype=float32)
dimension = 2, size = 2, step = 2

    @numpy_handle_methods
    def numpy_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.general import numpy_set_item
        from .indexing_slicing_joining_mutating_ops import numpy_stack_frnt
    
        slices = []
        self_shape = tuple(numpy_shape_frnt_(tensor))
        for i in range(0, numpy_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(numpy_shape_frnt_(tensor))
            slicing = numpy_set_item(slicing, dimension, slice(i, i + size))
            slices.append(numpy_get_item(tensor, tuple(slicing)))
>       stacked = numpy_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 2

    def numpy_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.numpy.manipulation import numpy_stack
    
>       return numpy_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def numpy_stack(
        arrays: Union[Tuple[np.ndarray], List[np.ndarray]],
        /,
        *,
        axis: int = 0,
        out: Optional[np.ndarray] = None,
    ):
>       return np.stack(arrays, axis, out=out)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/backends/numpy/manipulation.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 2, out = None

    @array_function_dispatch(_stack_dispatcher)
    def stack(arrays, axis=0, out=None, *, dtype=None, casting="same_kind"):
        """
        Join a sequence of arrays along a new axis.
    
        The ``axis`` parameter specifies the index of the new axis in the
        dimensions of the result. For example, if ``axis=0`` it will be the first
        dimension and if ``axis=-1`` it will be the last dimension.
    
        .. versionadded:: 1.10.0
    
        Parameters
        ----------
        arrays : sequence of array_like
            Each array must have the same shape.
    
        axis : int, optional
            The axis in the result array along which the input arrays are stacked.
    
        out : ndarray, optional
            If provided, the destination to place the result. The shape must be
            correct, matching that of what stack would have returned if no
            out argument were specified.
    
        dtype : str or dtype
            If provided, the destination array will have this dtype. Cannot be
            provided together with `out`.
    
            .. versionadded:: 1.24
    
        casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
            Controls what kind of data casting may occur. Defaults to 'same_kind'.
    
            .. versionadded:: 1.24
    
    
        Returns
        -------
        stacked : ndarray
            The stacked array has one more dimension than the input arrays.
    
        See Also
        --------
        concatenate : Join a sequence of arrays along an existing axis.
        block : Assemble an nd-array from nested lists of blocks.
        split : Split array into a list of multiple sub-arrays of equal size.
    
        Examples
        --------
        >>> arrays = [np.random.randn(3, 4) for _ in range(10)]
        >>> np.stack(arrays, axis=0).shape
        (10, 3, 4)
    
        >>> np.stack(arrays, axis=1).shape
        (3, 10, 4)
    
        >>> np.stack(arrays, axis=2).shape
        (3, 4, 10)
    
        >>> a = np.array([1, 2, 3])
        >>> b = np.array([4, 5, 6])
        >>> np.stack((a, b))
        array([[1, 2, 3],
               [4, 5, 6]])
    
        >>> np.stack((a, b), axis=-1)
        array([[1, 4],
               [2, 5],
               [3, 6]])
    
        """
        arrays = [asanyarray(arr) for arr in arrays]
        if not arrays:
>           raise ValueError('need at least one array to stack')
E           ValueError: need at least one array to stack

/opt/fw/mxnet/numpy/core/shape_base.py:445: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.equalization.equalize_clahe
___________________________________________________________________________________ test_equalize3d[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_equalize3d(target_framework, mode, backend_compile):
        trace_args = (torch.rand(1, 2, 3, 3, 3),)
        trace_kwargs = {}
        test_args = (torch.rand(5, 2, 3, 3, 3),)
        test_kwargs = {}
>       _test_function(
            kornia.enhance.equalize3d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_enhance.py:383: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f9253aa75b0>
trace_args = (tensor([[[[[0.4472, 0.8691, 0.1012],
           [0.6265, 0.1815, 0.7501],
           [0.8113, 0.7386, 0.1973]],

    ...,

          [[0.0513, 0.4469, 0.0235],
           [0.7019, 0.7398, 0.4879],
           [0.5197, 0.8362, 0.3356]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.7919, 0.4165, 0.4146],
           [0.2618, 0.3111, 0.0806],
           [0.3441, 0.8289, 0.7630]],

    ...,

          [[0.9799, 0.6981, 0.0695],
           [0.6860, 0.2994, 0.8345],
           [0.3844, 0.1661, 0.4867]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function equalize3d at 0x7f9253aa75b0>, fn_name = 'kornia.enhance.equalize3d'
trace_args = (tensor([[[[[0.4472, 0.8691, 0.1012],
           [0.6265, 0.1815, 0.7501],
           [0.8113, 0.7386, 0.1973]],

    ...,

          [[0.0513, 0.4469, 0.0235],
           [0.7019, 0.7398, 0.4879],
           [0.5197, 0.8362, 0.3356]]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[[0.7919, 0.4165, 0.4146],
           [0.2618, 0.3111, 0.0806],
           [0.3441, 0.8289, 0.7630]],

    ...,

          [[0.9799, 0.6981, 0.0695],
           [0.6860, 0.2994, 0.8345],
           [0.3844, 0.1661, 0.4867]]]]]),)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.44724828, 0.8691329 , 0.10120535],
          [0.6265421 , 0.18154061, 0.75006455],
          [0.81127864,...73],
          [0.7019027 , 0.7398458 , 0.48790395],
          [0.5197325 , 0.83622175, 0.33556402]]]]], dtype=float32)
args = (), kwargs = {}, numpy_numel_frnt_ = <function numpy_numel_frnt_ at 0x7f91fb5f0e50>, numpy_shape_frnt_ = <function numpy_shape_frnt_ at 0x7f91fb5f1fc0>
numpy_view_frnt_ = <function numpy_view_frnt_ at 0x7f91fb5f2050>, input_shape = ivy.frontends.torch.Size([1, 2, 3, 3, 3])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import numpy_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
    
        if not isinstance(input, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if numpy_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = numpy_shape_frnt_(input)
        input = numpy__to_bcdhw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[[[0.44724828, 0.8691329 , 0.10120535],
          [0.6265421 , 0.18154061, 0.75006455],
          [0.81127864,...73],
          [0.7019027 , 0.7398458 , 0.48790395],
          [0.5197325 , 0.83622175, 0.33556402]]]]], dtype=float32)

    @numpy_perform_keep_shape_video
    def numpy_equalize3d(input):
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_stack_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
    
        res = []
        for volume in input:
            scaled_input = numpy_stack_frnt(
>               [
                    numpy__scale_channel(
                        numpy_get_item(
                            volume,
                            (
                                i,
                                slice(None, None, None),
                                slice(None, None, None),
                                slice(None, None, None),
                            ),
                        )
                    )
                    for i in range(len(volume))
                ]
            )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7f91fa834ba0>

        [
>           numpy__scale_channel(
                numpy_get_item(
                    volume,
                    (
                        i,
                        slice(None, None, None),
                        slice(None, None, None),
                        slice(None, None, None),
                    ),
                )
            )
            for i in range(len(volume))
        ]
    )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

im = array([[[114.04831  , 221.62889  ,  25.807364 ],
        [159.76823  ,  46.292854 , 191.26646  ],
        [206.87605  ...  ],
        [ 11.159256 , 130.0424   ,  64.711716 ],
        [214.44148  , 137.72789  , 188.68768  ]]], dtype=float32)

    def numpy__scale_channel(im):
        from ...ivy.functional.frontends.torch.tensor import numpy_min_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_item_frnt_
        from ...ivy.functional.frontends.torch.comparison_ops import numpy_isclose_frnt
        from ...ivy.functional.frontends.torch.creation_ops import numpy_as_tensor_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..utils.helpers import numpy__torch_histc_cast
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_reshape_frnt,
        )
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_div_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_gather_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_long_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_flatten_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_as_frnt_
    
        min_ = numpy_min_frnt_(im)
        max_ = numpy_max_frnt_(im)
        if numpy_item_frnt_(min_) < 0.0 and not numpy_isclose_frnt(
            min_, numpy_as_tensor_frnt(0.0, dtype=min_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must greater or equal to 0.0. Found {numpy_item_frnt_(min_)}."
            )
        if numpy_item_frnt_(max_) > 1.0 and not numpy_isclose_frnt(
            max_, numpy_as_tensor_frnt(1.0, dtype=max_.dtype)
        ):
            raise ValueError(
                f"Values in the input tensor must lower or equal to 1.0. Found {numpy_item_frnt_(max_)}."
            )
        ndims = len(numpy_shape_frnt_(im))
        if ndims not in (2, 3):
            raise TypeError(f"Input tensor must have 2 or 3 dimensions. Found {ndims}.")
        im = im * 255.0
        histo = numpy__torch_histc_cast(im, bins=256, min=0, max=255)
        nonzero_histo = numpy_reshape_frnt(numpy_get_item(histo, histo != 0), [-1])
>       step = numpy_div_frnt(
            numpy_sum_frnt(nonzero_histo) - nonzero_histo[-1], 255, rounding_mode="trunc"
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/adjust.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = 26.0, other = 255

    def numpy_div_frnt(input, other, *, rounding_mode=None, out=None):
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...backends.numpy.data_type import numpy_astype
        from ...ivy.elementwise import numpy_trunc_divide_bknd
        from ...backends.numpy.elementwise import numpy_floor_divide
        from ...backends.numpy.elementwise import numpy_divide
    
>       input, other = numpy_promote_types_of_torch_inputs_frnt(input, other)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array(26., dtype=float32), x2 = array(255)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.adjust.equalize3d
___________________________________________________________________________________ test_histogram[numpy-s2s-False] ____________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 10),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f9253ac8ee0>
trace_args = (tensor([[0.5061, 0.1344, 0.5087, 0.2565, 0.5134, 0.7666, 0.2901, 0.2303, 0.2943,
         0.0909]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.8680, 0.6911, 0.0093, 0.5531, 0.2735, 0.2573, 0.3215, 0.3873, 0.1391,
         0.9294],
        [0.9598, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram at 0x7f9253ac8ee0>, fn_name = 'kornia.enhance.histogram'
trace_args = (tensor([[0.5061, 0.1344, 0.5087, 0.2565, 0.5134, 0.7666, 0.2901, 0.2303, 0.2943,
         0.0909]]), tensor([  0.0000...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.8680, 0.6911, 0.0093, 0.5531, 0.2735, 0.2573, 0.3215, 0.3873, 0.1391,
         0.9294],
        [0.9598, 0...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.5061434 , 0.13439637, 0.50866485, 0.2564677 , 0.5134047 ,
        0.7666072 , 0.29013628, 0.23031056, 0.29430634, 0.09091038]],
      dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram(x, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       pdf, _ = numpy_marginal_pdf(numpy_unsqueeze_frnt_(x, 2), bins, bandwidth, epsilon)

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.5061434 ],
        [0.13439637],
        [0.50866485],
        [0.2564677 ],
        [0.5134047 ],
        [0.7666072 ],
        [0.29013628],
        [0.23031056],
        [0.29430634],
        [0.09091038]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 5.6238157e-01, -1.6685897e+00, -3.8995609e+00, ...,
         -2.7830902e+02, -2.8053998e+02, -2.8277097e+02...01, -2.1299596e+00, -4.3609309e+00, ...,
         -2.7877039e+02, -2.8100134e+02, -2.8323233e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f91fa5fff40>
array_like = array([[[ 5.6238157e-01, -1.6685897e+00, -3.8995609e+00, ...,
         -2.7830902e+02, -2.8053998e+02, -2.8277097e+02]...53e-01, -2.1299596e+00, -4.3609309e+00, ...,
         -2.7877039e+02, -2.8100134e+02, -2.8323233e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 5.6238157e-01, -1.6685897e+00, -3.8995609e+00, ...,
         -2.7830902e+02, -2.8053998e+02, -2.8277097e+02]...53e-01, -2.1299596e+00, -4.3609309e+00, ...,
         -2.7877039e+02, -2.8100134e+02, -2.8323233e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 5.6238157e-01, -1.6685897e+00, -3.8995609e+00, ...,
         -2.7830902e+02, -2.8053998e+02, -2.8277097e+02...01, -2.1299596e+00, -4.3609309e+00, ...,
         -2.7877039e+02, -2.8100134e+02, -2.8323233e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f91fa5fff40>
array_like = array([[[ 5.6238157e-01, -1.6685897e+00, -3.8995609e+00, ...,
         -2.7830902e+02, -2.8053998e+02, -2.8277097e+02]...53e-01, -2.1299596e+00, -4.3609309e+00, ...,
         -2.7877039e+02, -2.8100134e+02, -2.8323233e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 5.6238157e-01, -1.6685897e+00, -3.8995609e+00, ...,
         -2.7830902e+02, -2.8053998e+02, -2.8277097e+02]...53e-01, -2.1299596e+00, -4.3609309e+00, ...,
         -2.7877039e+02, -2.8100134e+02, -2.8323233e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 5.6238157e-01, -1.6685897e+00, -3.8995609e+00, ...,
         -2.7830902e+02, -2.8053998e+02, -2.8277097e+02]...53e-01, -2.1299596e+00, -4.3609309e+00, ...,
         -2.7877039e+02, -2.8100134e+02, -2.8323233e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram
__________________________________________________________________________________ test_histogram2d[numpy-s2s-False] ___________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_histogram2d(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(2, 32),
            torch.rand(2, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        trace_kwargs = {"epsilon": 1e-10}
        test_args = (
            torch.rand(5, 32),
            torch.rand(5, 32),
            torch.linspace(0, 255, 128),
            torch.tensor(0.9),
        )
        test_kwargs = {"epsilon": 1e-10}
>       _test_function(
            kornia.enhance.histogram2d,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_enhance.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f9253ac9000>
trace_args = (tensor([[0.4160, 0.7234, 0.7090, 0.3558, 0.4255, 0.3342, 0.5538, 0.8051, 0.5527,
         0.0484, 0.9548, 0.2922, 0.1...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.7595, 0.2924, 0.6154, 0.5979, 0.3901, 0.9853, 0.6575, 0.1967, 0.3253,
         0.3856, 0.9989, 0.3765, 0.9...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function histogram2d at 0x7f9253ac9000>, fn_name = 'kornia.enhance.histogram2d'
trace_args = (tensor([[0.4160, 0.7234, 0.7090, 0.3558, 0.4255, 0.3342, 0.5538, 0.8051, 0.5527,
         0.0484, 0.9548, 0.2922, 0.1...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
trace_kwargs = {'epsilon': 1e-10}
test_args = (tensor([[0.7595, 0.2924, 0.6154, 0.5979, 0.3901, 0.9853, 0.6575, 0.1967, 0.3253,
         0.3856, 0.9989, 0.3765, 0.9...    238.9370, 240.9449, 242.9528, 244.9606, 246.9685, 248.9764, 250.9843,
        252.9921, 255.0000]), tensor(0.9000))
test_kwargs = {'epsilon': 1e-10}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[0.41599554, 0.723377  , 0.7090154 , 0.35579896, 0.42552185,
        0.3341717 , 0.5537559 , 0.805103  , 0.5526...6,
        0.8240843 , 0.929667  , 0.06558871, 0.11417776, 0.9084994 ,
        0.6790453 , 0.23926318]], dtype=float32)
x2 = array([[0.38411677, 0.36569226, 0.7405082 , 0.23021644, 0.9182924 ,
        0.88737595, 0.46394604, 0.14790386, 0.0975...8,
        0.33690107, 0.18795824, 0.06388426, 0.36035454, 0.37172014,
        0.46981812, 0.2748378 ]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
bandwidth = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_histogram2d(x1, x2, bins, bandwidth, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
    
>       _, kernel_values1 = numpy_marginal_pdf(
            numpy_unsqueeze_frnt_(x1, 2), bins, bandwidth, epsilon
        )

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = array([[[0.41599554],
        [0.723377  ],
        [0.7090154 ],
        [0.35579896],
        [0.42552185],
        ... [0.06558871],
        [0.11417776],
        [0.9084994 ],
        [0.6790453 ],
        [0.23926318]]], dtype=float32)
bins = array([  0.      ,   2.007874,   4.015748,   6.023622,   8.031496,
        10.03937 ,  12.047244,  14.055119,  16.0629... 240.94489 , 242.95276 , 244.96063 , 246.9685  , 248.97638 ,
       250.98425 , 252.99213 , 255.      ], dtype=float32)
sigma = array(0.9, dtype=float32), epsilon = 1e-10

    def numpy_marginal_pdf(values, bins, sigma, epsilon=1e-10):
        from ...ivy.functional.frontends.torch.tensor import numpy_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import numpy_sum_frnt
    
        if not isinstance(values, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input values type is not a torch.Tensor. Got {type(values)}")
        if not isinstance(bins, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input bins type is not a torch.Tensor. Got {type(bins)}")
        if not isinstance(sigma, (numpy.ndarray, numpy.ndarray)):
            raise TypeError(f"Input sigma type is not a torch.Tensor. Got {type(sigma)}")
        if not numpy_dim_frnt_(values) == 3:
            raise ValueError(
                f"Input values must be a of the shape BxNx1. Got {numpy_shape_frnt_(values)}"
            )
        if not numpy_dim_frnt_(bins) == 1:
            raise ValueError(
                f"Input bins must be a of the shape NUM_BINS. Got {numpy_shape_frnt_(bins)}"
            )
        if not numpy_dim_frnt_(sigma) == 0:
            raise ValueError(
                f"Input sigma must be a of the shape 1. Got {numpy_shape_frnt_(sigma)}"
            )
        residuals = values - numpy_unsqueeze_frnt_(numpy_unsqueeze_frnt_(bins, 0), 0)
>       kernel_values = numpy_exp_frnt(-0.5 * numpy_pow_frnt_(residuals / sigma, 2))

ivy_transpiled_outputs/numpy_outputs/kornia/enhance/histogram.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 4.6221727e-01, -1.7687539e+00, -3.9997251e+00, ...,
         -2.7840918e+02, -2.8064014e+02, -2.8287112e+02...01, -1.9651232e+00, -4.1960945e+00, ...,
         -2.7860556e+02, -2.8083652e+02, -2.8306750e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f91fac0d1b0>
array_like = array([[[ 4.6221727e-01, -1.7687539e+00, -3.9997251e+00, ...,
         -2.7840918e+02, -2.8064014e+02, -2.8287112e+02]...98e-01, -1.9651232e+00, -4.1960945e+00, ...,
         -2.7860556e+02, -2.8083652e+02, -2.8306750e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 4.6221727e-01, -1.7687539e+00, -3.9997251e+00, ...,
         -2.7840918e+02, -2.8064014e+02, -2.8287112e+02]...98e-01, -1.9651232e+00, -4.1960945e+00, ...,
         -2.7860556e+02, -2.8083652e+02, -2.8306750e+02]]], dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 4.6221727e-01, -1.7687539e+00, -3.9997251e+00, ...,
         -2.7840918e+02, -2.8064014e+02, -2.8287112e+02...01, -1.9651232e+00, -4.1960945e+00, ...,
         -2.7860556e+02, -2.8083652e+02, -2.8306750e+02]]], dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f91fac0d1b0>
array_like = array([[[ 4.6221727e-01, -1.7687539e+00, -3.9997251e+00, ...,
         -2.7840918e+02, -2.8064014e+02, -2.8287112e+02]...98e-01, -1.9651232e+00, -4.1960945e+00, ...,
         -2.7860556e+02, -2.8083652e+02, -2.8306750e+02]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 4.6221727e-01, -1.7687539e+00, -3.9997251e+00, ...,
         -2.7840918e+02, -2.8064014e+02, -2.8287112e+02]...98e-01, -1.9651232e+00, -4.1960945e+00, ...,
         -2.7860556e+02, -2.8083652e+02, -2.8306750e+02]]], dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 4.6221727e-01, -1.7687539e+00, -3.9997251e+00, ...,
         -2.7840918e+02, -2.8064014e+02, -2.8287112e+02]...98e-01, -1.9651232e+00, -4.1960945e+00, ...,
         -2.7860556e+02, -2.8083652e+02, -2.8306750e+02]]], dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.enhance.histogram.histogram2d
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_enhance.py::test_adjust_gamma[numpy-s2s-False] - TypeError: 'float' object cannot be interpreted as an integer
FAILED kornia/test_enhance.py::test_invert[numpy-s2s-False] - ImportError: Error loading module ivy_transpiled_outputs.numpy_outputs.kornia.enhance.adjust: 'float' object cannot be interpreted as a...
FAILED kornia/test_enhance.py::test_equalize[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_equalize_clahe[numpy-s2s-False] - ValueError: need at least one array to stack
FAILED kornia/test_enhance.py::test_equalize3d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/test_enhance.py::test_histogram2d[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
======================================================================== 7 failed, 19 passed, 13 skipped in 1595.05s (0:26:35) =========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation4.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 5.26s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 15 items

kornia/test_contrib.py ....Fssssssssss                                                                                                                                                           [100%]

=============================================================================================== FAILURES ===============================================================================================
_________________________________________________________________________________ test_diamond_square[numpy-s2s-False] _________________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_diamond_square(target_framework, mode, backend_compile):
        trace_args = ((1, 1, 8, 8),)
        trace_kwargs = {
            "roughness": 0.5,
            "random_scale": 1.0,
            "normalize_range": (0.0, 1.0),
            "random_fn": torch.ones,
        }
        test_args = ((5, 1, 8, 8),)
        test_kwargs = {
            "roughness": 0.7,
            "random_scale": 0.9,
            "normalize_range": (-1.0, 1.0),
            "random_fn": torch.ones,
        }
>       _test_function(
            kornia.contrib.diamond_square,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/test_contrib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7fbd1ab43130>, trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fbd36272900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fbd36272900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function diamond_square at 0x7fbd1ab43130>, fn_name = 'kornia.contrib.diamond_square', trace_args = ((1, 1, 8, 8),)
trace_kwargs = {'normalize_range': (0.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fbd36272900>, 'random_scale': 1.0, 'roughness': 0.5}, test_args = ((5, 1, 8, 8),)
test_kwargs = {'normalize_range': (-1.0, 1.0), 'random_fn': <built-in method ones of type object at 0x7fbd36272900>, 'random_scale': 0.9, 'roughness': 0.7}, target = 'numpy', backend_compile = False
tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output_size = (1, 1, 8, 8), roughness = 0.5, random_scale = 1.0, random_fn = <built-in method ones of type object at 0x7fbd36272900>, normalize_range = (0.0, 1.0), device = None, dtype = None

    def numpy_diamond_square(
        output_size,
        roughness=0.5,
        random_scale=1.0,
        random_fn=numpy_rand_frnt,
        normalize_range=None,
        device=None,
        dtype=None,
    ):
        from ..core.check import numpy_KORNIA_CHECK
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_frnt_
        from ..core.check import numpy_KORNIA_CHECK_IS_TENSOR
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.backends.numpy.general import numpy_get_item
        from ..enhance.normalize import numpy_normalize_min_max
        from ...ivy.functional.frontends.torch.tensor import numpy_contiguous_frnt_
    
        numpy_KORNIA_CHECK(len(output_size) == 4, "output_size must be (B,C,H,W)")
        if not isinstance(random_scale, (numpy.ndarray, numpy.ndarray)):
            random_scale = numpy_to_frnt_(
>               numpy.ndarray([[[[random_scale]]]]), device, dtype
            )
E           TypeError: 'list' object cannot be interpreted as an integer

ivy_transpiled_outputs/numpy_outputs/kornia/contrib/diamond_square.py:197: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.contrib.diamond_square.diamond_square
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_contrib.py::test_diamond_square[numpy-s2s-False] - TypeError: 'list' object cannot be interpreted as an integer
========================================================================= 1 failed, 4 passed, 10 skipped in 323.09s (0:05:23) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/test_sensors.py ssss                                                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 4.90s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ssssssssssssssss                                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 16 skipped in 5.11s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_AutoAugment[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAutoAugment = ivy.transpile(
            kornia.augmentation.auto.AutoAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = TranspiledAutoAugment()

kornia/augmentation/test_auto.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f8332908e20>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f8332908e20>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f8332908e20>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f8332908e20>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f8332909ab0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_AutoAugment object at 0x7f8332908e20>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        return tensorflow_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f83329085b0>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:138: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
________________________________________________________________________________ test_RandAugment[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRandAugment = ivy.transpile(
            kornia.augmentation.auto.RandAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = TranspiledRandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f833826d5d0>, n = 2, m = 10, policy = None
transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f833826d5d0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f833826d5d0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f833826d5d0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f833826ea40>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_RandAugment object at 0x7f833826d5d0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:83: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
______________________________________________________________________________ test_TrivialAugment[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTrivialAugment = ivy.transpile(
            kornia.augmentation.auto.TrivialAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = TranspiledTrivialAugment()

kornia/augmentation/test_auto.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f83327e1db0>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_tensor_frnt,
        )
        from .....torch.distributions.categorical import tensorflow_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f83327e1db0>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f83327e1db0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @tensorflow_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import tensorflow_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f83327e1db0>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7f83327e11b0>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/base.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_TrivialAugment object at 0x7f83327e1db0>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import tensorflow_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return tensorflow_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:71: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[tensorflow-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1436.80s (0:23:56) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py .......F                                                                                                                                                          [100%]

=============================================================================================== FAILURES ===============================================================================================
_______________________________________________________________________________ test_euclidean_distance[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_euclidean_distance(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(3, 5),
            torch.rand(3, 5),
        )
        trace_kwargs = {'keepdim': False, 'eps': 1e-6}
        test_args = (
            torch.rand(5, 3, 5),
            torch.rand(5, 3, 5),
        )
        test_kwargs = {'keepdim': False, 'eps': 1e-6}
>       _test_function(
            kornia.geometry.linalg.euclidean_distance,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_linalg.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f54979c1cf0>
trace_args = (tensor([[0.1690, 0.4304, 0.4932, 0.3528, 0.3266],
        [0.2581, 0.8965, 0.3544, 0.3859, 0.1903],
        [0.3124, ... 0.1740, 0.0334],
        [0.8934, 0.7769, 0.8552, 0.0348, 0.9817],
        [0.8063, 0.0313, 0.7765, 0.8971, 0.7287]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.8786, 0.7277, 0.5752, 0.1735, 0.1203],
         [0.9676, 0.8161, 0.2680, 0.8737, 0.5555],
         [0.247...5222, 0.9039],
         [0.2343, 0.9166, 0.9265, 0.9778, 0.0799],
         [0.9079, 0.1223, 0.1824, 0.6306, 0.8118]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function euclidean_distance at 0x7f54979c1cf0>, fn_name = 'kornia.geometry.linalg.euclidean_distance'
trace_args = (tensor([[0.1690, 0.4304, 0.4932, 0.3528, 0.3266],
        [0.2581, 0.8965, 0.3544, 0.3859, 0.1903],
        [0.3124, ... 0.1740, 0.0334],
        [0.8934, 0.7769, 0.8552, 0.0348, 0.9817],
        [0.8063, 0.0313, 0.7765, 0.8971, 0.7287]]))
trace_kwargs = {'eps': 1e-06, 'keepdim': False}
test_args = (tensor([[[0.8786, 0.7277, 0.5752, 0.1735, 0.1203],
         [0.9676, 0.8161, 0.2680, 0.8737, 0.5555],
         [0.247...5222, 0.9039],
         [0.2343, 0.9166, 0.9265, 0.9778, 0.0799],
         [0.9079, 0.1223, 0.1824, 0.6306, 0.8118]]]))
test_kwargs = {'eps': 1e-06, 'keepdim': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[0.16903162, 0.4303993 , 0.49324554, 0.35280436, 0.32658517],
       [0.25808048, 0.89654815, 0.35444206, 0.38589507, 0.1903494 ],
       [0.31243676, 0.6852414 , 0.5147866 , 0.15026253, 0.804073  ]],
      dtype=float32)
y = array([[0.78368926, 0.46159208, 0.60510164, 0.17401904, 0.03335756],
       [0.89341986, 0.7769011 , 0.8552054 , 0.03480005, 0.9816987 ],
       [0.80631983, 0.03127229, 0.77648103, 0.89711475, 0.7286775 ]],
      dtype=float32)
keepdim = False, eps = 1e-06

    def numpy_euclidean_distance(x, y, keepdim=False, eps=1e-06):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(x, ["*", "N"])
        numpy_KORNIA_CHECK_SHAPE(y, ["*", "N"])
        return numpy_sqrt_frnt_(
>           numpy_sum_frnt_(numpy_pow_frnt_(x - y + eps, 2), -1, keepdim)
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/linalg.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.6146566 , -0.03119178, -0.1118551 ,  0.17878632,  0.29322863],
       [-0.63533837,  0.11964802, -0.500762...9603, -0.7913483 ],
       [-0.49388206,  0.6539701 , -0.26169342, -0.7468512 ,  0.07539646]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f543f06f2e0>
array_like = array([[-0.6146566 , -0.03119178, -0.1118551 ,  0.17878632,  0.29322863],
       [-0.63533837,  0.11964802, -0.5007623...35109603, -0.7913483 ],
       [-0.49388206,  0.6539701 , -0.26169342, -0.7468512 ,  0.07539646]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[-0.6146566 , -0.03119178, -0.1118551 ,  0.17878632,  0.29322863],
       [-0.63533837,  0.11964802, -0.5007623...35109603, -0.7913483 ],
       [-0.49388206,  0.6539701 , -0.26169342, -0.7468512 ,  0.07539646]],
      dtype=float32)
exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[-0.6146566 , -0.03119178, -0.1118551 ,  0.17878632,  0.29322863],
       [-0.63533837,  0.11964802, -0.500762...9603, -0.7913483 ],
       [-0.49388206,  0.6539701 , -0.26169342, -0.7468512 ,  0.07539646]],
      dtype=float32), 2)
kwargs = {}, numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f543f06f2e0>
array_like = array([[-0.6146566 , -0.03119178, -0.1118551 ,  0.17878632,  0.29322863],
       [-0.63533837,  0.11964802, -0.5007623...35109603, -0.7913483 ],
       [-0.49388206,  0.6539701 , -0.26169342, -0.7468512 ,  0.07539646]],
      dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[-0.6146566 , -0.03119178, -0.1118551 ,  0.17878632,  0.29322863],
       [-0.63533837,  0.11964802, -0.5007623...35109603, -0.7913483 ],
       [-0.49388206,  0.6539701 , -0.26169342, -0.7468512 ,  0.07539646]],
      dtype=float32)
exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[-0.6146566 , -0.03119178, -0.1118551 ,  0.17878632,  0.29322863],
       [-0.63533837,  0.11964802, -0.5007623...35109603, -0.7913483 ],
       [-0.49388206,  0.6539701 , -0.26169342, -0.7468512 ,  0.07539646]],
      dtype=float32)
x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.linalg.euclidean_distance
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_linalg.py::test_euclidean_distance[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 1 failed, 7 passed in 264.06s (0:04:24) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/test_feature1.py .....F.............                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
____________________________________________________________________________ test_get_laf_descriptors[tensorflow-s2s-False] ____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_get_laf_descriptors(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 1, 32, 32),
            torch.rand(1, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        trace_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        test_args = (
            torch.rand(5, 1, 32, 32),
            torch.rand(5, 3, 2, 3),
            kornia.feature.OriNet(pretrained=False),
        )
        test_kwargs = {'patch_size': 32, 'grayscale_descriptor': True}
        class_info = {
            'trace_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            },
            'test_args': {
                2: {'object': kornia.feature.OriNet, 'kwargs': {'pretrained': False}}
            }
        }
>       _test_function(
            kornia.feature.get_laf_descriptors,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            class_info=class_info,
        )

kornia/test_feature1.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7ff39039f9a0>
trace_args = (tensor([[[[0.6899, 0.6914, 0.4378,  ..., 0.1253, 0.9172, 0.9520],
          [0.4011, 0.9076, 0.6503,  ..., 0.8959, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.2844, 0.6434, 0.1773,  ..., 0.0484, 0.5824, 0.3271],
          [0.0951, 0.0859, 0.3158,  ..., 0.2582, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function get_laf_descriptors at 0x7ff39039f9a0>, fn_name = 'kornia.feature.get_laf_descriptors'
trace_args = (tensor([[[[0.6899, 0.6914, 0.4378,  ..., 0.1253, 0.9172, 0.9520],
          [0.4011, 0.9076, 0.6503,  ..., 0.8959, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
trace_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}
test_args = (tensor([[[[0.2844, 0.6434, 0.1773,  ..., 0.0484, 0.5824, 0.3271],
          [0.0951, 0.0859, 0.3158,  ..., 0.2582, 0...., kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
))
test_kwargs = {'grayscale_descriptor': True, 'patch_size': 32}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True
class_info = {'test_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}, 'trace_args': {2: {'kwargs': {'pretrained': False}, 'object': <class 'kornia.feature.orientation.OriNet'>}}}

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
>       [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7ff33a935380>

>   [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]

helpers.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

original_model = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
translated_model = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models(
        original_model: "nn.Module",
        translated_model: Union["keras.Model", "KerasModel", "nnx.Module", "FlaxModel"],
    ):
        """Synchronizes the weights and buffers between a native PyTorch model
        (`torch.nn.Module`) and it's translated version in TensorFlow or Flax.
    
        Args:
        ----
            original_model (torch.nn.Module): The PyTorch model to synchronize from.
            translated_model (tf.keras.Model or nnx.Module): The target model to synchronize to,
                                                      either a TensorFlow or Flax model.
        """
        if not _is_submodule(original_model, "torch"):
            raise ivy.utils.exceptions.IvyException(
                "sync_models expected an instance of `nn.Module` as the first argument. got {}".format(
                    original_model
                )
            )
        if _is_submodule(translated_model, "keras"):
>           sync_models_torch_and_tf(original_model, translated_model)

../ivy/ivy/stateful/utilities.py:796: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model_pt = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model_tf = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def sync_models_torch_and_tf(
        model_pt: "nn.Module", model_tf: Union["keras.Model", "KerasModel"]
    ):
        """Synchronizes the weights and buffers between a PyTorch model
        (`torch.nn.Module`) and a TensorFlow model (`keras.Model`).
    
        This function ensures that both models have identical parameters and buffers by
        iterating through their submodules and synchronizing them. The TensorFlow model
        must either be an instance of `KerasModel` or have submodules that inherit from the
        translated `KerasModel`/`KerasLayer`, and expose interfaces similar to `torch.nn.Module`,
        including `named_parameters()` and `named_buffers()`.
    
        Args:
        ----
            model_pt (torch.nn.Module): The PyTorch model to synchronize from.
            model_tf (keras.Model): The TensorFlow model to synchronize to, with submodules
                                    inheriting from the custom `KerasModel`/`KerasLayer` class.
    
        Returns:
        -------
            None
    
    
        Example:
        -------
            ```python
            import torch.nn as nn
            import keras
    
            #`CustomKerasLinear` is a subclass of `Layer` that exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class CustomKerasLinear(Layer):
                def __init__(self, in_features, out_features):
                    super(CustomKerasLinear, self).__init__()
                    self.weight = tf.Variable(tf.random.normal([out_features, in_features]))
                    self.bias = tf.Variable(tf.random.normal([out_features]))
    
                def call(self, x):
                    return tf.matmul(x, self.weight) + self.bias
    
                def named_parameters(self):
                            return [("weight", self.weight), ("bias", self.bias)]
    
                def named_buffers(self):
                            return []
    
                def eval(self):
                    return False
    
            #`NativeKerasModel` is a subclass of keras.Model and does NOT exposes a similar
            # interface to torch.nn.Module (with named_parameters and named_buffers).
            class NativeKerasModel(keras.Model):
                def __init__(self):
                    super(NativeKerasModel, self).__init__()
                    self.linear = CustomKerasLinear(10, 5)
    
                def call(self, x):
                    return self.linear(x)
    
            class PyTorchModel(nn.Module):
                def __init__(self):
                    super(PyTorchModel, self).__init__()
                    self.linear = nn.Linear(10, 5)
    
                def forward(self, x):
                    return self.linear(x)
    
            # Instantiate both models
            model_pt = PyTorchModel()  # PyTorch model
            model_tf = NativeKerasModel()  # Native Keras model inheriting from keras.Model
    
            # Sync all submodules between the PyTorch and Keras models
            sync_models_torch_and_tf(model_pt, model_tf)
            ```
        """
    
        def _compute_module_dict_tf(model, prefix=""):
            _module_dict = dict()
            for key, value in model.__dict__.items():
                if isinstance(value, (tf.keras.Model, tf.keras.layers.Layer)):
                    if not hasattr(value, "named_parameters"):
                        _module_dict.update(
                            _compute_module_dict_tf(value, prefix=f"{key}.")
                        )
                    else:
                        _module_dict[prefix + key] = value
            return _module_dict
    
        try:
            pass
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`torch` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        try:
            import tensorflow as tf
        except ModuleNotFoundError as exc:
            raise ModuleNotFoundError(
                "`tensorflow` was not found installed on your system. Please proceed "
                "to install it and restart your interpreter to see the changes."
            ) from exc
    
        if hasattr(model_tf, "named_parameters"):
>           _sync_models_torch_and_tf(model_pt, model_tf)

../ivy/ivy/stateful/utilities.py:626: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model1 = OriNet(
  (features): Sequential(
    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False...2, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
    (20): Tanh()
    (21): AdaptiveAvgPool2d(output_size=1)
  )
)
model2 = tensorflow_OriNet(
  (features): tensorflow_Sequential(
    (0): KerasConv2D()
    (1): KerasBatchNorm2D()
    (2): te...tensorflow_Dropout()
    (19): KerasConv2D()
    (20): tensorflow_Tanh()
    (21): tensorflow_AdaptiveAvgPool2d()
  )
)

    def _sync_models_torch_and_tf(model1: "nn.Module", model2: "KerasModel"):
        """Synchronizes the parameters and buffers of the original and the
        translated model.
    
        Args:
        ----
            model1 (torch.nn.Module): The original PyTorch model.
            model2 (ivy.Module converted keras.Model)): The converted ivy.Module converted keras.Model.
    
        Returns:
        -------
            None
        """
        def _pt_name_to_keras_name(layer, weight_name):
            if layer.__class__.__name__ in ("KerasConv2D", "KerasDense"):
                param_and_buff_map = {
                    "weight": "_kernel",
                    "bias": "bias",
                }
            elif layer.__class__.__name__ == "KerasDepthwiseConv2D":
                if parse(keras.__version__).major > 2:
                    param_and_buff_map = {
                        "weight": "kernel",
                        "bias": "bias",
                    }
                else:
                    param_and_buff_map = {
                        "weight": "depthwise_kernel",
                        "bias": "bias",
                    }
            elif layer.__class__.__name__ == "KerasBatchNorm2D":
                param_and_buff_map = {
                    "weight": "gamma",
                    "bias": "beta",
                    "running_mean": "moving_mean",
                    "running_var": "moving_variance",
                    "num_batches_tracked": "num_batches_tracked",
                }
            else:
                raise ValueError(f"Layer '{layer}' is not supported.")
    
            return param_and_buff_map[weight_name]
    
        def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
            # Update the weight in the retrieved layer
            if hasattr(layer, weight_name):
                layer._is_built = True
                weight_var = getattr(layer, weight_name)
                if isinstance(weight_var, tf.Variable):
                    weight_var.assign(tf.Variable(new_weight, dtype=weight_var.dtype))
                elif isinstance(weight_var, KerasVariable):
                    weight_var.assign(
                        KerasVariable(
                            new_weight, dtype=weight_var.dtype, name=weight_var.name
                        )
                    )
                else:
                    setattr(
                        layer,
                        weight_name,
                        tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                    )
                # now also update the PT placeholder weights for this layer
                layer._is_built = False
                pt_weight_name = (
                    "pt_weight"
                    if weight_name == "weight"
                    else "pt_bias" if weight_name == "bias" else weight_name
                )
                setattr(
                    layer,
                    pt_weight_name,
                    None if original_weight is None else tf.convert_to_tensor(original_weight, dtype=weight_var.dtype),
                )
            else:
                raise AttributeError(
                    f"Layer '{layer}' does not have a weight named '{weight_name}'"
                )
    
        import torch
        import tensorflow as tf
        import keras
    
        if parse(keras.__version__).major > 2:
            KerasVariable = keras.src.backend.Variable
        else:
            KerasVariable = tf.Variable
    
        has_keras_layers = os.environ.get("USE_NATIVE_FW_LAYERS", "true") == "true"
        transpose_weights = (
            has_keras_layers
            or os.environ.get("APPLY_TRANSPOSE_OPTIMIZATION", "true") == "true"
        )
    
        params1 = dict(model1.named_parameters())
        params2 = dict(model2.named_parameters())
        buffers1 = dict(model1.named_buffers())
        buffers2 = dict(model2.named_buffers())
        # TODO: remove this once the stateful attribute name-conflict has been resolved.
        key_mapping = {}
        for k in params2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        for k in buffers2.keys():
            key_mapping[k.replace("pt_", "")] = k
    
        params2 = {k.replace("pt_", ""): v for k, v in params2.items()}
        buffers2 = {k.replace("pt_", ""): v for k, v in buffers2.items()}
    
        # Check if both models have the same parameters and buffers
        assert params1.keys() == params2.keys()
        assert buffers1.keys() == buffers2.keys()
    
        # Set the parameters and buffers of the second model to be the same as the first model
        with torch.no_grad():
            for name in params1:
                layer, weight_name = _retrive_layer(model2, key_mapping[name])
    
                params1_np = params1[name].cpu().detach().numpy()
                # Transpose the parameters to match the TensorFlow format
                params1_np = transpose_weights_pt_to_tf_jax(layer, params1_np, transpose_weights, fw='tensorflow')
    
                # inplace update the native keras layer. This is done as the parameters in
                # self.v are a different copy than the parameters in self.weights. Hence, we
                # need to explicitly update self.weights, otherwise the changes won't reflect.
                if layer.__class__.__name__.startswith("Keras"):
                    keras_name = _pt_name_to_keras_name(layer, weight_name)
>                   _maybe_update_keras_layer_weights(
                        layer=layer, weight_name=weight_name, new_weight=params1_np, original_weight=params1[name].cpu().detach().numpy()
                    )

../ivy/ivy/stateful/utilities.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

layer = KerasConv2D(), weight_name = 'weight'
new_weight = array([[[[-0.08703065, -0.16832928, -0.24788837,  0.07501563,
           0.01944828,  0.16840085,  0.00405781, -0.1656...88696, -0.15194595, -0.00362031,
           0.18245356,  0.28392023,  0.28989217, -0.16275363]]]],
      dtype=float32)
original_weight = array([[[[-0.08703065, -0.1806533 , -0.26843858],
         [ 0.00065569, -0.03845489, -0.19284551],
         [-0.02955...,
         [ 0.28705034,  0.08889314, -0.06958477],
         [ 0.32694516,  0.04513017, -0.16275363]]]], dtype=float32)

    def _maybe_update_keras_layer_weights(layer, weight_name, new_weight, original_weight):
        # Update the weight in the retrieved layer
        if hasattr(layer, weight_name):
            layer._is_built = True
>           weight_var = getattr(layer, weight_name)

../ivy/ivy/stateful/utilities.py:380: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KerasConv2D(), name = 'weight'

    def __getattribute__(self, name):
        built = object.__getattribute__(self, "__dict__").get("_is_built", False)
        use_bias = object.__getattribute__(self, "__dict__").get("use_bias", True)
        if built:
            attr_map = {"weight": "_kernel", "bias": "bias"}
        else:
            attr_map = {"weight": "pt_weight", "bias": "pt_bias"}
        if not use_bias:
            attr_map["bias"] = "pt_bias"
        new_name = attr_map[name] if name in attr_map else name
>       return super().__getattribute__(new_name)
E       AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful_layers.py:626: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.integrated.get_laf_descriptors
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature1.py::test_get_laf_descriptors[tensorflow-s2s-False] - AttributeError: 'KerasConv2D' object has no attribute '_kernel'. Did you mean: 'weights'?
============================================================================== 1 failed, 18 passed in 1600.71s (0:26:40) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 3 items

kornia/augmentation/test_auto.py FFF                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_AutoAugment[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_AutoAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.AutoAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAutoAugment = ivy.transpile(
            kornia.augmentation.auto.AutoAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.AutoAugment()
>       transpiled_aug = TranspiledAutoAugment()

kornia/augmentation/test_auto.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fc6774abf10>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.autoaugment.autoaugment.jax_AutoAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fc6774abf10>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fc6774abf10>, policy = 'imagenet', transformation_matrix_mode = 'silent'

    def __init__(self, policy="imagenet", transformation_matrix_mode="silent"):
        from ....core._backend import tensor
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy == "imagenet":
            _policy = imagenet_policy
        elif policy == "cifar10":
            _policy = cifar10_policy
        elif policy == "svhn":
            _policy = svhn_policy
        elif isinstance(policy, (list, tuple)):
            _policy = policy
        else:
            raise NotImplementedError(f"Invalid policy `{policy}`.")
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fc6774abf10>
args = ([[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8...rize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fc6774abf10>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fc6774abf10>
policy = [[('posterize', 0.4, 8), ('rotate', 0.6, 9)], [('solarize', 0.6, 5), ('auto_contrast', 0.6, None)], [('equalize', 0.8,...terize', 0.6, 6)], [('equalize', 0.4, None), ('solarize', 0.2, 4)], [('equalize', 0.4, None), ('rotate', 0.8, 8)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fc6774abd00>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_AutoAugment object at 0x7fc6774abf10>, subpolicy = [('posterize', 0.4, 8), ('rotate', 0.6, 9)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        return jax_PolicySequential(
>           *[
                getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
                for name, prob, mag in subpolicy
            ]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fc6774abca0>

        *[
>           getattr(kornia.augmentation.auto.autoaugment.ops, name)(prob, mag)
            for name, prob, mag in subpolicy
        ]
    )
E   NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/autoaugment/autoaugment.py:136: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.AutoAugment
___________________________________________________________________________________ test_RandAugment[jax-s2s-False] ____________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.RandAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRandAugment = ivy.transpile(
            kornia.augmentation.auto.RandAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.RandAugment(n=2, m=10)
>       transpiled_aug = TranspiledRandAugment(n=2, m=10)

kornia/augmentation/test_auto.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>, args = (), kwargs = {'m': 10, 'n': 2}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fc677cd8d00>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.rand_augment.rand_augment.jax_RandAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fc677cd8d00>, args = (), kwargs = {'m': 10, 'n': 2}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fc677cd8d00>, n = 2, m = 10, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, n, m, policy=None, transformation_matrix_mode="silent"):
        if m <= 0 or m >= 30:
            raise ValueError(f"Expect `m` in [0, 30]. Got {m}.")
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fc677cd8d00>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fc677cd8d00>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...], transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fc677cd8d00>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('invert', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fc675820c70>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_RandAugment object at 0x7fc677cd8d00>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for RandAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/rand_augment/rand_augment.py:81: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.RandAugment
__________________________________________________________________________________ test_TrivialAugment[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_TrivialAugment(target_framework, mode, backend_compile):
        print("kornia.augmentation.auto.TrivialAugment")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledTrivialAugment = ivy.transpile(
            kornia.augmentation.auto.TrivialAugment,
            source="torch",
            target=target_framework,
        )
    
        torch_aug = kornia.augmentation.auto.TrivialAugment()
>       transpiled_aug = TranspiledTrivialAugment()

kornia/augmentation/test_auto.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>, args = (), kwargs = {}
node = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fc6779fa440>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.augmentation.auto.trivial_augment.trivial_augment.jax_TrivialAugment'>
self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fc6779fa440>, args = (), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fc6779fa440>, policy = None, transformation_matrix_mode = 'silent'

    def __init__(self, policy=None, transformation_matrix_mode="silent"):
        from .....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
        from .....torch.distributions.categorical import jax_Categorical
    
        if policy is None:
            _policy = default_policy
        else:
            _policy = policy
>       super().__init__(_policy, transformation_matrix_mode=transformation_matrix_mode)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fc6779fa440>
args = ([[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...],)
kwargs = {'transformation_matrix_mode': 'silent'}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fc6779fa440>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]
transformation_matrix_mode = 'silent'

    @jax_store_config_info
    def __init__(self, policy, transformation_matrix_mode="silence"):
        from .operations.policy import jax_PolicySequential
    
>       policies = self.compose_policy(policy)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fc6779fa440>
policy = [[('auto_contrast', 0, 1)], [('equalize', 0, 1)], [('rotate', -30.0, 30.0)], [('posterize', 0.0, 4)], [('solarize', 0.0, 1.0)], [('contrast', 0.1, 1.9)], ...]

    def compose_policy(self, policy):
>       return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <list_iterator object at 0x7fc6779f9780>

>   return [self.compose_subpolicy_sequential(subpolicy) for subpolicy in policy]

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/base.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] jax_TrivialAugment object at 0x7fc6779fa440>, subpolicy = [('auto_contrast', 0, 1)]

    def compose_subpolicy_sequential(self, subpolicy):
        from ..operations.policy import jax_PolicySequential
    
        if len(subpolicy) != 1:
            raise RuntimeError(
                f"Each policy must have only one operation for TrivialAugment. Got {len(subpolicy)}."
            )
        name, low, high = subpolicy[0][0], subpolicy[0][1], subpolicy[0][2]
        return jax_PolicySequential(
>           *[getattr(kornia.augmentation.auto.rand_augment.ops, name)(low, high)]
        )
E       NameError: name 'kornia' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/auto/trivial_augment/trivial_augment.py:67: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.auto.TrivialAugment
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_auto.py::test_AutoAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_RandAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
FAILED kornia/augmentation/test_auto.py::test_TrivialAugment[jax-s2s-False] - NameError: name 'kornia' is not defined
==================================================================================== 3 failed in 1370.67s (0:22:50) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/geometry/test_quaternion.py .                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
===================================================================================== 1 passed in 90.02s (0:01:30) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 38 items

kornia/geometry/test_conversions.py ......................................                                                                                                                       [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
=================================================================================== 38 passed in 1999.72s (0:33:19) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/augmentation/test_container.py FFFFFF                                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________ test_AugmentationSequential[tensorflow-s2s-False] ___________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_AugmentationSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.AugmentationSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.AugmentationSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.augmentation.RandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledAugmentationSequential(
            TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledRandomAffine(360, p=1.0),
            data_keys=["input", "mask", "bbox", "keypoints"],
            same_on_batch=False,
            random_apply=10,
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
            torch.tensor([[
                [1., 1.],
                [2., 1.],
                [2., 2.],
                [1., 2.],
            ]]).expand(2, 1, -1, -1),
            torch.tensor([[[1., 1.]]]).expand(2, -1, -1),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-4.41512942e-01,  3.70644480e-01, -1.94193438e-01,
  ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8b6fad9e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-4.41512942e-01,  3.70644480e-01, -1.94193438e-01,
  ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, ...one, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-4.41512942e-01,  3.70644480e-01, -1.94193438e-01,
  ...=float32)>, <tf.Tensor: shape=(2, 1, 2), dtype=float32, numpy=
array([[[1., 1.]],

       [[1., 1.]]], dtype=float32)>)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (*args, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_AugmentationSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1,...e, shear=None, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, padding_mode=zeros, align_corners=False)
),)
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-4.41512942e-01,  3.70644480e-01, -1.94193438...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-4.41512942e-01,  3.70644480e-01, -1.94193438....18270659e+00, -1.92607113e-04,
           5.76401912e-02,  1.68199316e-01, -1.50121868e+00]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*args, params=None, data_keys=None)>, args = ()
kwargs = {'args': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[-4.41512942e-01,  3.70644480e-01, -1.94193438....18270659e+00, -1.92607113e-04,
           5.76401912e-02,  1.68199316e-01, -1.50121868e+00]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'args'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.AugmentationSequential
______________________________________________________________________ test_ManyToManyAugmentationDispather[tensorflow-s2s-False] ______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToManyAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToManyAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledManyToManyAugmentationDispather = ivy.transpile(
            kornia.augmentation.container.ManyToManyAugmentationDispather,
            source="torch",
            target=target_framework,
        )
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ManyToManyAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = TranspiledManyToManyAugmentationDispather(
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
            (torch.randn(2, 3, 5, 6), torch.ones(2, 3, 5, 6)),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather()
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.4397385 , -1.2587585 , -0.3790831 ,  1.4044774 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8b6ecf0840, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.439...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.4397385 , -1.2587585 , -0.3790831 ,  1.4044774 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(), (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.439...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToManyAugmentationDispather(), v = None, buffers = None
args = ((<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.4397385 , -1.2587585 , -0.3790831 ,  1.4044774 ,
...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>))
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.4397385 , -1.2587585 , -0.3790831 ,  1.4044774 ,
  ...,
         [ 0.29643965,  0.7194751 ,  1.9338365 ,  0.83338034,
          -0.10340908, -1.2599955 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToManyAugmentationDispather(),)
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.4397385 , -1.2587585 , -0.3790831 ,  1.4...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.4397385 , -1.2587585 , -0.3790831 ,  1.4...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 1.4397385 , -1.2587585 , -0.3790831 ,  1.4...   [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToManyAugmentationDispather
______________________________________________________________________ test_ManyToOneAugmentationDispather[tensorflow-s2s-False] _______________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ManyToOneAugmentationDispather(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ManyToOneAugmentationDispather")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledManyToOneAugmentationDispather = ivy.transpile(
            kornia.augmentation.container.ManyToOneAugmentationDispather,
            source="torch",
            target=target_framework,
        )
        TranspiledAugmentationSequential = ivy.transpile(
            kornia.augmentation.container.AugmentationSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ManyToOneAugmentationDispather(
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            kornia.augmentation.container.AugmentationSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                kornia.augmentation.RandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
        transpiled_aug_list = TranspiledManyToOneAugmentationDispather(
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            ),
            TranspiledAugmentationSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
                TranspiledRandomAffine(360, p=1.0),
                data_keys=["input", "mask",],
            )
        )
    
        torch_args = (
            torch.randn(2, 3, 5, 6),
            torch.ones(2, 3, 5, 6),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather()
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2578319 ,  1.305368  , -1.0592233 ,  2.0329628 ,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8b6ef18a40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.25783...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2578319 ,  1.305368  , -1.0592233 ,  2.0329628 ,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(), <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.25783...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ManyToOneAugmentationDispather(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2578319 ,  1.305368  , -1.0592233 ,  2.0329628 ,
 ...    [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1., 1.]]]], dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2578319 ,  1.305368  , -1.0592233 ,  2.0329628 ,
  ...,
         [ 1.6622553 , -0.3813076 ,  0.16473539, -0.31321612,
          -0.14017671, -0.9450551 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_ManyToOneAugmentationDispather(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2578319 ,  1.305368  , -1.0592233 ,  2.03...
         [ 1.6622553 , -0.3813076 ,  0.16473539, -0.31321612,
          -0.14017671, -0.9450551 ]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2578319 ,  1.305368  , -1.0592233 ,  2.03...
         [ 1.6622553 , -0.3813076 ,  0.16473539, -0.31321612,
          -0.14017671, -0.9450551 ]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 3, 5, 6), dtype=float32, numpy=
array([[[[ 0.2578319 ,  1.305368  , -1.0592233 ,  2.03...
         [ 1.6622553 , -0.3813076 ,  0.16473539, -0.31321612,
          -0.14017671, -0.9450551 ]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ManyToOneAugmentationDispather
______________________________________________________________________________ test_ImageSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_ImageSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.ImageSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
        TranspiledMedianBlur = ivy.transpile(
            kornia.filters.MedianBlur,
            source="torch",
            target=target_framework,
        )
        TranspiledInvert = ivy.transpile(
            kornia.enhance.Invert,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomMixUpV2 = ivy.transpile(
            kornia.augmentation.RandomMixUpV2,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.ImageSequential(
            kornia.color.BgrToRgb(),
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.filters.MedianBlur((3, 3)),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.enhance.Invert(),
            kornia.augmentation.RandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )
        transpiled_aug_list = TranspiledImageSequential(
            TranspiledBgrToRgb(),
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledMedianBlur((3, 3)),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledInvert(),
            TranspiledRandomMixUpV2(p=1.0),
            same_on_batch=True,
            random_apply=10,
        )

kornia/augmentation/test_container.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ColorJiggle' object has no attribute 'p'") raised in repr()] tensorflow_ColorJiggle object at 0x7f8b6c161990>, args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_ColorJiggle' object has no attribute 'p'") raised in repr()] tensorflow_ColorJiggle object at 0x7f8b6c161990>, brightness = 0.1, contrast = 0.1, saturation = 0.1
hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.random_generator._2d.color_jiggle'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:46: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.ImageSequential
______________________________________________________________________________ test_PatchSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_PatchSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.PatchSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledPatchSequential = ivy.transpile(
            kornia.augmentation.container.PatchSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledImageSequential = ivy.transpile(
            kornia.augmentation.container.ImageSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomPerspective = ivy.transpile(
            kornia.augmentation.RandomPerspective,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomSolarize = ivy.transpile(
            kornia.augmentation.RandomSolarize,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.PatchSequential(
            kornia.augmentation.container.ImageSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=0.5),
                kornia.augmentation.RandomPerspective(0.2, p=0.5),
                kornia.augmentation.RandomSolarize(0.1, 0.1, p=0.5),
            ),
            kornia.augmentation.RandomAffine(360, p=1.0),
            kornia.augmentation.container.ImageSequential(
                kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=0.5),
                kornia.augmentation.RandomPerspective(0.2, p=0.5),
                kornia.augmentation.RandomSolarize(0.1, 0.1, p=0.5),
            ),
            kornia.augmentation.RandomSolarize(0.1, 0.1, p=0.1),
            grid_size=(2,2),
            patchwise_apply=True,
            same_on_batch=True,
            random_apply=False,
        )
        transpiled_aug_list = TranspiledPatchSequential(
            TranspiledImageSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=0.5),
                TranspiledRandomPerspective(0.2, p=0.5),
                TranspiledRandomSolarize(0.1, 0.1, p=0.5),
            ),
            TranspiledRandomAffine(360, p=1.0),
            TranspiledImageSequential(
                TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=0.5),
                TranspiledRandomPerspective(0.2, p=0.5),
                TranspiledRandomSolarize(0.1, 0.1, p=0.5),
            ),
            TranspiledRandomSolarize(0.1, 0.1, p=0.1),
            grid_size=(2,2),
            patchwise_apply=True,
            same_on_batch=True,
            random_apply=False,
        )
    
        torch_args = (
            torch.randn(2, 3, 224, 224),
        )
        torch_out = torch_aug_list(*torch_args)
    
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
>       transpiled_out = transpiled_aug_list(*transpiled_args)

kornia/augmentation/test_container.py:363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
args = (<tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[-3.8235173e-01,  3.1080472e-01,  1.1827037e+00, ....0714908e+00,  9.9865776e-01, ...,
           2.4088771e+00,  5.6279320e-01, -1.7014978e+00]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f8b6ecf2e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle....0714908e+00,  9.9865776e-01, ...,
           2.4088771e+00,  5.6279320e-01, -1.7014978e+00]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[-3.8235173e-01,  3.1080472e-01,  1.1827037e+00, ....0714908e+00,  9.9865776e-01, ...,
           2.4088771e+00,  5.6279320e-01, -1.7014978e+00]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle....0714908e+00,  9.9865776e-01, ...,
           2.4088771e+00,  5.6279320e-01, -1.7014978e+00]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[-3.8235173e-01,  3.1080472e-01,  1.1827037e+00, ....0714908e+00,  9.9865776e-01, ...,
           2.4088771e+00,  5.6279320e-01, -1.7014978e+00]]]],
      dtype=float32)>,)
kwargs = {}, replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle...RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[-3.8235173e-01,  3.1080472e-01,  1.18270....0714908e+00,  9.9865776e-01, ...,
           2.4088771e+00,  5.6279320e-01, -1.7014978e+00]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
input = <tf.Tensor: shape=(2, 3, 224, 224), dtype=float32, numpy=
array([[[[-3.8235173e-01,  3.1080472e-01,  1.1827037e+00, .....1.0714908e+00,  9.9865776e-01, ...,
           2.4088771e+00,  5.6279320e-01, -1.7014978e+00]]]],
      dtype=float32)>
params = [tensorflow_PatchParamItem(indices=[0, 3], param=tensorflow_ParamItem(name='tensorflow_ImageSequential_0', data=[tenso..., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})]))]

    def call(self, input, params=None):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
    
        if isinstance(input, (tuple,)):
            raise ValueError("tuple input is not currently supported.")
        if params is None:
            params = self.forward_parameters(tensorflow_shape_frnt_(input))
>       output = self.transform_inputs(input, params=params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/patch.py:367: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
input = <tf.Tensor: shape=(2, 4, 3, 112, 112), dtype=float32, numpy=
array([[[[[-3.82351726e-01,  3.10804725e-01,  1.18270373e...396e-01, -1.00644422e+00, ...,
            2.40887713e+00,  5.62793195e-01, -1.70149779e+00]]]]],
      dtype=float32)>
params = [tensorflow_PatchParamItem(indices=[0, 3], param=tensorflow_ParamItem(name='tensorflow_ImageSequential_0', data=[tenso..., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})]))]
extra_args = {}

    def transform_inputs(self, input, params, extra_args={}):
        pad = self.compute_padding(input, self.padding)
        input = self.extract_patches(input, self.grid_size, pad)
>       input = self.forward_by_params(input, params)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/patch.py:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchSequential(
  (tensorflow_ImageSequential_0): tensorflow_ImageSequential(
    (tensorflow_ColorJiggle_...w_RandomSolarize_3): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.1, p_batch=1.0, same_on_batch=True)
)
input = <tf.Tensor: shape=(8, 3, 112, 112), dtype=float32, numpy=
array([[[[-3.82351726e-01,  3.10804725e-01,  1.18270373e+00,...74396e-01, -1.00644422e+00, ...,
           2.40887713e+00,  5.62793195e-01, -1.70149779e+00]]]],
      dtype=float32)>
params = [tensorflow_PatchParamItem(indices=[0, 3], param=tensorflow_ParamItem(name='tensorflow_ImageSequential_0', data=[tenso..., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})]))]

    def forward_by_params(self, input, params):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_reshape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .ops import tensorflow_InputSequentialOps
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        in_shape = tensorflow_shape_frnt_(input)
        input = tensorflow_reshape_frnt_(input, -1, *in_shape[-3:])
        for patch_param in params:
            module = self.get_submodule(patch_param.param.name)
            _input = tensorflow_get_item(input, patch_param.indices)
>           output = tensorflow_InputSequentialOps.transform(
                _input, module, patch_param.param, extra_args={}
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/patch.py:291: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.container.ops.tensorflow_InputSequentialOps'>
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[-0.38235173,  0.31080472,  1.1827037 , ...,  0.333...      [-1.3032898 , -2.5486605 ,  1.37242   , ..., -0.441484  ,
           2.1520352 ,  0.7208056 ]]]], dtype=float32)>
module = tensorflow_ImageSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturat...w_RandomSolarize_2): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
)
param = tensorflow_ParamItem(name='tensorflow_ImageSequential_0', data=[tensorflow_ParamItem(name='tensorflow_ColorJiggle_0', ...1., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})])
extra_args = {}

    @classmethod
    def transform(cls, input, module, param, extra_args={}):
        from .base import tensorflow_ImageSequentialBase
        from ..base import tensorflow__AugmentationBase
        from .._2d.mix.base import tensorflow_MixAugmentationBaseV2
        from ...constants import tensorflow_DataKey
        from ..auto.operations.base import tensorflow_OperationBase
        from ....ivy.functional.frontends.torch.tensor import tensorflow_data_frnt_
    
        if isinstance(
            module, (tensorflow__AugmentationBase, tensorflow_MixAugmentationBaseV2)
        ):
            input = module(
                input,
                params=cls.get_instance_module_param(param),
                data_keys=[tensorflow_DataKey.INPUT],
                **extra_args,
            )
        elif isinstance(module, (tensorflow_ImageSequentialBase,)):
>           input = module.transform_inputs(
                input,
                params=cls.get_sequential_module_param(param),
                extra_args=extra_args,

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/ops.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_ImageSequential(
  (tensorflow_ColorJiggle_0): tensorflow_ColorJiggle(brightness=0.1, contrast=0.1, saturat...w_RandomSolarize_2): tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
)
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
params = [tensorflow_ParamItem(name='tensorflow_ColorJiggle_0', data={'brightness_factor': <tf.Tensor: shape=(2,), dtype=float3...[1., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})]
extra_args = {}

    def transform_inputs(self, input, params, extra_args={}):
        from .ops import tensorflow_InputSequentialOps
    
        for param in params:
            module = self.get_submodule(param.name)
>           input = tensorflow_InputSequentialOps.transform(
                input, module=module, param=param, extra_args=extra_args
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/base.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.container.ops.tensorflow_InputSequentialOps'>
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
module = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
param = tensorflow_ParamItem(name='tensorflow_RandomSolarize_2', data={'thresholds': <tf.Tensor: shape=(2,), dtype=float32, nu...([1., 1.], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>})
extra_args = {}

    @classmethod
    def transform(cls, input, module, param, extra_args={}):
        from .base import tensorflow_ImageSequentialBase
        from ..base import tensorflow__AugmentationBase
        from .._2d.mix.base import tensorflow_MixAugmentationBaseV2
        from ...constants import tensorflow_DataKey
        from ..auto.operations.base import tensorflow_OperationBase
        from ....ivy.functional.frontends.torch.tensor import tensorflow_data_frnt_
    
        if isinstance(
            module, (tensorflow__AugmentationBase, tensorflow_MixAugmentationBaseV2)
        ):
>           input = module(
                input,
                params=cls.get_instance_module_param(param),
                data_keys=[tensorflow_DataKey.INPUT],
                **extra_args,

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/container/ops.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
args = (<tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.617065...
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>,)
kwargs = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>], 'params': {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=ar..., 224, 224])>, 'thresholds': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.491516, 0.491516], dtype=float32)>}}
stack = [FrameInfo(frame=<frame at 0x7f8b6c4d0640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/..., function='transform_inputs', code_context=['        input = self.forward_by_params(input, params)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.617065...
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>,)
kwargs = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>], 'params': {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=ar..., 224, 224])>, 'thresholds': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.491516, 0.491516], dtype=float32)>}}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.617065...
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>,)
kwargs = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>], 'params': {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=ar..., 224, 224])>, 'thresholds': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.491516, 0.491516], dtype=float32)>}}
first_arr = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
params = {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.05774875, -0.05774875], dtype=float32)>, 'batch_p...low_DataKey.IMAGE: 0>], 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>, ...}
kwargs = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f8b6c72d5a0>
tensorflow_set_item = <function tensorflow_set_item at 0x7f8b6cfac670>, tensor = <function tensorflow_tensor_frnt at 0x7f8b6c6c6710>
in_tensor = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([2, 3, 112, 112]), batch_shape = ivy.frontends.torch.Size([2, 3, 112, 112]), flags = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
in_tensor = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
params = {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.05774875, -0.05774875], dtype=float32)>, 'batch_p...low_DataKey.IMAGE: 0>], 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>, ...}
flags = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
params = {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.05774875, -0.05774875], dtype=float32)>, 'batch_p...low_DataKey.IMAGE: 0>], 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>, ...}
flags = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}
transform = <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7f8b6c72d5a0>, tensorflow_all_frnt_ = <function tensorflow_all_frnt_ at 0x7f8b675aa680>
tensorflow_any_frnt_ = <function tensorflow_any_frnt_ at 0x7f8b6e5b3a30>, tensorflow_get_item = <function tensorflow_get_item at 0x7f8b6cfac4c0>
tensorflow_is_autocast_enabled = <function tensorflow_is_autocast_enabled at 0x7f8b6c925cf0>, tensorflow_type_frnt_ = <function tensorflow_type_frnt_ at 0x7f8b6e5b3760>
tensorflow_index_put_frnt_ = <function tensorflow_index_put_frnt_ at 0x7f8b6e5b39a0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ..utils.helpers import tensorflow_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
        from .utils.helpers import tensorflow__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = tensorflow_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if tensorflow_all_frnt_(to_apply):
>           output = self.apply_transform(in_tensor, params, flags, transform=transform)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomSolarize(thresholds=0.1, additions=0.1, p=0.5, p_batch=1.0, same_on_batch=True)
input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
params = {'additions': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.05774875, -0.05774875], dtype=float32)>, 'batch_p...low_DataKey.IMAGE: 0>], 'forward_input_shape': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  2, 224, 224])>, ...}
flags = {'data_keys': [<tensorflow_DataKey.IMAGE: 0>]}
transform = <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=
array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)>

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.adjust import tensorflow_solarize
    
        thresholds = params["thresholds"]
        additions: typing.Any
        if "additions" in params:
            additions = params["additions"]
        else:
            additions = None
>       return tensorflow_solarize(input, thresholds, additions)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/solarize.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2, 3, 112, 112), dtype=float32, numpy=
array([[[[0.09087585, 0.4102996 , 1.        , ..., 0.6170655...],
         [0.03613377, 0.08442988, 1.        , ..., 0.03613377,
          0.8965822 , 0.8146866 ]]]], dtype=float32)>
thresholds = <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.491516, 0.491516], dtype=float32)>
additions = <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.05774875, -0.05774875], dtype=float32)>

    def tensorflow_solarize(input, thresholds=0.5, additions=None):
        from ...ivy.functional.frontends.torch.creation_ops import tensorflow_as_tensor_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_all_frnt
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_expand_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_clamp_frnt_
    
        if not isinstance(input, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input type is not a Tensor. Got {type(input)}")
        if not isinstance(thresholds, (float, tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(
                f"The factor should be either a float or Tensor. Got {type(thresholds)}"
            )
        if isinstance(thresholds, (float,)):
            thresholds = tensorflow_as_tensor_frnt(thresholds)
        if additions is not None:
            if not isinstance(additions, (float, tensorflow.Tensor, tensorflow.Variable)):
                raise TypeError(
                    f"The factor should be either a float or Tensor. Got {type(additions)}"
                )
            if isinstance(additions, (float,)):
                additions = tensorflow_as_tensor_frnt(additions)
>           if not tensorflow_all_frnt((additions < 0.5) * (additions > -0.5)):

ivy_transpiled_outputs/tensorflow_outputs/kornia/enhance/adjust.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>, rhs = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>, other = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>, other = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>, x2 = <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_RandomSolarize.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_RandomSolarize.call():
E          input=tf.Tensor(shape=(2, 3, 112, 112), dtype=float32)
E          params={'thresholds': 'tf.Tensor(shape=(2,), dtype=float32)', 'additions': 'tf.Tensor(shape=(2,), dtype=float32)', 'batch_prob': 'tf.Tensor(shape=(2,), dtype=float32)', 'forward_input_shape': 'tf.Tensor(shape=(3,), dtype=int64)'}
E          kwargs={'data_keys': ['<tensorflow_DataKey.IMAGE: 0>']}

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:363: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.PatchSequential
______________________________________________________________________________ test_VideoSequential[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_VideoSequential(target_framework, mode, backend_compile):
        print("kornia.augmentation.container.VideoSequential")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledVideoSequential = ivy.transpile(
            kornia.augmentation.container.VideoSequential,
            source="torch",
            target=target_framework,
        )
        TranspiledColorJiggle = ivy.transpile(
            kornia.augmentation.ColorJiggle,
            source="torch",
            target=target_framework,
        )
        TranspiledRandomAffine = ivy.transpile(
            kornia.augmentation.RandomAffine,
            source="torch",
            target=target_framework,
        )
        TranspiledBgrToRgb = ivy.transpile(
            kornia.color.BgrToRgb,
            source="torch",
            target=target_framework,
        )
    
        torch_aug_list = kornia.augmentation.container.VideoSequential(
            kornia.augmentation.ColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            kornia.color.BgrToRgb(),
            kornia.augmentation.RandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )
        transpiled_aug_list =  TranspiledVideoSequential(
>           TranspiledColorJiggle(0.1, 0.1, 0.1, 0.1, p=1.0),
            TranspiledBgrToRgb(),
            TranspiledRandomAffine(360, p=1.0),
            random_apply=10,
            data_format="BCTHW",
            same_on_frame=True
        )

kornia/augmentation/test_container.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'") raised in repr()] tensorflow_ColorJiggle object at 0x7f8b67422650>
args = (0.1, 0.1, 0.1, 0.1), kwargs = {'p': 1.0}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[ModuleNotFoundError("No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'") raised in repr()] tensorflow_ColorJiggle object at 0x7f8b67422650>, brightness = 0.1
contrast = 0.1, saturation = 0.1, hue = 0.1, same_on_batch = False, p = 1.0, keepdim = False

>   ???
E   ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'

/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/intensity/color_jiggle.py:46: ModuleNotFoundError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.container.VideoSequential
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_container.py::test_AugmentationSequential[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'args'
FAILED kornia/augmentation/test_container.py::test_ManyToManyAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ManyToOneAugmentationDispather[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_container.py::test_ImageSequential[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation.random...
FAILED kornia/augmentation/test_container.py::test_PatchSequential[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflo...
FAILED kornia/augmentation/test_container.py::test_VideoSequential[tensorflow-s2s-False] - ModuleNotFoundError: No module named 'ivy_transpiled_outputs.tensorflow_outputs.kornia.augmentation'
==================================================================================== 6 failed in 2380.03s (0:39:40) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py ssssssssss                                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 10 skipped in 5.15s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_boxes.py FF                                                                                                                                                                 [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_Boxes[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes = ivy.transpile(kornia.geometry.boxes.Boxes, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 1, 4], [5, 1, 8, 4]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes = kornia.geometry.boxes.Boxes.from_tensor(*torch_args, mode="xyxy")
        transpiled_boxes = TranspiledBoxes.from_tensor(*transpiled_args, mode="xyxy")
        _check_boxes_same(torch_boxes, transpiled_boxes)
    
        # test .compute_area
        torch_area = torch_boxes.compute_area()
        transpiled_area = transpiled_boxes.compute_area()
        _to_numpy_and_allclose(torch_area, transpiled_area)
    
        # test .get_boxes_shape
        torch_heights, torch_widths = torch_boxes.get_boxes_shape()
        transpiled_heights, transpiled_widths = transpiled_boxes.get_boxes_shape()
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .merge
        torch_x = torch.as_tensor([[6, 6, 10, 10], [6, 6, 10, 10]])
        transpiled_x = _nest_torch_tensor_to_new_framework(torch_x, target_framework)
        merge_boxes = kornia.geometry.boxes.Boxes.from_tensor(torch_x, mode="xyxy")
        transpiled_merge_boxes = TranspiledBoxes.from_tensor(transpiled_x, mode="xyxy")
        torch_merged_boxes = torch_boxes.merge(merge_boxes)
        transpiled_merged_boxes = transpiled_boxes.merge(transpiled_merge_boxes)
        _check_boxes_same(torch_merged_boxes, transpiled_merged_boxes)
    
        # test .to_mask
        height, width = 10, 10
        torch_mask = torch_boxes.to_mask(height, width)
        transpiled_mask = transpiled_boxes.to_mask(height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0....., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0...],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes
_____________________________________________________________________________________ test_Boxes3D[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Boxes3D(target_framework, mode, backend_compile):
        print("kornia.geometry.boxes.Boxes3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledBoxes3D = ivy.transpile(kornia.geometry.boxes.Boxes3D, source="torch", target=target_framework)
    
        torch_args = (
            torch.as_tensor([[0, 3, 6, 1, 4, 8], [5, 1, 3, 8, 4, 9]]),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        # test .from_tensor
        torch_boxes3d = kornia.geometry.boxes.Boxes3D.from_tensor(*torch_args, mode="xyzxyz")
        transpiled_boxes3d = TranspiledBoxes3D.from_tensor(*transpiled_args, mode="xyzxyz")
        _check_boxes_same(torch_boxes3d, transpiled_boxes3d)
    
        # test .get_boxes_shape
        torch_depths, torch_heights, torch_widths = torch_boxes3d.get_boxes_shape()
        transpiled_depths, transpiled_heights, transpiled_widths = transpiled_boxes3d.get_boxes_shape()
        _to_numpy_and_allclose(torch_depths, transpiled_depths)
        _to_numpy_and_allclose(torch_heights, transpiled_heights)
        _to_numpy_and_allclose(torch_widths, transpiled_widths)
    
        # test .to_mask
        depth, height, width = 10, 10, 10
        torch_mask = torch_boxes3d.to_mask(depth, height, width)
        transpiled_mask = transpiled_boxes3d.to_mask(depth, height, width)
>       _to_numpy_and_allclose(torch_mask, transpiled_mask)

kornia/geometry/test_boxes.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0... [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
transpiled_x = Array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
y = array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]...0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.boxes.Boxes3D
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_boxes.py::test_Boxes[jax-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_boxes.py::test_Boxes3D[jax-s2s-False] - AssertionError: numpy array values are not all close
==================================================================================== 2 failed in 198.07s (0:03:18) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 35 items

kornia/test_losses.py .................FF..F.............                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_HausdorffERLoss[tensorflow-s2s-False] ______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss = ivy.transpile(kornia.losses.HausdorffERLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss()
        transpiled_loss_fn = TranspiledHausdorffERLoss()
    
        torch_args = (
            torch.randn(5, 3, 20, 20),
            (torch.rand(5, 1, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:446: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.59981230e-03, -9.07764673e-01, ...        ...,
         [0, 0, 1, ..., 1, 1, 1],
         [0, 1, 0, ..., 0, 1, 0],
         [0, 1, 1, ..., 0, 0, 0]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7faf0030c640, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.5...        ...,
         [0, 0, 1, ..., 1, 1, 1],
         [0, 1, 0, ..., 0, 1, 0],
         [0, 1, 1, ..., 0, 0, 0]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.59981230e-03, -9.07764673e-01, ...        ...,
         [0, 0, 1, ..., 1, 1, 1],
         [0, 1, 0, ..., 0, 1, 0],
         [0, 1, 1, ..., 0, 0, 0]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(), <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.5...        ...,
         [0, 0, 1, ..., 1, 1, 1],
         [0, 1, 0, ..., 0, 1, 0],
         [0, 1, 1, ..., 0, 0, 0]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.59981230e-03, -9.07764673e-01, ...        ...,
         [0, 0, 1, ..., 1, 1, 1],
         [0, 1, 0, ..., 0, 1, 0],
         [0, 1, 1, ..., 0, 0, 0]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.59981230e-03, -9.07764673e-01, ....73594e-01, -2.03613698e-01, ...,
          -1.33123207e+00,  7.18773454e-02, -1.43948615e+00]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.59981230e-03, -9.077646...        ...,
         [0, 0, 1, ..., 1, 1, 1],
         [0, 1, 0, ..., 0, 1, 0],
         [0, 1, 1, ..., 0, 0, 0]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.59981230e-03, -9.07764673e-01, ....73594e-01, -2.03613698e-01, ...,
          -1.33123207e+00,  7.18773454e-02, -1.43948615e+00]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 0, 0, ..., 1, 0, 1],
         [0, 0, 0, ..., 1, 1, ...         ...,
         [0, 0, 1, ..., 1, 1, 1],
         [0, 1, 0, ..., 0, 1, 0],
         [0, 1, 1, ..., 0, 0, 0]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
    
        if tensorflow_dim_frnt_(pred) != 4:
            raise ValueError(
                f"Only 2D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
        if not (
            tensorflow_max_frnt_(target) < tensorflow_size_frnt_(pred, 1)
            and tensorflow_min_frnt_(target) >= 0
            and target.dtype == tf.int64
        ):
            raise ValueError(
                f"Expect long type target value in range (0, {tensorflow_size_frnt_(pred, 1)}). ({tensorflow_min_frnt_(target)}, {tensorflow_max_frnt_(target)})"
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:289: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 3, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.59981230e-03, -9.07764673e-01, ....73594e-01, -2.03613698e-01, ...,
          -1.33123207e+00,  7.18773454e-02, -1.43948615e+00]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[1, 0, 0, ..., 1, 0, 1],
         [0, 0, 0, ..., 1, 1, ...         ...,
         [0, 0, 1, ..., 1, 1, 1],
         [0, 1, 0, ..., 0, 1, 0],
         [0, 1, 1, ..., 0, 0, 0]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7faef08f1fb0>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss()
pred = <tf.Tensor: shape=(5, 1, 20, 20), dtype=float32, numpy=
array([[[[ 5.54103553e-01,  6.59981230e-03, -9.07764673e-01, ....09048e-01,  1.36794078e+00, ...,
          -8.50368738e-01,  9.09779429e-01,  6.07544124e-01]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20), dtype=int64, numpy=
array([[[[0, 1, 1, ..., 0, 1, 0],
         [1, 1, 1, ..., 0, 0, ...         ...,
         [1, 1, 0, ..., 0, 0, 0],
         [1, 0, 1, ..., 1, 0, 1],
         [1, 0, 0, ..., 1, 1, 1]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
E           
E           [1mtensorflow_conv2d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss.call():
E              pred=tf.Tensor(shape=(5, 3, 20, 20), dtype=float32)
E              target=tf.Tensor(shape=(5, 1, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss
_____________________________________________________________________________ test_HausdorffERLoss3D[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HausdorffERLoss3D(target_framework, mode, backend_compile):
        print("kornia.losses.HausdorffERLoss3D")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHausdorffERLoss3D = ivy.transpile(kornia.losses.HausdorffERLoss3D, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.HausdorffERLoss3D()
        transpiled_loss_fn = TranspiledHausdorffERLoss3D()
    
        torch_args = (
            torch.randn(5, 3, 20, 20, 20),
            (torch.rand(5, 1, 20, 20, 20) * 2).long(),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:471: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-02, -9.99671519e-01,  4.56319451e...    ...,
          [0, 0, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., 0, 0, 0],
          [0, 0, 0, ..., 0, 1, 1]]]]])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7faef02ef130, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-0...    ...,
          [0, 0, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., 0, 0, 0],
          [0, 0, 0, ..., 0, 1, 1]]]]])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-02, -9.99671519e-01,  4.56319451e...    ...,
          [0, 0, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., 0, 0, 0],
          [0, 0, 0, ..., 0, 1, 1]]]]])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(), <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-0...    ...,
          [0, 0, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., 0, 0, 0],
          [0, 0, 0, ..., 0, 1, 1]]]]])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D(), v = None, buffers = None
args = (<tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-02, -9.99671519e-01,  4.56319451e...    ...,
          [0, 0, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., 0, 0, 0],
          [0, 0, 0, ..., 0, 1, 1]]]]])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-02, -9.99671519e-01,  4.56319451e-...067e-01, -1.24976858e-01, ...,
            1.35643691e-01,  1.21393239e+00,  5.06539762e-01]]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (pred, target)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_HausdorffERLoss3D(),)
kwargs = {'pred': <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-02, -9.99671519e-01,  4.5...    ...,
          [0, 0, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., 0, 0, 0],
          [0, 0, 0, ..., 0, 1, 1]]]]])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-02, -9.99671519e-01,  4.56319451e-...067e-01, -1.24976858e-01, ...,
            1.35643691e-01,  1.21393239e+00,  5.06539762e-01]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 1, 0, ..., 0, 1, 0],
          [1, 0, 0, ..., ...     ...,
          [0, 0, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., 0, 0, 0],
          [0, 0, 0, ..., 0, 1, 1]]]]])>

    def call(self, pred, target):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_dim_frnt_
    
        if tensorflow_dim_frnt_(pred) != 5:
            raise ValueError(
                f"Only 3D images supported. Got {tensorflow_dim_frnt_(pred)}."
            )
>       return super().call(pred, target)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:280: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 3, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-02, -9.99671519e-01,  4.56319451e-...067e-01, -1.24976858e-01, ...,
            1.35643691e-01,  1.21393239e+00,  5.06539762e-01]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[0, 1, 0, ..., 0, 1, 0],
          [1, 0, 0, ..., ...     ...,
          [0, 0, 0, ..., 0, 0, 0],
          [0, 0, 1, ..., 0, 0, 0],
          [0, 0, 0, ..., 0, 1, 1]]]]])>

    def call(self, pred, target):
        from ..core._backend import where
        from ..core._backend import stack
        from ..core._backend import tensor
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
    
        if not (
            tensorflow_shape_frnt_(pred)[2:] == tensorflow_shape_frnt_(target)[2:]
            and tensorflow_size_frnt_(pred, 0) == tensorflow_size_frnt_(target, 0)
            and tensorflow_size_frnt_(target, 1) == 1
        ):
            raise ValueError(
                f"Prediction and target need to be of same size, and target should not be one-hot.Got {tensorflow_shape_frnt_(pred)} and {tensorflow_shape_frnt_(target)}."
            )
        if tensorflow_size_frnt_(pred, 1) < tensorflow_item_frnt_(
            tensorflow_max_frnt_(target)
        ):
            raise ValueError("Invalid target value.")
        out = stack(
>           [
                self.perform_erosion(
                    tensorflow_get_item(
                        pred, (slice(None, None, None), slice(i, i + 1, None))
                    ),
                    where(
                        target == i,
                        tensor(1, device=target.device, dtype=target.dtype),
                        tensor(0, device=target.device, dtype=target.dtype),
                    ),
                )
                for i in range(tensorflow_size_frnt_(pred, 1))
            ]
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <range_iterator object at 0x7faef09e72a0>

        [
>           self.perform_erosion(
                tensorflow_get_item(
                    pred, (slice(None, None, None), slice(i, i + 1, None))
                ),
                where(
                    target == i,
                    tensor(1, device=target.device, dtype=target.dtype),
                    tensor(0, device=target.device, dtype=target.dtype),
                ),
            )
            for i in range(tensorflow_size_frnt_(pred, 1))
        ]
    )

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HausdorffERLoss3D()
pred = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=float32, numpy=
array([[[[[-3.32767405e-02, -9.99671519e-01,  4.56319451e-...084e-01,  4.86444086e-01, ...,
           -1.77043831e+00, -7.42642760e-01,  1.17186999e+00]]]]],
      dtype=float32)>
target = <tf.Tensor: shape=(5, 1, 20, 20, 20), dtype=int64, numpy=
array([[[[[1, 0, 1, ..., 1, 0, 1],
          [0, 1, 1, ..., ...     ...,
          [1, 1, 1, ..., 1, 1, 1],
          [1, 1, 0, ..., 1, 1, 1],
          [1, 1, 1, ..., 1, 0, 0]]]]])>

    def perform_erosion(self, pred, target):
        from ..core._backend import as_tensor
        from ..core._backend import zeros_like
        from ..core._backend import where
        from ...ivy.functional.frontends.torch.creation_ops import (
            tensorflow_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_size_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ...ivy.functional.frontends.torch.tensor import tensorflow_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
    
        bound = (pred - target) ** 2
        kernel = as_tensor(self.kernel, device=pred.device, dtype=pred.dtype)
        eroded = zeros_like(bound, device=pred.device, dtype=pred.dtype)
        mask = tensorflow_ones_like_v_0p4p0_and_above_frnt(
            bound, device=pred.device, dtype=tf.bool
        )
        padding = (tensorflow_size_frnt_(kernel, -1) - 1) // 2
        for k in range(self.k):
>           dilation = self.conv(bound, weight=kernel, padding=padding, groups=1)
E           TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
E           
E           [1mtensorflow_conv3d_frnt() got multiple values for argument 'weight'[0m
E           
E           Arguments received by tensorflow_HausdorffERLoss3D.call():
E              pred=tf.Tensor(shape=(5, 3, 20, 20, 20), dtype=float32)
E              target=tf.Tensor(shape=(5, 1, 20, 20, 20), dtype=int64)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/hausdorff.py:83: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.HausdorffERLoss3D
________________________________________________________________________________ test_MS_SSIMLoss[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_MS_SSIMLoss(target_framework, mode, backend_compile):
        print("kornia.losses.MS_SSIMLoss")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledMS_SSIMLoss = ivy.transpile(kornia.losses.MS_SSIMLoss, source="torch", target=target_framework)
    
        torch_loss_fn = kornia.losses.MS_SSIMLoss()
        transpiled_loss_fn = TranspiledMS_SSIMLoss()
    
        torch_args = (
            torch.rand(1, 3, 5, 5),
            torch.rand(1, 3, 5, 5),
        )
        transpiled_args = _nest_torch_tensor_to_new_framework(torch_args, target_framework)
    
        torch_res = torch_loss_fn(*torch_args)
>       transpiled_res = transpiled_loss_fn(*transpiled_args)

kornia/test_losses.py:546: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.443...        [7.36114860e-01, 9.46071684e-01, 2.98331141e-01,
          4.69787300e-01, 8.24386895e-01]]]], dtype=float32)>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x5587a9c7e780, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.2...        [7.36114860e-01, 9.46071684e-01, 2.98331141e-01,
          4.69787300e-01, 8.24386895e-01]]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.443...        [7.36114860e-01, 9.46071684e-01, 2.98331141e-01,
          4.69787300e-01, 8.24386895e-01]]]], dtype=float32)>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(), <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.2...        [7.36114860e-01, 9.46071684e-01, 2.98331141e-01,
          4.69787300e-01, 8.24386895e-01]]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss(), v = None, buffers = None
args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.443...        [7.36114860e-01, 9.46071684e-01, 2.98331141e-01,
          4.69787300e-01, 8.24386895e-01]]]], dtype=float32)>)
kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.4430....32623088, 0.3544948 ],
         [0.6479529 , 0.92489886, 0.07468843, 0.77110064, 0.38537025]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (img1, img2)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_MS_SSIMLoss(),)
kwargs = {'img1': <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.4525827...        [7.36114860e-01, 9.46071684e-01, 2.98331141e-01,
          4.69787300e-01, 8.24386895e-01]]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_MS_SSIMLoss()
img1 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.4430....32623088, 0.3544948 ],
         [0.6479529 , 0.92489886, 0.07468843, 0.77110064, 0.38537025]]]],
      dtype=float32)>
img2 = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[5.20141840e-01, 7.52918601e-01, 1.33272707e-01,
      ...         [7.36114860e-01, 9.46071684e-01, 2.98331141e-01,
          4.69787300e-01, 8.24386895e-01]]]], dtype=float32)>

    def call(self, img1, img2):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.frontends.torch._jit_internal import (
            tensorflow_annotate_frnt,
        )
        from ...ivy.functional.frontends.torch.nn.functional.convolution_functions import (
            tensorflow_conv2d_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_prod_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.loss_functions import (
            tensorflow_l1_loss_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import tensorflow_mean_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_mean_frnt
        from ...ivy.functional.frontends.torch.reduction_ops import tensorflow_sum_frnt
    
        if not isinstance(img1, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Input type is not a torch.Tensor. Got {type(img1)}")
        if not isinstance(img2, (tensorflow.Tensor, tensorflow.Variable)):
            raise TypeError(f"Output type is not a torch.Tensor. Got {type(img2)}")
        if not len(tensorflow_shape_frnt_(img1)) == len(tensorflow_shape_frnt_(img2)):
            raise ValueError(
                f"Input shapes should be same. Got {type(img1)} and {type(img2)}."
            )
        g_masks: typing.Any = tensorflow_annotate_frnt(
            tensorflow.Variable, self._g_masks
        )
        CH: typing.Any = tensorflow_shape_frnt_(img1)[-3]
>       mux = tensorflow_conv2d_frnt(img1, g_masks, groups=CH, padding=self.pad)

ivy_transpiled_outputs/tensorflow_outputs/kornia/losses/ms_ssim.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.4430....32623088, 0.3544948 ],
         [0.6479529 , 0.92489886, 0.07468843, 0.77110064, 0.38537025]]]],
      dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = 16, dilation = 1, groups = 3

    def tensorflow_conv2d_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
>       return tensorflow__conv_frnt(
            input,
            weight,
            bias=bias,
            stride=stride,
            padding=padding,
            dilation=dilation,
            groups=groups,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.4430....32623088, 0.3544948 ],
         [0.6479529 , 0.92489886, 0.07468843, 0.77110064, 0.38537025]]]],
      dtype=float32)>
weight = <tf.Tensor: shape=(15, 1, 33, 33), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...2472e-05, 6.2838459e-05, 7.8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>
bias = None, stride = 1, padding = [(16, 16), (16, 16)], dilation = 1, groups = 3

    def tensorflow__conv_frnt(
        input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1
    ):
        from ...tensor import tensorflow_shape_frnt_
        from .....backends.tensorflow.layers import tensorflow_conv_general_dilated
    
        dims = len(tensorflow_shape_frnt_(input)) - 2
        if isinstance(padding, (str,)):
            padding = padding.upper()
        elif isinstance(padding, (int,)):
            padding = [*[(padding, padding) for _ in range(dims)]]
        else:
            padding = [*[(p, p) for p in padding]]
>       ret = tensorflow_conv_general_dilated(
            input,
            weight,
            stride,
            padding,
            dims=dims,
            data_format="channel_last",
            filter_format="channel_last",
            dilations=dilation,
            feature_group_count=groups,
            bias=bias,
        )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/nn/functional/convolution_functions.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.443....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'bias': None, 'data_format': 'channel_first', 'dilations': 1, 'dims': 2, ...}, tensorflow_set_item = <function tensorflow_set_item at 0x7faedd81bac0>
tensorflow_get_item = <function tensorflow_get_item at 0x7faedd81b910>, DATA_FORMAT = 'channels_first', value_map = {'NHWC': 'NCHW', 'NSC': 'NCS', 'channel_last': 'channel_first'}

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = [<tf.Tensor: shape=(1, 3, 5, 5), dtype=float32, numpy=
array([[[[0.29764265, 0.75195014, 0.24959028, 0.45258278, 0.443....8817087e-05, ...,
          7.8817087e-05, 6.2838459e-05, 4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)]]
kwargs = {'bias': None, 'data_format': 'channel_first', 'dilations': 1, 'dims': 2, ...}, tensorflow_is_array_bknd = <function tensorflow_is_array_bknd at 0x7faedd8196c0>
tensorflow_set_item = <function tensorflow_set_item at 0x7faedd81bac0>, tensorflow_asarray = <function tensorflow_asarray at 0x7faedd81a320>
tensorflow_get_item = <function tensorflow_get_item at 0x7faedd81b910>, num_args = 4
type_hints = mappingproxy(OrderedDict([('x', <Parameter "x: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops...."out: Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable, NoneType] = None">)]))
parameters = ['x', 'filters', 'strides', 'padding', 'dims', 'data_format', ...]
annotations = [typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.ops.variables.Variable], typing.Union[tenso...le[int, int, int]], typing.Union[str, int, typing.Sequence[typing.Tuple[int, int]]], <class 'int'>, <class 'str'>, ...]
device = '/job:localhost/replica:0/task:0/device:CPU:0', i = 3

    @functools.wraps(fn)
    def _handle_array_like_without_promotion(*args, **kwargs):
        from .functional.ivy.general import tensorflow_is_array_bknd
        from .functional.backends.tensorflow.general import tensorflow_set_item
        from .functional.backends.tensorflow.creation import tensorflow_asarray
        from .functional.backends.tensorflow.general import tensorflow_get_item
    
        args = list(args)
        num_args = len(args)
        try:
            type_hints = inspect.signature(fn).parameters
        except (TypeError, ValueError):
            return fn(*args, **kwargs)
        parameters = list(type_hints.keys())
        annotations = [param.annotation for param in type_hints.values()]
        device = tensorflow__get_preferred_device(args, kwargs)
        for i, (annotation, parameter, arg) in enumerate(
            zip(annotations, parameters, args)
        ):
            annotation_str = str(annotation)
            if (
                ("rray" in annotation_str or "Tensor" in annotation_str)
                and parameter != "out"
                and all(
                    sq not in annotation_str
                    for sq in ["Sequence", "List", "Tuple", "float", "int", "bool"]
                )
            ):
                if i < num_args:
                    if arg is None or tensorflow__check_in_nested_sequence(
                        arg, value=Ellipsis, _type=slice
                    ):
                        continue
                    if not tensorflow_is_array_bknd(arg):
                        args = tensorflow_set_item(
                            args, i, tensorflow_asarray(arg, device=device)
                        )
                elif parameters in kwargs:
                    kwarg = tensorflow_get_item(kwargs, parameter)
                    if not tensorflow_is_array_bknd(kwarg):
                        kwargs = tensorflow_set_item(
                            kwargs, parameter, tensorflow_asarray(kwarg, device=device)
                        )
>       return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.29764265, 0.8181323 , 0.43534583],
         [0.75195...8843],
         [0.32544357, 0.6523146 , 0.77110064],
         [0.98463887, 0.86287934, 0.38537025]]]], dtype=float32)>
filters = <tf.Tensor: shape=(33, 33, 1, 15), dtype=float32, numpy=
array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
 ...0000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.9322472e-05, 4.9322472e-05, 4.9322472e-05]]]], dtype=float32)>
strides = 1, padding = [(16, 16), (16, 16)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    @tensorflow_handle_array_like_without_promotion
    def tensorflow_conv_general_dilated(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        dims: int = 2,
        data_format: str = "channel_last",
        filter_format: str = "channel_last",
        feature_group_count: int = 1,
        x_dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        dilations: Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int]] = 1,
        bias: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
        from ...ivy.layers import tensorflow__get_x_data_format_bknd
    
        if filter_format == "channel_first":
            filters = tensorflow.transpose(filters, (*range(2, dims + 2), 1, 0))
        num_channels = x.shape[1] if data_format == "channel_first" else x.shape[-1]
        if filters.shape[-2] != num_channels // feature_group_count:
            raise Exception(
                f"given feature_group_count {feature_group_count} expected input channel of the filter to be {num_channels // feature_group_count} but got {filters.shape[-2]}"
            )
        if num_channels % feature_group_count != 0:
            raise Exception(
                f"input channel should be divisible by feature group count {feature_group_count} but got input channel {num_channels}"
            )
        permuted_x = False
        if data_format == "channel_first" and (
            tensorflow_dev(x) == "cpu" or feature_group_count != 1
        ):
            x = tensorflow.transpose(x, (0, *range(2, dims + 2), 1))
            data_format = "channel_last"
            permuted_x = True
        data_format = tensorflow__get_x_data_format_bknd(dims, data_format)
        x = tensorflow__x_dil_before_conv(x, dims, x_dilations, data_format)
        if dims == 2:
            padding = tensorflow__extend_2d_padding(padding, data_format)
            if feature_group_count == 1:
                res = tensorflow.nn.conv2d(
                    x,
                    filters,
                    strides,
                    padding,
                    data_format=data_format,
                    dilations=dilations,
                )
            else:
                if not isinstance(padding, str):
                    padding = padding[1:-1]
>               res = tensorflow_depthwise_conv2d(
                    x,
                    tensorflow.transpose(filters, (0, 1, 3, 2)),
                    strides,
                    padding,
                    data_format=data_format,
                    dilations=dilations,
                )

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.29764265, 0.8181323 , 0.43534583],
         [0.7519...      [4.9322472e-05],
         [4.9322472e-05],
         [4.9322472e-05]]]], dtype=float32)>, 1, [(16, 16), (16, 16)])
kwargs = {'data_format': 'NHWC', 'dilations': 1}, tensorflow_set_item = <function tensorflow_set_item at 0x7faedd81bac0>, tensorflow_get_item = <function tensorflow_get_item at 0x7faedd81b910>
DATA_FORMAT = 'channels_last'

    @functools.wraps(fn)
    def transpose_wrapper(*args, **kwargs):
        from ..functional.backends.tensorflow.general import tensorflow_set_item
        from ..functional.backends.tensorflow.general import tensorflow_get_item
    
        DATA_FORMAT = os.environ.get("DATA_FORMAT", "channels_first")
        if DATA_FORMAT == "channels_first":
            value_map = {"channel_last": "channel_first", "NHWC": "NCHW", "NSC": "NCS"}
            if "data_format" in kwargs and kwargs["data_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "data_format",
                    tensorflow_get_item(value_map, kwargs["data_format"]),
                )
            if "filter_format" in kwargs and kwargs["filter_format"] in value_map:
                kwargs = tensorflow_set_item(
                    kwargs,
                    "filter_format",
                    tensorflow_get_item(value_map, kwargs["filter_format"]),
                )
            os.environ = tensorflow_set_item(os.environ, "DATA_FORMAT", "channels_last")
>       res = fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 5, 5, 3), dtype=float32, numpy=
array([[[[0.29764265, 0.8181323 , 0.43534583],
         [0.75195...8843],
         [0.32544357, 0.6523146 , 0.77110064],
         [0.98463887, 0.86287934, 0.38537025]]]], dtype=float32)>
filters = <tf.Tensor: shape=(33, 33, 15, 1), dtype=float32, numpy=
array([[[[0.0000000e+00],
         [0.0000000e+00],
         ...00e+00],
         ...,
         [4.9322472e-05],
         [4.9322472e-05],
         [4.9322472e-05]]]], dtype=float32)>
strides = [1, 1, 1, 1], padding = [(0, 0), (16, 16), (16, 16), (0, 0)]

    @tensorflow_handle_transpose_in_input_and_output_for_functions
    def tensorflow_depthwise_conv2d(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        filters: Union[tensorflow.Tensor, tensorflow.Variable],
        strides: Union[int, Tuple[int, int]],
        padding: Union[str, int, Sequence[Tuple[int, int]]],
        /,
        *,
        data_format: str = "NHWC",
        dilations: Union[int, Tuple[int, int]] = 1,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from .device import tensorflow_dev
    
        strides = [strides] * 2 if isinstance(strides, int) else strides
        dilations = [dilations] * 2 if isinstance(dilations, int) else dilations
        permuted_x = False
        if data_format == "NCHW" and tensorflow_dev(x) == "cpu":
            x = tensorflow.transpose(x, (0, 2, 3, 1))
            data_format = "NHWC"
            permuted_x = True
        if tensorflow.rank(filters) == 3:
            filters = tensorflow.expand_dims(filters, -1)
        padding = tensorflow__extend_2d_padding(padding, data_format)
        strides = [1, strides[0], strides[1], 1]
>       res = tensorflow.nn.depthwise_conv2d(
            x, filters, strides, padding, data_format, dilations
        )
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
E       
E       [1m{{function_node __wrapped__DepthwiseConv2dNative_device_/job:localhost/replica:0/task:0/device:CPU:0}} input and filter must have the same depth: 3 vs 15 [Op:DepthwiseConv2dNative] name: [0m
E       
E       Arguments received by tensorflow_MS_SSIMLoss.call():
E          img1=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)
E          img2=tf.Tensor(shape=(1, 3, 5, 5), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/layers.py:137: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.losses.MS_SSIMLoss
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_losses.py::test_HausdorffERLoss[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss.call().
FAILED kornia/test_losses.py::test_HausdorffERLoss3D[tensorflow-s2s-False] - TypeError: Exception encountered when calling tensorflow_HausdorffERLoss3D.call().
FAILED kornia/test_losses.py::test_MS_SSIMLoss[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_MS_SSIMLoss.call().
============================================================================== 3 failed, 32 passed in 2156.50s (0:35:56) ===============================================================================


========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py ........FF...FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_RandomResizedCrop[tensorflow-s2s-False] _____________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomResizedCrop(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomResizedCrop")
    
        init_args = ()
        init_kwargs = {"size": (3, 3), "scale": (3., 3.), "ratio": (2., 2.), "p": 1., "cropping_mode": "resample"}
        call_args = (torch.tensor([[[0., 1., 2.],
                                    [3., 4., 5.],
                                    [6., 7., 8.]]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomResizedCrop,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.resized_crop.RandomResizedCrop'>, target = 'tensorflow', init_args = ()
init_kwargs = {'cropping_mode': 'resample', 'p': 1.0, 'ratio': (2.0, 2.0), 'scale': (3.0, 3.0), ...}, call_args = (tensor([[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff3fe609e40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_...e=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
v = None, buffers = None, args = (<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, replace_v = False, replace_buffers = False
call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros),)
kwargs = {'input': <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
input = <tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=
array([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]], dtype=float32)>, params = None, kwargs = {}
tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7ff403da8dc0>, tensorflow_set_item = <function tensorflow_set_item at 0x7ff404108430>
tensor = <function tensorflow_tensor_frnt at 0x7ff3e4b5e560>
in_tensor = <tf.Tensor: shape=(1, 1, 3, 3), dtype=float32, numpy=
array([[[[0., 1., 2.],
         [3., 4., 5.],
         [6., 7., 8.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([1, 3, 3]), batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
>           params = self.forward_parameters(batch_shape)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = ivy.frontends.torch.Size([1, 1, 3, 3])

    def forward_parameters(self, batch_shape):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import tensorflow_item_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        batch_prob = self.__batch_prob_generator__(
            batch_shape, self.p, self.p_batch, self.same_on_batch
        )
        to_apply = batch_prob > 0.5
>       _params = self.generate_parameters(
            tuple(
                (
                    int(tensorflow_item_frnt_(tensorflow_sum_frnt_(to_apply))),
                    *batch_shape[1:],
                )
            )
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomResizedCrop(scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), p=1.0, p_batch=1.0, same_on_batch=False, size=(3, 3), resample=bilinear, align_corners=True, cropping_mode=resample, padding_mode=zeros)
batch_shape = (1, 1, 3, 3)

    def generate_parameters(self, batch_shape):
        if self._param_generator is not None:
>           return self._param_generator(batch_shape, self.same_on_batch)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), args = ((1, 1, 3, 3), False), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff3fe60ae40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ion.py', lineno=46, function='__call__', code_context=['            return call_fn(*args, **kwargs)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), v = None, buffers = None, args = ((1, 1, 3, 3), False), kwargs = {}, replace_v = False, replace_buffers = False
call_signature = <Signature (batch_shape, same_on_batch=False)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = scale=(3.0, 3.0), resize_to=(2.0, 2.0), output_size=(3, 3), batch_shape = (1, 1, 3, 3), same_on_batch = False

    def call(self, batch_shape, same_on_batch=False):
        from ....utils.helpers import tensorflow__extract_device_dtype
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ...utils.helpers import tensorflow__adapted_rsampling
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_exp_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_floor_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_round_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_sqrt_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_int_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_max_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_cumsum_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_bool_frnt_
        from .....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from .....ivy.functional.frontends.torch.creation_ops import (
            tensorflow_arange_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from .....ivy.functional.frontends.torch.tensor import tensorflow_min_frnt_
        from .....ivy.functional.frontends.torch.pointwise_ops import (
            tensorflow_round_frnt,
        )
        from .....ivy.functional.frontends.torch.tensor import tensorflow_where_frnt_
        from .....ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            tensorflow_stack_frnt,
        )
        from ....core._backend import tensor
        from ....core._backend import zeros
    
        batch_size = batch_shape[0]
        size = batch_shape[-2], batch_shape[-1]
        _device, _dtype = tensorflow__extract_device_dtype([self.scale, self.ratio])
        if batch_size == 0:
            return {
                "src": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "dst": zeros([0, 4, 2], device=_device, dtype=_dtype),
                "size": zeros([0, 2], device=_device, dtype=_dtype),
            }
        rand = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.rand_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        area = (
            (rand * (self.scale[1] - self.scale[0]) + self.scale[0]) * size[0] * size[1]
        )
        log_ratio = tensorflow_to_frnt_(
            tensorflow__adapted_rsampling(
                (batch_size, 10), self.log_ratio_sampler, same_on_batch
            ),
            device=_device,
            dtype=_dtype,
        )
        aspect_ratio = tensorflow_exp_frnt(log_ratio)
        w = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area * aspect_ratio))
        )
        h = tensorflow_floor_frnt_(
            tensorflow_round_frnt_(tensorflow_sqrt_frnt(area / aspect_ratio))
        )
>       cond = tensorflow_int_frnt_((0 < w) * (w < size[0]) * (0 < h) * (h < size[1]))

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/random_generator/_2d/crop.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
rhs = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def impl(self, rhs):
        try:
            return original_method(self, rhs)
        except Exception:
>           return patched_method(self, rhs)

ivy_transpiled_outputs/tensorflow_outputs/__init__.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow___mul___frnt_(tensor, other):
        from .pointwise_ops import tensorflow_mul_frnt
    
>       return tensorflow_mul_frnt(tensor, other)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/tensor.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
other = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_mul_frnt(input, other, *, out=None):
        from .__init__ import tensorflow_promote_types_of_torch_inputs_frnt
        from ...backends.tensorflow.elementwise import tensorflow_multiply
    
        input, other = tensorflow_promote_types_of_torch_inputs_frnt(input, other)
>       return tensorflow_multiply(input, other, out=out)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/frontends/torch/pointwise_ops.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,
         True]])>
x2 = <tf.Tensor: shape=(1, 10), dtype=bool, numpy=
array([[False, False, False, False, False, False, False, False, False,
        False]])>

    def tensorflow_multiply(
        x1: Union[float, tensorflow.Tensor, tensorflow.Variable],
        x2: Union[float, tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        out: Optional[Union[tensorflow.Tensor, tensorflow.Variable]] = None,
    ):
        from ...ivy.data_type import tensorflow_promote_types_of_inputs_bknd
    
        x1, x2 = tensorflow_promote_types_of_inputs_bknd(x1, x2)
>       return tensorflow.math.multiply(x1, x2)
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling tensorflow_ResizedCropGenerator.call().
E       
E       [1mValue for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128
E       	; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul] name: [0m
E       
E       Arguments received by tensorflow_ResizedCropGenerator.call():
E          batch_shape=('1', '1', '3', '3')
E          same_on_batch=False

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/elementwise.py:353: InvalidArgumentError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomResizedCrop
______________________________________________________________________________ test_RandomRotation[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomRotation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation")
    
        init_args = ()
        init_kwargs = {"degrees": 45.0, "p": 1.}
        call_args = (torch.tensor([[1., 0., 0., 2.],
                                   [0., 0., 0., 0.],
                                   [0., 1., 2., 0.],
                                   [0., 0., 1., 2.]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.rotation.RandomRotation'>, target = 'tensorflow', init_args = (), init_kwargs = {'degrees': 45.0, 'p': 1.0}
call_args = (tensor([[1., 0., 0., 2.],
        [0., 0., 0., 0.],
        [0., 1., 2., 0.],
        [0., 0., 1., 2.]]),), call_kwargs = {}, deterministic_output = False, backend_compile = False
tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff3fe57c040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=Tru...=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True), v = None, buffers = None
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=Tru...=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True), v = None, buffers = None
args = (<tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>,), kwargs = {}
first_arr = <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>, replace_v = False
replace_buffers = False, call_signature = <Signature (input, params=None, **kwargs)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True),)
kwargs = {'input': <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-39.651344], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
kwargs = {}, tensorflow_shape_frnt_ = <function tensorflow_shape_frnt_ at 0x7ff403c36f80>, tensorflow_set_item = <function tensorflow_set_item at 0x7ff3e4c2a680>
tensor = <function tensorflow_tensor_frnt at 0x7ff3e4987130>
in_tensor = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
input_shape = ivy.frontends.torch.Size([4, 4]), batch_shape = ivy.frontends.torch.Size([1, 1, 4, 4]), flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def call(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = tensorflow_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = tensorflow_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = tensorflow_set_item(
                params, "batch_prob", tensor([True] * batch_shape[0])
            )
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/base.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
in_tensor = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-39.651344], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-39.651344], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import tensorflow_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_all_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_get_item
        from ...utils.helpers import tensorflow_is_autocast_enabled
        from ....ivy.functional.frontends.torch.tensor import tensorflow_type_frnt_
        from ....ivy.functional.frontends.torch.tensor import tensorflow_index_put_frnt_
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not tensorflow_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif tensorflow_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/base.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = <tf.Tensor: shape=(1, 1, 4, 4), dtype=float32, numpy=
array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)>
params = {'batch_prob': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'degrees': <tf.Tensor: shape=...([-39.651344], dtype=float32)>, 'forward_input_shape': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 4, 4])>}
flags = {'align_corners': True, 'resample': <tensorflow_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from ....geometry.transform.affwarp import tensorflow__compute_tensor_center
        from ....geometry.transform.affwarp import tensorflow__compute_rotation_matrix
        from .....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....utils.misc import tensorflow_eye_like
        from .....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        angles: typing.Any = tensorflow_to_frnt_(params["degrees"], input)
        center: typing.Any = tensorflow__compute_tensor_center(input)
        rotation_mat: typing.Any = tensorflow__compute_rotation_matrix(
>           angles, center.expand(tensorflow_shape_frnt_(angles)[0], -1)
        )
E       AttributeError: Exception encountered when calling tensorflow_RandomRotation.call().
E       
E       [1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'expand'[0m
E       
E       Arguments received by tensorflow_RandomRotation.call():
E          input=tf.Tensor(shape=(4, 4), dtype=float32)
E          params=None
E          kwargs=<class 'inspect._empty'>

ivy_transpiled_outputs/tensorflow_outputs/kornia/augmentation/_2d/geometric/rotation.py:70: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation
______________________________________________________________________________ test_RandomCutMixV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.0374, 0.5868, 0.4089],
          [0.9027, 0.0678, 0.7722],
          [0.1730, 0.5431, 0.7386]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
>       transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)

kornia/augmentation/test_augmentation3.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, source = 'torch', target = 'tensorflow', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4dcc880>, node = <gast.gast.Module object at 0x7ff3fddd32b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4dcc880>, node = <gast.gast.Module object at 0x7ff3fddd32b0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4dcc880>, node = <gast.gast.ClassDef object at 0x7ff3fe35f910>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4dcc880>, node = <gast.gast.FunctionDef object at 0x7ff3fe35f280>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4dcc880>, node = <gast.gast.AnnAssign object at 0x7ff3e48dea40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4dcc880>, node = <gast.gast.Call object at 0x7ff3fe35e080>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4dcc880>, node = <gast.gast.Call object at 0x7ff3fe35e080>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4dcc880>, node = <gast.gast.Attribute object at 0x7ff3fe35f1f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.Module object at 0x7ff3fc2e7910>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.Module object at 0x7ff3fc2e7910>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.ClassDef object at 0x7ff3fc2e4460>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.FunctionDef object at 0x7ff3fdc6ea70>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.Assign object at 0x7ff3fdc6fb20>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.Assign object at 0x7ff3fdc6fb20>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.Call object at 0x7ff3fdc6fee0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.Call object at 0x7ff3fdc6fee0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fc3fad70>, node = <gast.gast.Attribute object at 0x7ff3fc808e80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.Module object at 0x7ff3f4ef19f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.Module object at 0x7ff3f4ef19f0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.ClassDef object at 0x7ff3f4ef0820>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.FunctionDef object at 0x7ff3f4706da0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.Assign object at 0x7ff3f4705810>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.Assign object at 0x7ff3f4705810>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.Call object at 0x7ff3f4707d60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.Call object at 0x7ff3f4707d60>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3f4ef2e90>, node = <gast.gast.Attribute object at 0x7ff403de0af0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Module object at 0x7ff4040cc6a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Module object at 0x7ff4040cc6a0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.ClassDef object at 0x7ff4040cd900>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.FunctionDef object at 0x7ff3fcf2cc40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Return object at 0x7ff3fd8f9ea0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Return object at 0x7ff3fd8f9ea0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Call object at 0x7ff3fd8fa5c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Call object at 0x7ff3fd8fa5c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Attribute object at 0x7ff3fd8fa2c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Attribute object at 0x7ff3fd8fa2c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4afff10>, node = <gast.gast.Name object at 0x7ff3fd8f9ff0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4bc6f20>, node = <gast.gast.Module object at 0x7ff3e4afd210>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4bc6f20>, node = <gast.gast.Module object at 0x7ff3e4afd210>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4bc6f20>, node = <gast.gast.ClassDef object at 0x7ff3fd4102e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4bc5ea0>, node = <gast.gast.Module object at 0x7ff404209cc0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4bc5ea0>, node = <gast.gast.Module object at 0x7ff404209cc0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3e4bc5ea0>, node = <gast.gast.ClassDef object at 0x7ff404208610>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fcea2170>, node = <gast.gast.Module object at 0x7ff3fe75b2b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fcea2170>, node = <gast.gast.Module object at 0x7ff3fe75b2b0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7ff3fcea2170>, node = <gast.gast.ClassDef object at 0x7ff3fe7588e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IM.pyx:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
_______________________________________________________________________________ test_RandomJigsaw[tensorflow-s2s-False] ________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'tensorflow', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[-6.1059e-02, -2.2401e-01,  5.2649e-01,  ...,  2.2257e-01,
           -9.1170e-01, -4.1116e-01],
          ...9e-01],
          [-7.4240e-01,  4.0627e-01,  1.3784e+00,  ...,  4.1072e-01,
           -1.3343e+00,  1.1648e+00]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4))
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-6.10590316e-02, -2.24005595e-01,  5.26494145e-01...368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7ff3fe8aaa40, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...1368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-6.10590316e-02, -2.24005595e-01,  5.26494145e-01...368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), <tf.Tensor: shape=(8, 3, ...1368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), v = None, buffers = None
args = (<tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-6.10590316e-02, -2.24005595e-01,  5.26494145e-01...368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-6.10590316e-02, -2.24005595e-01,  5.26494145e-01,...71368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)),)
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-6.10590316e-02, -2.24005595e-01,  5.264...1368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-6.10590316e-02, -2.24005595e-01,  5.264...1368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(8, 3, 256, 256), dtype=float32, numpy=
array([[[[-6.10590316e-02, -2.24005595e-01,  5.264...1368e-01,  1.37843549e+00, ...,
           4.10715848e-01, -1.33427882e+00,  1.16480470e+00]]]],
      dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
_______________________________________________________________________________ test_RandomMixUpV2[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'tensorflow', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.3255, 0.8103, 0.2472],
          [0.4855, 0.7068, 0.3791],
          [0.3617, 0.6772, 0.6019]]],


        [[[0.3138, 0.4327, 0.8431],
          [0.8975, 0.8620, 0.1759],
          [0.7720, 0.5647, 0.1278]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False)
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.32548612, 0.81034875, 0.24716592],
         [0.4854...   [0.77195257, 0.56472087, 0.12776953]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x55564cb99ec0, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...kexec', code_context=['        return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.77195257, 0.56472087, 0.12776953]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.32548612, 0.81034875, 0.24716592],
         [0.4854...   [0.77195257, 0.56472087, 0.12776953]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), <tf.Tensor: shape=(2, 1, 3, 3), d...   [0.77195257, 0.56472087, 0.12776953]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.32548612, 0.81034875, 0.24716592],
         [0.4854...   [0.77195257, 0.56472087, 0.12776953]]]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.32548612, 0.81034875, 0.24716592],
         [0.48549...595 ],
         [0.8975132 , 0.86198646, 0.17591482],
         [0.77195257, 0.56472087, 0.12776953]]]], dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (*input, params=None, data_keys=None)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False),)
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.32548612, 0.81034875, 0.24716592],
       ...5257, 0.56472087, 0.12776953]]]], dtype=float32)>, 'params': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.32548612, 0.81034875, 0.24716592],
       ...95 ],
         [0.8975132 , 0.86198646, 0.17591482],
         [0.77195257, 0.56472087, 0.12776953]]]], dtype=float32)>}

    def bind(self, /, *args, **kwargs):
        """Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        """
>       return self._bind(args, kwargs)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Signature (*input, params=None, data_keys=None)>, args = ()
kwargs = {'input': <tf.Tensor: shape=(2, 1, 3, 3), dtype=float32, numpy=
array([[[[0.32548612, 0.81034875, 0.24716592],
       ...95 ],
         [0.8975132 , 0.86198646, 0.17591482],
         [0.77195257, 0.56472087, 0.12776953]]]], dtype=float32)>}

    def _bind(self, args, kwargs, *, partial=False):
        """Private method. Don't use directly."""
    
        arguments = {}
    
        parameters = iter(self.parameters.values())
        parameters_ex = ()
        arg_vals = iter(args)
    
        while True:
            # Let's iterate through the positional arguments and corresponding
            # parameters
            try:
                arg_val = next(arg_vals)
            except StopIteration:
                # No more positional arguments
                try:
                    param = next(parameters)
                except StopIteration:
                    # No more parameters. That's it. Just need to check that
                    # we have no `kwargs` after this while loop
                    break
                else:
                    if param.kind == _VAR_POSITIONAL:
                        # That's OK, just empty *args.  Let's start parsing
                        # kwargs
                        break
                    elif param.name in kwargs:
                        if param.kind == _POSITIONAL_ONLY:
                            msg = '{arg!r} parameter is positional only, ' \
                                  'but was passed as a keyword'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
                        parameters_ex = (param,)
                        break
                    elif (param.kind == _VAR_KEYWORD or
                                                param.default is not _empty):
                        # That's fine too - we have a default value for this
                        # parameter.  So, lets start parsing `kwargs`, starting
                        # with the current parameter
                        parameters_ex = (param,)
                        break
                    else:
                        # No default, not VAR_KEYWORD, not VAR_POSITIONAL,
                        # not in `kwargs`
                        if partial:
                            parameters_ex = (param,)
                            break
                        else:
                            msg = 'missing a required argument: {arg!r}'
                            msg = msg.format(arg=param.name)
                            raise TypeError(msg) from None
            else:
                # We have a positional argument to process
                try:
                    param = next(parameters)
                except StopIteration:
                    raise TypeError('too many positional arguments') from None
                else:
                    if param.kind in (_VAR_KEYWORD, _KEYWORD_ONLY):
                        # Looks like we have no parameter for this positional
                        # argument
                        raise TypeError(
                            'too many positional arguments') from None
    
                    if param.kind == _VAR_POSITIONAL:
                        # We have an '*args'-like argument, let's fill it with
                        # all positional arguments we have left and move on to
                        # the next phase
                        values = [arg_val]
                        values.extend(arg_vals)
                        arguments[param.name] = tuple(values)
                        break
    
                    if param.name in kwargs and param.kind != _POSITIONAL_ONLY:
                        raise TypeError(
                            'multiple values for argument {arg!r}'.format(
                                arg=param.name)) from None
    
                    arguments[param.name] = arg_val
    
        # Now, we iterate through the remaining parameters to process
        # keyword arguments
        kwargs_param = None
        for param in itertools.chain(parameters_ex, parameters):
            if param.kind == _VAR_KEYWORD:
                # Memorize that we have a '**kwargs'-like parameter
                kwargs_param = param
                continue
    
            if param.kind == _VAR_POSITIONAL:
                # Named arguments don't refer to '*args'-like parameters.
                # We only arrive here if the positional arguments ended
                # before reaching the last parameter before *args.
                continue
    
            param_name = param.name
            try:
                arg_val = kwargs.pop(param_name)
            except KeyError:
                # We have no value for this parameter.  It's fine though,
                # if it has a default value, or it is an '*args'-like
                # parameter, left alone by the processing of positional
                # arguments.
                if (not partial and param.kind != _VAR_POSITIONAL and
                                                    param.default is _empty):
                    raise TypeError('missing a required argument: {arg!r}'. \
                                    format(arg=param_name)) from None
    
            else:
                if param.kind == _POSITIONAL_ONLY:
                    # This should never happen in case of a properly built
                    # Signature object (but let's have this check here
                    # to ensure correct behaviour just in case)
                    raise TypeError('{arg!r} parameter is positional only, '
                                    'but was passed as a keyword'. \
                                    format(arg=param.name))
    
                arguments[param_name] = arg_val
    
        if kwargs:
            if kwargs_param is not None:
                # Process our '**kwargs'-like parameter
                arguments[kwargs_param.name] = kwargs
            else:
>               raise TypeError(
                    'got an unexpected keyword argument {arg!r}'.format(
                        arg=next(iter(kwargs))))
E               TypeError: got an unexpected keyword argument 'input'

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:3166: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomResizedCrop[tensorflow-s2s-False] - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling ten...
FAILED kornia/augmentation/test_augmentation3.py::test_RandomRotation[tensorflow-s2s-False] - AttributeError: Exception encountered when calling tensorflow_RandomRotation.call().
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[tensorflow-s2s-False] - OSError: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[tensorflow-s2s-False] - TypeError: got an unexpected keyword argument 'input'
============================================================================== 5 failed, 11 passed in 3561.88s (0:59:21) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 16 items

kornia/augmentation/test_augmentation3.py .........F...FFF                                                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_RandomRotation[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomRotation(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomRotation")
    
        init_args = ()
        init_kwargs = {"degrees": 45.0, "p": 1.}
        call_args = (torch.tensor([[1., 0., 0., 2.],
                                   [0., 0., 0., 0.],
                                   [0., 1., 2., 0.],
                                   [0., 0., 1., 2.]]),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomRotation,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.geometric.rotation.RandomRotation'>, target = 'jax', init_args = (), init_kwargs = {'degrees': 45.0, 'p': 1.0}
call_args = (tensor([[1., 0., 0., 2.],
        [0., 0., 0., 0.],
        [0., 1., 2., 0.],
        [0., 0., 1., 2.]]),), call_kwargs = {}, deterministic_output = False, backend_compile = False
tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[1., 0., 0., 2.],
       [0., 0., 0., 0.],
       [0., 1., 2., 0.],
       [0., 0., 1., 2.]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fd294a57d00>, jax_set_item = <function jax_set_item at 0x7fd2a8653130>, tensor = <function jax_tensor_frnt at 0x7fd2949f84c0>
in_tensor = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32), input_shape = ivy.frontends.torch.Size([4, 4])
batch_shape = ivy.frontends.torch.Size([1, 1, 4, 4]), flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
in_tensor = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
>       trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def generate_transformation_matrix(self, input, params, flags):
        from ....ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ....ivy.functional.backends.jax.general import jax_get_item
        from ...utils.helpers import jax_is_autocast_enabled
        from ....ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ....ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
    
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        in_tensor = self.transform_tensor(input)
        if not jax_any_frnt_(to_apply):
            trans_matrix = self.identity_matrix(in_tensor)
        elif jax_all_frnt_(to_apply):
>           trans_matrix = self.compute_transformation(
                in_tensor, params=params, flags=flags
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomRotation(degrees=45.0, p=1.0, p_batch=1.0, same_on_batch=False, resample=bilinear, align_corners=True)
input = Array([[[[1., 0., 0., 2.],
         [0., 0., 0., 0.],
         [0., 1., 2., 0.],
         [0., 0., 1., 2.]]]], dtype=float32)
params = {'batch_prob': Array([1.], dtype=float32), 'degrees': Array([-35.516792], dtype=float32), 'forward_input_shape': Array([1, 1, 4, 4], dtype=int64)}
flags = {'align_corners': True, 'resample': <jax_Resample.BILINEAR: 1>}

    def compute_transformation(self, input, params, flags):
        from .....ivy.functional.frontends.torch.tensor import jax_to_frnt_
        from ....geometry.transform.affwarp import jax__compute_tensor_center
        from ....geometry.transform.affwarp import jax__compute_rotation_matrix
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....utils.misc import jax_eye_like
        from .....ivy.functional.backends.jax.general import jax_set_item
    
        angles: typing.Any = jax_to_frnt_(params["degrees"], input)
        center: typing.Any = jax__compute_tensor_center(input)
        rotation_mat: typing.Any = jax__compute_rotation_matrix(
>           angles, center.expand(jax_shape_frnt_(angles)[0], -1)
        )
E       AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/geometric/rotation.py:66: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomRotation
__________________________________________________________________________________ test_RandomCutMixV2[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomCutMixV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomCutMixV2")
    
        input = torch.rand(2, 1, 3, 3)
        input[0] = torch.ones((1, 3, 3))
        label = torch.tensor([0, 1])
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (input, label)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomCutMixV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000]]],


        [[[0.9991, 0.6221, 0.8439],
          [0.8803, 0.5164, 0.7130],
          [0.9238, 0.4092, 0.5817]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
>       transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)

kornia/augmentation/test_augmentation3.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'kornia.augmentation._2d.mix.cutmix.RandomCutMixV2'>, source = 'torch', target = 'jax', reuse_existing = True

    def transpile(
        object,
        source: str = "torch",
        target: str = "tensorflow",
        reuse_existing: bool = True,
    ):
        """Converts a given object (class/function) from one framework to another.
    
        This function performs source-to-source translation of a given object from the source framework
        to the target framework.
    
        The object can be translated between two frameworks or between the Ivy IR as well
        e.g. (source="torch_frontend", target="ivy") or (source="torch_frontend", target="tensorflow") etc.
    
        Args:
            object: The object (class/function) to be translated.
            source (str, optional): The source framework. Defaults to 'torch'.
            target (str, optional): The target framework. Defaults to 'tensorflow'.
            reuse_existing (bool, optional): If True, the function will check if `object`
                                             already exists in the translated directory and reuse it.
                                             If False, it will re-translate `object`,
                                             even if it already exists in the directory, and overwrite
                                             the old implementation. Defaults to 'True'.
    
        Returns:
            The translated object."""
    
        from ._compiler import transpile as _transpile
    
>       return _transpile(
            object=object,
            source=source,
            target=target,
            reuse_existing=reuse_existing,
        )

../ivy/ivy/compiler/compiler.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:234: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:212: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXL.pyx:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2b0167070>, node = <gast.gast.Module object at 0x7fd2a82663e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2b0167070>, node = <gast.gast.Module object at 0x7fd2a82663e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2b0167070>, node = <gast.gast.ClassDef object at 0x7fd2a8264190>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2b0167070>, node = <gast.gast.FunctionDef object at 0x7fd2a82657e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2b0167070>, node = <gast.gast.AnnAssign object at 0x7fd2a8540d60>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:319: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2b0167070>, node = <gast.gast.Call object at 0x7fd2a8267490>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2b0167070>, node = <gast.gast.Call object at 0x7fd2a8267490>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2b0167070>, node = <gast.gast.Attribute object at 0x7fd2a8266110>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.Module object at 0x7fd2a809c160>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.Module object at 0x7fd2a809c160>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.ClassDef object at 0x7fd2a809dea0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.FunctionDef object at 0x7fd2947b57e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.Assign object at 0x7fd2947b5120>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.Assign object at 0x7fd2947b5120>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.Call object at 0x7fd2947b7df0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.Call object at 0x7fd2947b7df0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8e0b340>, node = <gast.gast.Attribute object at 0x7fd2dfa1dff0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.Module object at 0x7fd2a8dc75e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.Module object at 0x7fd2a8dc75e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.ClassDef object at 0x7fd2a8dc5b40>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.FunctionDef object at 0x7fd2a8dc62f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.Assign object at 0x7fd2a8dc6110>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.Assign object at 0x7fd2a8dc6110>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.Call object at 0x7fd2a8dc74c0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.Call object at 0x7fd2a8dc74c0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2ded91e70>, node = <gast.gast.Attribute object at 0x7fd2a8e82fb0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Module object at 0x7fd2a8764280>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Module object at 0x7fd2a8764280>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.ClassDef object at 0x7fd2a87656f0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.FunctionDef object at 0x7fd2ded464d0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Return object at 0x7fd2a809a1a0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Return object at 0x7fd2a809a1a0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Call object at 0x7fd2a809a950>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Call object at 0x7fd2a809a950>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Attribute object at 0x7fd2a809abc0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Attribute object at 0x7fd2a809abc0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
                        value = self.visit(value)
                        if value is None:
                            continue
                        elif not isinstance(value, AST):
                            new_values.extend(value)
                            continue
                    new_values.append(value)
                old_value[:] = new_values
            elif isinstance(old_value, AST):
>               new_node = self.visit(old_value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd29496fcd0>, node = <gast.gast.Name object at 0x7fd2a80985b0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2945024a0>, node = <gast.gast.Module object at 0x7fd2a83b5c30>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2945024a0>, node = <gast.gast.Module object at 0x7fd2a83b5c30>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2945024a0>, node = <gast.gast.ClassDef object at 0x7fd2a83b6fe0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8147d30>, node = <gast.gast.Module object at 0x7fd2949d6c80>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8147d30>, node = <gast.gast.Module object at 0x7fd2949d6c80>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2a8147d30>, node = <gast.gast.ClassDef object at 0x7fd2949d7250>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

MC.pyx:127: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

XL.pyx:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2dc112f20>, node = <gast.gast.Module object at 0x7fd2b039e0e0>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2dc112f20>, node = <gast.gast.Module object at 0x7fd2b039e0e0>

    def generic_visit(self, node):
        for field, old_value in iter_fields(node):
            if isinstance(old_value, list):
                new_values = []
                for value in old_value:
                    if isinstance(value, AST):
>                       value = self.visit(value)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

II.pyx:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MM.NativeTorchRecurser object at 0x7fd2dc112f20>, node = <gast.gast.ClassDef object at 0x7fd2b039d270>

    def visit(self, node):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
>       return visitor(node)

/opt/miniconda/envs/multienv/lib/python3.10/ast.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

DM.pyx:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:244: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IL.pyx:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IM.pyx:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def getsourcelines(object):
        """Return a list of source lines and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of the lines
        corresponding to the object and the line number indicates where in the
        original source file the first line of code was found.  An OSError is
        raised if the source code cannot be retrieved."""
        object = unwrap(object)
>       lines, lnum = findsource(object)

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:1129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object = <class 'torch._C._FunctionBase'>

    def findsource(object):
        """Return the entire source file and starting line number for an object.
    
        The argument may be a module, class, method, function, traceback, frame,
        or code object.  The source code is returned as a list of all the lines
        in the file and the line number indexes a line in that list.  An OSError
        is raised if the source code cannot be retrieved."""
    
        file = getsourcefile(object)
        if file:
            # Invalidate cache if needed.
            linecache.checkcache(file)
        else:
            file = getfile(object)
            # Allow filenames in form of "<something>" to pass through.
            # `doctest` monkeypatches `linecache` module to enable
            # inspection, so let `linecache.getlines` to be called.
            if not (file.startswith('<') and file.endswith('>')):
>               raise OSError('source code not available')
E               OSError: source code not available

/opt/miniconda/envs/multienv/lib/python3.10/inspect.py:950: OSError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomCutMixV2
___________________________________________________________________________________ test_RandomJigsaw[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomJigsaw(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomJigsaw")
    
        init_args = ((4, 4),)
        init_kwargs = {}
        call_args = (torch.randn(8, 3, 256, 256),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomJigsaw,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.jigsaw.RandomJigsaw'>, target = 'jax', init_args = ((4, 4),), init_kwargs = {}
call_args = (tensor([[[[-9.2063e-01,  6.5566e-01, -8.4490e-01,  ..., -3.0022e-01,
           -2.9716e-01, -2.8747e-01],
          ...9e-01],
          [ 9.7758e-01,  3.1661e-01, -8.6051e-01,  ...,  7.4284e-01,
            3.6991e-01, -2.1395e+00]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomJigsaw(grid=(4, 4), p=0.5, p_batch=1.0, same_on_batch=False, grid=(4, 4)), params = None, data_keys = None
input = (Array([[[[-9.20633197e-01,  6.55655921e-01, -8.44897032e-01, ...,
          -3.00224066e-01, -2.97161430e-01, -2.8746...09919e-01, -8.60507607e-01, ...,
           7.42835879e-01,  3.69908839e-01, -2.13945818e+00]]]],      dtype=float32),)
tensor = <function jax_tensor_frnt at 0x7fd296f3a440>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomJigsaw
__________________________________________________________________________________ test_RandomMixUpV2[jax-s2s-False] ___________________________________________________________________________________

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
>           res = inp.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError

During handling of the above exception, another exception occurred:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomMixUpV2(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomMixUpV2")
    
        init_args = ()
        init_kwargs = {"data_keys": ["input", "class"]}
        call_args = (torch.rand(2, 1, 3, 3), torch.tensor([0, 1]))
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomMixUpV2,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation3.py:394: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.mix.mixup.RandomMixUpV2'>, target = 'jax', init_args = (), init_kwargs = {'data_keys': ['input', 'class']}
call_args = (tensor([[[[0.0996, 0.4978, 0.6177],
          [0.3719, 0.5137, 0.8534],
          [0.0967, 0.1949, 0.9677]]],


        [[[0.3318, 0.2606, 0.8212],
          [0.5317, 0.9791, 0.3676],
          [0.7323, 0.2928, 0.5355]]]]), tensor([0, 1]))
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation3.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomMixUpV2(lambda_val=None, p=1.0, p_batch=1.0, same_on_batch=False), params = None, data_keys = None
input = (Array([[[[0.09960538, 0.49778003, 0.61768585],
         [0.37192565, 0.5137135 , 0.8533687 ],
         [0.09672093, 0... 0.9791445 , 0.3675819 ],
         [0.7323263 , 0.29276437, 0.53549284]]]], dtype=float32), Array([0, 1], dtype=int64))
tensor = <function jax_tensor_frnt at 0x7fd2de405510>

    def __call__(self, *input, params=None, data_keys=None):
        from ....core._backend import tensor
        from .....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....geometry.boxes import jax_Boxes
        from .....ivy.functional.backends.jax.general import jax_get_item
        from ....constants import jax_DType
        from ....core.check import jax_KORNIA_UNWRAP
    
        keys: typing.Any
        if data_keys is None:
            keys = self.data_keys
        else:
            keys = [jax_DataKey.get(inp) for inp in data_keys]
        if params is None:
            in_tensor_idx: typing.Any = keys.index(jax_DataKey.INPUT)
            in_tensor: typing.Any = jax_get_item(input, in_tensor_idx)
            in_tensor = self.transform_tensor(in_tensor)
            self._params = self.forward_parameters(jax_shape_frnt_(in_tensor))
>           self._params.update({"dtype": tensor(jax_DType.get(in_tensor.dtype).value)})

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/mix/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, value = dtype('float32')

    @classmethod
    def get(cls, value):
        from ..ivy.functional.backends.jax.general import jax_get_item
        from ..ivy.functional.frontends.torch.tensor import jax_item_frnt_
    
        if isinstance(value, (np.dtype,)):
>           return jax_get_item(cls, str(value).upper()[6:])

ivy_transpiled_outputs/jax_outputs/kornia/constants.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2', kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, **kwargs):
        try:
            res = inp.__getitem__(query)
        except Exception:
>           res = fn(inp, query, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, '2'), kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/func_wrapper.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, query = '2'

    @jax_handle_get_item
    @jax_handle_partial_mixed_function
    def jax_get_item(
        x: jax.Array, /, query: Union[jax.Array, Tuple], *, copy: Optional[bool] = None
    ):
        from ...ivy.general import jax_is_array_bknd
        from ...ivy.data_type import jax_is_bool_dtype_bknd
    
        if copy:
            x = x.copy()
        if jax_is_array_bknd(query) and jax_is_bool_dtype_bknd(query):
            if not len(query.shape):
                if not query:
                    return jax.numpy.array([], dtype=x.dtype)
                else:
                    return jax.numpy.expand_dims(x, 0)
            query = jax__mask_to_index(query, x)
        elif isinstance(query, list):
            query = (query,)
>       return x.__getitem__(query)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/general.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = jax_DType.INT64 | jax_DType.FLOAT16 | jax_DType.FLOAT32 | jax_DType.FLOAT64, name = '2'

    def __getitem__(cls, name):
>       return cls._member_map_[name]
E       KeyError: '2'

/opt/miniconda/envs/multienv/lib/python3.10/enum.py:432: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomMixUpV2
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation3.py::test_RandomRotation[jax-s2s-False] - AttributeError: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'expand'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomCutMixV2[jax-s2s-False] - OSError: source code not available
FAILED kornia/augmentation/test_augmentation3.py::test_RandomJigsaw[jax-s2s-False] - KeyError: '2'
FAILED kornia/augmentation/test_augmentation3.py::test_RandomMixUpV2[jax-s2s-False] - KeyError: '2'
============================================================================== 4 failed, 12 passed in 3201.58s (0:53:21) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F............                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
__________________________________________________________________________________ test_upscale_double[jax-s2s-False] __________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7ff2c6e56440>
trace_args = (tensor([[[[0.2696, 0.2282, 0.2096, 0.0525],
          [0.5895, 0.6115, 0.1864, 0.8536],
          [0.5821, 0.6404, 0...., 0.8581, 0.3153, 0.1025],
          [0.2456, 0.6350, 0.3086, 0.3462],
          [0.4794, 0.8610, 0.9321, 0.9441]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[6.0806e-01, 4.5672e-01, 2.8195e-01, 5.7061e-01, 5.5836e-01,
           9.1529e-01, 2.8243e-01, 1.2582e-01]...      [3.4942e-01, 2.4286e-01, 5.9295e-01, 8.6142e-01, 7.4280e-02,
           8.1075e-01, 2.0958e-01, 3.2163e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7ff2c6e56440>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.2696, 0.2282, 0.2096, 0.0525],
          [0.5895, 0.6115, 0.1864, 0.8536],
          [0.5821, 0.6404, 0...., 0.8581, 0.3153, 0.1025],
          [0.2456, 0.6350, 0.3086, 0.3462],
          [0.4794, 0.8610, 0.9321, 0.9441]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[6.0806e-01, 4.5672e-01, 2.8195e-01, 5.7061e-01, 5.5836e-01,
           9.1529e-01, 2.8243e-01, 1.2582e-01]...      [3.4942e-01, 2.4286e-01, 5.9295e-01, 8.6142e-01, 7.4280e-02,
           8.1075e-01, 2.0958e-01, 3.2163e-01]]]]),)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = Array([[[[0.26959866, 0.22820312, 0.20955753, 0.05245161],
         [0.58951175, 0.611548  , 0.18643385, 0.85357773],
... 0.6350442 , 0.30861706, 0.34621495],
         [0.4793523 , 0.8610165 , 0.9320792 , 0.94406706]]]],      dtype=float32)

    def jax_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import jax_KORNIA_CHECK_IS_TENSOR
        from ...core.check import jax_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ....ivy.functional.backends.jax.general import jax_set_item
    
        jax_KORNIA_CHECK_IS_TENSOR(x)
        jax_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = jax_shape_frnt_(x)[:-2] + (
            jax_shape_frnt_(x)[-2] * 2,
            jax_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = jax_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = jax_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/pyramid.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Array([[[[0.26959866, 0.        , 0.22820312, 0.        , 0.20955753,
          0.        , 0.05245161, 0.        ],
 ...     , 0.        , 0.        , 0.        , 0.        ,
          0.        , 0.        , 0.        ]]]], dtype=float32)
i = (Ellipsis, slice(None, None, 2), slice(1, None, 2))
x = Array([[[[0.24890089, 0.21888033, 0.13100457, 0.        ],
         [0.6005299 , 0.39899093, 0.5200058 , 0.        ],
... 0.47183064, 0.327416  , 0.        ],
         [0.6701844 , 0.89654785, 0.93807316, 0.        ]]]],      dtype=float32)

    def _unimplemented_setitem(self, i, x):
      msg = ("'{}' object does not support item assignment. JAX arrays are "
             "immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` "
             "or another .at[] method: "
             "https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html")
>     raise TypeError(msg.format(type(self)))
E     TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html

/opt/fw/jax/jax/_src/numpy/array_methods.py:587: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
______________________________________________________________________________________ test_Shear[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledShear = ivy.transpile(kornia.geometry.transform.Shear, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = TranspiledShear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_Shear()
input = Array([[[[0.17793322, 0.18721223, 0.94313514, 0.08721542],
         [0.77130246, 0.7009466 , 0.7666235 , 0.45514375],
... 0.02152956, 0.24842387, 0.252742  ],
         [0.53764623, 0.91546136, 0.9631049 , 0.53624004]]]],      dtype=float32)

    def __call__(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: name 'shear' is not defined

ivy_transpiled_outputs/jax_outputs/kornia/geometry/transform/affwarp.py:52: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[jax-s2s-False] - TypeError: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutabl...
FAILED kornia/geometry/test_transform.py::test_Shear[jax-s2s-False] - NameError: name 'shear' is not defined
============================================================================== 2 failed, 54 passed in 5087.81s (1:24:47) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ..                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 134.52s (0:02:14) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_homography.py FFFF.F.F                                                                                                                                                      [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_find_homography_dlt[numpy-s2s-False] _______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4), 'solver': 'svd'}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4), 'solver': 'svd'}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7f82e625d000>
trace_args = (tensor([[[0.3352, 0.8167],
         [0.2931, 0.9323],
         [0.7248, 0.8579],
         [0.9724, 0.0484]]]), tensor....9786e-01],
         [6.2241e-01, 3.7976e-01],
         [2.1915e-01, 3.6207e-01],
         [3.7366e-04, 1.9940e-01]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.7740, 0.8776, 0.1524, 0.1497]])}
test_args = (tensor([[[0.4938, 0.6819],
         [0.5742, 0.6460],
         [0.3378, 0.2281],
         [0.7492, 0.1896]],

       ...7667]],

        [[0.1947, 0.7804],
         [0.3308, 0.4317],
         [0.5867, 0.4624],
         [0.6004, 0.8926]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[0.9918, 0.5738, 0.7422, 0.1353],
        [0.2479, 0.5713, 0.5185, 0.6650],
        [0.9338, 0.4034, 0.5138, 0.3933],
        [0.9181, 0.0618, 0.5611, 0.2354],
        [0.2368, 0.1769, 0.1624, 0.8794]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt at 0x7f82e625d000>, fn_name = 'kornia.geometry.homography.find_homography_dlt'
trace_args = (tensor([[[0.3352, 0.8167],
         [0.2931, 0.9323],
         [0.7248, 0.8579],
         [0.9724, 0.0484]]]), tensor....9786e-01],
         [6.2241e-01, 3.7976e-01],
         [2.1915e-01, 3.6207e-01],
         [3.7366e-04, 1.9940e-01]]]))
trace_kwargs = {'solver': 'svd', 'weights': tensor([[0.7740, 0.8776, 0.1524, 0.1497]])}
test_args = (tensor([[[0.4938, 0.6819],
         [0.5742, 0.6460],
         [0.3378, 0.2281],
         [0.7492, 0.1896]],

       ...7667]],

        [[0.1947, 0.7804],
         [0.3308, 0.4317],
         [0.5867, 0.4624],
         [0.6004, 0.8926]]]))
test_kwargs = {'solver': 'svd', 'weights': tensor([[0.9918, 0.5738, 0.7422, 0.1353],
        [0.2479, 0.5713, 0.5185, 0.6650],
        [0.9338, 0.4034, 0.5138, 0.3933],
        [0.9181, 0.0618, 0.5611, 0.2354],
        [0.2368, 0.1769, 0.1624, 0.8794]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.33515054, 0.8166907 ],
        [0.29314995, 0.93231976],
        [0.72481465, 0.8578889 ],
        [0.97242266, 0.0484041 ]]], dtype=float32)
points2 = array([[[7.9115731e-01, 2.9785651e-01],
        [6.2241143e-01, 3.7976199e-01],
        [2.1914840e-01, 3.6206502e-01],
        [3.7366152e-04, 1.9940388e-01]]], dtype=float32)
weights = array([[0.7739654 , 0.87761635, 0.15235877, 0.1496678 ]], dtype=float32), solver = 'svd'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:94: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.7739654 , 0.7739654 , 0.87761635, 0.87761635, 0.15235877,
         0.15235877, 0.1496678 , 0.1496678 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
__________________________________________________________________________ test_find_homography_dlt_iterated[numpy-s2s-False] __________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f82e625d120>
trace_args = (tensor([[[0.9286, 0.4406],
         [0.1964, 0.1541],
         [0.2395, 0.2968],
         [0.0402, 0.0244]]]), tensor... [0.8702, 0.7396],
         [0.8555, 0.4261],
         [0.9357, 0.9267]]]), tensor([[0.7502, 0.3985, 0.6471, 0.3504]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.4928, 0.4381],
         [0.2117, 0.4457],
         [0.6024, 0.1414],
         [0.2277, 0.7671]],

       ...[0.4189, 0.3973, 0.7665, 0.9607],
        [0.1662, 0.9114, 0.4983, 0.3847],
        [0.2421, 0.2440, 0.7041, 0.2962]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_dlt_iterated at 0x7f82e625d120>, fn_name = 'kornia.geometry.homography.find_homography_dlt_iterated'
trace_args = (tensor([[[0.9286, 0.4406],
         [0.1964, 0.1541],
         [0.2395, 0.2968],
         [0.0402, 0.0244]]]), tensor... [0.8702, 0.7396],
         [0.8555, 0.4261],
         [0.9357, 0.9267]]]), tensor([[0.7502, 0.3985, 0.6471, 0.3504]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}
test_args = (tensor([[[0.4928, 0.4381],
         [0.2117, 0.4457],
         [0.6024, 0.1414],
         [0.2277, 0.7671]],

       ...[0.4189, 0.3973, 0.7665, 0.9607],
        [0.1662, 0.9114, 0.4983, 0.3847],
        [0.2421, 0.2440, 0.7041, 0.2962]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.9286205 , 0.44059533],
        [0.1963647 , 0.1541363 ],
        [0.2395364 , 0.2968428 ],
        [0.04017651, 0.02438021]]], dtype=float32)
points2 = array([[[0.12969714, 0.04451752],
        [0.87016475, 0.73963255],
        [0.85552627, 0.4260583 ],
        [0.93573254, 0.9267412 ]]], dtype=float32)
weights = array([[0.75024986, 0.39854258, 0.6471244 , 0.35039562]], dtype=float32), soft_inl_th = 3.0, n_iter = 5

    def numpy_find_homography_dlt_iterated(
        points1, points2, weights, soft_inl_th=3.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_dlt(points1, points2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:183: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

points1 = array([[[0.9286205 , 0.44059533],
        [0.1963647 , 0.1541363 ],
        [0.2395364 , 0.2968428 ],
        [0.04017651, 0.02438021]]], dtype=float32)
points2 = array([[[0.12969714, 0.04451752],
        [0.87016475, 0.73963255],
        [0.85552627, 0.4260583 ],
        [0.93573254, 0.9267412 ]]], dtype=float32)
weights = array([[0.75024986, 0.39854258, 0.6471244 , 0.35039562]], dtype=float32), solver = 'lu'

    def numpy_find_homography_dlt(points1, points2, weights=None, solver="lu"):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import (
            numpy_ones_like_v_0p4p0_and_above_frnt,
        )
        from ...ivy.functional.frontends.torch.creation_ops import numpy_zeros_like_frnt
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.creation_ops import numpy_ones_frnt
        from ..utils.helpers import numpy_safe_solve_with_mask
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if numpy_shape_frnt_(points1) != numpy_shape_frnt_(points2):
            raise AssertionError(numpy_shape_frnt_(points1))
        if numpy_shape_frnt_(points1)[1] < 4:
            raise AssertionError(numpy_shape_frnt_(points1))
        numpy_KORNIA_CHECK_SHAPE(points1, ["B", "N", "2"])
        numpy_KORNIA_CHECK_SHAPE(points2, ["B", "N", "2"])
        device, dtype = numpy__extract_device_dtype([points1, points2])
        eps: typing.Any = 1e-08
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        x1, y1 = numpy_chunk_frnt(points1_norm, dim=-1, chunks=2)
        x2, y2 = numpy_chunk_frnt(points2_norm, dim=-1, chunks=2)
        ones, zeros = numpy_ones_like_v_0p4p0_and_above_frnt(x1), numpy_zeros_like_frnt(x1)
        ax = numpy_cat_frnt(
            [zeros, zeros, zeros, -x1, -y1, -ones, y2 * x1, y2 * y1, y2], dim=-1
        )
        ay = numpy_cat_frnt(
            [x1, y1, ones, zeros, zeros, zeros, -x2 * x1, -x2 * y1, -x2], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(points1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.75024986, 0.75024986, 0.39854258, 0.39854258, 0.6471244 ,
         0.6471244 , 0.35039562, 0.35039562]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
___________________________________________________________________________ test_find_homography_lines_dlt[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
        )
        trace_kwargs = {'weights': torch.rand(1, 4)}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
        )
        test_kwargs = {'weights': torch.rand(5, 4)}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7f82e625d240>
trace_args = (tensor([[[[0.9076, 0.4865],
          [0.5909, 0.5590]],

         [[0.1080, 0.5805],
          [0.2025, 0.0721]],

 ...

         [[0.0018, 0.4516],
          [0.3177, 0.0421]],

         [[0.2217, 0.3184],
          [0.2513, 0.8760]]]]))
trace_kwargs = {'weights': tensor([[0.3855, 0.0257, 0.2851, 0.3634]])}
test_args = (tensor([[[[0.0361, 0.0754],
          [0.9547, 0.0238]],

         [[0.4064, 0.5009],
          [0.2485, 0.3768]],

 ...

         [[0.6018, 0.4263],
          [0.8068, 0.9537]],

         [[0.7747, 0.7995],
          [0.5387, 0.2461]]]]))
test_kwargs = {'weights': tensor([[0.9892, 0.8111, 0.2082, 0.0862],
        [0.6147, 0.3240, 0.8171, 0.5722],
        [0.3015, 0.4344, 0.7691, 0.2274],
        [0.5083, 0.2417, 0.8930, 0.1018],
        [0.0876, 0.4443, 0.1657, 0.4264]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt at 0x7f82e625d240>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt'
trace_args = (tensor([[[[0.9076, 0.4865],
          [0.5909, 0.5590]],

         [[0.1080, 0.5805],
          [0.2025, 0.0721]],

 ...

         [[0.0018, 0.4516],
          [0.3177, 0.0421]],

         [[0.2217, 0.3184],
          [0.2513, 0.8760]]]]))
trace_kwargs = {'weights': tensor([[0.3855, 0.0257, 0.2851, 0.3634]])}
test_args = (tensor([[[[0.0361, 0.0754],
          [0.9547, 0.0238]],

         [[0.4064, 0.5009],
          [0.2485, 0.3768]],

 ...

         [[0.6018, 0.4263],
          [0.8068, 0.9537]],

         [[0.7747, 0.7995],
          [0.5387, 0.2461]]]]))
test_kwargs = {'weights': tensor([[0.9892, 0.8111, 0.2082, 0.0862],
        [0.6147, 0.3240, 0.8171, 0.5722],
        [0.3015, 0.4344, 0.7691, 0.2274],
        [0.5083, 0.2417, 0.8930, 0.1018],
        [0.0876, 0.4443, 0.1657, 0.4264]])}
target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.90755796, 0.48646736],
         [0.59089446, 0.559005  ]],

        [[0.1079827 , 0.5804934 ],
         [0...    [0.79124284, 0.10949165]],

        [[0.47331983, 0.02892047],
         [0.59911644, 0.21006107]]]], dtype=float32)
ls2 = array([[[[0.2782032 , 0.64890313],
         [0.5954717 , 0.17814457]],

        [[0.9200899 , 0.28870022],
         [0...    [0.31770748, 0.04208314]],

        [[0.22169   , 0.31835425],
         [0.25131315, 0.87598383]]]], dtype=float32)
weights = array([[0.38554496, 0.02565998, 0.28506088, 0.36335313]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.38554496, 0.38554496, 0.02565998, 0.02565998, 0.28506088,
         0.28506088, 0.36335313, 0.36335313]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:79: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if input.dtype == np.bool:
_______________________________________________________________________ test_find_homography_lines_dlt_iterated[numpy-s2s-False] _______________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_find_homography_lines_dlt_iterated(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4, 2, 2),
            torch.rand(1, 4),
        )
        trace_kwargs = {'soft_inl_th': 4.0, 'n_iter': 5}
        test_args = (
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4, 2, 2),
            torch.rand(5, 4),
        )
        test_kwargs = {'soft_inl_th': 3.0, 'n_iter': 5}
>       _test_function(
            kornia.geometry.homography.find_homography_lines_dlt_iterated,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=5e-2,
            mode=mode,
            # NOTE: numerical instability in svd()/lu() leads to logits not being allclose
            deterministic=False,
        )

kornia/geometry/test_homography.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7f82e625d360>
trace_args = (tensor([[[[0.4623, 0.0787],
          [0.5494, 0.7121]],

         [[0.0460, 0.8973],
          [0.5699, 0.4818]],

 ...836, 0.9706]],

         [[0.8679, 0.3850],
          [0.5489, 0.7873]]]]), tensor([[0.0208, 0.1967, 0.6875, 0.7823]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.8553, 0.7651],
          [0.3987, 0.1743]],

         [[0.5357, 0.6939],
          [0.2089, 0.5745]],

 ...[0.9411, 0.0814, 0.4626, 0.7665],
        [0.4458, 0.7945, 0.8630, 0.6580],
        [0.2059, 0.5097, 0.9723, 0.5124]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, mode = 's2s', skip = False, deterministic = False, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function find_homography_lines_dlt_iterated at 0x7f82e625d360>, fn_name = 'kornia.geometry.homography.find_homography_lines_dlt_iterated'
trace_args = (tensor([[[[0.4623, 0.0787],
          [0.5494, 0.7121]],

         [[0.0460, 0.8973],
          [0.5699, 0.4818]],

 ...836, 0.9706]],

         [[0.8679, 0.3850],
          [0.5489, 0.7873]]]]), tensor([[0.0208, 0.1967, 0.6875, 0.7823]]))
trace_kwargs = {'n_iter': 5, 'soft_inl_th': 4.0}
test_args = (tensor([[[[0.8553, 0.7651],
          [0.3987, 0.1743]],

         [[0.5357, 0.6939],
          [0.2089, 0.5745]],

 ...[0.9411, 0.0814, 0.4626, 0.7665],
        [0.4458, 0.7945, 0.8630, 0.6580],
        [0.2059, 0.5097, 0.9723, 0.5124]]))
test_kwargs = {'n_iter': 5, 'soft_inl_th': 3.0}, target = 'numpy', backend_compile = False, tolerance = 0.05, deterministic = False, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.46226054, 0.07870102],
         [0.5494111 , 0.7121096 ]],

        [[0.04601282, 0.89730376],
         [0...    [0.9723821 , 0.23126388]],

        [[0.20092833, 0.13551617],
         [0.26037264, 0.10522968]]]], dtype=float32)
ls2 = array([[[[0.11127305, 0.66596544],
         [0.38807195, 0.0658989 ]],

        [[0.01171559, 0.893001  ],
         [0...    [0.38356596, 0.9706117 ]],

        [[0.86785537, 0.385046  ],
         [0.54891926, 0.78728586]]]], dtype=float32)
weights = array([[0.02082449, 0.19674683, 0.68745416, 0.7823006 ]], dtype=float32), soft_inl_th = 4.0, n_iter = 5

    def numpy_find_homography_lines_dlt_iterated(
        ls1, ls2, weights, soft_inl_th=4.0, n_iter=5
    ):
        from ...ivy.functional.frontends.torch.pointwise_ops import numpy_exp_frnt
    
>       H: typing.Any = numpy_find_homography_lines_dlt(ls1, ls2, weights)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ls1 = array([[[[0.46226054, 0.07870102],
         [0.5494111 , 0.7121096 ]],

        [[0.04601282, 0.89730376],
         [0...    [0.9723821 , 0.23126388]],

        [[0.20092833, 0.13551617],
         [0.26037264, 0.10522968]]]], dtype=float32)
ls2 = array([[[[0.11127305, 0.66596544],
         [0.38807195, 0.0658989 ]],

        [[0.01171559, 0.893001  ],
         [0...    [0.38356596, 0.9706117 ]],

        [[0.86785537, 0.385046  ],
         [0.54891926, 0.78728586]]]], dtype=float32)
weights = array([[0.02082449, 0.19674683, 0.68745416, 0.7823006 ]], dtype=float32)

    def numpy_find_homography_lines_dlt(ls1, ls2, weights=None):
        from ...ivy.functional.frontends.torch.tensor import numpy_shape_frnt_
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ..utils.helpers import numpy__extract_device_dtype
        from ...ivy.functional.frontends.torch.tensor import numpy_reshape_frnt_
        from .epipolar.fundamental import numpy_normalize_points
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_chunk_frnt,
        )
        from ...ivy.functional.frontends.torch.indexing_slicing_joining_mutating_ops import (
            numpy_cat_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_transpose_frnt_
        from ...ivy.functional.frontends.torch.miscellaneous_ops import (
            numpy_diag_embed_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import numpy_repeat_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_unsqueeze_frnt_
        from ..utils.helpers import numpy__torch_svd_cast
        from ...ivy.functional.frontends.torch.creation_ops import numpy_empty_frnt
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ..utils.helpers import numpy_safe_inverse_with_mask
    
        if len(numpy_shape_frnt_(ls1)) == 3:
            ls1 = ls1[None]
        if len(numpy_shape_frnt_(ls2)) == 3:
            ls2 = ls2[None]
        numpy_KORNIA_CHECK_SHAPE(ls1, ["B", "N", "2", "2"])
        numpy_KORNIA_CHECK_SHAPE(ls2, ["B", "N", "2", "2"])
        BS, N = numpy_shape_frnt_(ls1)[:2][0], numpy_shape_frnt_(ls1)[:2][1]
        device, dtype = numpy__extract_device_dtype([ls1, ls2])
        points1 = numpy_reshape_frnt_(ls1, BS, 2 * N, 2)
        points2 = numpy_reshape_frnt_(ls2, BS, 2 * N, 2)
        points1_norm, transform1 = numpy_normalize_points(points1)
        points2_norm, transform2 = numpy_normalize_points(points2)
        lst1, le1 = numpy_chunk_frnt(points1_norm, dim=1, chunks=2)
        lst2, le2 = numpy_chunk_frnt(points2_norm, dim=1, chunks=2)
        xs1, ys1 = numpy_chunk_frnt(lst1, dim=-1, chunks=2)
        xs2, ys2 = numpy_chunk_frnt(lst2, dim=-1, chunks=2)
        xe1, ye1 = numpy_chunk_frnt(le1, dim=-1, chunks=2)
        xe2, ye2 = numpy_chunk_frnt(le2, dim=-1, chunks=2)
        A = ys2 - ye2
        B = xe2 - xs2
        C = xs2 * ye2 - xe2 * ys2
        eps: typing.Any = 1e-08
        ax = numpy_cat_frnt(
            [A * xs1, A * ys1, A, B * xs1, B * ys1, B, C * xs1, C * ys1, C], dim=-1
        )
        ay = numpy_cat_frnt(
            [A * xe1, A * ye1, A, B * xe1, B * ye1, B, C * xe1, C * ye1, C], dim=-1
        )
        A = numpy_reshape_frnt_(
            numpy_cat_frnt((ax, ay), dim=-1),
            numpy_shape_frnt_(ax)[0],
            -1,
            numpy_shape_frnt_(ax)[-1],
        )
        if weights is None:
            A = numpy_transpose_frnt_(A, -2, -1) @ A
        else:
            if not (
                len(numpy_shape_frnt_(weights)) == 2
                and numpy_shape_frnt_(weights) == numpy_shape_frnt_(ls1)[:2]
            ):
                raise AssertionError(numpy_shape_frnt_(weights))
>           w_diag = numpy_diag_embed_frnt(
                numpy_reshape_frnt_(
                    numpy_repeat_frnt_(numpy_unsqueeze_frnt_(weights, dim=-1), 1, 1, 2),
                    numpy_shape_frnt_(weights)[0],
                    -1,
                )
            )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.02082449, 0.02082449, 0.19674683, 0.19674683, 0.68745416,
         0.68745416, 0.7823006 , 0.7823006 ]]], dtype=float32), offset = 0, dim1 = 1, dim2 = 2

    def numpy_diag_embed_frnt(input, offset=0, dim1=-2, dim2=-1):
        from ...backends.numpy.data_type import numpy_dtype
        from .tensor import numpy_ndim_frnt_
        from .tensor import numpy_shape_frnt_
        from ...backends.numpy.general import numpy_set_item
        from ...backends.numpy.creation import numpy_zeros
        from ...backends.numpy.manipulation import numpy_concat
        from ....data_classes.array.experimental.manipulation import numpy_moveaxis_bknd_
        from ....data_classes.array.manipulation import numpy_expand_dims_bknd_
        from ...backends.numpy.creation import numpy_arange
        from .tensor import numpy_reshape_frnt_
        from .tensor import numpy_logical_and_frnt_
        from ...backends.numpy.searching import numpy_where
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        def _handle_dim(rank, idx):
            if idx >= 0 and idx < rank:
                return idx
            if idx < 0:
                idx = idx + rank
            if idx < 0 or idx >= rank:
                raise IndexError
            return idx
    
        input_type = numpy_dtype(input)
        rank = numpy_ndim_frnt_(input) + 1
        dim1 = _handle_dim(rank, dim1)
        dim2 = _handle_dim(rank, dim2)
        if dim1 > dim2:
            dim1, dim2 = dim2, dim1
            offset = -offset
        last_dim = list(numpy_shape_frnt_(input))[-1]
        if offset != 0:
            t_shape = list(numpy_shape_frnt_(input))
            t_shape = numpy_set_item(t_shape, -1, abs(offset))
            z = numpy_zeros(t_shape, dtype=input.dtype, device=None)
            pair = (z, input) if offset > 0 else (input, z)
            input = numpy_concat(pair, axis=-1)
            last_dim = last_dim + abs(offset)
        input = numpy_moveaxis_bknd_(numpy_expand_dims_bknd_(input, axis=dim1), -1, dim2)
        a_range = numpy_arange(last_dim, device=None, dtype=np.int64)
        b_range = numpy_arange(offset, last_dim + offset, device=None, dtype=np.int64)
        cond = a_range == numpy_expand_dims_bknd_(b_range, axis=-1)
        ag__result_list_0 = []
        for i in range(len(numpy_shape_frnt_(input))):
            res = last_dim if i in (dim1, dim2) else 1
            ag__result_list_0.append(res)
        cond_shape = ag__result_list_0
        cond = numpy_reshape_frnt_(cond, cond_shape)
>       if input.dtype == np.bool:

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

attr = 'bool'

    def __getattr__(attr):
        # Warn for expired attributes, and return a dummy function
        # that always raises an exception.
        import warnings
        import math
        try:
            msg = __expired_functions__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
    
            def _expired(*args, **kwds):
                raise RuntimeError(msg)
    
            return _expired
    
        # Emit warnings for deprecated attributes
        try:
            val, msg = __deprecated_attrs__[attr]
        except KeyError:
            pass
        else:
            warnings.warn(msg, DeprecationWarning, stacklevel=2)
            return val
    
        if attr in __future_scalars__:
            # And future warnings for those that will change, but also give
            # the AttributeError
            warnings.warn(
                f"In the future `np.{attr}` will be defined as the "
                "corresponding NumPy scalar.", FutureWarning, stacklevel=2)
    
        if attr in __former_attrs__:
>           raise AttributeError(__former_attrs__[attr])
E           AttributeError: module 'numpy' has no attribute 'bool'.
E           `np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

/opt/fw/mxnet/numpy/__init__.py:324: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.find_homography_lines_dlt_iterated
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/miscellaneous_ops.py:91: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
_____________________________________________________________________________ test_oneway_transfer_error[numpy-s2s-False] ______________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_oneway_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': False, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': False, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.oneway_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7f82e625cdc0>
trace_args = (tensor([[[0.2265, 0.1403],
         [0.5075, 0.6038],
         [0.1824, 0.1017],
         [0.0270, 0.9005]]]), tensor...0.3216]]]), tensor([[[0.7836, 0.7800, 0.0259],
         [0.8165, 0.1787, 0.7394],
         [0.4945, 0.9209, 0.2007]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.4248, 0.2984],
         [0.9673, 0.9986],
         [0.4217, 0.3452],
         [0.0721, 0.7437]],

       ... 0.6941]],

        [[0.2585, 0.3064, 0.7439],
         [0.4267, 0.8684, 0.0092],
         [0.2998, 0.3226, 0.5820]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function oneway_transfer_error at 0x7f82e625cdc0>, fn_name = 'kornia.geometry.homography.oneway_transfer_error'
trace_args = (tensor([[[0.2265, 0.1403],
         [0.5075, 0.6038],
         [0.1824, 0.1017],
         [0.0270, 0.9005]]]), tensor...0.3216]]]), tensor([[[0.7836, 0.7800, 0.0259],
         [0.8165, 0.1787, 0.7394],
         [0.4945, 0.9209, 0.2007]]]))
trace_kwargs = {'eps': 1e-08, 'squared': False}
test_args = (tensor([[[0.4248, 0.2984],
         [0.9673, 0.9986],
         [0.4217, 0.3452],
         [0.0721, 0.7437]],

       ... 0.6941]],

        [[0.2585, 0.3064, 0.7439],
         [0.4267, 0.8684, 0.0092],
         [0.2998, 0.3226, 0.5820]]]))
test_kwargs = {'eps': 1e-07, 'squared': False}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.22649479, 0.14025581],
        [0.5075223 , 0.6037999 ],
        [0.18244207, 0.10171914],
        [0.02704561, 0.90052956]]], dtype=float32)
pts2 = array([[[0.10657644, 0.78095746],
        [0.9942792 , 0.8892656 ],
        [0.7653793 , 0.59195375],
        [0.3357638 , 0.32158625]]], dtype=float32)
H = array([[[0.7836305 , 0.77995425, 0.02589601],
        [0.81649745, 0.1787448 , 0.7394483 ],
        [0.49445927, 0.92094755, 0.20066172]]], dtype=float32), squared = False, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 0.60134906,  1.3679845 ],
        [-0.10655361,  0.36288446],
        [-0.11995083,  1.7655909 ],
        [ 0.38254118,  0.56255966]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f828d1ecee0>
array_like = array([[[ 0.60134906,  1.3679845 ],
        [-0.10655361,  0.36288446],
        [-0.11995083,  1.7655909 ],
        [ 0.38254118,  0.56255966]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[ 0.60134906,  1.3679845 ],
        [-0.10655361,  0.36288446],
        [-0.11995083,  1.7655909 ],
        [ 0.38254118,  0.56255966]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[ 0.60134906,  1.3679845 ],
        [-0.10655361,  0.36288446],
        [-0.11995083,  1.7655909 ],
        [ 0.38254118,  0.56255966]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f828d1ecee0>
array_like = array([[[ 0.60134906,  1.3679845 ],
        [-0.10655361,  0.36288446],
        [-0.11995083,  1.7655909 ],
        [ 0.38254118,  0.56255966]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[ 0.60134906,  1.3679845 ],
        [-0.10655361,  0.36288446],
        [-0.11995083,  1.7655909 ],
        [ 0.38254118,  0.56255966]]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[ 0.60134906,  1.3679845 ],
        [-0.10655361,  0.36288446],
        [-0.11995083,  1.7655909 ],
        [ 0.38254118,  0.56255966]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.oneway_transfer_error
____________________________________________________________________________ test_symmetric_transfer_error[numpy-s2s-False] ____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_symmetric_transfer_error(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 4, 2),
            torch.rand(1, 4, 2),
            torch.rand(1, 3, 3),
        )
        trace_kwargs = {'squared': True, 'eps': 1e-8}
        test_args = (
            torch.rand(5, 4, 2),
            torch.rand(5, 4, 2),
            torch.rand(5, 3, 3),
        )
        test_kwargs = {'squared': True, 'eps': 1e-7}
>       _test_function(
            kornia.geometry.homography.symmetric_transfer_error,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_homography.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7f82e625cee0>
trace_args = (tensor([[[0.0599, 0.3612],
         [0.6871, 0.2926],
         [0.0179, 0.6699],
         [0.6503, 0.2204]]]), tensor...0.4933]]]), tensor([[[0.2741, 0.1216, 0.2026],
         [0.2833, 0.8790, 0.2481],
         [0.6677, 0.1323, 0.1641]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.9816, 0.0608],
         [0.2839, 0.6305],
         [0.9588, 0.2198],
         [0.1179, 0.2975]],

       ... 0.5787]],

        [[0.9186, 0.9813, 0.6025],
         [0.5284, 0.3514, 0.0628],
         [0.6958, 0.8410, 0.0790]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function symmetric_transfer_error at 0x7f82e625cee0>, fn_name = 'kornia.geometry.homography.symmetric_transfer_error'
trace_args = (tensor([[[0.0599, 0.3612],
         [0.6871, 0.2926],
         [0.0179, 0.6699],
         [0.6503, 0.2204]]]), tensor...0.4933]]]), tensor([[[0.2741, 0.1216, 0.2026],
         [0.2833, 0.8790, 0.2481],
         [0.6677, 0.1323, 0.1641]]]))
trace_kwargs = {'eps': 1e-08, 'squared': True}
test_args = (tensor([[[0.9816, 0.0608],
         [0.2839, 0.6305],
         [0.9588, 0.2198],
         [0.1179, 0.2975]],

       ... 0.5787]],

        [[0.9186, 0.9813, 0.6025],
         [0.5284, 0.3514, 0.0628],
         [0.6958, 0.8410, 0.0790]]]))
test_kwargs = {'eps': 1e-07, 'squared': True}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
>       graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:336: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.05992264, 0.3612284 ],
        [0.68706447, 0.2926439 ],
        [0.0179342 , 0.6698776 ],
        [0.65031624, 0.22043389]]], dtype=float32)
pts2 = array([[[0.9790732 , 0.6540419 ],
        [0.6035219 , 0.33841658],
        [0.03101563, 0.76265216],
        [0.02598137, 0.4933492 ]]], dtype=float32)
H = array([[[0.27409792, 0.12155092, 0.2025646 ],
        [0.2832752 , 0.87896514, 0.24805254],
        [0.6676774 , 0.13232416, 0.1640889 ]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_symmetric_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from ...ivy.functional.frontends.torch.miscellaneous_ops import numpy_finfo_frnt
        from ..utils.helpers import numpy_safe_inverse_with_mask
        from ...ivy.functional.frontends.torch.tensor import numpy_expand_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_view_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_to_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        max_num = numpy_finfo_frnt(pts1.dtype).max
        H_inv, good_H = numpy_safe_inverse_with_mask(H)
>       there: typing.Any = numpy_oneway_transfer_error(pts1, pts2, H, True, eps)

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pts1 = array([[[0.05992264, 0.3612284 ],
        [0.68706447, 0.2926439 ],
        [0.0179342 , 0.6698776 ],
        [0.65031624, 0.22043389]]], dtype=float32)
pts2 = array([[[0.9790732 , 0.6540419 ],
        [0.6035219 , 0.33841658],
        [0.03101563, 0.76265216],
        [0.02598137, 0.4933492 ]]], dtype=float32)
H = array([[[0.27409792, 0.12155092, 0.2025646 ],
        [0.2832752 , 0.87896514, 0.24805254],
        [0.6676774 , 0.13232416, 0.1640889 ]]], dtype=float32), squared = True, eps = 1e-08

    def numpy_oneway_transfer_error(pts1, pts2, H, squared=True, eps=1e-08):
        from ..core.check import numpy_KORNIA_CHECK_SHAPE
        from ...ivy.functional.frontends.torch.tensor import numpy_size_frnt_
        from .conversions import numpy_convert_points_from_homogeneous
        from .linalg import numpy_transform_points
        from ...ivy.functional.frontends.torch.tensor import numpy_sum_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_pow_frnt_
        from ...ivy.functional.frontends.torch.tensor import numpy_sqrt_frnt_
    
        numpy_KORNIA_CHECK_SHAPE(H, ["B", "3", "3"])
        if numpy_size_frnt_(pts1, -1) == 3:
            pts1 = numpy_convert_points_from_homogeneous(pts1)
        if numpy_size_frnt_(pts2, -1) == 3:
            pts2 = numpy_convert_points_from_homogeneous(pts2)
        pts1_in_2: typing.Any = numpy_transform_points(H, pts1)
        error_squared: typing.Any = numpy_sum_frnt_(
>           numpy_pow_frnt_(pts1_in_2 - pts2, 2), dim=-1
        )

ivy_transpiled_outputs/numpy_outputs/kornia/geometry/homography.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[0.06459433, 1.6585461 ],
        [0.04111356, 0.71956015],
        [1.0604086 , 2.418     ],
        [0.6236369 , 0.50436485]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f828d090040>
array_like = array([[[0.06459433, 1.6585461 ],
        [0.04111356, 0.71956015],
        [1.0604086 , 2.418     ],
        [0.6236369 , 0.50436485]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = array([[[0.06459433, 1.6585461 ],
        [0.04111356, 0.71956015],
        [1.0604086 , 2.418     ],
        [0.6236369 , 0.50436485]]], dtype=float32), exponent = 2

    @numpy_handle_methods
    def numpy_pow_frnt_(tensor, exponent):
        from .pointwise_ops import numpy_pow_frnt
    
>       return numpy_pow_frnt(tensor, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/tensor.py:272: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (array([[[0.06459433, 1.6585461 ],
        [0.04111356, 0.71956015],
        [1.0604086 , 2.418     ],
        [0.6236369 , 0.50436485]]], dtype=float32), 2), kwargs = {}
numpy_is_array_bknd = <function numpy_is_array_bknd at 0x7f828d090040>
array_like = array([[[0.06459433, 1.6585461 ],
        [0.04111356, 0.71956015],
        [1.0604086 , 2.418     ],
        [0.6236369 , 0.50436485]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import numpy_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if numpy_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/numpy_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = array([[[0.06459433, 1.6585461 ],
        [0.04111356, 0.71956015],
        [1.0604086 , 2.418     ],
        [0.6236369 , 0.50436485]]], dtype=float32), exponent = array(2)

    @numpy_handle_methods
    def numpy_pow_frnt(input, exponent, *, out=None):
        from ...ivy.general import numpy_is_array_bknd
        from .creation_ops import numpy_as_tensor_frnt
        from ...backends.numpy.creation import numpy_asarray
        from .__init__ import numpy_promote_types_of_torch_inputs_frnt
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.elementwise import numpy_pow
        from ...backends.numpy.utility import numpy_any
        from ...backends.numpy.searching import numpy_where
        from ...backends.numpy.elementwise import numpy_bitwise_and
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        if not numpy_is_array_bknd(input):
            input = numpy_as_tensor_frnt(input)
        if not numpy_is_array_bknd(exponent):
            if (
                any(dtype in str(input.dtype) for dtype in ["int8", "int16"])
                and isinstance(exponent, (int,))
                or "float16" in str(input.dtype)
                and isinstance(exponent, (float,))
            ):
                exponent = numpy_asarray(exponent, dtype=input.dtype)
            else:
                exponent = numpy_as_tensor_frnt(exponent)
>       input, exponent = numpy_promote_types_of_torch_inputs_frnt(input, exponent)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/pointwise_ops.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x1 = array([[[0.06459433, 1.6585461 ],
        [0.04111356, 0.71956015],
        [1.0604086 , 2.418     ],
        [0.6236369 , 0.50436485]]], dtype=float32), x2 = array(2)

    def numpy_promote_types_of_torch_inputs_frnt(x1, x2, /):
        from ...ivy.general import numpy_isscalar_bknd
        from ...ivy.data_type import numpy_is_int_dtype_bknd
        from ...backends.numpy.creation import numpy_asarray
        from ...ivy.data_type import numpy_default_dtype_bknd
        from .tensor import numpy_shape_frnt_
        from ...ivy.device import numpy_default_device_bknd
        from ....data_classes.array.data_type import numpy_astype_bknd_
    
        """Promote the dtype of the given native array inputs to a common dtype
        based on type promotion rules.
    
        While passing float or integer values or any other non-array input
        to this function, it should be noted that the return will be an
        array-like object. Therefore, outputs from this function should be
        used as inputs only for those functions that expect an array-like or
        tensor-like objects, otherwise it might give unexpected results.
        """
        if (
            numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x1):
            x1 = numpy_asarray(x1, dtype="int64")
        elif numpy_isscalar_bknd(x1) or isinstance(x1, (list, tuple)):
            x1 = numpy_asarray(x1)
        if (
            numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple))
        ) and numpy_is_int_dtype_bknd(x2):
            x2 = numpy_asarray(x2, dtype="int64")
        elif numpy_isscalar_bknd(x2) or isinstance(x2, (list, tuple)):
            x2 = numpy_asarray(x2)
        type1 = numpy_default_dtype_bknd(item=x1).strip("u123456789")
        type2 = numpy_default_dtype_bknd(item=x2).strip("u123456789")
        if numpy_shape_frnt_(x1) != () and numpy_shape_frnt_(x2) == () and type1 == type2:
            x2 = numpy_asarray(
                x2,
                dtype=x1.dtype,
                device=numpy_default_device_bknd(item=x1, as_native=False),
            )
        elif numpy_shape_frnt_(x1) == () and numpy_shape_frnt_(x2) != () and type1 == type2:
            x1 = numpy_asarray(
                x1,
                dtype=x2.dtype,
                device=numpy_default_device_bknd(item=x2, as_native=False),
            )
        elif x1.dtype != x2.dtype:
>           promoted = numpy_promote_types_torch_frnt(x1.dtype, x2.dtype)

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

type1 = dtype('float32'), type2 = dtype('int64')

    def numpy_promote_types_torch_frnt(type1, type2, /):
        from ...backends.numpy.general import numpy_get_item
        from ...backends.numpy.data_type import numpy_as_ivy_dtype
    
        try:
            ret = numpy_get_item(
>               torch_promotion_table,
                (numpy_as_ivy_dtype(type1), numpy_as_ivy_dtype(type2)),
            )
E           NameError: name 'torch_promotion_table' is not defined

ivy_transpiled_outputs/numpy_outputs/ivy/functional/frontends/torch/__init__.py:34: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.homography.symmetric_transfer_error
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_find_homography_lines_dlt_iterated[numpy-s2s-False] - AttributeError: module 'numpy' has no attribute 'bool'.
FAILED kornia/geometry/test_homography.py::test_oneway_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
FAILED kornia/geometry/test_homography.py::test_symmetric_transfer_error[numpy-s2s-False] - NameError: name 'torch_promotion_table' is not defined
=============================================================================== 6 failed, 2 passed in 557.98s (0:09:17) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/geometry/test_vector.py ..                                                                                                                                                                [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 137.65s (0:02:17) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.....ssss                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_mean_average_precision[numpy-s2s-False] _____________________________________________________________________________

target_framework = 'numpy', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7ff6aeaf4a60>
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7ff6aeaf4a60>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], [array([0.7], dtype=float32)], [array([[100.,  50., 150., 100.]], dtype=float32)], [array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'numpy', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [array([1.], dtype=float32)], pred_scores = [array([0.7], dtype=float32)]
gt_boxes = [array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[numpy-s2s-False] - TypeError: 'int' object is not callable
========================================================================== 1 failed, 8 passed, 4 skipped in 456.75s (0:07:36) ==========================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 5 items

kornia/test_x.py sssss                                                                                                                                                                           [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 5 skipped in 298.21s (0:04:58) ====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 56 items

kornia/geometry/test_transform.py ........................F..................F.......F..FF                                                                                                       [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_upscale_double[tensorflow-s2s-False] _______________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_upscale_double(target_framework, mode, backend_compile):
        trace_args = (
            torch.rand(1, 3, 4, 4),
        )
        trace_kwargs = {}
        test_args = (
            torch.rand(5, 3, 8, 8),
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.transform.upscale_double,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_transform.py:612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f072421a440>
trace_args = (tensor([[[[0.4464, 0.9742, 0.1274, 0.6877],
          [0.5123, 0.9747, 0.1212, 0.8405],
          [0.5895, 0.4033, 0...., 0.5142, 0.3064, 0.9437],
          [0.9289, 0.3095, 0.5357, 0.8844],
          [0.6701, 0.6951, 0.6093, 0.7304]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[3.9556e-01, 9.3764e-01, 8.8806e-01, 7.7434e-01, 5.2663e-01,
           7.8675e-01, 7.9551e-03, 9.2416e-01]...      [2.3253e-01, 9.8190e-01, 4.5697e-01, 9.5469e-01, 5.2136e-01,
           9.8218e-02, 6.5785e-01, 7.6584e-01]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function upscale_double at 0x7f072421a440>, fn_name = 'kornia.geometry.transform.upscale_double'
trace_args = (tensor([[[[0.4464, 0.9742, 0.1274, 0.6877],
          [0.5123, 0.9747, 0.1212, 0.8405],
          [0.5895, 0.4033, 0...., 0.5142, 0.3064, 0.9437],
          [0.9289, 0.3095, 0.5357, 0.8844],
          [0.6701, 0.6951, 0.6093, 0.7304]]]]),)
trace_kwargs = {}
test_args = (tensor([[[[3.9556e-01, 9.3764e-01, 8.8806e-01, 7.7434e-01, 5.2663e-01,
           7.8675e-01, 7.9551e-03, 9.2416e-01]...      [2.3253e-01, 9.8190e-01, 4.5697e-01, 9.5469e-01, 5.2136e-01,
           9.8218e-02, 6.5785e-01, 7.6584e-01]]]]),)
test_kwargs = {}, target = 'tensorflow', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
>           graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)

helpers.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???

IXC.pyx:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = <tf.Tensor: shape=(1, 3, 4, 4), dtype=float32, numpy=
array([[[[0.44635242, 0.9742323 , 0.12743145, 0.68770134],
     ....30951166, 0.535696  , 0.8844128 ],
         [0.6701144 , 0.6951225 , 0.6093378 , 0.7304272 ]]]],
      dtype=float32)>

    def tensorflow_upscale_double(x):
        from ...core._backend import zeros
        from ...core.check import tensorflow_KORNIA_CHECK_IS_TENSOR
        from ...core.check import tensorflow_KORNIA_CHECK_SHAPE
        from ....ivy.functional.frontends.torch.tensor import tensorflow_shape_frnt_
        from ....ivy.functional.backends.tensorflow.general import tensorflow_set_item
    
        tensorflow_KORNIA_CHECK_IS_TENSOR(x)
        tensorflow_KORNIA_CHECK_SHAPE(x, ["*", "H", "W"])
        double_shape = tensorflow_shape_frnt_(x)[:-2] + (
            tensorflow_shape_frnt_(x)[-2] * 2,
            tensorflow_shape_frnt_(x)[-1] * 2,
        )
        upscaled = zeros(double_shape, device=x.device, dtype=x.dtype)
        upscaled = tensorflow_set_item(
            upscaled, (..., slice(None, None, 2), slice(None, None, 2)), x
        )
>       upscaled[..., ::2, 1::2] = tensorflow_set_item(
            upscaled[..., ::2, 1::2],
            (..., slice(None, -1, None)),
            (upscaled[..., ::2, ::2][..., :-1] + upscaled[..., ::2, 2::2]) / 2,
        )
E       TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/pyramid.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.pyramid.upscale_double
___________________________________________________________________________________ test_Shear[tensorflow-s2s-False] ___________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Shear(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Shear")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledShear = ivy.transpile(kornia.geometry.transform.Shear, source="torch", target=target_framework)
    
        x = torch.rand(2, 3, 4, 4)
        shear = torch.tensor([[0.5, 0.0], [0.0, 0.5]])
        torch_out = kornia.geometry.transform.Shear(shear)(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_shear = _nest_torch_tensor_to_new_framework(shear, target_framework)
>       transpiled_out = TranspiledShear(transpiled_shear)(transpiled_x)

kornia/geometry/test_transform.py:1156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.3158028 , 0.43474346, 0.9184409 , 0.5840528 ],
    ...8861957, 0.24259311, 0.71297747],
         [0.17982   , 0.16642988, 0.36340207, 0.7479899 ]]]],
      dtype=float32)>,)
kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f06d0bb1590, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.3158028 , 0.43474346, 0.9184409...48861957, 0.24259311, 0.71297747],
         [0.17982   , 0.16642988, 0.36340207, 0.7479899 ]]]],
      dtype=float32)>)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.3158028 , 0.43474346, 0.9184409 , 0.5840528 ],
    ...8861957, 0.24259311, 0.71297747],
         [0.17982   , 0.16642988, 0.36340207, 0.7479899 ]]]],
      dtype=float32)>,)
kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:2013: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(), <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.3158028 , 0.43474346, 0.9184409...48861957, 0.24259311, 0.71297747],
         [0.17982   , 0.16642988, 0.36340207, 0.7479899 ]]]],
      dtype=float32)>)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear(), v = None, buffers = None
args = (<tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.3158028 , 0.43474346, 0.9184409 , 0.5840528 ],
    ...8861957, 0.24259311, 0.71297747],
         [0.17982   , 0.16642988, 0.36340207, 0.7479899 ]]]],
      dtype=float32)>,)
kwargs = {}
first_arr = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.3158028 , 0.43474346, 0.9184409 , 0.5840528 ],
     ....48861957, 0.24259311, 0.71297747],
         [0.17982   , 0.16642988, 0.36340207, 0.7479899 ]]]],
      dtype=float32)>
replace_v = False, replace_buffers = False, call_signature = <Signature (input)>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Model, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Model, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Model, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Shear(),)
kwargs = {'input': <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.3158028 , 0.43474346, 0.9184409 , 0.584052...48861957, 0.24259311, 0.71297747],
         [0.17982   , 0.16642988, 0.36340207, 0.7479899 ]]]],
      dtype=float32)>}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Shear()
input = <tf.Tensor: shape=(2, 3, 4, 4), dtype=float32, numpy=
array([[[[0.3158028 , 0.43474346, 0.9184409 , 0.5840528 ],
     ....48861957, 0.24259311, 0.71297747],
         [0.17982   , 0.16642988, 0.36340207, 0.7479899 ]]]],
      dtype=float32)>

    def call(self, input):
>       return shear(
            input, self.shear, self.mode, self.padding_mode, self.align_corners
        )
E       NameError: Exception encountered when calling tensorflow_Shear.call().
E       
E       [1mname 'shear' is not defined[0m
E       
E       Arguments received by tensorflow_Shear.call():
E          input=tf.Tensor(shape=(2, 3, 4, 4), dtype=float32)

ivy_transpiled_outputs/tensorflow_outputs/kornia/geometry/transform/affwarp.py:55: NameError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Shear
__________________________________________________________________________________ test_Rescale[tensorflow-s2s-False] __________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Rescale(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Rescale")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledRescale = ivy.transpile(kornia.geometry.transform.Rescale, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 4, 4)
        torch_out = kornia.geometry.transform.Rescale((2.0, 3.0))(x)
    
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
        transpiled_out = TranspiledRescale((2.0, 3.0))(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/geometry/test_transform.py:1294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[[0.9931, 0.9217, 0.8503, 0.7789, 0.7104, 0.6477, 0.5850, 0.5223,
           0.5276, 0.5668, 0.6061, 0.6453],...        [0.5012, 0.5071, 0.5130, 0.5189, 0.4831, 0.3639, 0.2447, 0.1255,
           0.1126, 0.1528, 0.1931, 0.2333]]]])
transpiled_x = <tf.Tensor: shape=(1, 3, 8, 12), dtype=float32, numpy=
array([[[[0.99309736, 0.99309736, 0.905831  , 0.8185646 , 0.731...      0.37716383, 0.23149055, 0.08581734, 0.1349665 , 0.18411562,
          0.23326474, 0.23326474]]]], dtype=float32)>
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[0.99309736, 0.9216976 , 0.8502978 , 0.778898  , 0.7104013 ,
          0.6477107 , 0.58502007, 0.5223294 , 0....       0.3639208 , 0.24473357, 0.12554637, 0.11262596, 0.15283889,
          0.19305183, 0.23326474]]]], dtype=float32)
y = array([[[[0.99309736, 0.99309736, 0.905831  , 0.8185646 , 0.7312982 ,
          0.6546763 , 0.5780544 , 0.50143254, 0....       0.37716383, 0.23149055, 0.08581734, 0.1349665 , 0.18411562,
          0.23326474, 0.23326474]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Rescale
________________________________________________________________________________ test_Homography[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Homography(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Homography")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomography = ivy.transpile(
            kornia.geometry.transform.image_registrator.Homography, source="torch", target=target_framework
        )
    
        torch_out = kornia.geometry.transform.image_registrator.Homography()()
>       transpiled_out = TranspiledHomography()()

kornia/geometry/test_transform.py:1354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>), args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f069a236320, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>),), kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>), v = None, buffers = None
args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>),)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>), v = None, buffers = None
args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False, call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Homography(<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>),), kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7f06b83f5c60>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Homography
________________________________________________________________________________ test_Similarity[tensorflow-s2s-False] _________________________________________________________________________________

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_Similarity(target_framework, mode, backend_compile):
        print("kornia.geometry.transform.Similarity")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledSimilarity = ivy.transpile(
            kornia.geometry.transform.image_registrator.Similarity, source="torch", target=target_framework
        )
    
        torch_out = kornia.geometry.transform.image_registrator.Similarity()()
>       transpiled_out = TranspiledSimilarity()()

kornia/geometry/test_transform.py:1392: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,  ...[0.]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>)
args = (), kwargs = {}
stack = [FrameInfo(frame=<frame at 0x7f06d0c16040, file '/ivy/ivy-integration-tests/ivy_transpiled_outputs/tensorflow_outputs/...ode_context=['        return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n'], index=0), ...]

    @functools.wraps(fn)
    def frame_info_wrapper(self, *args, **kwargs):
        if self._previous_frame_info is None:
            # store the info about the calling frame.
            stack = inspect.stack()
            self._previous_frame_info = stack[1]
>       res = fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, ....]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>),)
kwargs = {}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,  ...[0.]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>)
v = None, buffers = None, args = (), kwargs = {}

    @store_frame_info
    @tf.autograph.experimental.do_not_convert
    def __call__(
        self,
        *args,
        v=None,
        buffers=None,
        **kwargs,
    ):
        # TODO: Temp workaround to avoid `call`` from being transformed by AutoGraph
        if not hasattr(self.__class__.call, "autograph_info__"):
            setattr(self.__class__.call, "autograph_info__", True)
>       ret = self._call(*args, v=v, buffers=buffers, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, ....]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>),)
kwargs = {'buffers': None, 'v': None}

    def wrapper(*args, **kwargs):
      with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
>       return func(*args, **kwargs)

/opt/fw/tensorflow/tensorflow/python/autograph/impl/api.py:643: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,  ...[0.]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>)
v = None, buffers = None, args = (), kwargs = {}, first_arr = None, replace_v = False, replace_buffers = False, call_signature = <Signature ()>

    @tf.autograph.experimental.do_not_convert
    def _call(self, *args, v=None, buffers=None, **kwargs):
        if not self._built or not self.built:
            if not self._built:
                first_arr = self._get_first_array(*args, **kwargs)
                self.build(
                    *args,
                    **kwargs,
                    from_call=True,
                    dtype=first_arr.dtype if first_arr is not None else tf.float32,
                )
    
            if not self.built:
                # Don't use `keras` build method
                if os.environ.get("USE_KERAS_BUILD", "False").lower() == "false":
                    self.inputs = tf.nest.flatten(args)
                else:
                    input_shapes = self._get_input_shapes(*args)
                    if len(input_shapes) == 0:
                        input_shapes = tf.TensorShape(None)
                    elif len(input_shapes) == 1:
                        input_shapes = input_shapes[0]
    
                super(Layer, self).build(tf.TensorShape(None))  # noqa: UP008
    
        # If `v` was provided, replace with the module's v
        replace_v = False
        if v is not None:
            v_orig = self.v
            self._v = v
            replace_v = True
    
        # If `buffers` were provided, replace with the module's buffers
        replace_buffers = False
        if buffers is not None:
            buffers_orig = self.buffers
            self._buffers = buffers
            replace_buffers = True
    
        if replace_v or replace_buffers:
            # Call the forward pass
            ret = super(Layer, self).__call__(*args, **kwargs)  # noqa: UP008
            # Replace v, buffers if needed
            self._v = v_orig if replace_v else self._v
            self._buffers = buffers_orig if replace_buffers else self._buffers
            return ret
        elif hasattr(self.__call__, "wrapped"):
            return self.__call__(*args, **kwargs)
    
        # Get the signature of the call method
        call_signature = inspect.signature(self.call)
    
        # Convert all positional arguments to keyword arguments based on the signature
        new_kwargs = {}
        for idx, (param_name, param) in enumerate(call_signature.parameters.items()):
            if idx < len(args):
                new_kwargs[param_name] = args[idx]
    
        # Merge the existing kwargs
        new_kwargs.update(kwargs)
>       return super(Layer, self).__call__(**new_kwargs)  # noqa: UP008

ivy_transpiled_outputs/tensorflow_outputs/tensorflow__stateful.py:1089: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (tensorflow_Similarity(angle = <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, ....]]], dtype=float32)>, 
 scale=<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>),)
kwargs = {}

    @wraps(fn)
    def error_handler(*args, **kwargs):
        if not is_traceback_filtering_enabled():
            return fn(*args, **kwargs)
    
        filtered_tb = None
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            filtered_tb = _process_traceback_frames(e.__traceback__)
            # To get the full stack trace, call:
            # `keras.config.disable_traceback_filtering()`
>           raise e.with_traceback(filtered_tb) from None

/opt/fw/tensorflow/keras/src/utils/traceback_utils.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <keras.src.layers.layer.CallSpec object at 0x7f06b8f0ab60>, signature = <Signature ()>, args = (), kwargs = {}

    def __init__(self, signature, args, kwargs):
        # `training` and `mask` are special kwargs that are always available in
        # a layer, if user specifies them in their call without adding to spec,
        # we remove them to be able to bind variables. User is not using
        # `training` anyway so we can ignore.
        # TODO: If necessary use workaround for `mask`
        if "training" in kwargs and "training" not in signature.parameters:
            kwargs.pop("training")
            bound_args = signature.bind(*args, **kwargs)
        else:
            bound_args = signature.bind(*args, **kwargs)
        self.user_arguments_dict = {
            k: v for k, v in bound_args.arguments.items()
        }
        bound_args.apply_defaults()
        arg_dict = {}
        arg_names = []
        tensor_arg_dict = {}
        tensor_args = []
        tensor_arg_names = []
        nested_tensor_arg_names = []
        for name, value in bound_args.arguments.items():
            arg_dict[name] = value
            arg_names.append(name)
            if is_backend_tensor_or_symbolic(value):
                tensor_args.append(value)
                tensor_arg_names.append(name)
                tensor_arg_dict[name] = value
            elif tree.is_nested(value) and len(value) > 0:
                flat_values = tree.flatten(value)
                if all(
                    is_backend_tensor_or_symbolic(x, allow_none=True)
                    for x in flat_values
                ):
                    tensor_args.append(value)
                    tensor_arg_names.append(name)
                    tensor_arg_dict[name] = value
                    nested_tensor_arg_names.append(name)
                elif any(is_backend_tensor_or_symbolic(x) for x in flat_values):
                    raise ValueError(
                        "In a nested call() argument, "
                        "you cannot mix tensors and non-tensors. "
                        "Received invalid mixed argument: "
                        f"{name}={value}"
                    )
        self.arguments_dict = arg_dict
        self.argument_names = arg_names
        self.tensor_arguments_dict = tensor_arg_dict
        self.tensor_arguments_names = tensor_arg_names
        self.nested_tensor_argument_names = nested_tensor_arg_names
>       self.first_arg = arg_dict[arg_names[0]]
E       IndexError: list index out of range

/opt/fw/tensorflow/keras/src/layers/layer.py:1608: IndexError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.transform.Similarity
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_transform.py::test_upscale_double[tensorflow-s2s-False] - TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
FAILED kornia/geometry/test_transform.py::test_Shear[tensorflow-s2s-False] - NameError: Exception encountered when calling tensorflow_Shear.call().
FAILED kornia/geometry/test_transform.py::test_Rescale[tensorflow-s2s-False] - AssertionError: numpy array values are not all close
FAILED kornia/geometry/test_transform.py::test_Homography[tensorflow-s2s-False] - IndexError: list index out of range
FAILED kornia/geometry/test_transform.py::test_Similarity[tensorflow-s2s-False] - IndexError: list index out of range
============================================================================== 5 failed, 51 passed in 5491.71s (1:31:31) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_linalg.py ........                                                                                                                                                          [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 276.27s (0:04:36) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/augmentation/test_augmentation2.py sssssssssssssssss                                                                                                                                      [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================= 17 skipped in 4.98s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_feature3.py .........F...                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
________________________________________________________________________________ test_ScaleSpaceDetector[jax-s2s-False] ________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_ScaleSpaceDetector(target_framework, mode, backend_compile):
        print("kornia.feature.ScaleSpaceDetector")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledScaleSpaceDetector = ivy.transpile(kornia.feature.ScaleSpaceDetector, source="torch", target=target_framework)
    
        x = torch.rand(1, 1, 32, 32) * 10.
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.ScaleSpaceDetector()
        torch_out = model(x)
    
        transpiled_model = TranspiledScaleSpaceDetector()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_allclose(torch_out, transpiled_out)

kornia/test_feature3.py:206: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = (tensor([[[[10.7536,  0.0000, 21.1468],
          [ 0.0000, 10.7536, 11.0011]],

         [[30.4626,  0.0000,  9.9816]...00, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]))
transpiled_x = (Array([[[[10.753628 ,  0.       , 21.146759 ],
         [ 0.       , 10.753628 , 11.001112 ]],

        [[10.717737 ,...   , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],      dtype=float32))
tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = (array([[[[10.753628 ,  0.       , 21.146759 ],
         [ 0.       , 10.753628 , 11.001112 ]],

        [[30.462578 ,...        ,  0.        ,
         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],
      dtype=float32))
y = (array([[[[10.753628 ,  0.       , 21.146759 ],
         [ 0.       , 10.753628 , 11.001112 ]],

        [[10.717737 ,...  , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32))
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
            assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
            return
    
        if isinstance(x, (list, set, tuple)):
>           all([
                _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
            ])

helpers.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <zip object at 0x7f5ce09aae00>

    all([
>       _check_allclose(element_x, element_y, tolerance=tolerance) for element_x, element_y in zip(x, y)
    ])

helpers.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[[10.753628 ,  0.       , 21.146759 ],
         [ 0.       , 10.753628 , 11.001112 ]],

        [[30.462578 , ...68 ]],

        [[54.300278 ,  0.       ,  7.994562 ],
         [ 0.       , 54.300278 , 14.0001135]]]], dtype=float32)
y = array([[[[10.753628 ,  0.       , 21.146759 ],
         [ 0.       , 10.753628 , 11.001112 ]],

        [[10.717737 , ...35 ]],

        [[15.030199 ,  0.       ,  5.9807644],
         [ 0.       , 15.030199 , 26.005377 ]]]], dtype=float32)
tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.ScaleSpaceDetector
All parameters and buffers are now synced!
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature3.py::test_ScaleSpaceDetector[jax-s2s-False] - AssertionError: numpy array values are not all close
============================================================================== 1 failed, 12 passed in 1883.85s (0:31:23) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 2 items

kornia/test_io.py ..                                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 2 passed in 119.62s (0:01:59) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 6 items

kornia/geometry/test_depth.py ......                                                                                                                                                             [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 6 passed in 351.02s (0:05:51) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 18 items

kornia/augmentation/test_augmentation1.py .......F..........                                                                                                                                     [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_RandomClahe[jax-s2s-False] ____________________________________________________________________________________

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
>           return jax.numpy.stack(arrays, axis=axis)

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = [], axis = 3, out = None, dtype = None

    def stack(arrays: np.ndarray | Array | Sequence[ArrayLike],
              axis: int = 0, out: None = None, dtype: DTypeLike | None = None) -> Array:
      """Join arrays along a new axis.
    
      JAX implementation of :func:`numpy.stack`.
    
      Args:
        arrays: a sequence of arrays to stack; each must have the same shape. If a
          single array is given it will be treated equivalently to
          `arrays = unstack(arrays)`, but the implementation will avoid explicit
          unstacking.
        axis: specify the axis along which to stack.
        out: unused by JAX
        dtype: optional dtype of the resulting array. If not specified, the dtype
          will be determined via type promotion rules described in :ref:`type-promotion`.
    
      Returns:
        the stacked result.
    
      See also:
        - :func:`jax.numpy.unstack`: inverse of ``stack``.
        - :func:`jax.numpy.concatenate`: concatenation along existing axes.
        - :func:`jax.numpy.vstack`: stack vertically, i.e. along axis 0.
        - :func:`jax.numpy.hstack`: stack horizontally, i.e. along axis 1.
        - :func:`jax.numpy.dstack`: stack depth-wise, i.e. along axis 2.
        - :func:`jax.numpy.column_stack`: stack columns.
    
      Examples:
        >>> x = jnp.array([1, 2, 3])
        >>> y = jnp.array([4, 5, 6])
        >>> jnp.stack([x, y])
        Array([[1, 2, 3],
               [4, 5, 6]], dtype=int32)
        >>> jnp.stack([x, y], axis=1)
        Array([[1, 4],
               [2, 5],
               [3, 6]], dtype=int32)
    
        :func:`~jax.numpy.unstack` performs the inverse operation:
    
        >>> arr = jnp.stack([x, y], axis=1)
        >>> x, y = jnp.unstack(arr, axis=1)
        >>> x
        Array([1, 2, 3], dtype=int32)
        >>> y
        Array([4, 5, 6], dtype=int32)
      """
      if not len(arrays):
>       raise ValueError("Need at least one array to stack.")
E       ValueError: Need at least one array to stack.

/opt/fw/jax/jax/_src/numpy/lax_numpy.py:4094: ValueError

The above exception was the direct cause of the following exception:

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_RandomClahe(target_framework, mode, backend_compile):
        print("kornia.augmentation.RandomClahe")
    
        init_args = ()
        init_kwargs = {}
        call_args = (torch.rand(2, 3, 10, 20),)
        call_kwargs = {}
    
>       _test_augmentation_class(
            kornia.augmentation.RandomClahe,
            target_framework,
            init_args,
            init_kwargs,
            call_args,
            call_kwargs,
            deterministic_output=False,
            backend_compile=backend_compile,
        )

kornia/augmentation/test_augmentation1.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

augmentation_cls = <class 'kornia.augmentation._2d.intensity.clahe.RandomClahe'>, target = 'jax', init_args = (), init_kwargs = {}
call_args = (tensor([[[[5.4114e-01, 5.6931e-01, 2.8334e-01,  ..., 6.7394e-01,
           5.4312e-01, 9.2741e-01],
          [6.373... 2.2334e-01],
          [1.6995e-01, 3.6473e-01, 6.6461e-01,  ..., 5.9787e-01,
           9.7770e-01, 3.3522e-01]]]]),)
call_kwargs = {}, deterministic_output = False, backend_compile = False, tolerance = 0.001

    def _test_augmentation_class(
        augmentation_cls,
        target,
        init_args=(),
        init_kwargs={},
        call_args=(),
        call_kwargs={},
        deterministic_output=True,
        backend_compile=False,
        tolerance=1e-3,
    ):
        if backend_compile or target == "numpy":
            pytest.skip()
    
        transpiled_cls = ivy.transpile(augmentation_cls, source="torch", target=target)
    
        torch_aug = augmentation_cls(*init_args, **init_kwargs)
        transpiled_init_args = _nest_torch_tensor_to_new_framework(init_args, target)
        transpiled_init_kwargs = _nest_torch_tensor_to_new_framework(init_kwargs, target)
        transpiled_aug = transpiled_cls(*transpiled_init_args, **transpiled_init_kwargs)
    
        # assert dir(torch_aug) == dir(transpiled_aug), f"attributes/methods of transpiled object do not align with the original - orig: {dir(torch_aug)} != transpiled: {dir(transpiled_aug)}"
    
        torch_out = torch_aug(*call_args, **call_kwargs)
        transpiled_call_args = _nest_torch_tensor_to_new_framework(call_args, target)
        transpiled_call_kwargs = _nest_torch_tensor_to_new_framework(call_kwargs, target)
>       transpiled_out = transpiled_aug(*transpiled_call_args, **transpiled_call_kwargs)

kornia/augmentation/test_augmentation1.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[5.41142941e-01, 5.69306314e-01, 2.83343077e-01, ...,
          6.73937678e-01, 5.43117046e-01, 9.27407920e-0... 3.64726424e-01, 6.64606094e-01, ...,
          5.97872496e-01, 9.77700055e-01, 3.35221052e-01]]]],      dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}, kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fcf14791990>, jax_set_item = <function jax_set_item at 0x7fcf34537250>, tensor = <function jax_tensor_frnt at 0x7fcf143b0af0>
in_tensor = Array([[[[5.41142941e-01, 5.69306314e-01, 2.83343077e-01, ...,
          6.73937678e-01, 5.43117046e-01, 9.27407920e-0... 3.64726424e-01, 6.64606094e-01, ...,
          5.97872496e-01, 9.77700055e-01, 3.35221052e-01]]]],      dtype=float32)
input_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), batch_shape = ivy.frontends.torch.Size([2, 3, 10, 20]), flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def __call__(self, input, params=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.backends.jax.general import jax_set_item
        from ..core._backend import tensor
    
        in_tensor = self.__unpack_input__(input)
        input_shape = jax_shape_frnt_(in_tensor)
        in_tensor = self.transform_tensor(in_tensor)
        batch_shape = jax_shape_frnt_(in_tensor)
        if params is None:
            params = self.forward_parameters(batch_shape)
        if "batch_prob" not in params:
            params = jax_set_item(params, "batch_prob", tensor([True] * batch_shape[0]))
        params, flags = self._process_kwargs_to_params_and_flags(
            params, self.flags, **kwargs
        )
>       output = self.apply_func(in_tensor, params, flags)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
in_tensor = Array([[[[5.41142941e-01, 5.69306314e-01, 2.83343077e-01, ...,
          6.73937678e-01, 5.43117046e-01, 9.27407920e-0... 3.64726424e-01, 6.64606094e-01, ...,
          5.97872496e-01, 9.77700055e-01, 3.35221052e-01]]]],      dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}

    def apply_func(self, in_tensor, params, flags=None):
        if flags is None:
            flags = self.flags
        trans_matrix = self.generate_transformation_matrix(in_tensor, params, flags)
>       output = self.transform_inputs(in_tensor, params, flags, trans_matrix)

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/base.py:123: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[5.41142941e-01, 5.69306314e-01, 2.83343077e-01, ...,
          6.73937678e-01, 5.43117046e-01, 9.27407920e-0... 3.64726424e-01, 6.64606094e-01, ...,
          5.97872496e-01, 9.77700055e-01, 3.35221052e-01]]]],      dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}
transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]],

       [[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32), kwargs = {}
jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fcf14791990>, jax_all_frnt_ = <function jax_all_frnt_ at 0x7fcf14792f80>, jax_any_frnt_ = <function jax_any_frnt_ at 0x7fcf445b5f30>
jax_get_item = <function jax_get_item at 0x7fcf345370a0>, jax_is_autocast_enabled = <function jax_is_autocast_enabled at 0x7fcf3450d870>, jax_type_frnt_ = <function jax_type_frnt_ at 0x7fcf445b6440>
jax_index_put_frnt_ = <function jax_index_put_frnt_ at 0x7fcf445b6ef0>

    def transform_inputs(self, input, params, flags, transform=None, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_all_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_any_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ..utils.helpers import jax_is_autocast_enabled
        from ...ivy.functional.frontends.torch.tensor import jax_type_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_index_put_frnt_
        from .utils.helpers import jax__transform_output_shape
    
        params, flags = self._process_kwargs_to_params_and_flags(
            self._params if params is None else params, flags, **kwargs
        )
        batch_prob = params["batch_prob"]
        to_apply = batch_prob > 0.5
        ori_shape = jax_shape_frnt_(input)
        in_tensor = self.transform_tensor(input)
        self.validate_tensor(in_tensor)
        if jax_all_frnt_(to_apply):
            output = self.apply_transform(in_tensor, params, flags, transform=transform)
        elif not jax_any_frnt_(to_apply):
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
        else:
            output = self.apply_non_transform(
                in_tensor, params, flags, transform=transform
            )
>           applied = self.apply_transform(
                jax_get_item(in_tensor, to_apply),
                params,
                flags,
                transform=transform
                if transform is None
                else jax_get_item(transform, to_apply),
            )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/base.py:342: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_RandomClahe(clip_limit_factor=(40.0, 40.0), p=0.5, p_batch=1.0, same_on_batch=False, grid_size=(8, 8), slow_and_differentiable=False)
input = Array([[[[5.13854682e-01, 9.15671408e-01, 2.50701308e-01,
          5.32836020e-01, 7.36931503e-01, 3.75533104e-03,
  ...
          5.92378914e-01, 7.73343444e-01, 5.97872496e-01,
          9.77700055e-01, 3.35221052e-01]]]], dtype=float32)
params = {'batch_prob': Array([0., 1.], dtype=float32), 'clip_limit_factor': Array([40.], dtype=float32), 'forward_input_shape': Array([ 2,  3, 10, 20], dtype=int64)}
flags = {'grid_size': (8, 8), 'slow_and_differentiable': False}, transform = Array([[[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]]], dtype=float32)

    def apply_transform(self, input, params, flags, transform=None):
        from ....enhance.equalization import jax_equalize_clahe
    
        clip_limit = float(params["clip_limit_factor"][0])
>       return jax_equalize_clahe(
            input, clip_limit, flags["grid_size"], flags["slow_and_differentiable"]
        )

ivy_transpiled_outputs/jax_outputs/kornia/augmentation/_2d/intensity/clahe.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[5.13854682e-01, 9.15671408e-01, 2.50701308e-01,
          5.32836020e-01, 7.36931503e-01, 3.75533104e-03,
  ...
          5.92378914e-01, 7.73343444e-01, 5.97872496e-01,
          9.77700055e-01, 3.35221052e-01]]]], dtype=float32)
args = (40.0, (8, 8), False), kwargs = {}, jax_numel_frnt_ = <function jax_numel_frnt_ at 0x7fcf147931c0>, jax_shape_frnt_ = <function jax_shape_frnt_ at 0x7fcf14791990>
jax_view_frnt_ = <function jax_view_frnt_ at 0x7fcf440ddd80>, input_shape = ivy.frontends.torch.Size([1, 3, 10, 20])

    @wraps(f)
    def _wrapper(input, *args, **kwargs):
        from ...ivy.functional.frontends.torch.tensor import jax_numel_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_view_frnt_
    
        if not isinstance(input, (jax.Array, nnx.Param)):
            raise TypeError(f"Input input type is not a Tensor. Got {type(input)}")
        if jax_numel_frnt_(input) == 0:
            raise ValueError("Invalid input tensor, it is empty.")
        input_shape = jax_shape_frnt_(input)
        input = jax__to_bchw(input)
>       output = f(input, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/kornia/utils/image.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = Array([[[[5.13854682e-01, 9.15671408e-01, 2.50701308e-01,
          5.32836020e-01, 7.36931503e-01, 3.75533104e-03,
  ...
          5.92378914e-01, 7.73343444e-01, 5.97872496e-01,
          9.77700055e-01, 3.35221052e-01]]]], dtype=float32)
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    @jax_perform_keep_shape_image
    def jax_equalize_clahe(
        input, clip_limit=40.0, grid_size=(8, 8), slow_and_differentiable=False
    ):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_reshape_as_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_permute_frnt_
        from ...ivy.functional.backends.jax.general import jax_get_item
        from ...ivy.functional.frontends.torch.tensor import jax_dim_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
    
        if not isinstance(clip_limit, (float,)):
            raise TypeError(f"Input clip_limit type is not float. Got {type(clip_limit)}")
        if not isinstance(grid_size, (tuple,)):
            raise TypeError(f"Input grid_size type is not Tuple. Got {type(grid_size)}")
        if len(grid_size) != 2:
            raise TypeError(
                f"Input grid_size is not a Tuple with 2 elements. Got {len(grid_size)}"
            )
        if isinstance(grid_size[0], (float,)) or isinstance(grid_size[1], (float,)):
            raise TypeError("Input grid_size type is not valid, must be a Tuple[int, int].")
        if grid_size[0] <= 0 or grid_size[1] <= 0:
            raise ValueError(f"Input grid_size elements must be positive. Got {grid_size}")
        imgs: typing.Any = input
>       hist_tiles, img_padded = jax__compute_tiles(imgs, grid_size, True)

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:485: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imgs = Array([[[[5.13854682e-01, 9.15671408e-01, 2.50701308e-01,
          5.32836020e-01, 7.36931503e-01, 3.75533104e-03,
  ...
          5.92378914e-01, 7.73343444e-01, 5.97872496e-01,
          9.77700055e-01, 3.35221052e-01]]]], dtype=float32)
grid_size = (8, 8), even_tile_size = True

    def jax__compute_tiles(imgs, grid_size, even_tile_size=False):
        from ...ivy.functional.frontends.torch.tensor import jax_shape_frnt_
        from ...ivy.functional.frontends.torch.nn.functional.vision_functions import (
            jax_pad_frnt,
        )
        from ...ivy.functional.frontends.torch.tensor import jax_contiguous_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_squeeze_frnt_
        from ...ivy.functional.frontends.torch.tensor import jax_unfold_frnt_
    
        batch: typing.Any = imgs
        h, w = jax_shape_frnt_(batch)[-2:][0], jax_shape_frnt_(batch)[-2:][1]
        kernel_vert: typing.Any = math.ceil(h / grid_size[0])
        kernel_horz: typing.Any = math.ceil(w / grid_size[1])
        if even_tile_size:
            kernel_vert = kernel_vert + (1 if kernel_vert % 2 else 0)
            kernel_horz = kernel_horz + (1 if kernel_horz % 2 else 0)
        pad_vert = kernel_vert * grid_size[0] - h
        pad_horz = kernel_horz * grid_size[1] - w
        if pad_vert > jax_shape_frnt_(batch)[-2] or pad_horz > jax_shape_frnt_(batch)[-1]:
            raise ValueError(
                "Cannot compute tiles on the image according to the given grid size"
            )
        if pad_vert > 0 or pad_horz > 0:
            batch = jax_pad_frnt(batch, [0, pad_horz, 0, pad_vert], mode="reflect")
        c: typing.Any = jax_shape_frnt_(batch)[-3]
        tiles: typing.Any = jax_contiguous_frnt_(
            jax_squeeze_frnt_(
>               jax_unfold_frnt_(
                    jax_unfold_frnt_(
                        jax_unfold_frnt_(batch, 1, c, c), 2, kernel_vert, kernel_vert
                    ),
                    3,
                    kernel_horz,
                    kernel_horz,
                ),
                1,
            )
        )

ivy_transpiled_outputs/jax_outputs/kornia/enhance/equalization.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (Array([[[[[[0.5138547 , 0.9156714 , 0.2507013 , ..., 0.21882379,
            0.2590803 , 0.60137063],
           [0.4...0.63972133, 0.27957296, 0.7627582 , ..., 0.9551832 ,
            0.1024828 , 0.8420493 ]]]]]], dtype=float32), 3, 4, 4)
kwargs = {}, jax_is_array_bknd = <function jax_is_array_bknd at 0x7fcf143eb370>
array_like = Array([[[[[[0.5138547 , 0.9156714 , 0.2507013 , ..., 0.21882379,
            0.2590803 , 0.60137063],
           [0.46...         [0.63972133, 0.27957296, 0.7627582 , ..., 0.9551832 ,
            0.1024828 , 0.8420493 ]]]]]], dtype=float32)

    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        from ..functional.ivy.general import jax_is_array_bknd
    
        array_like = args[0]
        if hasattr(array_like, "__class__") and array_like.__class__.__name__ in [
            "list",
            "tuple",
        ]:
            array_like = array_like[0]
        if jax_is_array_bknd(array_like):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = Array([[[[[[0.5138547 , 0.9156714 , 0.2507013 , ..., 0.21882379,
            0.2590803 , 0.60137063],
           [0.46...         [0.63972133, 0.27957296, 0.7627582 , ..., 0.9551832 ,
            0.1024828 , 0.8420493 ]]]]]], dtype=float32)
dimension = 3, size = 4, step = 4

    @jax_handle_methods
    def jax_unfold_frnt_(tensor, dimension, size, step):
        from ...backends.jax.general import jax_get_item
        from ...backends.jax.general import jax_set_item
        from .indexing_slicing_joining_mutating_ops import jax_stack_frnt
    
        slices = []
        self_shape = tuple(jax_shape_frnt_(tensor))
        for i in range(0, jax_get_item(self_shape, dimension) - size + 1, step):
            slicing = [slice(None)] * len(jax_shape_frnt_(tensor))
            slicing = jax_set_item(slicing, dimension, slice(i, i + size))
            slices.append(jax_get_item(tensor, tuple(slicing)))
>       stacked = jax_stack_frnt(slices, dim=dimension)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/tensor.py:648: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [], dim = 3

    def jax_stack_frnt(tensors, dim=0, *, out=None):
        from ...backends.jax.manipulation import jax_stack
    
>       return jax_stack(tensors, axis=dim, out=out)

ivy_transpiled_outputs/jax_outputs/ivy/functional/frontends/torch/indexing_slicing_joining_mutating_ops.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arrays = []

    def jax_stack(
        arrays: Union[Tuple[jax.Array], List[jax.Array]],
        /,
        *,
        axis: int = 0,
        out: Optional[jax.Array] = None,
    ):
        try:
            return jax.numpy.stack(arrays, axis=axis)
        except ValueError as error:
>           raise Exception(error) from error
E           Exception: Need at least one array to stack.

ivy_transpiled_outputs/jax_outputs/ivy/functional/backends/jax/manipulation.py:149: Exception
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.augmentation.RandomClahe
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/augmentation/test_augmentation1.py::test_RandomClahe[jax-s2s-False] - Exception: Need at least one array to stack.
============================================================================== 1 failed, 17 passed in 3433.87s (0:57:13) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 17 items

kornia/test_feature2.py ...........ssssss                                                                                                                                                        [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 11 passed, 6 skipped in 597.57s (0:09:57) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 10 items

kornia/test_feature5.py .......FF.                                                                                                                                                               [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________________ test_DeDoDe[jax-s2s-False] ______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DeDoDe(target_framework, mode, backend_compile):
        print("kornia.feature.DeDoDe")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDeDoDe = ivy.transpile(kornia.feature.DeDoDe, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DeDoDe(amp_dtype=torch.float32)
        torch_out = model(x)
    
        ivy.set_backend(target_framework)
>       transpiled_model = TranspiledDeDoDe(amp_dtype=ivy.as_native_dtype("float32"))

kornia/test_feature5.py:182: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, args = (), kwargs = {'amp_dtype': dtype('float32')}, node = jax_DeDoDe()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.dedode.jax_DeDoDe'>, self = jax_DeDoDe(), args = (), kwargs = {'amp_dtype': dtype('float32')}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_DeDoDe(), detector_model = 'L', descriptor_model = 'G', amp_dtype = dtype('float32')

    def __init__(self, detector_model="L", descriptor_model="G", amp_dtype=jnp.float16):
        from .dedode_models import jax_get_detector
        from .dedode_models import jax_get_descriptor
        from ...enhance.normalize import jax_Normalize
        from ....ivy.functional.frontends.torch.creation_ops import jax_tensor_frnt
    
        self.super___init__(
            detector_model=detector_model,
            descriptor_model=descriptor_model,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.detector: typing.Any = jax_get_detector(detector_model, amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kind = 'L', amp_dtype = dtype('float32')

    def jax_get_detector(kind="L", amp_dtype=jnp.float16):
        if kind == "L":
>           return jax_dedode_detector_L(amp_dtype)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

amp_dtype = dtype('float32')

    def jax_dedode_detector_L(amp_dtype=jnp.float16):
        from ....torch.nn.modules.container import jax_ModuleDict
        from .decoder import jax_ConvRefiner
        from .encoder import jax_VGG19
        from .decoder import jax_Decoder
        from .detector import jax_DeDoDeDetector
    
        NUM_PROTOTYPES = 1
        residual = True
        hidden_blocks = 8
        amp = True
        conv_refiner = jax_ModuleDict(
            {
>               "8": jax_ConvRefiner(
                    512,
                    512,
                    256 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "4": jax_ConvRefiner(
                    256 + 256,
                    256,
                    128 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "2": jax_ConvRefiner(
                    128 + 128,
                    128,
                    64 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
                "1": jax_ConvRefiner(
                    64 + 64,
                    64,
                    1 + NUM_PROTOTYPES,
                    hidden_blocks=hidden_blocks,
                    residual=residual,
                    amp=amp,
                    amp_dtype=amp_dtype,
                ),
            }
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/dedode_models.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}, node = jax_ConvRefiner()

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.kornia.feature.dedode.decoder.jax_ConvRefiner'>, self = jax_ConvRefiner(), args = (512, 512, 257)
kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), args = (512, 512, 257), kwargs = {'amp': True, 'amp_dtype': dtype('float32'), 'hidden_blocks': 8, 'residual': True}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/jax_outputs/ivy/utils/decorator_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, hidden_dim = 512, out_dim = 257, dw = True, kernel_size = 5, hidden_blocks = 8, amp = True, residual = True, amp_dtype = dtype('float32')

    @jax_store_config_info
    def __init__(
        self,
        in_dim=6,
        hidden_dim=16,
        out_dim=2,
        dw=True,
        kernel_size=5,
        hidden_blocks=5,
        amp=True,
        residual=False,
        amp_dtype=jnp.float16,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....jax__stateful_layers import FlaxConv
    
        self.super___init__(
            in_dim=in_dim,
            hidden_dim=hidden_dim,
            out_dim=out_dim,
            dw=dw,
            kernel_size=kernel_size,
            hidden_blocks=hidden_blocks,
            amp=amp,
            residual=residual,
            amp_dtype=amp_dtype,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
>       self.block1 = self.create_block(in_dim, hidden_dim, dw=False, kernel_size=1)

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = jax_ConvRefiner(), in_dim = 512, out_dim = 512, dw = False, kernel_size = 1, bias = True, norm_type = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>

    def create_block(
        self,
        in_dim,
        out_dim,
        dw=True,
        kernel_size=5,
        bias=True,
        norm_type=FlaxBatchNorm,
    ):
        from ....torch.nn.modules.container import jax_Sequential
        from ....torch.nn.modules.activation import jax_ReLU
        from ....jax__stateful_layers import FlaxConv
        from ....jax__stateful_layers import FlaxBatchNorm
    
        num_groups = 1 if not dw else in_dim
        if dw:
            if out_dim % in_dim != 0:
                raise Exception("outdim must be divisible by indim for depthwise")
        conv1 = FlaxConv(
            in_features=in_dim,
            out_features=out_dim,
            kernel_size=kernel_size,
            strides=1,
            padding=kernel_size // 2,
            padding_mode="zeros",
            use_bias=bias,
            feature_group_count=num_groups,
            input_dilation=1,
            kernel_dilation=1,
        )
        norm = (
>           norm_type(out_dim)
            if norm_type is FlaxBatchNorm
            else norm_type(num_channels=out_dim)
        )

ivy_transpiled_outputs/jax_outputs/kornia/feature/dedode/decoder.py:268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
>     return _graph_node_meta_call(cls, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>, args = (512,), kwargs = {}
node = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7f8b1a332440>

    def _graph_node_meta_call(cls: tp.Type[G], *args, **kwargs) -> G:
      node = cls.__new__(cls, *args, **kwargs)
      vars(node)['_object__state'] = ObjectState()
>     cls._object_meta_construct(node, *args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:88: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'ivy_transpiled_outputs.jax_outputs.jax__stateful_layers.FlaxBatchNorm'>
self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7f8b1a332440>, args = (512,), kwargs = {}

    def _object_meta_construct(cls, self, *args, **kwargs):
>     self.__init__(*args, **kwargs)

/opt/fw/jax/flax/nnx/nnx/object.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlaxBatchNorm' object has no attribute 'num_features'") raised in repr()] FlaxBatchNorm object at 0x7f8b1a332440>, args = (512,), kwargs = {}

    def __init__(self, *args, **kwargs):
        self._previous_frame_info = None
        self._built = False
    
        # Map PyTorch-style parameters to Flax parameters
        self.num_batches_tracked = jnp.array(0)
        self.track_running_stats = kwargs.pop("track_running_stats", True)
    
>       num_features = kwargs.pop("num_features")
E       KeyError: 'num_features'

ivy_transpiled_outputs/jax_outputs/jax__stateful_layers.py:428: KeyError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DeDoDe
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth

  0%|          | 0.00/1.13G [00:00<?, ?B/s]
  2%|         | 21.0M/1.13G [00:00<00:05, 220MB/s]
  4%|         | 43.9M/1.13G [00:00<00:05, 232MB/s]
  6%|         | 72.2M/1.13G [00:00<00:04, 262MB/s]
  8%|         | 97.2M/1.13G [00:00<00:06, 179MB/s]
 11%|         | 125M/1.13G [00:00<00:05, 210MB/s] 
 14%|        | 159M/1.13G [00:00<00:04, 251MB/s]
 17%|        | 192M/1.13G [00:00<00:03, 278MB/s]
 19%|        | 220M/1.13G [00:00<00:03, 282MB/s]
 22%|       | 250M/1.13G [00:01<00:03, 289MB/s]
 24%|       | 278M/1.13G [00:01<00:03, 283MB/s]
 26%|       | 306M/1.13G [00:01<00:03, 241MB/s]
 29%|       | 332M/1.13G [00:01<00:03, 250MB/s]
 31%|       | 360M/1.13G [00:01<00:03, 260MB/s]
 33%|      | 388M/1.13G [00:01<00:03, 268MB/s]
 36%|      | 416M/1.13G [00:01<00:02, 276MB/s]
 39%|      | 449M/1.13G [00:01<00:02, 298MB/s]
 42%|     | 485M/1.13G [00:01<00:02, 321MB/s]
 44%|     | 516M/1.13G [00:02<00:02, 255MB/s]
 47%|     | 543M/1.13G [00:02<00:02, 262MB/s]
 49%|     | 570M/1.13G [00:02<00:02, 249MB/s]
 52%|    | 600M/1.13G [00:02<00:02, 266MB/s]
 54%|    | 627M/1.13G [00:02<00:02, 195MB/s]
 56%|    | 648M/1.13G [00:02<00:03, 175MB/s]
 58%|    | 676M/1.13G [00:02<00:02, 199MB/s]
 60%|    | 698M/1.13G [00:03<00:02, 170MB/s]
 62%|   | 724M/1.13G [00:03<00:02, 191MB/s]
 64%|   | 747M/1.13G [00:03<00:02, 203MB/s]
 66%|   | 771M/1.13G [00:03<00:01, 216MB/s]
 69%|   | 800M/1.13G [00:03<00:01, 239MB/s]
 72%|  | 834M/1.13G [00:03<00:01, 271MB/s]
 74%|  | 863M/1.13G [00:03<00:01, 279MB/s]
 77%|  | 898M/1.13G [00:03<00:00, 304MB/s]
 80%|  | 931M/1.13G [00:03<00:00, 315MB/s]
 83%| | 965M/1.13G [00:04<00:00, 327MB/s]
 86%| | 996M/1.13G [00:04<00:00, 319MB/s]
 89%| | 1.01G/1.13G [00:04<00:00, 330MB/s]
 91%|| 1.04G/1.13G [00:04<00:00, 326MB/s]
 94%|| 1.07G/1.13G [00:04<00:00, 314MB/s]
 97%|| 1.10G/1.13G [00:04<00:00, 326MB/s]
100%|| 1.13G/1.13G [00:04<00:00, 334MB/s]
100%|| 1.13G/1.13G [00:04<00:00, 262MB/s]
_______________________________________________________________________________________ test_DISK[jax-s2s-False] _______________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_DISK(target_framework, mode, backend_compile):
        print("kornia.feature.DISK")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledDISK = ivy.transpile(kornia.feature.DISK, source="torch", target=target_framework)
    
        x = torch.rand(1, 3, 256, 256)
        transpiled_x = _nest_torch_tensor_to_new_framework(x, target_framework)
    
        model = kornia.feature.DISK()
        torch_out = model(x)
    
        transpiled_model = TranspiledDISK()
        if target_framework == "tensorflow":
            # build the layers
            transpiled_model(transpiled_x)
    
        ivy.sync_models(model, transpiled_model)
    
        transpiled_out = transpiled_model(transpiled_x)
    
>       _to_numpy_and_shape_allclose(torch_out.keypoints, transpiled_out.keypoints)
E       AttributeError: 'list' object has no attribute 'keypoints'

kornia/test_feature5.py:217: AttributeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.feature.DISK
All parameters and buffers are now synced!
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
/ivy/ivy-integration-tests/ivy_transpiled_outputs/jax_outputs/torch/nn/modules/instancenorm.py:129: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False
  warnings.warn(
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_feature5.py::test_DeDoDe[jax-s2s-False] - KeyError: 'num_features'
FAILED kornia/test_feature5.py::test_DISK[jax-s2s-False] - AttributeError: 'list' object has no attribute 'keypoints'
=============================================================================== 2 failed, 8 passed in 1811.10s (0:30:11) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 4 items

kornia/geometry/test_liegroup.py ssss                                                                                                                                                            [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
========================================================================================== 4 skipped in 5.06s ==========================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 44 items

kornia/test_filters.py ...........................sssssssssssssssss                                                                                                                              [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================= 27 passed, 17 skipped in 1736.79s (0:28:56) ==============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 13 items

kornia/test_metrics.py ...F.........                                                                                                                                                             [100%]

=============================================================================================== FAILURES ===============================================================================================
______________________________________________________________________________ test_mean_average_precision[jax-s2s-False] ______________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_mean_average_precision(target_framework, mode, backend_compile):
        trace_args = (
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            [torch.tensor([0.7])],
            [torch.tensor([[100, 50, 150, 100.]])],
            [torch.tensor([1.])],
            2,
        )
        trace_kwargs = {}
        test_args = (
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            [torch.tensor([0.6, 0.8])],
            [torch.tensor([[50, 25, 75, 50], [100, 50, 150, 100.]])],
            [torch.tensor([1, 2.])],
            3,
        )
        kornia.metrics.mean_average_precision(*trace_args)
        kornia.metrics.mean_average_precision(*test_args)
        test_kwargs = {}
    
        # NOTE: this test fails due to the use of dynamic control flow; skipping
>       _test_function(
            kornia.metrics.mean_average_precision,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
            skip=True,
        )

kornia/test_metrics.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f0dcd314a60>
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s', skip = True, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function mean_average_precision at 0x7f0dcd314a60>, fn_name = 'kornia.metrics.mean_average_precision'
trace_args = ([Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], [Array([0.7], dtype=float32)], [Array([[100.,  50., 150., 100.]], dtype=float32)], [Array([1.], dtype=float32)], 2)
trace_kwargs = {}
test_args = ([Array([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)]...rray([[ 50.,  25.,  75.,  50.],
       [100.,  50., 150., 100.]], dtype=float32)], [Array([1., 2.], dtype=float32)], 3)
test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
>       orig_out = fn(*trace_args, **trace_kwargs)

helpers.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], pred_labels = [Array([1.], dtype=float32)], pred_scores = [Array([0.7], dtype=float32)]
gt_boxes = [Array([[100.,  50., 150., 100.]], dtype=float32)], gt_labels = [Array([1.], dtype=float32)], n_classes = 2, threshold = 0.5

    def mean_average_precision(
        pred_boxes: List[Tensor],
        pred_labels: List[Tensor],
        pred_scores: List[Tensor],
        gt_boxes: List[Tensor],
        gt_labels: List[Tensor],
        n_classes: int,
        threshold: float = 0.5,
    ) -> Tuple[Tensor, Dict[int, float]]:
        """Calculate the Mean Average Precision (mAP) of detected objects.
    
        Code altered from https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L271.
        Background class (0 index) is excluded.
    
        Args:
            pred_boxes: a tensor list of predicted bounding boxes.
            pred_labels: a tensor list of predicted labels.
            pred_scores: a tensor list of predicted labels' scores.
            gt_boxes: a tensor list of ground truth bounding boxes.
            gt_labels: a tensor list of ground truth labels.
            n_classes: the number of classes.
            threshold: count as a positive if the overlap is greater than the threshold.
    
        Returns:
            mean average precision (mAP), list of average precisions for each class.
    
        Examples:
            >>> boxes, labels, scores = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1]), torch.tensor([.7])
            >>> gt_boxes, gt_labels = torch.tensor([[100, 50, 150, 100.]]), torch.tensor([1])
            >>> mean_average_precision([boxes], [labels], [scores], [gt_boxes], [gt_labels], 2)
            (tensor(1.), {1: 1.0})
        """
        # these are all lists of tensors of the same length, i.e. number of images
        if not len(pred_boxes) == len(pred_labels) == len(pred_scores) == len(gt_boxes) == len(gt_labels):
            raise AssertionError
    
        # Store all (true) objects in a single continuous tensor while keeping track of the image it is from
        gt_images = []
        for i, labels in enumerate(gt_labels):
>           gt_images.extend([i] * labels.size(0))
E           TypeError: 'int' object is not callable

/opt/miniconda/envs/multienv/lib/python3.10/site-packages/kornia/metrics/mean_average_precision.py:49: TypeError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.metrics.mean_average_precision.mean_average_precision
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_metrics.py::test_mean_average_precision[jax-s2s-False] - TypeError: 'int' object is not callable
=============================================================================== 1 failed, 12 passed in 757.83s (0:12:37) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 19 items

kornia/geometry/test_camera.py .................ss                                                                                                                                               [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
============================================================================== 17 passed, 2 skipped in 851.53s (0:14:11) ===============================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/geometry/test_bbox.py ..F.....                                                                                                                                                            [100%]

=============================================================================================== FAILURES ===============================================================================================
___________________________________________________________________________________ test_bbox_to_mask[jax-s2s-False] ___________________________________________________________________________________

target_framework = 'jax', mode = 's2s', backend_compile = False

    def test_bbox_to_mask(target_framework, mode, backend_compile):
        trace_args = (
            torch.tensor([[[1., 1.], [3., 1.], [3., 2.], [1., 2.]]]),
            5,
            5,
        )
        trace_kwargs = {}
        test_args = (
            torch.tensor([[[2., 2.], [4., 2.], [4., 3.], [2., 3.]]]),
            6,
            6,
        )
        test_kwargs = {}
>       _test_function(
            kornia.geometry.bbox.bbox_to_mask,
            trace_args,
            trace_kwargs,
            test_args,
            test_kwargs,
            target_framework,
            backend_compile,
            tolerance=1e-3,
            mode=mode,
        )

kornia/geometry/test_bbox.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f9c12029f30>, trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5), trace_kwargs = {}
test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001, mode = 's2s'
skip = False, deterministic = True, class_info = None

    def _test_function(
        fn,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        mode="transpile",
        skip=False,
        deterministic=True,
        class_info=None,
    ):
        # print out the full function module/name, so it will appear in the test_report.json
        print(f"{fn.__module__}.{fn.__name__}")
        fn_name = _get_fn_name_from_stack()
        if skip and mode != "s2s":
            # any skipped due to DCF issues should still work with ivy.source_to_source
            pytest.skip()
    
        if mode == "s2s":
>           _test_source_to_source_function(
                fn,
                fn_name,
                trace_args,
                trace_kwargs,
                test_args,
                test_kwargs,
                target,
                backend_compile,
                tolerance=tolerance,
                deterministic=deterministic,
                class_info=class_info,

helpers.py:376: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <function bbox_to_mask at 0x7f9c12029f30>, fn_name = 'kornia.geometry.bbox.bbox_to_mask', trace_args = (tensor([[[1., 1.],
         [3., 1.],
         [3., 2.],
         [1., 2.]]]), 5, 5)
trace_kwargs = {}, test_args = (tensor([[[2., 2.],
         [4., 2.],
         [4., 3.],
         [2., 3.]]]), 6, 6), test_kwargs = {}, target = 'jax', backend_compile = False, tolerance = 0.001
deterministic = True, class_info = None

    def _test_source_to_source_function(
        fn,
        fn_name,
        trace_args,
        trace_kwargs,
        test_args,
        test_kwargs,
        target,
        backend_compile,
        tolerance=1e-3,
        deterministic=True,
        class_info=None,
    ):
        if backend_compile and target == "numpy":
            pytest.skip()
    
        transpiled_kornia = ivy.transpile(kornia, source="torch", target=target)
        def transpile_and_instantiate(arg, arg_class_info=None):
            if arg_class_info:
                # If we have class info, transpile the class and instantiate it
                transpiled_class = ivy.transpile(arg_class_info['object'], source="torch", target=target)
                args = arg_class_info.get('args', ())
                kwargs = arg_class_info.get('kwargs', {})
                transpiled_args = _nest_torch_tensor_to_new_framework(args, target)
                transpiled_kwargs = _nest_torch_tensor_to_new_framework(kwargs, target)
                return transpiled_class(*transpiled_args, **transpiled_kwargs)
            else:
                # For other arguments, convert to the target framework
                return _nest_torch_tensor_to_new_framework(arg, target)
    
        if fn_name:
            translated_fn = eval("transpiled_" + f"{fn_name}")
        else:
            translated_fn = eval("transpiled_" + f"{fn.__module__}.{fn.__name__}")
    
        if backend_compile:
            try:
                fn = torch.compile(fn)
                fn(*trace_args, **trace_kwargs)
                orig_compilable = True
            except:
                orig_compilable = False
    
            # only test with backend compilation if the original function was compilable in torch
            if orig_compilable:
                translated_fn = _backend_compile(translated_fn, target)
    
        # Transpile and prepare trace arguments
        transpiled_trace_args = [
            transpile_and_instantiate(arg, class_info.get('trace_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(trace_args)
        ]
        transpiled_trace_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('trace_kwargs', {}).get(k) if class_info else None)
            for k, v in trace_kwargs.items()
        }
    
        # Transpile and prepare test arguments
        transpiled_test_args = [
            transpile_and_instantiate(arg, class_info.get('test_args', {}).get(i) if class_info else None)
            for i, arg in enumerate(test_args)
        ]
        transpiled_test_kwargs = {
            k: transpile_and_instantiate(v, class_info.get('test_kwargs', {}).get(k) if class_info else None)
            for k, v in test_kwargs.items()
        }
    
        if target == 'tensorflow':
            # build the model
            graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
        # sync models if needed
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_args, transpiled_trace_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(trace_kwargs.values(), transpiled_trace_kwargs.values()) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_args, transpiled_test_args) if isinstance(m1, torch.nn.Module)]
        [ivy.sync_models(m1, m2) for m1, m2 in zip(test_kwargs.values(), transpiled_test_kwargs.values()) if isinstance(m1, torch.nn.Module)]
    
        # Test with trace_args
        orig_out = fn(*trace_args, **trace_kwargs)
        graph_out = translated_fn(*transpiled_trace_args, **transpiled_trace_kwargs)
    
    
        if deterministic:
>           _to_numpy_and_allclose(orig_out, graph_out, tolerance=tolerance)

helpers.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

torch_x = tensor([[[0., 0., 0., 0., 0.],
         [0., 1., 1., 1., 0.],
         [0., 1., 1., 1., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
transpiled_x = Array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _to_numpy_and_allclose(torch_x, transpiled_x, tolerance=1e-3):
        orig_data = _nest_array_to_numpy(torch_x)
        transpiled_data = _nest_array_to_numpy(transpiled_x)
>       _check_allclose(orig_data, transpiled_data, tolerance=tolerance)

helpers.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[0., 0., 0., 0., 0.],
        [0., 1., 1., 1., 0.],
        [0., 1., 1., 1., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32)
y = array([[[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]]], dtype=float32), tolerance = 0.001

    def _check_allclose(x, y, tolerance=1e-3):
        """
        Checks that all values are close. Any arrays must already be in numpy format, rather than native framework.
        """
    
        if isinstance(x, np.ndarray):
>           assert np.allclose(x, y, atol=tolerance), "numpy array values are not all close"
E           AssertionError: numpy array values are not all close

helpers.py:26: AssertionError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.geometry.bbox.bbox_to_mask
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/geometry/test_bbox.py::test_bbox_to_mask[jax-s2s-False] - AssertionError: numpy array values are not all close
=============================================================================== 1 failed, 7 passed in 485.58s (0:08:05) ================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 8 items

kornia/test_image.py ........                                                                                                                                                                    [100%]

--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
==================================================================================== 8 passed in 364.11s (0:06:04) =====================================================================================

========================================================================================= test session starts ==========================================================================================
platform linux -- Python 3.10.0, pytest-8.3.3, pluggy-1.5.0
rootdir: /ivy/ivy-integration-tests
plugins: anyio-4.6.0, hypothesis-6.98.10, metadata-3.1.1, json-report-1.5.0
collected 1 item

kornia/test_tracking.py F                                                                                                                                                                        [100%]

=============================================================================================== FAILURES ===============================================================================================
_____________________________________________________________________________ test_HomographyTracker[tensorflow-s2s-False] _____________________________________________________________________________

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.6996112 ]],

       [[ 0.50521326]],

       [[ 0.888464  ]],

       [[-0.52466583]],

       [[-0.8952868 ]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
>           inp.__setitem__(query, val)
E           AttributeError: 'ResourceVariable' object has no attribute '__setitem__'. Did you mean: '__getitem__'?

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:233: AttributeError

During handling of the above exception, another exception occurred:

target_framework = 'tensorflow', mode = 's2s', backend_compile = False

    def test_HomographyTracker(target_framework, mode, backend_compile):
        print("kornia.tracking.HomographyTracker")
    
        if backend_compile or target_framework == "numpy":
            pytest.skip()
    
        TranspiledHomographyTracker = ivy.transpile(kornia.tracking.HomographyTracker, source="torch", target=target_framework)
    
        tracker = kornia.tracking.HomographyTracker()
>       transpiled_tracker = TranspiledHomographyTracker()

kornia/test_tracking.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_HomographyTracker(), initial_matcher = None, fast_matcher = None, ransac = None, minimum_inliers_num = 30

    def __init__(
        self,
        initial_matcher=None,
        fast_matcher=None,
        ransac=None,
        minimum_inliers_num=30,
    ):
        from ..feature.integrated import tensorflow_LocalFeatureMatcher
        from ..feature.integrated import tensorflow_GFTTAffNetHardNet
        from ..feature.matching import tensorflow_DescriptorMatcher
        from ..feature.loftr.loftr import tensorflow_LoFTR
        from ..geometry.ransac import tensorflow_RANSAC
    
        self.super___init__(
            initial_matcher=initial_matcher,
            fast_matcher=fast_matcher,
            ransac=ransac,
            minimum_inliers_num=minimum_inliers_num,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.initial_matcher = initial_matcher or tensorflow_LocalFeatureMatcher(
>           tensorflow_GFTTAffNetHardNet(3000),
            tensorflow_DescriptorMatcher("smnn", 0.95),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/tracking/planar_tracker.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f7757d328f0>, args = (3000,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'NoneType' object has no attribute 'items'") raised in repr()] tensorflow_GFTTAffNetHardNet object at 0x7f7757d328f0>, num_features = 3000, upright = False, device = 'cpu'
config = {'nms_size': 15, 'pyramid_levels': 4, 's_mult': 22.0, 'scale_factor_levels': 1.4142135623730951, ...}

    @tensorflow_store_config_info
    def __init__(
        self,
        num_features=8000,
        upright=False,
        device=tensorflow_device_frnt("cpu"),
        config=tensorflow_get_default_detector_config(),
    ):
        from ...ivy.functional.frontends.torch.tensor import tensorflow_to_frnt_
        from .scale_space_detector import tensorflow_MultiResolutionDetector
        from .responses import tensorflow_CornerGFTT
        from .orientation import tensorflow_PassLAF
        from .orientation import tensorflow_LAFOrienter
        from .affine_shape import tensorflow_LAFAffNetShapeEstimator
    
        detector = tensorflow_to_frnt_(
            tensorflow_MultiResolutionDetector(
                tensorflow_CornerGFTT(),
                num_features,
                config,
                ori_module=tensorflow_PassLAF()
                if upright
>               else tensorflow_LAFOrienter(19),
                aff_module=tensorflow_LAFAffNetShapeEstimator(True).eval(),
            ),
            device,
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/integrated.py:352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f7757d31690>, args = (19,), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'tensorflow_LAFOrienter' object has no attribute 'angle_detector'") raised in repr()] tensorflow_LAFOrienter object at 0x7f7757d31690>, patch_size = 19, num_angular_bins = 36
angle_detector = None

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, angle_detector=None):
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            angle_detector=angle_detector,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.angle_detector: typing.Any
        if angle_detector is None:
>           self.angle_detector = tensorflow_PatchDominantGradientOrientation(
                self.patch_size, self.num_ang_bins
            )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:387: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), args = (19, 36), kwargs = {}

    @functools.wraps(fn)
    def wrapper(self, *args, **kwargs):
>       fn(self, *args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:247: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensorflow_PatchDominantGradientOrientation(patch_size=19, num_ang_bins=36, eps=1e-08), patch_size = 19, num_angular_bins = 36, eps = 1e-08

    @tensorflow_store_config_info
    def __init__(self, patch_size=32, num_angular_bins=36, eps=1e-08):
        from ..filters.sobel import tensorflow_SpatialGradient
        from ...torch.nn.modules.conv import tensorflow_Conv1d
        from ...ivy.functional.backends.tensorflow.general import tensorflow_set_item
        from ..filters.kernels import tensorflow_get_gaussian_discrete_kernel1d
        from ..filters.kernels import tensorflow_get_gaussian_kernel2d
    
        self.super___init__(
            patch_size=patch_size,
            num_angular_bins=num_angular_bins,
            eps=eps,
            v=getattr(self, "_v", None),
            buffers=getattr(self, "_buffers", None),
            module_dict=getattr(self, "_module_dict", None),
        )
        self.patch_size = patch_size
        self.num_ang_bins = num_angular_bins
        self.gradient = tensorflow_SpatialGradient("sobel", 1)
        self.eps = eps
        self.angular_smooth = tensorflow_Conv1d(
            1, 1, kernel_size=5, padding=2, bias=False, padding_mode="circular"
        )
>       self.angular_smooth.weight = tensorflow_set_item(
            self.angular_smooth.weight,
            slice(None, None, None),
            tensorflow_get_gaussian_discrete_kernel1d(5, 1.6),
        )

ivy_transpiled_outputs/tensorflow_outputs/kornia/feature/orientation.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inp = <tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.6996112 ]],

       [[ 0.50521326]],

       [[ 0.888464  ]],

       [[-0.52466583]],

       [[-0.8952868 ]]], dtype=float32)>
query = slice(None, None, None), val = <tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>, kwargs = {}

    @functools.wraps(fn)
    def wrapper(inp, query, val, **kwargs):
        try:
            inp.__setitem__(query, val)
            res = inp
        except IndexError:
            raise
        except Exception:
>           res = fn(inp, query, val, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/utils/decorator_utils.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<tf.Variable 'Variable:0' shape=(5, 1, 1) dtype=float32, numpy=
array([[[ 0.6996112 ]],

       [[ 0.50521326]],

   ... 5), dtype=float32, numpy=
array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)>)
kwargs = {}, handle_mixed_in_backend = True

    @functools.wraps(fn)
    def _handle_partial_mixed_function(*args, **kwargs):
        handle_mixed_in_backend = False
        if not hasattr(fn, "partial_mixed_handler"):
            handle_mixed_in_backend = True
        else:
            compos = getattr(fn, "compos")
            condition = getattr(fn, "partial_mixed_handler")
        if handle_mixed_in_backend or condition(*args, **kwargs):
>           return fn(*args, **kwargs)

ivy_transpiled_outputs/tensorflow_outputs/ivy/func_wrapper.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[[ 0.6996112 ]],

       [[ 0.50521326]],

       [[ 0.888464  ]],

       [[-0.52466583]],

       [[-0.8952868 ]]], dtype=float32), query = slice(None, None, None)
val = array([[0.1190625 , 0.2311236 , 0.29962778, 0.2311236 , 0.1190625 ]],
      dtype=float32)

    @tensorflow_handle_set_item
    @tensorflow_handle_partial_mixed_function
    def tensorflow_set_item(
        x: Union[tensorflow.Tensor, tensorflow.Variable],
        query: Union[tensorflow.Tensor, tensorflow.Variable, Tuple],
        val: Union[tensorflow.Tensor, tensorflow.Variable],
        /,
        *,
        copy: Optional[bool] = False,
    ):
        if tensorflow.is_tensor(x):
            x = x.numpy()
        if tensorflow.is_tensor(val):
            val = val.numpy()
        if isinstance(query, (tensorflow.Tensor, tensorflow.Variable)):
            query = query.numpy()
        elif isinstance(query, tuple):
            query = tuple(
                q.numpy() if isinstance(q, (tensorflow.Tensor, tensorflow.Variable)) else q
                for q in query
            )
>       x[query] = val
E       ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)

ivy_transpiled_outputs/tensorflow_outputs/ivy/functional/backends/tensorflow/general.py:109: ValueError
----------------------------------------------------------------------------------------- Captured stdout call -----------------------------------------------------------------------------------------
kornia.tracking.HomographyTracker
----------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------
Downloading: "https://github.com/ducha-aiki/affnet/raw/master/pretrained/AffNet.pth" to /root/.cache/torch/hub/checkpoints/AffNet.pth

  0%|          | 0.00/332k [00:00<?, ?B/s]
100%|| 332k/332k [00:00<00:00, 60.0MB/s]
Downloading: "https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth

  0%|          | 0.00/5.10M [00:00<?, ?B/s]
100%|| 5.10M/5.10M [00:00<00:00, 250MB/s]
Downloading: "http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt" to /root/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt

  0%|          | 0.00/44.2M [00:00<?, ?B/s]
  0%|          | 128k/44.2M [00:00<01:54, 405kB/s]
  1%|          | 256k/44.2M [00:00<01:09, 668kB/s]
  1%|          | 512k/44.2M [00:00<00:37, 1.22MB/s]
  2%|         | 896k/44.2M [00:00<00:22, 1.99MB/s]
  4%|         | 1.75M/44.2M [00:00<00:11, 4.00MB/s]
  8%|         | 3.50M/44.2M [00:00<00:05, 8.00MB/s]
 14%|        | 6.25M/44.2M [00:00<00:02, 13.7MB/s]
 21%|        | 9.25M/44.2M [00:01<00:01, 18.4MB/s]
 27%|       | 12.1M/44.2M [00:01<00:01, 21.4MB/s]
 34%|      | 15.1M/44.2M [00:01<00:01, 23.7MB/s]
 41%|      | 18.1M/44.2M [00:01<00:01, 25.4MB/s]
 48%|     | 21.1M/44.2M [00:01<00:00, 26.5MB/s]
 54%|    | 24.0M/44.2M [00:01<00:00, 27.1MB/s]
 61%|    | 26.9M/44.2M [00:01<00:00, 27.4MB/s]
 68%|   | 29.9M/44.2M [00:01<00:00, 27.9MB/s]
 74%|  | 32.8M/44.2M [00:01<00:00, 28.0MB/s]
 80%|  | 35.5M/44.2M [00:02<00:00, 27.6MB/s]
 87%| | 38.5M/44.2M [00:02<00:00, 28.1MB/s]
 94%|| 41.4M/44.2M [00:02<00:00, 28.2MB/s]
100%|| 44.2M/44.2M [00:02<00:00, 20.4MB/s]
--------------------------------------------------------------------------------------------- JSON report ----------------------------------------------------------------------------------------------
report saved to: test_report.json
======================================================================================= short test summary info ========================================================================================
FAILED kornia/test_tracking.py::test_HomographyTracker[tensorflow-s2s-False] - ValueError: could not broadcast input array from shape (1,5) into shape (5,1,1)
==================================================================================== 1 failed in 470.32s (0:07:50) =====================================================================================

